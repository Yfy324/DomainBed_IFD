
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [6]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 2.5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 2.812885384798702e-06
	weight_decay_d: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 197, in <module>
    rate = args.holdout_fraction
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [6]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 2.5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 2.812885384798702e-06
	weight_decay_d: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 197, in <module>
    rate = args.holdout_fraction
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 2.5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 2.812885384798702e-06
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2708333333  0.2142857143  0.2663690476  0.2619047619  0.2559523810  0.2857142857  0.2574404762  0.2559523810  0.2571428571  0.2464285714  0.2595238095  0.2571428571  0.0000000000  0.1918869019  1.4120990038  0.0563254356  0             0.4866156578 
0.3407738095  0.2857142857  0.3437500000  0.3690476190  0.3526785714  0.3333333333  0.3363095238  0.3035714286  0.2988095238  0.3059523810  0.3547619048  0.3130952381  2.3809523810  0.1325012302  1.3876930022  0.0605759621  50            0.1741738224 
0.4062500000  0.3988095238  0.4226190476  0.4166666667  0.4404761905  0.4107142857  0.4211309524  0.4047619048  0.3738095238  0.3952380952  0.3535714286  0.3547619048  4.7619047619  0.1165394926  1.3493016434  0.0605759621  100           0.1717883062 
0.4613095238  0.4583333333  0.4761904762  0.5416666667  0.4806547619  0.4583333333  0.4791666667  0.5178571429  0.4380952381  0.4285714286  0.4000000000  0.3845238095  7.1428571429  0.1113471317  1.3269336200  0.0629324913  150           0.1694664812 
0.6413690476  0.5714285714  0.6220238095  0.6369047619  0.6502976190  0.6250000000  0.6250000000  0.6309523810  0.5750000000  0.5309523810  0.5178571429  0.4952380952  9.5238095238  0.1069239426  1.2911567521  0.0644330978  200           0.1709639978 
0.6800595238  0.6428571429  0.6755952381  0.6845238095  0.7008928571  0.6547619048  0.6830357143  0.6190476190  0.6071428571  0.5511904762  0.5488095238  0.5345238095  11.904761904  0.1168079519  1.2440904427  0.0644330978  250           0.1736092234 
0.6785714286  0.6130952381  0.6636904762  0.6607142857  0.6770833333  0.6964285714  0.6815476190  0.6904761905  0.5940476190  0.5583333333  0.5476190476  0.5166666667  14.285714285  0.1229030609  1.1937855816  0.0644330978  300           0.1701768112 
0.6443452381  0.6428571429  0.6413690476  0.6666666667  0.6607142857  0.6666666667  0.6622023810  0.6547619048  0.5726190476  0.5714285714  0.5440476190  0.5190476190  16.666666666  0.1385405159  1.1378489757  0.0644330978  350           0.1722076654 
0.6547619048  0.6250000000  0.6532738095  0.6488095238  0.6681547619  0.6309523810  0.6681547619  0.6011904762  0.5285714286  0.5428571429  0.5071428571  0.4785714286  19.047619047  0.1655537057  1.0712618804  0.0644330978  400           0.1749781227 
0.6592261905  0.6488095238  0.6681547619  0.6785714286  0.7008928571  0.7202380952  0.7083333333  0.6785714286  0.6000000000  0.5964285714  0.5559523810  0.5404761905  21.428571428  0.1824451566  0.9900306237  0.0644330978  450           0.1715481043 
0.6815476190  0.6726190476  0.6696428571  0.6488095238  0.7068452381  0.7202380952  0.7321428571  0.6904761905  0.6000000000  0.6238095238  0.5666666667  0.5964285714  23.809523809  0.1762900519  0.9407609046  0.0644330978  500           0.1724819899 
0.7172619048  0.6666666667  0.7261904762  0.7500000000  0.7261904762  0.7559523810  0.7366071429  0.7023809524  0.6523809524  0.5952380952  0.5869047619  0.5595238095  26.190476190  0.2065275836  0.8910252714  0.0644330978  550           0.1733944321 
0.7455357143  0.7261904762  0.7544642857  0.7380952381  0.7767857143  0.7559523810  0.7559523810  0.7738095238  0.6440476190  0.6345238095  0.5904761905  0.5880952381  28.571428571  0.2195232058  0.8381416345  0.0644330978  600           0.1710979509 
0.7232142857  0.6785714286  0.7306547619  0.7023809524  0.7559523810  0.7023809524  0.7157738095  0.7142857143  0.6023809524  0.5988095238  0.5642857143  0.5630952381  30.952380952  0.2043266916  0.7957518232  0.0644330978  650           0.1685857630 
0.7500000000  0.7261904762  0.7663690476  0.7440476190  0.7812500000  0.7678571429  0.7559523810  0.7261904762  0.6095238095  0.6250000000  0.5821428571  0.5869047619  33.333333333  0.2291036248  0.7804385102  0.0644330978  700           0.1719215155 
0.7782738095  0.7380952381  0.7931547619  0.7738095238  0.7976190476  0.7738095238  0.7723214286  0.7559523810  0.6392857143  0.6333333333  0.6000000000  0.6083333333  35.714285714  0.2551919055  0.7452405190  0.0644330978  750           0.1702137089 
0.7991071429  0.7976190476  0.7991071429  0.7678571429  0.8139880952  0.8333333333  0.8229166667  0.7916666667  0.6690476190  0.6738095238  0.6238095238  0.6428571429  38.095238095  0.2589886165  0.7181588745  0.0644330978  800           0.1710243750 
0.8244047619  0.7738095238  0.7946428571  0.7619047619  0.8288690476  0.8154761905  0.8467261905  0.8035714286  0.6976190476  0.6511904762  0.6261904762  0.6571428571  40.476190476  0.2360938191  0.6910716414  0.0644330978  850           0.1696336079 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 356, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2842261905  0.2440476190  0.2901785714  0.2559523810  0.2589285714  0.2916666667  0.2678571429  0.2738095238  0.2750000000  0.2642857143  0.2678571429  0.2738095238  0.0000000000  0.2157435417  1.4120990038  0.0563254356  0             0.4753150940 
0.4523809524  0.4166666667  0.4419642857  0.4583333333  0.4523809524  0.4285714286  0.4613095238  0.4047619048  0.4130952381  0.3857142857  0.4023809524  0.3845238095  2.3809523810  0.1281514215  1.3642549586  0.0605740547  50            0.1711638784 
0.5937500000  0.5833333333  0.6160714286  0.6071428571  0.6116071429  0.6011904762  0.5922619048  0.5535714286  0.5428571429  0.5000000000  0.5011904762  0.4750000000  4.7619047619  0.1247653055  1.2939976263  0.0622925758  100           0.1714674854 
0.6294642857  0.5773809524  0.5982142857  0.6369047619  0.6309523810  0.6071428571  0.6309523810  0.6309523810  0.5797619048  0.5761904762  0.5071428571  0.5071428571  7.1428571429  0.1275590372  1.2299380803  0.0622925758  150           0.1710207129 
0.6562500000  0.6190476190  0.6592261905  0.5952380952  0.6800595238  0.6428571429  0.6785714286  0.6904761905  0.5666666667  0.5857142857  0.5309523810  0.5416666667  9.5238095238  0.1537420511  1.1273859429  0.0622925758  200           0.1729591322 
0.7410714286  0.7321428571  0.7247023810  0.7083333333  0.7767857143  0.7321428571  0.7901785714  0.7500000000  0.6690476190  0.6523809524  0.5940476190  0.6309523810  11.904761904  0.1938898063  0.9924405670  0.0622925758  250           0.1699706459 
0.7008928571  0.7142857143  0.6860119048  0.6547619048  0.7053571429  0.6666666667  0.7247023810  0.6845238095  0.6000000000  0.6166666667  0.5619047619  0.5619047619  14.285714285  0.2241793919  0.8897947156  0.0622925758  300           0.1706695700 
0.7157738095  0.7083333333  0.7127976190  0.7023809524  0.7291666667  0.7142857143  0.7172619048  0.6964285714  0.6095238095  0.6261904762  0.5750000000  0.5833333333  16.666666666  0.2518395042  0.8014808631  0.0622925758  350           0.1715809536 
0.7976190476  0.7440476190  0.8125000000  0.7797619048  0.8125000000  0.8035714286  0.8318452381  0.7619047619  0.6035714286  0.5904761905  0.5750000000  0.5833333333  19.047619047  0.2512502885  0.7559404874  0.0622925758  400           0.1762188721 
0.8080357143  0.7261904762  0.8050595238  0.7857142857  0.8020833333  0.7500000000  0.8377976190  0.7678571429  0.5916666667  0.5880952381  0.5809523810  0.5773809524  21.428571428  0.2248009515  0.6957429814  0.0624957085  450           0.1728089714 
0.8199404762  0.8095238095  0.8244047619  0.8035714286  0.8482142857  0.8511904762  0.8214285714  0.8095238095  0.6071428571  0.6214285714  0.5928571429  0.5976190476  23.809523809  0.2562603188  0.6706973970  0.0624957085  500           0.1760777998 
0.8065476190  0.8154761905  0.8199404762  0.8214285714  0.8288690476  0.8452380952  0.8065476190  0.8035714286  0.6821428571  0.6119047619  0.6107142857  0.6095238095  26.190476190  0.2278519046  0.6292567325  0.0624957085  550           0.1776352882 
0.8720238095  0.8511904762  0.8869047619  0.8214285714  0.8750000000  0.8392857143  0.8794642857  0.8333333333  0.6083333333  0.5916666667  0.5761904762  0.5619047619  28.571428571  0.2609442675  0.5999664307  0.0624957085  600           0.1739714479 
0.8452380952  0.8392857143  0.8616071429  0.8690476190  0.8482142857  0.8690476190  0.8288690476  0.8095238095  0.5607142857  0.5571428571  0.5440476190  0.5285714286  30.952380952  0.2199440420  0.5623490173  0.0635261536  650           0.1837504196 
0.8690476190  0.9047619048  0.8809523810  0.8452380952  0.8839285714  0.8809523810  0.8824404762  0.8571428571  0.6083333333  0.5988095238  0.5726190476  0.5583333333  33.333333333  0.2690798461  0.5447399950  0.0635261536  700           0.1815577459 
0.8750000000  0.8869047619  0.8809523810  0.8273809524  0.8794642857  0.8690476190  0.8898809524  0.8690476190  0.6833333333  0.6535714286  0.6095238095  0.6119047619  35.714285714  0.2518153632  0.4963226104  0.0635261536  750           0.1763462019 
0.8720238095  0.8928571429  0.8809523810  0.8333333333  0.8839285714  0.8869047619  0.8928571429  0.8750000000  0.6845238095  0.6309523810  0.6083333333  0.6083333333  38.095238095  0.2617245483  0.4703009427  0.0635261536  800           0.1807487249 
0.8809523810  0.8809523810  0.8779761905  0.8392857143  0.8913690476  0.8809523810  0.8943452381  0.8690476190  0.7190476190  0.6654761905  0.6297619048  0.6547619048  40.476190476  0.2362423325  0.4384982747  0.0635261536  850           0.1791400528 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 356, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2842261905  0.2440476190  0.2901785714  0.2559523810  0.2589285714  0.2916666667  0.2678571429  0.2738095238  0.2750000000  0.2642857143  0.2678571429  0.2738095238  0.0000000000  0.2157435417  1.4120990038  0.0563254356  0             0.5252683163 
0.4523809524  0.4166666667  0.4419642857  0.4583333333  0.4523809524  0.4285714286  0.4613095238  0.4047619048  0.4130952381  0.3857142857  0.4023809524  0.3845238095  2.3809523810  0.1281514215  1.3642549586  0.0631022453  50            0.1771523333 
0.5937500000  0.5833333333  0.6160714286  0.6071428571  0.6116071429  0.6011904762  0.5922619048  0.5535714286  0.5428571429  0.5000000000  0.5011904762  0.4750000000  4.7619047619  0.1247653055  1.2939976263  0.0631022453  100           0.1714344597 
0.6294642857  0.5773809524  0.5982142857  0.6369047619  0.6309523810  0.6071428571  0.6309523810  0.6309523810  0.5797619048  0.5761904762  0.5071428571  0.5071428571  7.1428571429  0.1275590372  1.2299380803  0.0631022453  150           0.1741626692 
0.6562500000  0.6190476190  0.6592261905  0.5952380952  0.6800595238  0.6428571429  0.6785714286  0.6904761905  0.5666666667  0.5857142857  0.5309523810  0.5416666667  9.5238095238  0.1537420511  1.1273859429  0.0631022453  200           0.1708204174 
0.7410714286  0.7321428571  0.7247023810  0.7083333333  0.7767857143  0.7321428571  0.7901785714  0.7500000000  0.6690476190  0.6523809524  0.5940476190  0.6309523810  11.904761904  0.1938898063  0.9924405670  0.0631022453  250           0.1677715588 
0.7008928571  0.7142857143  0.6860119048  0.6547619048  0.7053571429  0.6666666667  0.7247023810  0.6845238095  0.6000000000  0.6166666667  0.5619047619  0.5619047619  14.285714285  0.2241793919  0.8897947156  0.0631022453  300           0.1724479008 
0.7157738095  0.7083333333  0.7127976190  0.7023809524  0.7291666667  0.7142857143  0.7172619048  0.6964285714  0.6095238095  0.6261904762  0.5750000000  0.5833333333  16.666666666  0.2518395042  0.8014808631  0.0631022453  350           0.1713515997 
0.7976190476  0.7440476190  0.8125000000  0.7797619048  0.8125000000  0.8035714286  0.8318452381  0.7619047619  0.6035714286  0.5904761905  0.5750000000  0.5833333333  19.047619047  0.2512502885  0.7559404874  0.0631022453  400           0.1707934713 
0.8080357143  0.7261904762  0.8050595238  0.7857142857  0.8020833333  0.7500000000  0.8377976190  0.7678571429  0.5916666667  0.5880952381  0.5809523810  0.5773809524  21.428571428  0.2248009515  0.6957429814  0.0631022453  450           0.1688064957 
0.8199404762  0.8095238095  0.8244047619  0.8035714286  0.8482142857  0.8511904762  0.8214285714  0.8095238095  0.6071428571  0.6214285714  0.5928571429  0.5976190476  23.809523809  0.2562603188  0.6706973970  0.0631022453  500           0.1700791216 
0.8065476190  0.8154761905  0.8199404762  0.8214285714  0.8288690476  0.8452380952  0.8065476190  0.8035714286  0.6821428571  0.6119047619  0.6107142857  0.6095238095  26.190476190  0.2278519046  0.6292567325  0.0631022453  550           0.1724432707 
0.8720238095  0.8511904762  0.8869047619  0.8214285714  0.8750000000  0.8392857143  0.8794642857  0.8333333333  0.6083333333  0.5916666667  0.5761904762  0.5619047619  28.571428571  0.2609442675  0.5999664307  0.0631022453  600           0.1705925274 
0.8452380952  0.8392857143  0.8616071429  0.8690476190  0.8482142857  0.8690476190  0.8288690476  0.8095238095  0.5607142857  0.5571428571  0.5440476190  0.5285714286  30.952380952  0.2199440420  0.5623490173  0.0631022453  650           0.1675836420 
0.8690476190  0.9047619048  0.8809523810  0.8452380952  0.8839285714  0.8809523810  0.8824404762  0.8571428571  0.6083333333  0.5988095238  0.5726190476  0.5583333333  33.333333333  0.2690798461  0.5447399950  0.0631022453  700           0.1686167383 
0.8750000000  0.8869047619  0.8809523810  0.8273809524  0.8794642857  0.8690476190  0.8898809524  0.8690476190  0.6833333333  0.6535714286  0.6095238095  0.6119047619  35.714285714  0.2518153632  0.4963226104  0.0631022453  750           0.1715776587 
0.8720238095  0.8928571429  0.8809523810  0.8333333333  0.8839285714  0.8869047619  0.8928571429  0.8750000000  0.6845238095  0.6309523810  0.6083333333  0.6083333333  38.095238095  0.2617245483  0.4703009427  0.0631022453  800           0.1691460991 
0.8809523810  0.8809523810  0.8779761905  0.8392857143  0.8913690476  0.8809523810  0.8943452381  0.8690476190  0.7190476190  0.6654761905  0.6297619048  0.6547619048  40.476190476  0.2362423325  0.4384982747  0.0631022453  850           0.1698720694 
0.9345238095  0.8928571429  0.9166666667  0.8452380952  0.9285714286  0.8630952381  0.9375000000  0.8571428571  0.5690476190  0.5845238095  0.6071428571  0.5726190476  42.857142857  0.2476559162  0.4057420278  0.0631022453  900           0.1697267771 
0.9017857143  0.8928571429  0.8958333333  0.8392857143  0.8958333333  0.8690476190  0.9181547619  0.8750000000  0.7285714286  0.6535714286  0.6535714286  0.6321428571  45.238095238  0.2487560207  0.3733064055  0.0631022453  950           0.1704383326 
0.9315476190  0.9166666667  0.9375000000  0.8750000000  0.9211309524  0.8928571429  0.9479166667  0.8750000000  0.5535714286  0.5297619048  0.5523809524  0.5035714286  47.619047619  0.2505802619  0.3489207190  0.0631022453  1000          0.1678395081 
0.9032738095  0.9166666667  0.9136904762  0.8690476190  0.8943452381  0.8928571429  0.9062500000  0.8630952381  0.6404761905  0.5869047619  0.5880952381  0.5702380952  50.000000000  0.2257591754  0.3175232357  0.0631022453  1050          0.1752988625 
0.9360119048  0.8928571429  0.9285714286  0.8750000000  0.9226190476  0.8988095238  0.9419642857  0.9107142857  0.6261904762  0.6047619048  0.6035714286  0.5714285714  52.380952381  0.2317249900  0.3011278087  0.0631022453  1100          0.1675180197 
0.9494047619  0.9166666667  0.9419642857  0.8690476190  0.9508928571  0.8750000000  0.9627976190  0.9047619048  0.6238095238  0.5690476190  0.6059523810  0.5607142857  54.761904761  0.2137156487  0.2896805802  0.0636248589  1150          0.1710143232 
0.9702380952  0.9226190476  0.9747023810  0.9107142857  0.9687500000  0.8750000000  0.9553571429  0.8630952381  0.5928571429  0.5380952381  0.5821428571  0.5559523810  57.142857142  0.2002332479  0.2539506996  0.0636248589  1200          0.1739769363 
0.9226190476  0.9166666667  0.9330357143  0.8869047619  0.9300595238  0.9107142857  0.9241071429  0.9047619048  0.6297619048  0.5976190476  0.5940476190  0.5726190476  59.523809523  0.2235851485  0.2363368994  0.0636248589  1250          0.1689014149 
0.9806547619  0.9583333333  0.9851190476  0.9226190476  0.9806547619  0.9285714286  0.9776785714  0.9166666667  0.5642857143  0.5119047619  0.5809523810  0.5321428571  61.904761904  0.2101158869  0.2218936253  0.0636248589  1300          0.1712609434 
0.9851190476  0.9702380952  0.9880952381  0.9345238095  0.9880952381  0.9226190476  0.9791666667  0.8928571429  0.5250000000  0.4821428571  0.5464285714  0.4833333333  64.285714285  0.2040945730  0.1945900443  0.0636248589  1350          0.1696568346 
0.9851190476  0.9583333333  0.9806547619  0.8928571429  0.9806547619  0.9404761905  0.9851190476  0.9226190476  0.6452380952  0.5690476190  0.6309523810  0.6000000000  66.666666666  0.1754795992  0.1822331902  0.0636248589  1400          0.1670127392 
0.9910714286  0.9642857143  0.9910714286  0.9285714286  0.9940476190  0.9583333333  0.9940476190  0.9166666667  0.5559523810  0.4940476190  0.5607142857  0.5059523810  69.047619047  0.1928540629  0.1646220736  0.0636248589  1450          0.1698215103 
0.9940476190  0.9821428571  0.9940476190  0.9285714286  0.9940476190  0.9583333333  0.9985119048  0.9166666667  0.5785714286  0.5083333333  0.5773809524  0.5166666667  71.428571428  0.1624802029  0.1553620785  0.0636248589  1500          0.1709379578 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 356, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 0.2733254999483027
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py:418: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.
  if param.grad is not None:
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.2589285714  0.2559523810  0.2574404762  0.2619047619  0.2633928571  0.2678571429  0.2574404762  0.2619047619  0.2571428571  0.2547619048  0.2547619048  0.2583333333  0.0000000000  4.2432036400  0.1006202698  0             0.4718346596 
0.9092261905  0.8988095238  0.9047619048  0.8690476190  0.9092261905  0.8511904762  0.9002976190  0.8511904762  0.6119047619  0.6142857143  0.6011904762  0.5797619048  2.3809523810  2.0258652270  0.2653427124  50            0.0594382763 
0.9479166667  0.9166666667  0.9166666667  0.8988095238  0.9389880952  0.9166666667  0.9404761905  0.9047619048  0.6095238095  0.5642857143  0.5750000000  0.5750000000  4.7619047619  0.8936968297  0.2653427124  100           0.0606515789 
0.9583333333  0.9107142857  0.9598214286  0.8690476190  0.9747023810  0.8630952381  0.9568452381  0.8809523810  0.6071428571  0.5845238095  0.6154761905  0.6178571429  7.1428571429  0.4612692055  0.2653427124  150           0.0599090004 
0.9866071429  0.9642857143  0.9970238095  0.9583333333  0.9955357143  0.9583333333  1.0000000000  0.9761904762  0.5916666667  0.5702380952  0.5928571429  0.5952380952  9.5238095238  0.2703605396  0.2654218674  200           0.0594239140 
0.9940476190  0.9702380952  0.9970238095  0.9583333333  1.0000000000  0.9642857143  0.9985119048  0.9702380952  0.6107142857  0.5714285714  0.6261904762  0.6202380952  11.904761904  0.1588229213  0.2654218674  250           0.0579032612 
0.9955357143  0.9761904762  1.0000000000  0.9642857143  0.9955357143  0.9761904762  0.9895833333  0.9404761905  0.5785714286  0.5500000000  0.5988095238  0.5964285714  14.285714285  0.1085290696  0.2654218674  300           0.0604734945 
1.0000000000  0.9702380952  1.0000000000  0.9642857143  0.9970238095  0.9821428571  0.9985119048  0.9642857143  0.5904761905  0.5619047619  0.6011904762  0.6011904762  16.666666666  0.0990391382  0.2654218674  350           0.0586759663 
0.9985119048  0.9642857143  1.0000000000  0.9642857143  1.0000000000  0.9880952381  1.0000000000  0.9880952381  0.6011904762  0.5595238095  0.6011904762  0.6000000000  19.047619047  0.0536200449  0.2654218674  400           0.0612223959 
1.0000000000  0.9821428571  1.0000000000  0.9702380952  1.0000000000  0.9821428571  1.0000000000  0.9821428571  0.5916666667  0.5464285714  0.5833333333  0.5892857143  21.428571428  0.0268634618  0.2654218674  450           0.0599685907 
1.0000000000  0.9880952381  1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9821428571  0.6190476190  0.5654761905  0.6214285714  0.6000000000  23.809523809  0.0412444010  0.2654218674  500           0.0602454901 
1.0000000000  0.9702380952  1.0000000000  0.9761904762  1.0000000000  0.9821428571  1.0000000000  0.9880952381  0.6107142857  0.5547619048  0.6047619048  0.5904761905  26.190476190  0.0569110938  0.2654218674  550           0.0594357252 
1.0000000000  0.9880952381  1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9821428571  0.6035714286  0.5619047619  0.5988095238  0.6011904762  28.571428571  0.0159732753  0.2654218674  600           0.0598583317 
1.0000000000  0.9642857143  1.0000000000  0.9821428571  1.0000000000  0.9821428571  1.0000000000  0.9821428571  0.6238095238  0.5738095238  0.6214285714  0.6214285714  30.952380952  0.0142979621  0.2654218674  650           0.0603260088 
1.0000000000  1.0000000000  1.0000000000  0.9821428571  1.0000000000  0.9880952381  1.0000000000  0.9821428571  0.6333333333  0.5690476190  0.6202380952  0.6154761905  33.333333333  0.0149050021  0.2654218674  700           0.0591184759 
0.9985119048  0.9464285714  0.9940476190  0.9345238095  0.9985119048  0.9464285714  1.0000000000  0.9702380952  0.5380952381  0.4880952381  0.5250000000  0.5464285714  35.714285714  0.0155542032  0.2654218674  750           0.0601675749 
1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  0.9642857143  1.0000000000  0.9880952381  0.6083333333  0.5619047619  0.6095238095  0.6011904762  38.095238095  0.0136034464  0.2654218674  800           0.0606226063 
1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  0.9821428571  1.0000000000  0.9940476190  0.5976190476  0.5297619048  0.5916666667  0.5892857143  40.476190476  0.0088127611  0.2654218674  850           0.0596113682 
1.0000000000  0.9880952381  1.0000000000  0.9821428571  1.0000000000  0.9880952381  1.0000000000  0.9880952381  0.6190476190  0.5571428571  0.6226190476  0.6047619048  42.857142857  0.0092698131  0.2654218674  900           0.0591080141 
1.0000000000  0.9880952381  1.0000000000  0.9761904762  1.0000000000  0.9702380952  1.0000000000  0.9880952381  0.5535714286  0.4869047619  0.5464285714  0.5488095238  45.238095238  0.0129018582  0.2654218674  950           0.0598504639 
1.0000000000  0.9940476190  1.0000000000  0.9940476190  1.0000000000  0.9821428571  1.0000000000  0.9880952381  0.5619047619  0.4976190476  0.5583333333  0.5666666667  47.619047619  0.0124842229  0.2654218674  1000          0.0592749166 
1.0000000000  0.9940476190  1.0000000000  0.9880952381  1.0000000000  0.9821428571  1.0000000000  0.9880952381  0.5928571429  0.5261904762  0.5892857143  0.5809523810  50.000000000  0.0037837222  0.2654218674  1050          0.0597208881 
1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9940476190  0.6130952381  0.5523809524  0.5976190476  0.6154761905  52.380952381  0.0162861934  0.2654218674  1100          0.0598894119 
1.0000000000  0.9642857143  1.0000000000  0.9642857143  1.0000000000  0.9761904762  1.0000000000  0.9821428571  0.5964285714  0.5500000000  0.5761904762  0.5928571429  54.761904761  0.0115196308  0.2654218674  1150          0.0592336273 
1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9761904762  0.6488095238  0.5880952381  0.6488095238  0.6464285714  57.142857142  0.0137968042  0.2654218674  1200          0.0584946871 
1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9880952381  0.5976190476  0.5476190476  0.5928571429  0.5940476190  59.523809523  0.0065382842  0.2654218674  1250          0.0586401510 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  0.9880952381  0.5773809524  0.5214285714  0.5547619048  0.5666666667  61.904761904  0.0070041260  0.2654218674  1300          0.0593894005 
1.0000000000  0.9821428571  1.0000000000  0.9821428571  1.0000000000  0.9880952381  1.0000000000  0.9940476190  0.5976190476  0.5428571429  0.5916666667  0.5869047619  64.285714285  0.0098763883  0.2654395103  1350          0.0591761780 
1.0000000000  0.9940476190  1.0000000000  0.9940476190  1.0000000000  0.9821428571  1.0000000000  0.9880952381  0.6238095238  0.5476190476  0.6059523810  0.6154761905  66.666666666  0.0069899249  0.2654395103  1400          0.0600603390 
1.0000000000  0.9940476190  1.0000000000  0.9821428571  1.0000000000  0.9880952381  1.0000000000  0.9821428571  0.5928571429  0.5273809524  0.5821428571  0.5916666667  69.047619047  0.0081706940  0.2654395103  1450          0.0606346560 
1.0000000000  0.9821428571  0.9985119048  0.9940476190  1.0000000000  0.9880952381  0.9955357143  0.9642857143  0.6059523810  0.5440476190  0.5940476190  0.5880952381  71.428571428  0.0214446626  0.2654395103  1500          0.0597909927 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 0.2733254999483027
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.2589285714  0.2559523810  0.2574404762  0.2619047619  0.2633928571  0.2678571429  0.2574404762  0.2619047619  0.2571428571  0.2547619048  0.2547619048  0.2583333333  0.0000000000  4.2432036400  0.1006202698  0             19.016852378 
0.9092261905  0.8988095238  0.9047619048  0.8690476190  0.9092261905  0.8511904762  0.9002976190  0.8511904762  0.6119047619  0.6142857143  0.6011904762  0.5797619048  2.3809523810  2.0258652270  0.2653431892  50            0.1623068142 
0.9479166667  0.9166666667  0.9166666667  0.8988095238  0.9389880952  0.9166666667  0.9404761905  0.9047619048  0.6095238095  0.5642857143  0.5750000000  0.5750000000  4.7619047619  0.8936968297  0.2653608322  100           0.0625206089 
0.9583333333  0.9107142857  0.9598214286  0.8690476190  0.9747023810  0.8630952381  0.9568452381  0.8809523810  0.6071428571  0.5845238095  0.6154761905  0.6178571429  7.1428571429  0.4612692055  0.2653608322  150           0.0661816216 
0.9866071429  0.9642857143  0.9970238095  0.9583333333  0.9955357143  0.9583333333  1.0000000000  0.9761904762  0.5916666667  0.5702380952  0.5928571429  0.5952380952  9.5238095238  0.2703605396  0.2653608322  200           0.0607420635 
0.9940476190  0.9702380952  0.9970238095  0.9583333333  1.0000000000  0.9642857143  0.9985119048  0.9702380952  0.6107142857  0.5714285714  0.6261904762  0.6202380952  11.904761904  0.1588229213  0.2653608322  250           0.0616507339 
0.9955357143  0.9761904762  1.0000000000  0.9642857143  0.9955357143  0.9761904762  0.9895833333  0.9404761905  0.5785714286  0.5500000000  0.5988095238  0.5964285714  14.285714285  0.1085290696  0.2653608322  300           0.0622161770 

trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0005
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.3705357143  0.3392857143  0.3616071429  0.3928571429  0.3720238095  0.4047619048  0.3630952381  0.3750000000  0.3678571429  0.3535714286  0.3476190476  0.3547619048  0.0000000000  0.3039782047  1.4120990038  0.0563254356  0             0.5217587948 
0.5520833333  0.5357142857  0.5372023810  0.5238095238  0.5416666667  0.5833333333  0.6294642857  0.6190476190  0.5845238095  0.5738095238  0.5321428571  0.5750000000  2.3809523810  0.2290730619  1.1084077191  0.0619950294  50            0.1748814344 
0.6726190476  0.7023809524  0.7023809524  0.6904761905  0.7023809524  0.7202380952  0.6875000000  0.7202380952  0.6547619048  0.5785714286  0.5690476190  0.5630952381  4.7619047619  0.2702243519  0.8254117072  0.0619950294  100           0.1708780909 
0.8035714286  0.8035714286  0.7961309524  0.7916666667  0.7857142857  0.7261904762  0.7693452381  0.7916666667  0.5761904762  0.5928571429  0.5607142857  0.5476190476  7.1428571429  0.2687204146  0.6692564106  0.0619950294  150           0.1752673197 
0.9002976190  0.8988095238  0.8690476190  0.8511904762  0.9002976190  0.8511904762  0.8794642857  0.8869047619  0.6595238095  0.6428571429  0.6392857143  0.6523809524  9.5238095238  0.2391327012  0.5851583421  0.0619950294  200           0.1784321547 
0.9077380952  0.9166666667  0.8779761905  0.8511904762  0.9017857143  0.8690476190  0.9077380952  0.8928571429  0.6833333333  0.6297619048  0.6452380952  0.6750000000  11.904761904  0.2545582414  0.4583882779  0.0619950294  250           0.1735206318 
0.9107142857  0.9226190476  0.9479166667  0.9107142857  0.9151785714  0.8333333333  0.8928571429  0.8511904762  0.5059523810  0.5452380952  0.5571428571  0.5380952381  14.285714285  0.2184229201  0.3672462988  0.0619950294  300           0.1736193657 
0.9479166667  0.9285714286  0.9375000000  0.9107142857  0.9449404762  0.9107142857  0.9315476190  0.9166666667  0.5654761905  0.5428571429  0.5809523810  0.5857142857  16.666666666  0.2467117399  0.2771969357  0.0619950294  350           0.1693329906 
0.9776785714  0.9404761905  0.9702380952  0.9285714286  0.9717261905  0.9642857143  0.9702380952  0.9642857143  0.6488095238  0.5654761905  0.6119047619  0.6333333333  19.047619047  0.2197391006  0.1961622289  0.0619950294  400           0.1706089544 
0.9613095238  0.9166666667  0.9508928571  0.9404761905  0.9598214286  0.9583333333  0.9568452381  0.9642857143  0.5940476190  0.5321428571  0.5690476190  0.5940476190  21.428571428  0.1780277902  0.1471817002  0.0619950294  450           0.1776440859 
0.9791666667  0.9642857143  0.9895833333  0.9702380952  0.9821428571  0.9702380952  0.9806547619  0.9880952381  0.6107142857  0.5500000000  0.6035714286  0.6202380952  23.809523809  0.1670900391  0.1174591255  0.0620584488  500           0.1770009184 
0.9895833333  0.9702380952  0.9940476190  0.9702380952  0.9955357143  0.9821428571  0.9955357143  0.9761904762  0.6273809524  0.5595238095  0.6226190476  0.6214285714  26.190476190  0.1153358211  0.0607119795  0.0620584488  550           0.1805955982 

trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0005
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.3705357143  0.3392857143  0.3616071429  0.3928571429  0.3720238095  0.4047619048  0.3630952381  0.3750000000  0.3678571429  0.3535714286  0.3476190476  0.3547619048  0.0000000000  0.3039782047  1.4120990038  0.0563254356  0             0.4529421329 
0.5520833333  0.5357142857  0.5372023810  0.5238095238  0.5416666667  0.5833333333  0.6294642857  0.6190476190  0.5845238095  0.5738095238  0.5321428571  0.5750000000  2.3809523810  0.2290730619  1.1084077191  0.0604138374  50            0.1504658127 
0.6726190476  0.7023809524  0.7023809524  0.6904761905  0.7023809524  0.7202380952  0.6875000000  0.7202380952  0.6547619048  0.5785714286  0.5690476190  0.5630952381  4.7619047619  0.2702243519  0.8254117072  0.0604138374  100           0.1491707087 
0.8035714286  0.8035714286  0.7961309524  0.7916666667  0.7857142857  0.7261904762  0.7693452381  0.7916666667  0.5761904762  0.5928571429  0.5607142857  0.5476190476  7.1428571429  0.2687204146  0.6692564106  0.0604138374  150           0.1463319445 
0.9002976190  0.8988095238  0.8690476190  0.8511904762  0.9002976190  0.8511904762  0.8794642857  0.8869047619  0.6595238095  0.6428571429  0.6392857143  0.6523809524  9.5238095238  0.2391327012  0.5851583421  0.0604138374  200           0.1497657633 
0.9077380952  0.9166666667  0.8779761905  0.8511904762  0.9017857143  0.8690476190  0.9077380952  0.8928571429  0.6833333333  0.6297619048  0.6452380952  0.6750000000  11.904761904  0.2545582414  0.4583882779  0.0604138374  250           0.1522052240 
0.9107142857  0.9226190476  0.9479166667  0.9107142857  0.9151785714  0.8333333333  0.8928571429  0.8511904762  0.5059523810  0.5452380952  0.5571428571  0.5380952381  14.285714285  0.2184229201  0.3672462988  0.0604138374  300           0.1516381979 

trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0005
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.3705357143  0.3392857143  0.3616071429  0.3928571429  0.3720238095  0.4047619048  0.3630952381  0.3750000000  0.3678571429  0.3535714286  0.3476190476  0.3547619048  0.0000000000  0.3039782047  1.4120990038  0.0563254356  0             0.4766128063 
0.5520833333  0.5357142857  0.5372023810  0.5238095238  0.5416666667  0.5833333333  0.6294642857  0.6190476190  0.5845238095  0.5738095238  0.5321428571  0.5750000000  2.3809523810  0.2290730619  1.1084077191  0.0604138374  50            0.1461544752 
0.6726190476  0.7023809524  0.7023809524  0.6904761905  0.7023809524  0.7202380952  0.6875000000  0.7202380952  0.6547619048  0.5785714286  0.5690476190  0.5630952381  4.7619047619  0.2702243519  0.8254117072  0.0604138374  100           0.1558274364 
0.8035714286  0.8035714286  0.7961309524  0.7916666667  0.7857142857  0.7261904762  0.7693452381  0.7916666667  0.5761904762  0.5928571429  0.5607142857  0.5476190476  7.1428571429  0.2687204146  0.6692564106  0.0604138374  150           0.1482749128 
0.9002976190  0.8988095238  0.8690476190  0.8511904762  0.9002976190  0.8511904762  0.8794642857  0.8869047619  0.6595238095  0.6428571429  0.6392857143  0.6523809524  9.5238095238  0.2391327012  0.5851583421  0.0604138374  200           0.1462811184 
0.9077380952  0.9166666667  0.8779761905  0.8511904762  0.9017857143  0.8690476190  0.9077380952  0.8928571429  0.6833333333  0.6297619048  0.6452380952  0.6750000000  11.904761904  0.2545582414  0.4583882779  0.0604138374  250           0.1435246277 
0.9107142857  0.9226190476  0.9479166667  0.9107142857  0.9151785714  0.8333333333  0.8928571429  0.8511904762  0.5059523810  0.5452380952  0.5571428571  0.5380952381  14.285714285  0.2184229201  0.3672462988  0.0604138374  300           0.1492438364 

trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0005
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.3705357143  0.3392857143  0.3616071429  0.3928571429  0.3720238095  0.4047619048  0.3630952381  0.3750000000  0.3678571429  0.3535714286  0.3476190476  0.3547619048  0.0000000000  0.3039782047  1.4120990038  0.0563254356  0             0.4794561863 
0.5520833333  0.5357142857  0.5372023810  0.5238095238  0.5416666667  0.5833333333  0.6294642857  0.6190476190  0.5845238095  0.5738095238  0.5321428571  0.5750000000  2.3809523810  0.2290730619  1.1084077191  0.0604929924  50            0.1691595602 
0.6726190476  0.7023809524  0.7023809524  0.6904761905  0.7023809524  0.7202380952  0.6875000000  0.7202380952  0.6547619048  0.5785714286  0.5690476190  0.5630952381  4.7619047619  0.2702243519  0.8254117072  0.0604929924  100           0.1765991640 
0.8035714286  0.8035714286  0.7961309524  0.7916666667  0.7857142857  0.7261904762  0.7693452381  0.7916666667  0.5761904762  0.5928571429  0.5607142857  0.5476190476  7.1428571429  0.2687204146  0.6692564106  0.0604929924  150           0.1769917822 
0.9002976190  0.8988095238  0.8690476190  0.8511904762  0.9002976190  0.8511904762  0.8794642857  0.8869047619  0.6595238095  0.6428571429  0.6392857143  0.6523809524  9.5238095238  0.2391327012  0.5851583421  0.0633463860  200           0.1752219915 
0.9077380952  0.9166666667  0.8779761905  0.8511904762  0.9017857143  0.8690476190  0.9077380952  0.8928571429  0.6833333333  0.6297619048  0.6452380952  0.6750000000  11.904761904  0.2545582414  0.4583882779  0.0633463860  250           0.1758690500 
0.9107142857  0.9226190476  0.9479166667  0.9107142857  0.9151785714  0.8333333333  0.8928571429  0.8511904762  0.5059523810  0.5452380952  0.5571428571  0.5380952381  14.285714285  0.2184229201  0.3672462988  0.0633463860  300           0.1777517796 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    self.adv_classifier = self.proj(self.hparams['delta'], self.adv_classifier, self.classifier)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1935, in proj
    dist = self.distance(adv_h, h)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1929, in distance
    dist += torch.norm(h1_param - h2_param) ** 2  # use Frobenius norms for matrices
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2961309524  0.2321428571  0.3005952381  0.3273809524  0.2797619048  0.3035714286  0.2827380952  0.2797619048  0.2833333333  0.2761904762  0.2857142857  0.2809523810  0.0000000000  0.1481699944  1.4120990038  0.0563254356  0             0.5140235424 
0.3660714286  0.3333333333  0.3675595238  0.3095238095  0.3735119048  0.3511904762  0.4017857143  0.3750000000  0.3428571429  0.3595238095  0.3273809524  0.3523809524  2.3809523810  0.1249509621  1.3302374172  0.0604305267  50            0.1742171955 
0.6979166667  0.6488095238  0.6875000000  0.6547619048  0.6904761905  0.6666666667  0.6666666667  0.6488095238  0.5761904762  0.5250000000  0.5130952381  0.5047619048  4.7619047619  0.1678362322  1.1923669624  0.0604305267  100           0.1729921341 
0.5922619048  0.5833333333  0.5997023810  0.6011904762  0.5848214286  0.5714285714  0.5967261905  0.6011904762  0.5309523810  0.5250000000  0.5130952381  0.4976190476  7.1428571429  0.2079047298  1.0089550316  0.0604305267  150           0.1723555565 
0.7931547619  0.7976190476  0.7723214286  0.7559523810  0.8005952381  0.7619047619  0.8035714286  0.8095238095  0.6928571429  0.6690476190  0.6404761905  0.6678571429  9.5238095238  0.2534582806  0.8568397725  0.0604314804  200           0.1699368763 
0.8050595238  0.8214285714  0.8184523810  0.8035714286  0.8363095238  0.8214285714  0.8110119048  0.7976190476  0.6952380952  0.6488095238  0.6166666667  0.6511904762  11.904761904  0.2238916564  0.7516537523  0.0604314804  250           0.1738914537 
0.8452380952  0.7916666667  0.8184523810  0.7678571429  0.8273809524  0.8154761905  0.8809523810  0.7797619048  0.6559523810  0.6297619048  0.6154761905  0.6035714286  14.285714285  0.2684456217  0.6663807285  0.0604314804  300           0.1725096130 
0.8913690476  0.8690476190  0.8660714286  0.8035714286  0.8705357143  0.7916666667  0.8898809524  0.7678571429  0.6000000000  0.6107142857  0.6107142857  0.5916666667  16.666666666  0.2319124508  0.6265518963  0.0604314804  350           0.1716719866 
0.9136904762  0.8928571429  0.9122023810  0.8333333333  0.9047619048  0.8452380952  0.8943452381  0.8154761905  0.5642857143  0.5678571429  0.5821428571  0.5547619048  19.047619047  0.2570138848  0.5675873667  0.0604314804  400           0.1703766203 
0.8705357143  0.8690476190  0.8720238095  0.8392857143  0.8571428571  0.8630952381  0.8645833333  0.8750000000  0.6642857143  0.6511904762  0.6202380952  0.6095238095  21.428571428  0.2374787700  0.5089240599  0.0633463860  450           0.1734077168 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1983, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 4
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2946428571  0.2202380952  0.2901785714  0.3154761905  0.2827380952  0.2976190476  0.2738095238  0.2678571429  0.2785714286  0.2726190476  0.2869047619  0.2797619048  0.0000000000  0.2966871262  1.4120990038  0.0563235283  0             0.4936623573 
0.4598214286  0.4404761905  0.4434523810  0.4761904762  0.4508928571  0.4702380952  0.4226190476  0.4226190476  0.4321428571  0.3869047619  0.3988095238  0.3880952381  2.3809523810  0.2612587833  1.3686566830  0.0604314804  50            0.1697341204 
0.3437500000  0.3392857143  0.3720238095  0.3452380952  0.3764880952  0.3690476190  0.3630952381  0.3809523810  0.3547619048  0.3345238095  0.3083333333  0.2952380952  4.7619047619  0.1716240120  1.3416606402  0.0607929230  100           0.1695648479 
0.4151785714  0.3869047619  0.4464285714  0.4285714286  0.4747023810  0.4880952381  0.4657738095  0.4464285714  0.4369047619  0.4428571429  0.4047619048  0.3904761905  7.1428571429  0.1528009892  1.3313370252  0.0607929230  150           0.1713456869 
0.4077380952  0.3928571429  0.3794642857  0.3571428571  0.4375000000  0.4107142857  0.4047619048  0.4523809524  0.4059523810  0.3702380952  0.3571428571  0.3738095238  9.5238095238  0.1271425915  1.3254930592  0.0607929230  200           0.1713608932 
0.5163690476  0.4880952381  0.5342261905  0.4821428571  0.5877976190  0.4940476190  0.5386904762  0.4940476190  0.5226190476  0.5285714286  0.4702380952  0.4488095238  11.904761904  0.1125051975  1.3023075080  0.0607929230  250           0.1711813593 
0.5758928571  0.5476190476  0.5520833333  0.5297619048  0.5892857143  0.6011904762  0.6116071429  0.5476190476  0.5928571429  0.5809523810  0.5071428571  0.5464285714  14.285714285  0.1404349232  1.2529331756  0.0607929230  300           0.1776725006 
0.6205357143  0.6130952381  0.6309523810  0.6309523810  0.6398809524  0.6488095238  0.6354166667  0.6190476190  0.5857142857  0.5702380952  0.5500000000  0.5261904762  16.666666666  0.1645028019  1.2008717847  0.0607929230  350           0.1734058857 
0.5788690476  0.5535714286  0.5892857143  0.5892857143  0.6026785714  0.5952380952  0.6309523810  0.5357142857  0.5571428571  0.5559523810  0.5071428571  0.5023809524  19.047619047  0.1587083626  1.1647524023  0.0607929230  400           0.1678928995 
0.6041666667  0.6369047619  0.5654761905  0.5000000000  0.6056547619  0.6309523810  0.6354166667  0.6190476190  0.6095238095  0.6273809524  0.5440476190  0.5464285714  21.428571428  0.1851836109  1.0955396771  0.0607929230  450           0.1729247093 
0.6086309524  0.5773809524  0.6264880952  0.5416666667  0.6309523810  0.6309523810  0.6473214286  0.5654761905  0.4833333333  0.5488095238  0.5238095238  0.5178571429  23.809523809  0.1992775917  1.0182802582  0.0607929230  500           0.1790165901 
0.6339285714  0.6369047619  0.6160714286  0.6190476190  0.6250000000  0.6666666667  0.6488095238  0.6666666667  0.6690476190  0.6107142857  0.5869047619  0.6000000000  26.190476190  0.2402511644  0.9602494776  0.0607929230  550           0.1739946508 
0.6770833333  0.6547619048  0.6800595238  0.6547619048  0.6934523810  0.6845238095  0.7068452381  0.6666666667  0.5940476190  0.6488095238  0.5666666667  0.5880952381  28.571428571  0.2448523951  0.9080903137  0.0633816719  600           0.1772268343 
0.6741071429  0.6666666667  0.6934523810  0.6785714286  0.6875000000  0.6904761905  0.6741071429  0.6607142857  0.5785714286  0.5773809524  0.5547619048  0.5428571429  30.952380952  0.2183969116  0.8785169005  0.0633816719  650           0.1720632315 
0.6815476190  0.6428571429  0.6830357143  0.6428571429  0.7023809524  0.7023809524  0.7202380952  0.7023809524  0.5904761905  0.6511904762  0.5714285714  0.6035714286  33.333333333  0.2652177906  0.8611452377  0.0633816719  700           0.1838950682 
0.7023809524  0.7261904762  0.7187500000  0.6845238095  0.7321428571  0.7023809524  0.6889880952  0.7083333333  0.6083333333  0.5916666667  0.5559523810  0.5916666667  35.714285714  0.2732723570  0.8462233353  0.0633816719  750           0.1818308973 
0.6860119048  0.7083333333  0.6860119048  0.6785714286  0.7068452381  0.6845238095  0.7038690476  0.7202380952  0.6297619048  0.6583333333  0.5964285714  0.6309523810  38.095238095  0.2788574600  0.8293483448  0.0633816719  800           0.1787082720 
0.7187500000  0.6547619048  0.7068452381  0.6428571429  0.7693452381  0.7261904762  0.7708333333  0.7142857143  0.5488095238  0.5892857143  0.5547619048  0.6071428571  40.476190476  0.2803376150  0.8006985080  0.0633816719  850           0.1719230843 
0.7351190476  0.7321428571  0.7455357143  0.7142857143  0.7589285714  0.7202380952  0.7708333333  0.7619047619  0.6250000000  0.6523809524  0.6011904762  0.6250000000  42.857142857  0.2718498707  0.7854471564  0.0633816719  900           0.1793414640 
0.7351190476  0.7440476190  0.7321428571  0.7380952381  0.7470238095  0.7440476190  0.7366071429  0.7321428571  0.7119047619  0.6309523810  0.6642857143  0.6630952381  45.238095238  0.2578837204  0.7887588060  0.0633816719  950           0.1762560987 
0.8258928571  0.8333333333  0.8273809524  0.8214285714  0.8422619048  0.8392857143  0.8318452381  0.8214285714  0.7273809524  0.6619047619  0.6523809524  0.6595238095  47.619047619  0.2740263081  0.7508993840  0.0633816719  1000          0.1736683941 
0.8065476190  0.8035714286  0.7723214286  0.7559523810  0.7976190476  0.7916666667  0.8095238095  0.8035714286  0.6595238095  0.6511904762  0.6107142857  0.6428571429  50.000000000  0.2781390810  0.7090294003  0.0633816719  1050          0.1776720524 
0.6994047619  0.6964285714  0.6875000000  0.6785714286  0.7053571429  0.6726190476  0.7336309524  0.7380952381  0.5464285714  0.5309523810  0.5297619048  0.5369047619  52.380952381  0.2897816420  0.7112787068  0.0633816719  1100          0.1706017447 
0.7589285714  0.7619047619  0.7693452381  0.7678571429  0.7708333333  0.7619047619  0.7693452381  0.7440476190  0.5857142857  0.5809523810  0.5583333333  0.5547619048  54.761904761  0.2434992409  0.6904702890  0.0633816719  1150          0.1769424200 
0.8616071429  0.8750000000  0.8199404762  0.7976190476  0.8645833333  0.8571428571  0.8988095238  0.8988095238  0.6809523810  0.6369047619  0.6035714286  0.6357142857  57.142857142  0.2760226822  0.6500316238  0.0633816719  1200          0.1725794125 
0.7857142857  0.8035714286  0.8110119048  0.8035714286  0.7842261905  0.8154761905  0.7678571429  0.7500000000  0.5464285714  0.5488095238  0.5309523810  0.5166666667  59.523809523  0.2990993500  0.6466979933  0.0633816719  1250          0.1709758902 
0.9107142857  0.9047619048  0.9002976190  0.8690476190  0.8958333333  0.8630952381  0.9062500000  0.8571428571  0.5916666667  0.5976190476  0.5785714286  0.5678571429  61.904761904  0.2722032261  0.5956753922  0.0633816719  1300          0.1692632771 
0.9330357143  0.9226190476  0.9404761905  0.9047619048  0.9315476190  0.8869047619  0.9047619048  0.8392857143  0.5297619048  0.5357142857  0.5547619048  0.5261904762  64.285714285  0.2964042759  0.5492543679  0.0633816719  1350          0.1704487467 
0.9166666667  0.8988095238  0.9047619048  0.8690476190  0.9151785714  0.8750000000  0.9449404762  0.9047619048  0.6678571429  0.6285714286  0.6273809524  0.6380952381  66.666666666  0.3412168217  0.5003605276  0.0633816719  1400          0.1688914967 
0.9404761905  0.9285714286  0.9449404762  0.9047619048  0.9464285714  0.8750000000  0.9241071429  0.8392857143  0.5261904762  0.5095238095  0.5607142857  0.5202380952  69.047619047  0.3309468222  0.4834151393  0.0633816719  1450          0.1686733007 
0.9389880952  0.9404761905  0.9538690476  0.9107142857  0.9389880952  0.8928571429  0.9345238095  0.8750000000  0.5785714286  0.5345238095  0.5750000000  0.5595238095  71.428571428  0.3160689831  0.4595549101  0.0633816719  1500          0.1752090120 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 10
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 553, in cwru_domain
    Ax, Ay, numA = CWRU(self.dir, domain='A', balance=2).get_files()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 212, in get_files
    data1, lab1 = self.data_load(path1, j, label=int(k))
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 280, in data_load
    x = fl[start:end]
TypeError: slice indices must be integers or None or have an __index__ method
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 10
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.3184523810  0.3035714286  0.2931547619  0.2916666667  0.2886904762  0.3511904762  0.2812500000  0.2916666667  0.2773809524  0.3047619048  0.2976190476  0.2928571429  0.0000000000  1.1858332157  1.4161008596  0.0563254356  0             0.5104122162 
0.2946428571  0.2916666667  0.2961309524  0.2797619048  0.2767857143  0.2738095238  0.2574404762  0.2976190476  0.2880952381  0.2750000000  0.2654761905  0.2583333333  2.3809523810  0.6724737883  1.3907541227  0.0604314804  50            0.1772042227 
0.3214285714  0.3154761905  0.3288690476  0.2797619048  0.3214285714  0.3035714286  0.3750000000  0.3095238095  0.3297619048  0.3035714286  0.2773809524  0.3190476190  4.7619047619  0.4173473358  1.3749773002  0.0605716705  100           0.1726893234 
0.3005952381  0.2619047619  0.2991071429  0.3095238095  0.3020833333  0.3154761905  0.3020833333  0.3273809524  0.2904761905  0.2821428571  0.2642857143  0.2928571429  7.1428571429  0.2499536753  1.3762910843  0.0605716705  150           0.1709361935 
0.3407738095  0.3214285714  0.3482142857  0.3511904762  0.3794642857  0.3273809524  0.3437500000  0.3988095238  0.3428571429  0.3023809524  0.3452380952  0.3535714286  9.5238095238  0.2082740545  1.3749777770  0.0605716705  200           0.1705462217 
0.3050595238  0.2619047619  0.3080357143  0.3154761905  0.2857142857  0.3452380952  0.3229166667  0.3690476190  0.2809523810  0.2440476190  0.2654761905  0.2559523810  11.904761904  0.1977422237  1.3737013054  0.0605716705  250           0.1740708494 
0.3184523810  0.3571428571  0.3139880952  0.3452380952  0.3139880952  0.3452380952  0.3348214286  0.3273809524  0.3107142857  0.2666666667  0.2726190476  0.3023809524  14.285714285  0.1665215731  1.3742460346  0.0605716705  300           0.1715699530 
0.3154761905  0.3214285714  0.2976190476  0.2678571429  0.2916666667  0.3095238095  0.3169642857  0.3392857143  0.3178571429  0.2892857143  0.2761904762  0.2869047619  16.666666666  0.1406780720  1.3763505554  0.0605716705  350           0.1763528442 
0.3303571429  0.3392857143  0.3035714286  0.3095238095  0.2976190476  0.3750000000  0.3214285714  0.3988095238  0.3261904762  0.2809523810  0.2761904762  0.3226190476  19.047619047  0.1484641314  1.3779212546  0.0605716705  400           0.1737453270 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 999, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 1302248, 1302251, 1302257) exited unexpectedly
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 10
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2592592593  0.2268518519  0.2430555556  0.2777777778  0.2650462963  0.2870370370  0.2581018519  0.2546296296  0.2648148148  0.2481481481  0.2462962963  0.2629629630  0.0000000000  1.5713202953  1.4966689348  0.1991610527  0             0.4998071194 
0.2673611111  0.2685185185  0.2303240741  0.2777777778  0.2500000000  0.2685185185  0.2453703704  0.2500000000  0.2222222222  0.2388888889  0.2361111111  0.2388888889  1.8518518519  0.9766727448  1.3884547114  0.2039504051  50            0.1855841780 
0.3946759259  0.3564814815  0.3761574074  0.3935185185  0.3599537037  0.4212962963  0.3310185185  0.3333333333  0.4351851852  0.3944444444  0.4064814815  0.3870370370  3.7037037037  0.6659406424  1.3772404122  0.2039504051  100           0.1736201572 
0.2534722222  0.2731481481  0.2465277778  0.2638888889  0.2581018519  0.2500000000  0.2615740741  0.2731481481  0.2509259259  0.2546296296  0.2287037037  0.2231481481  5.5555555556  0.5124376297  1.3666417241  0.2041316032  150           0.1774559546 
0.2812500000  0.2870370370  0.2974537037  0.3194444444  0.2928240741  0.3379629630  0.2997685185  0.3425925926  0.2731481481  0.2685185185  0.2722222222  0.2787037037  7.4074074074  0.2179557562  1.3726432705  0.2044930458  200           0.1830722761 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1983, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2523148148  0.2268518519  0.2407407407  0.2731481481  0.2615740741  0.2685185185  0.2592592593  0.2731481481  0.2638888889  0.2537037037  0.2546296296  0.2592592593  0.0000000000  0.3203382492  1.4966689348  0.1991610527  0             0.4835305214 
0.4085648148  0.4027777778  0.4004629630  0.3703703704  0.4201388889  0.4074074074  0.4201388889  0.4120370370  0.4212962963  0.3518518519  0.3694444444  0.3398148148  1.8518518519  0.1733049154  1.3402854371  0.2043724060  50            0.1894098949 
0.7025462963  0.7129629630  0.6863425926  0.6296296296  0.7407407407  0.6851851852  0.7662037037  0.7361111111  0.6425925926  0.6287037037  0.5824074074  0.6314814815  3.7037037037  0.1853887224  1.2017933583  0.2043724060  100           0.1805627203 
0.7500000000  0.7453703704  0.7511574074  0.7037037037  0.7673611111  0.7453703704  0.7939814815  0.7314814815  0.6231481481  0.6277777778  0.5907407407  0.6222222222  5.5555555556  0.2274543953  0.9830724216  0.2106890678  150           0.1789529419 
0.7754629630  0.7546296296  0.8009259259  0.7870370370  0.8078703704  0.7870370370  0.8217592593  0.7638888889  0.6379629630  0.6027777778  0.5583333333  0.5611111111  7.4074074074  0.2482627153  0.7903656805  0.2106890678  200           0.1799975777 
0.8344907407  0.8379629630  0.8136574074  0.7824074074  0.8356481481  0.8425925926  0.8449074074  0.7824074074  0.6018518519  0.6296296296  0.5703703704  0.5990740741  9.2592592593  0.2550258756  0.6551187789  0.2106890678  250           0.1789127636 
0.8680555556  0.8287037037  0.8425925926  0.7962962963  0.8796296296  0.8611111111  0.9027777778  0.8657407407  0.7000000000  0.6527777778  0.6027777778  0.6305555556  11.111111111  0.2877405655  0.5530846280  0.2106890678  300           0.1789099646 
0.8819444444  0.8472222222  0.8773148148  0.8611111111  0.8819444444  0.8888888889  0.8877314815  0.8657407407  0.5518518519  0.5962962963  0.5157407407  0.5083333333  12.962962963  0.2566828501  0.4746983916  0.2106890678  350           0.2001976299 
0.9016203704  0.8564814815  0.9016203704  0.8842592593  0.9004629630  0.8981481481  0.8437500000  0.7824074074  0.5101851852  0.5250000000  0.5138888889  0.4814814815  14.814814814  0.2294718647  0.4150511003  0.2106890678  400           0.1925129843 
0.9120370370  0.8796296296  0.8900462963  0.8379629630  0.9166666667  0.8935185185  0.9270833333  0.8796296296  0.6453703704  0.6398148148  0.5851851852  0.5694444444  16.666666666  0.2580761611  0.3596668392  0.2106890678  450           0.1853315735 
0.9699074074  0.9351851852  0.9479166667  0.9120370370  0.9467592593  0.9259259259  0.9629629630  0.9398148148  0.5518518519  0.5907407407  0.5805555556  0.5648148148  18.518518518  0.2837560624  0.2957749256  0.2106890678  500           0.1811319685 
0.9432870370  0.8888888889  0.9155092593  0.8796296296  0.9236111111  0.8935185185  0.9398148148  0.8981481481  0.6000000000  0.6138888889  0.5851851852  0.5601851852  20.370370370  0.2455047330  0.2343415001  0.2106890678  550           0.1958862257 
0.9849537037  0.9675925926  0.9791666667  0.9629629630  0.9641203704  0.9398148148  0.9571759259  0.8981481481  0.4148148148  0.5120370370  0.5250000000  0.4444444444  22.222222222  0.2380275807  0.2196859738  0.2106890678  600           0.1900901461 
0.9664351852  0.9305555556  0.9363425926  0.9074074074  0.9328703704  0.9027777778  0.9305555556  0.8564814815  0.4657407407  0.5259259259  0.5250000000  0.4314814815  24.074074074  0.2293038628  0.1865241231  0.2130155563  650           0.1797121668 
0.9884259259  0.9768518519  0.9953703704  0.9814814815  0.9976851852  0.9907407407  0.9907407407  0.9768518519  0.5194444444  0.5611111111  0.5500000000  0.5425925926  25.925925925  0.1971219897  0.1451921171  0.2130155563  700           0.1820172930 
0.9884259259  0.9814814815  0.9884259259  0.9583333333  0.9988425926  0.9907407407  0.9907407407  0.9768518519  0.5879629630  0.5898148148  0.5657407407  0.5703703704  27.777777777  0.1864574960  0.1190684035  0.2130155563  750           0.1845852375 
0.9942129630  0.9768518519  0.9953703704  0.9907407407  0.9976851852  0.9907407407  0.9942129630  0.9814814815  0.5314814815  0.5546296296  0.5462962963  0.5379629630  29.629629629  0.1833868216  0.1148944201  0.2130155563  800           0.1791224098 
0.9953703704  0.9861111111  0.9988425926  0.9907407407  1.0000000000  0.9953703704  0.9953703704  0.9814814815  0.5305555556  0.5574074074  0.5435185185  0.5296296296  31.481481481  0.1659240399  0.0826743314  0.2130155563  850           0.1819598913 
0.9953703704  0.9907407407  1.0000000000  0.9907407407  1.0000000000  1.0000000000  0.9953703704  0.9768518519  0.5324074074  0.5592592593  0.5398148148  0.5333333333  33.333333333  0.1448682365  0.0743267547  0.2130155563  900           0.1793464327 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1982, in update
    gap = -self.hparams['t_lambda'] * self.loss_gap(minibatches, self, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1950, in loss_gap
    p = model.adv_classifier(model.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 285, in forward
    x = self.layer2(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 886, in _call_impl
    if torch._C._get_tracing_state():
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.2442129630  0.2314814815  0.2430555556  0.2407407407  0.2384259259  0.2546296296  0.2372685185  0.2453703704  0.2222222222  0.2388888889  0.2342592593  0.2351851852  0.0000000000  4.7266674042  0.3691520691  0             0.3793487549 
0.9652777778  0.9259259259  0.9456018519  0.9120370370  0.9421296296  0.9074074074  0.9571759259  0.9444444444  0.5222222222  0.6009259259  0.6138888889  0.5898148148  1.8518518519  2.3012447572  0.9716796875  50            0.0611689520 
0.9583333333  0.9166666667  0.9247685185  0.9120370370  0.9363425926  0.9027777778  0.9537037037  0.9398148148  0.6870370370  0.5740740741  0.6064814815  0.6518518519  3.7037037037  0.6103752169  0.9716796875  100           0.0614505434 
0.9166666667  0.8935185185  0.9166666667  0.9027777778  0.9131944444  0.8935185185  0.8472222222  0.7870370370  0.5444444444  0.5351851852  0.5555555556  0.5120370370  5.5555555556  0.2564120258  0.9716796875  150           0.0615101290 
0.9942129630  0.9907407407  0.9965277778  0.9953703704  1.0000000000  0.9861111111  0.9976851852  0.9953703704  0.5398148148  0.4712962963  0.4944444444  0.5185185185  7.4074074074  0.1507391805  0.9716796875  200           0.0630539799 
0.9976851852  0.9953703704  1.0000000000  0.9953703704  1.0000000000  1.0000000000  0.9988425926  1.0000000000  0.6138888889  0.5722222222  0.5703703704  0.5546296296  9.2592592593  0.0901108670  0.9716796875  250           0.0615717983 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.5351851852  0.4814814815  0.4824074074  0.5138888889  11.111111111  0.0529815551  0.9724578857  300           0.0641085243 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9988425926  1.0000000000  0.5416666667  0.4777777778  0.4925925926  0.5194444444  12.962962963  0.0348578380  0.9724578857  350           0.0609839725 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9861111111  0.5148148148  0.4527777778  0.4574074074  0.5027777778  14.814814814  0.0252695118  0.9724578857  400           0.0631964636 
0.9988425926  1.0000000000  1.0000000000  0.9953703704  1.0000000000  0.9907407407  1.0000000000  0.9953703704  0.4666666667  0.4250000000  0.4648148148  0.4768518519  16.666666666  0.0273417921  0.9724578857  450           0.0626990080 
0.9872685185  0.9768518519  0.9756944444  0.9398148148  0.9895833333  0.9722222222  0.9826388889  0.9444444444  0.4731481481  0.4259259259  0.4685185185  0.4833333333  18.518518518  0.0379864450  0.9724578857  500           0.0621875715 
0.9953703704  1.0000000000  0.9918981481  0.9953703704  1.0000000000  0.9907407407  1.0000000000  1.0000000000  0.4824074074  0.4314814815  0.4861111111  0.5092592593  20.370370370  0.3417965124  0.9724578857  550           0.0641688919 
1.0000000000  1.0000000000  1.0000000000  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5111111111  0.4425925926  0.4953703704  0.5231481481  22.222222222  0.0206185745  0.9724578857  600           0.0634908724 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1368708) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.2280092593  0.2314814815  0.2314814815  0.2268518519  0.2361111111  0.2592592593  0.2476851852  0.2638888889  0.2388888889  0.2268518519  0.2361111111  0.2444444444  0.0000000000  4.7266674042  0.3691520691  0             0.3652930260 
0.3287037037  0.3240740741  0.3043981481  0.3287037037  0.3113425926  0.3379629630  0.2928240741  0.2870370370  0.2750000000  0.2462962963  0.2425925926  0.2712962963  1.8518518519  4.2248901129  0.9714274406  50            0.0624284458 
0.5601851852  0.5370370370  0.5578703704  0.5694444444  0.5706018519  0.5787037037  0.5277777778  0.5370370370  0.4592592593  0.4212962963  0.4231481481  0.4305555556  3.7037037037  3.9995611238  0.9716672897  100           0.0625462532 
0.6481481481  0.6157407407  0.6296296296  0.6296296296  0.6550925926  0.6481481481  0.5844907407  0.5879629630  0.5000000000  0.4592592593  0.4555555556  0.4500000000  5.5555555556  3.7110099602  0.9719071388  150           0.0615016174 
0.6678240741  0.6250000000  0.6782407407  0.6342592593  0.6956018519  0.7175925926  0.6354166667  0.6064814815  0.5444444444  0.4972222222  0.4907407407  0.4805555556  7.4074074074  3.3597910500  0.9719071388  200           0.0620741940 
0.7210648148  0.6944444444  0.7129629630  0.7129629630  0.7314814815  0.7407407407  0.7199074074  0.6527777778  0.5666666667  0.5703703704  0.5259259259  0.5250000000  9.2592592593  2.9797297096  0.9719071388  250           0.0606043053 
0.7569444444  0.7175925926  0.7488425926  0.7083333333  0.7592592593  0.7685185185  0.7349537037  0.6574074074  0.6138888889  0.5601851852  0.5351851852  0.5240740741  11.111111111  2.7050970030  0.9725084305  300           0.0623421764 
0.7731481481  0.7314814815  0.7731481481  0.7314814815  0.7719907407  0.7870370370  0.7476851852  0.6527777778  0.6018518519  0.5675925926  0.5379629630  0.5268518519  12.962962963  2.4547924137  0.9725084305  350           0.0627740860 
0.8159722222  0.7731481481  0.8125000000  0.7685185185  0.8055555556  0.7870370370  0.7743055556  0.6805555556  0.6296296296  0.5722222222  0.5546296296  0.5416666667  14.814814814  2.2708288479  0.9725084305  400           0.0614055872 
0.8356481481  0.7870370370  0.8252314815  0.7500000000  0.8229166667  0.8148148148  0.8263888889  0.7314814815  0.6305555556  0.6129629630  0.5490740741  0.5583333333  16.666666666  2.1705209351  0.9725084305  450           0.0643052387 
0.8564814815  0.8148148148  0.8495370370  0.7824074074  0.8379629630  0.8425925926  0.8379629630  0.7638888889  0.6129629630  0.5879629630  0.5444444444  0.5203703704  18.518518518  2.0041378284  0.9725084305  500           0.0644382477 
0.8761574074  0.8240740741  0.8611111111  0.8055555556  0.8645833333  0.8564814815  0.8611111111  0.7962962963  0.6240740741  0.6166666667  0.5564814815  0.5527777778  20.370370370  1.8671721840  0.9725084305  550           0.0642079163 
0.8831018519  0.8518518519  0.8738425926  0.8055555556  0.8923611111  0.8379629630  0.8935185185  0.8333333333  0.6694444444  0.6407407407  0.5592592593  0.5712962963  22.222222222  1.8003366399  0.9725084305  600           0.0651843119 
0.8993055556  0.8657407407  0.8877314815  0.8333333333  0.8981481481  0.8657407407  0.8923611111  0.8657407407  0.6537037037  0.6305555556  0.5574074074  0.5638888889  24.074074074  1.7315587330  0.9725084305  650           0.0631150866 
0.9027777778  0.8703703704  0.8900462963  0.8379629630  0.9039351852  0.8703703704  0.9016203704  0.8750000000  0.6537037037  0.6462962963  0.5731481481  0.5824074074  25.925925925  1.6522646070  0.9725084305  700           0.0626767778 
0.9004629630  0.8611111111  0.8784722222  0.8101851852  0.8981481481  0.8611111111  0.9050925926  0.8750000000  0.6796296296  0.6629629630  0.5648148148  0.5944444444  27.777777777  1.6365137744  0.9725084305  750           0.0642300653 
0.9085648148  0.8703703704  0.8877314815  0.8333333333  0.9085648148  0.8842592593  0.8993055556  0.8657407407  0.6518518519  0.6407407407  0.5574074074  0.5564814815  29.629629629  1.5335285807  0.9725084305  800           0.0704289579 
0.9120370370  0.8796296296  0.8993055556  0.8657407407  0.9131944444  0.8981481481  0.9027777778  0.8703703704  0.6240740741  0.6351851852  0.5564814815  0.5546296296  31.481481481  1.4276897907  0.9725084305  850           0.0627619791 
0.9085648148  0.8703703704  0.8958333333  0.8657407407  0.9120370370  0.8981481481  0.9062500000  0.8750000000  0.6407407407  0.6500000000  0.5546296296  0.5694444444  33.333333333  1.3453666735  0.9725084305  900           0.0613916349 
0.9143518519  0.8842592593  0.8981481481  0.8703703704  0.9143518519  0.8981481481  0.9050925926  0.8750000000  0.6314814815  0.6416666667  0.5509259259  0.5462962963  35.185185185  1.2394598174  0.9725084305  950           0.0637227201 
0.9224537037  0.8888888889  0.9016203704  0.8750000000  0.9120370370  0.8981481481  0.9166666667  0.8935185185  0.6166666667  0.6425925926  0.5759259259  0.5574074074  37.037037037  1.1870408487  0.9725084305  1000          0.0621181631 
0.9305555556  0.8796296296  0.9074074074  0.8750000000  0.9131944444  0.8981481481  0.9224537037  0.8888888889  0.6037037037  0.6342592593  0.5703703704  0.5425925926  38.888888888  1.1012825930  0.9725084305  1050          0.0637399054 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):

trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	cos_lambda: 0.0001
	data_augmentation: True
	groupdro_eta: 0.01
	iters: 70
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2581018519  0.2592592593  0.2442129630  0.2546296296  0.2384259259  0.2407407407  0.2418981481  0.2407407407  0.2453703704  0.2388888889  0.2388888889  0.2351851852  0.0000000000  0.1991977692  1.4249777794  0             0.3628718853  0.0000000000 
0.4085648148  0.3981481481  0.4571759259  0.4583333333  0.4363425926  0.3888888889  0.3773148148  0.3981481481  0.4083333333  0.4083333333  0.3888888889  0.3805555556  1.8518518519  0.2041659355  1.3779614067  50            0.0171876717  0.0000000000 
0.4027777778  0.3888888889  0.4467592593  0.4675925926  0.3935185185  0.3750000000  0.3668981481  0.3750000000  0.3888888889  0.3444444444  0.3814814815  0.3435185185  3.7037037037  0.2041659355  1.3278126931  100           0.1085606480  0.7261897230 
0.6203703704  0.6203703704  0.6597222222  0.6481481481  0.5868055556  0.5694444444  0.5092592593  0.5092592593  0.5166666667  0.4361111111  0.4953703704  0.4398148148  5.5555555556  0.2041659355  1.2625212646  150           0.1359241867  0.9317325258 
0.6412037037  0.6435185185  0.6724537037  0.6342592593  0.6377314815  0.6388888889  0.5590277778  0.5601851852  0.5750000000  0.4759259259  0.5037037037  0.4759259259  7.4074074074  0.2041854858  1.2203690934  200           0.1442316437  0.8058856440 
0.6574074074  0.6574074074  0.6875000000  0.6759259259  0.6550925926  0.6250000000  0.5694444444  0.5879629630  0.5842592593  0.4675925926  0.5185185185  0.4879629630  9.2592592593  0.2041854858  1.1789822364  250           0.1306459951  0.7245863342 
0.6701388889  0.6851851852  0.7210648148  0.6990740741  0.6840277778  0.6851851852  0.5983796296  0.6018518519  0.5990740741  0.4675925926  0.5148148148  0.4814814815  11.111111111  0.2041854858  1.1411655307  300           0.1325253534  0.6719175816 
0.6851851852  0.6898148148  0.7407407407  0.7129629630  0.6956018519  0.6990740741  0.6076388889  0.5972222222  0.5768518519  0.4601851852  0.5055555556  0.4731481481  12.962962963  0.2041864395  1.0990737820  350           0.1387900066  0.5803698468 
0.7141203704  0.7083333333  0.7372685185  0.7407407407  0.7233796296  0.7361111111  0.6759259259  0.6250000000  0.5768518519  0.4759259259  0.4935185185  0.4712962963  14.814814814  0.2041864395  1.0676648331  400           0.1331685495  0.5296284008 
0.7638888889  0.7268518519  0.7905092593  0.7592592593  0.7743055556  0.7685185185  0.7222222222  0.6898148148  0.6018518519  0.5064814815  0.5074074074  0.4907407407  16.666666666  0.2041864395  1.0326256526  450           0.1264404631  0.4775984204 
0.8356481481  0.7962962963  0.8298611111  0.8009259259  0.8252314815  0.8240740741  0.8136574074  0.7546296296  0.6240740741  0.5601851852  0.5296296296  0.5064814815  18.518518518  0.2041864395  1.0020973897  500           0.1247381067  0.4639354992 
0.8518518519  0.8101851852  0.8460648148  0.8009259259  0.8460648148  0.8379629630  0.8414351852  0.7870370370  0.6185185185  0.5685185185  0.5203703704  0.5064814815  20.370370370  0.2048463821  0.9732356966  550           0.1341869879  0.4297693813 
0.8622685185  0.8287037037  0.8530092593  0.8240740741  0.8564814815  0.8425925926  0.8611111111  0.8148148148  0.6277777778  0.5944444444  0.5324074074  0.5342592593  22.222222222  0.2048463821  0.9493084049  600           0.1350666666  0.4241903663 
0.8750000000  0.8472222222  0.8703703704  0.8425925926  0.8761574074  0.8564814815  0.8703703704  0.8194444444  0.6546296296  0.6203703704  0.5509259259  0.5712962963  24.074074074  0.2147488594  0.9234734821  650           0.1390652180  0.3947301912 
0.8761574074  0.8379629630  0.8703703704  0.8379629630  0.8854166667  0.8611111111  0.8831018519  0.8518518519  0.6777777778  0.6564814815  0.5824074074  0.6157407407  25.925925925  0.2147488594  0.8856016028  700           0.1359996176  0.3668197954 
0.8784722222  0.8425925926  0.8680555556  0.8333333333  0.8923611111  0.8611111111  0.8993055556  0.8611111111  0.6898148148  0.6462962963  0.5703703704  0.5898148148  27.777777777  0.2147488594  0.8651675975  750           0.1353505325  0.3583734000 
0.8807870370  0.8518518519  0.8761574074  0.8472222222  0.8969907407  0.8750000000  0.8993055556  0.8611111111  0.6740740741  0.6592592593  0.5925925926  0.6203703704  29.629629629  0.2147488594  0.8329513204  800           0.1375030947  0.3387756217 
0.8842592593  0.8564814815  0.8773148148  0.8518518519  0.8981481481  0.8657407407  0.9050925926  0.8657407407  0.6925925926  0.6657407407  0.6064814815  0.6277777778  31.481481481  0.2147488594  0.8053535247  850           0.1341542816  0.3289327884 
0.8773148148  0.8425925926  0.8645833333  0.8148148148  0.8865740741  0.8518518519  0.9016203704  0.8657407407  0.7194444444  0.6851851852  0.6148148148  0.6453703704  33.333333333  0.2147488594  0.7949225259  900           0.1319750738  0.3097926188 
0.8796296296  0.8518518519  0.8692129630  0.8240740741  0.8935185185  0.8703703704  0.9027777778  0.8657407407  0.7046296296  0.6777777778  0.6101851852  0.6351851852  35.185185185  0.2147488594  0.7684440506  950           0.1366325235  0.3039568746 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
      File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	cos_lambda: 0.0001
	data_augmentation: True
	groupdro_eta: 0.01
	iters: 70
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2581018519  0.2592592593  0.2442129630  0.2546296296  0.2384259259  0.2407407407  0.2418981481  0.2407407407  0.2453703704  0.0000000000  0.1991977692  1.4249777794  0             0.3928363323  0.0000000000 
0.3634259259  0.3657407407  0.4027777778  0.4444444444  0.3807870370  0.3888888889  0.3379629630  0.3611111111  0.3537037037  1.8518518519  0.2039856911  1.3765889120  50            0.0168962526  0.0000000000 
0.4340277778  0.4120370370  0.4791666667  0.5138888889  0.4293981481  0.4259259259  0.3645833333  0.3796296296  0.3990740741  3.7037037037  0.2039856911  1.3297078490  100           0.0884918928  0.7173420954 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1945106) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	cos_lambda: 0.0001
	data_augmentation: True
	groupdro_eta: 0.01
	iters: 70
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2581018519  0.2592592593  0.2442129630  0.2546296296  0.2384259259  0.2407407407  0.2418981481  0.2407407407  0.2453703704  0.0000000000  0.1991977692  1.4249777794  0             0.3295464516  0.0000000000 
0.3634259259  0.3657407407  0.4027777778  0.4444444444  0.3807870370  0.3888888889  0.3379629630  0.3611111111  0.3537037037  1.8518518519  0.2039847374  1.3765889120  50            0.0167124462  0.0000000000 
0.4340277778  0.4120370370  0.4791666667  0.5138888889  0.4293981481  0.4259259259  0.3645833333  0.3796296296  0.3990740741  3.7037037037  0.2040042877  1.3297078490  100           0.0880309629  0.7173420954 
0.6192129630  0.6157407407  0.6481481481  0.6203703704  0.5868055556  0.5416666667  0.5115740741  0.5231481481  0.5268518519  5.5555555556  0.2040042877  1.2639060879  150           0.1313506985  0.9381830263 
0.6585648148  0.6435185185  0.7164351852  0.7037037037  0.6516203704  0.6435185185  0.5659722222  0.5787037037  0.5472222222  7.4074074074  0.2044916153  1.2074926186  200           0.1322010946  0.7910914421 
0.6956018519  0.6666666667  0.7314814815  0.7175925926  0.6909722222  0.6944444444  0.6157407407  0.6157407407  0.6000000000  9.2592592593  0.2044916153  1.1780904722  250           0.1306616688  0.7569004464 
0.7372685185  0.7037037037  0.7442129630  0.7361111111  0.7106481481  0.7037037037  0.6412037037  0.6342592593  0.6157407407  11.111111111  0.2048463821  1.1288596749  300           0.1305801773  0.6632334447 
0.7743055556  0.7407407407  0.7893518519  0.7824074074  0.7569444444  0.7453703704  0.6967592593  0.6620370370  0.5935185185  12.962962963  0.2048463821  1.0914474821  350           0.1279346275  0.6032957196 
0.8125000000  0.7870370370  0.8159722222  0.7916666667  0.8125000000  0.8101851852  0.7905092593  0.7222222222  0.6388888889  14.814814814  0.2048463821  1.0580511761  400           0.1305024004  0.5326703501 
0.8252314815  0.8101851852  0.8298611111  0.7962962963  0.8333333333  0.8194444444  0.8171296296  0.7546296296  0.6712962963  16.666666666  0.2048463821  1.0208936751  450           0.1310072756  0.4904521048 
0.8483796296  0.8194444444  0.8518518519  0.8194444444  0.8599537037  0.8518518519  0.8460648148  0.8055555556  0.6657407407  18.518518518  0.2048463821  0.9900488043  500           0.1294778633  0.4358813500 
0.8622685185  0.8425925926  0.8657407407  0.8287037037  0.8715277778  0.8472222222  0.8541666667  0.8240740741  0.6805555556  20.370370370  0.2048463821  0.9527123547  550           0.1300064564  0.4162577748 
0.8680555556  0.8518518519  0.8692129630  0.8333333333  0.8877314815  0.8472222222  0.8657407407  0.8518518519  0.6972222222  22.222222222  0.2048463821  0.9280659223  600           0.1332433844  0.4163514924 
0.8784722222  0.8611111111  0.8715277778  0.8333333333  0.8923611111  0.8750000000  0.8912037037  0.8564814815  0.7027777778  24.074074074  0.2048463821  0.9113658440  650           0.1333742714  0.3954801095 
0.8726851852  0.8518518519  0.8553240741  0.8287037037  0.8773148148  0.8611111111  0.8923611111  0.8564814815  0.7259259259  25.925925925  0.2048463821  0.8823959982  700           0.1397665071  0.3509944022 
0.8645833333  0.8194444444  0.8368055556  0.8009259259  0.8611111111  0.8379629630  0.8854166667  0.8564814815  0.7416666667  27.777777777  0.2051463127  0.8639520693  750           0.1370986938  0.3642811584 
0.8668981481  0.8287037037  0.8402777778  0.7962962963  0.8692129630  0.8518518519  0.8958333333  0.8564814815  0.7425925926  29.629629629  0.2053275108  0.8389954913  800           0.1415492392  0.3360592127 
0.8703703704  0.8379629630  0.8518518519  0.8055555556  0.8726851852  0.8564814815  0.8969907407  0.8657407407  0.7333333333  31.481481481  0.2055077553  0.8262311494  850           0.1362057638  0.3312218034 
0.8750000000  0.8472222222  0.8611111111  0.8101851852  0.8796296296  0.8564814815  0.9027777778  0.8657407407  0.7240740741  33.333333333  0.2055077553  0.7911094749  900           0.1299528265  0.3188713014 
0.8726851852  0.8472222222  0.8518518519  0.7962962963  0.8761574074  0.8564814815  0.8993055556  0.8611111111  0.7435185185  35.185185185  0.2058486938  0.7729664493  950           0.1326841974  0.3036609399 
0.8750000000  0.8472222222  0.8611111111  0.8055555556  0.8865740741  0.8564814815  0.9050925926  0.8611111111  0.7259259259  37.037037037  0.2058486938  0.7590542459  1000          0.1284325552  0.2925578320 
0.8750000000  0.8425925926  0.8622685185  0.8055555556  0.8842592593  0.8564814815  0.9050925926  0.8657407407  0.7324074074  38.888888888  0.2058486938  0.7320351243  1050          0.1383595037  0.2618023312 
0.8726851852  0.8472222222  0.8530092593  0.7824074074  0.8726851852  0.8611111111  0.8993055556  0.8611111111  0.7537037037  40.740740740  0.2058486938  0.7271934736  1100          0.1319379091  0.2867278194 
0.8715277778  0.8472222222  0.8506944444  0.7870370370  0.8726851852  0.8564814815  0.8946759259  0.8611111111  0.7592592593  42.592592592  0.2058486938  0.7176689827  1150          0.1303152704  0.2603572929 
0.8750000000  0.8564814815  0.8518518519  0.8009259259  0.8784722222  0.8657407407  0.8958333333  0.8611111111  0.7407407407  44.444444444  0.2058486938  0.7049829650  1200          0.1286406469  0.2582533360 
0.8738425926  0.8564814815  0.8518518519  0.8055555556  0.8761574074  0.8657407407  0.8923611111  0.8611111111  0.7388888889  46.296296296  0.2058486938  0.6770018446  1250          0.1299132824  0.2469100940 
0.8715277778  0.8518518519  0.8472222222  0.7870370370  0.8715277778  0.8564814815  0.8877314815  0.8564814815  0.7472222222  48.148148148  0.2133293152  0.6668308413  1300          0.1297223568  0.2588487160 
0.8657407407  0.8472222222  0.8414351852  0.7777777778  0.8680555556  0.8564814815  0.8796296296  0.8472222222  0.7500000000  50.000000000  0.2155904770  0.6564538193  1350          0.1284490061  0.2444885206 
0.8750000000  0.8518518519  0.8530092593  0.7962962963  0.8796296296  0.8611111111  0.8900462963  0.8564814815  0.7490740741  51.851851851  0.2155904770  0.6428758180  1400          0.1323148012  0.2469244492 
0.8796296296  0.8564814815  0.8726851852  0.8194444444  0.8877314815  0.8703703704  0.8969907407  0.8657407407  0.7064814815  53.703703703  0.2155904770  0.6254381096  1450          0.1319056082  0.2160880935 
0.8819444444  0.8564814815  0.8750000000  0.8379629630  0.8981481481  0.8750000000  0.9016203704  0.8657407407  0.7064814815  55.555555555  0.2155904770  0.6053488982  1500          0.1265407276  0.2128078151 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2442129630  0.2453703704  0.2685185185  0.2638888889  0.2719907407  0.2824074074  0.2731481481  0.2731481481  0.2740740741  0.0000000000  0.0000000000  1.4966689348  0.1991610527  0             0.4727382660 
0.5706018519  0.5601851852  0.5648148148  0.5879629630  0.5868055556  0.6018518519  0.5439814815  0.5324074074  0.5074074074  1.8518518519  0.0000000000  1.3716548753  0.2037692070  50            0.1802654791 
0.7048611111  0.6574074074  0.6689814815  0.6527777778  0.6967592593  0.6666666667  0.6516203704  0.6250000000  0.6074074074  3.7037037037  0.0000000000  1.2247832775  0.2039504051  100           0.1766103792 
0.7210648148  0.6944444444  0.7152777778  0.7129629630  0.7384259259  0.7222222222  0.6851851852  0.6388888889  0.5805555556  5.5555555556  0.0000000000  1.0241348505  0.2041316032  150           0.1761572218 
0.7766203704  0.7222222222  0.7800925926  0.7453703704  0.7800925926  0.7500000000  0.7488425926  0.6898148148  0.6212962963  7.4074074074  0.0000000000  0.8488118780  0.2117710114  200           0.1900754547 
0.8379629630  0.7777777778  0.8009259259  0.7685185185  0.8171296296  0.7638888889  0.8101851852  0.7314814815  0.6611111111  9.2592592593  0.0000000000  0.7463239932  0.2117710114  250           0.1860715008 
0.8587962963  0.8101851852  0.8379629630  0.8101851852  0.8472222222  0.8148148148  0.8472222222  0.7685185185  0.6324074074  11.111111111  0.0000000000  0.6734516144  0.2117710114  300           0.1835472107 
0.8750000000  0.8333333333  0.8622685185  0.8148148148  0.8703703704  0.8194444444  0.8888888889  0.8379629630  0.6740740741  12.962962963  0.0000000000  0.6033626765  0.2117710114  350           0.1886306286 
0.8981481481  0.8518518519  0.8888888889  0.8425925926  0.8969907407  0.8611111111  0.8958333333  0.8564814815  0.6472222222  14.814814814  0.0000000000  0.5652953511  0.2117710114  400           0.1742863226 
0.9039351852  0.8750000000  0.8969907407  0.8472222222  0.9085648148  0.8935185185  0.9027777778  0.8750000000  0.6425925926  16.666666666  0.0000000000  0.5276447529  0.2160348892  450           0.1755953026 
0.9085648148  0.8796296296  0.8993055556  0.8518518519  0.9131944444  0.8935185185  0.9039351852  0.8750000000  0.6296296296  18.518518518  0.0000000000  0.4872421557  0.2160348892  500           0.1763851690 
0.9143518519  0.8796296296  0.9016203704  0.8611111111  0.9143518519  0.8981481481  0.9062500000  0.8750000000  0.6175925926  20.370370370  0.0000000000  0.4394264996  0.2160348892  550           0.1783480358 
0.9120370370  0.8842592593  0.9016203704  0.8657407407  0.9143518519  0.8981481481  0.9074074074  0.8750000000  0.6351851852  22.222222222  0.0000000000  0.3975207001  0.2164692879  600           0.1763694382 
0.9155092593  0.8888888889  0.9120370370  0.8842592593  0.9212962963  0.8981481481  0.9039351852  0.8750000000  0.5990740741  24.074074074  0.0000000000  0.3682134587  0.2164692879  650           0.1831177425 
0.9317129630  0.8842592593  0.9074074074  0.8750000000  0.9143518519  0.8981481481  0.9270833333  0.8888888889  0.5944444444  25.925925925  0.0000000000  0.3215937880  0.2164692879  700           0.1945414639 
0.9583333333  0.9074074074  0.9386574074  0.8981481481  0.9386574074  0.9027777778  0.9479166667  0.9212962963  0.5370370370  27.777777777  0.0000000000  0.2847320175  0.2164692879  750           0.1781520271 
0.9421296296  0.8981481481  0.9224537037  0.8981481481  0.9247685185  0.8981481481  0.9328703704  0.8981481481  0.5453703704  29.629629629  0.0000000000  0.2620757699  0.2164692879  800           0.1882907391 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1990115) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1989362) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2500000000  0.2500000000  0.2696759259  0.2546296296  0.2731481481  0.2824074074  0.2731481481  0.2731481481  0.2740740741  0.0000000000  0.1262532473  1.4966689348  0.1991610527  0             0.5080134869 
0.3692129630  0.3240740741  0.3530092593  0.3981481481  0.3472222222  0.4120370370  0.3553240741  0.3518518519  0.3546296296  1.8518518519  0.0849488783  1.4040605569  0.2037692070  50            0.1756606531 
0.3842592593  0.3425925926  0.3784722222  0.3750000000  0.3807870370  0.4212962963  0.3634259259  0.3796296296  0.3685185185  3.7037037037  0.0868625069  1.3651732659  0.2039494514  100           0.1758780766 
0.4629629630  0.4583333333  0.4780092593  0.4583333333  0.5092592593  0.5833333333  0.5011574074  0.5046296296  0.4916666667  5.5555555556  0.0843735600  1.3240436482  0.2041902542  150           0.1763860083 
0.5740740741  0.5694444444  0.5625000000  0.5740740741  0.6030092593  0.6157407407  0.5636574074  0.5416666667  0.5611111111  7.4074074074  0.0993368125  1.2771289396  0.2041902542  200           0.1762830830 
0.6643518519  0.6805555556  0.6666666667  0.6805555556  0.6967592593  0.6574074074  0.6539351852  0.5925925926  0.5685185185  9.2592592593  0.0992441249  1.2186797333  0.2041902542  250           0.1786474562 
0.6620370370  0.6203703704  0.6782407407  0.6620370370  0.6689814815  0.6851851852  0.6423611111  0.6111111111  0.5824074074  11.111111111  0.1074697709  1.1561535215  0.2043714523  300           0.1773093414 
0.6967592593  0.6805555556  0.6689814815  0.6296296296  0.7048611111  0.7037037037  0.7245370370  0.6805555556  0.6074074074  12.962962963  0.1075507700  1.0780088854  0.2046113014  350           0.1779969501 
0.7141203704  0.6944444444  0.7118055556  0.7037037037  0.7372685185  0.7222222222  0.7303240741  0.7129629630  0.5925925926  14.814814814  0.1220619559  1.0172053444  0.2046113014  400           0.1764326000 
0.7060185185  0.6666666667  0.7083333333  0.6944444444  0.7245370370  0.7222222222  0.7013888889  0.6574074074  0.5833333333  16.666666666  0.1173644066  0.9633119214  0.2046113014  450           0.1768887806 
0.7071759259  0.6851851852  0.7094907407  0.6990740741  0.7326388889  0.7361111111  0.7175925926  0.6759259259  0.5601851852  18.518518518  0.1458294880  0.9012760258  0.2046113014  500           0.1791789722 
0.7164351852  0.6851851852  0.7256944444  0.7222222222  0.7442129630  0.7407407407  0.7222222222  0.6990740741  0.5629629630  20.370370370  0.1498225474  0.8517427003  0.2046113014  550           0.1799755001 
0.7280092593  0.6944444444  0.7361111111  0.7175925926  0.7500000000  0.7453703704  0.7361111111  0.6944444444  0.5564814815  22.222222222  0.1491335177  0.8133384621  0.2046113014  600           0.1778632355 
0.7615740741  0.7268518519  0.7708333333  0.7361111111  0.7719907407  0.7777777778  0.7673611111  0.6990740741  0.5972222222  24.074074074  0.1402638459  0.7812439334  0.2139105797  650           0.1774131632 
0.7638888889  0.7268518519  0.7581018519  0.7129629630  0.7650462963  0.7453703704  0.7835648148  0.7500000000  0.6037037037  25.925925925  0.1589818132  0.7449866545  0.2139105797  700           0.1779288721 
0.7569444444  0.7222222222  0.7685185185  0.7361111111  0.7627314815  0.7500000000  0.7685185185  0.7037037037  0.5935185185  27.777777777  0.1493634200  0.7101511204  0.2139105797  750           0.1785307837 
0.8113425926  0.7500000000  0.8090277778  0.7731481481  0.7986111111  0.7916666667  0.8125000000  0.7175925926  0.6101851852  29.629629629  0.1459845257  0.6965668011  0.2139105797  800           0.1771801853 
0.8159722222  0.7870370370  0.8182870370  0.7777777778  0.8194444444  0.7824074074  0.8148148148  0.7314814815  0.6166666667  31.481481481  0.1640725183  0.6856900084  0.2139105797  850           0.1778627825 
0.8148148148  0.7453703704  0.8159722222  0.7731481481  0.8055555556  0.8009259259  0.8159722222  0.7638888889  0.5907407407  33.333333333  0.1386299896  0.6449433029  0.2139105797  900           0.1768764973 
0.8333333333  0.7777777778  0.8263888889  0.7870370370  0.8263888889  0.8101851852  0.8333333333  0.7500000000  0.6092592593  35.185185185  0.1440426517  0.6291361535  0.2139105797  950           0.1763998461 
0.8715277778  0.8333333333  0.8425925926  0.8148148148  0.8472222222  0.8287037037  0.8460648148  0.7824074074  0.6148148148  37.037037037  0.1518648344  0.6192917323  0.2139105797  1000          0.1755894232 
0.8854166667  0.8657407407  0.8680555556  0.8379629630  0.8761574074  0.8657407407  0.8680555556  0.8055555556  0.6046296296  38.888888888  0.1484500819  0.5899553287  0.2139105797  1050          0.1770568180 
0.8668981481  0.8194444444  0.8356481481  0.7916666667  0.8437500000  0.8518518519  0.8622685185  0.8055555556  0.6064814815  40.740740740  0.1460193169  0.5855395907  0.2139105797  1100          0.1818161440 
0.9016203704  0.8564814815  0.8807870370  0.8425925926  0.8900462963  0.8796296296  0.8923611111  0.8425925926  0.6064814815  42.592592592  0.1443361706  0.5662902784  0.2139105797  1150          0.1778826094 
0.9004629630  0.8611111111  0.8888888889  0.8379629630  0.8958333333  0.8796296296  0.9027777778  0.8518518519  0.6537037037  44.444444444  0.1456514049  0.5468608183  0.2139105797  1200          0.1790780401 
0.9062500000  0.8796296296  0.9016203704  0.8750000000  0.8900462963  0.8842592593  0.8796296296  0.8240740741  0.5805555556  46.296296296  0.1703509527  0.5221102250  0.2139105797  1250          0.1758021736 
0.9131944444  0.8703703704  0.9004629630  0.8472222222  0.9085648148  0.8842592593  0.9143518519  0.8750000000  0.6324074074  48.148148148  0.1615589005  0.5106936306  0.2139105797  1300          0.1806266022 
0.9039351852  0.8703703704  0.8969907407  0.8703703704  0.8993055556  0.8935185185  0.9050925926  0.8518518519  0.6342592593  50.000000000  0.1337495095  0.5051178646  0.2139105797  1350          0.1816756868 
0.8993055556  0.8611111111  0.8750000000  0.7962962963  0.8981481481  0.8611111111  0.9155092593  0.8703703704  0.6824074074  51.851851851  0.1403016257  0.4720168537  0.2139105797  1400          0.1791944075 
0.9027777778  0.8657407407  0.8946759259  0.8564814815  0.8958333333  0.8935185185  0.9120370370  0.8657407407  0.6296296296  53.703703703  0.1334365213  0.4632907122  0.2139105797  1450          0.1767884827 
0.9120370370  0.8842592593  0.9074074074  0.8796296296  0.9155092593  0.8981481481  0.9131944444  0.8796296296  0.5814814815  55.555555555  0.1308603305  0.4474839717  0.2139105797  1500          0.1774141598 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 5
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2453703704  0.2500000000  0.2673611111  0.2638888889  0.2731481481  0.2824074074  0.2731481481  0.2824074074  0.2759259259  0.0000000000  0.6431162357  1.4966689348  0.1991610527  0             0.5024909973 
0.2835648148  0.2731481481  0.2361111111  0.2824074074  0.2476851852  0.3194444444  0.2465277778  0.2361111111  0.2203703704  1.8518518519  0.4538462639  1.4263184190  0.2042489052  50            0.1809322119 
0.3009259259  0.3009259259  0.2673611111  0.3009259259  0.2789351852  0.3194444444  0.2789351852  0.3101851852  0.2537037037  3.7037037037  0.4374027967  1.4128397679  0.2105665207  100           0.1804838371 
0.2569444444  0.2407407407  0.2638888889  0.3101851852  0.2939814815  0.3101851852  0.2719907407  0.2638888889  0.2305555556  5.5555555556  0.4143912196  1.3970529747  0.2105665207  150           0.1792635489 
0.2928240741  0.2685185185  0.2789351852  0.2916666667  0.2951388889  0.3148148148  0.3194444444  0.2731481481  0.2601851852  7.4074074074  0.3970009089  1.3858439183  0.2160348892  200           0.1801381302 
0.3333333333  0.2592592593  0.3101851852  0.3333333333  0.3055555556  0.2824074074  0.3032407407  0.3055555556  0.2750000000  9.2592592593  0.3562154770  1.3778341651  0.2160348892  250           0.1794667149 
0.2905092593  0.2870370370  0.2835648148  0.3240740741  0.3113425926  0.2870370370  0.2743055556  0.3009259259  0.2657407407  11.111111111  0.3474104762  1.3761267662  0.2160348892  300           0.1794180346 
0.3449074074  0.2731481481  0.3182870370  0.3240740741  0.3437500000  0.3379629630  0.3136574074  0.3657407407  0.3203703704  12.962962963  0.2964200735  1.3731980562  0.2160348892  350           0.1788433599 
0.3622685185  0.3194444444  0.3530092593  0.3287037037  0.3587962963  0.3472222222  0.3391203704  0.3703703704  0.3370370370  14.814814814  0.2779659748  1.3724822187  0.2160348892  400           0.1801453018 
0.3078703704  0.3009259259  0.2893518519  0.2777777778  0.3055555556  0.3009259259  0.3113425926  0.3101851852  0.2814814815  16.666666666  0.2414280295  1.3725760245  0.2160348892  450           0.1778339958 
0.2766203704  0.2546296296  0.2384259259  0.2592592593  0.2754629630  0.3101851852  0.2569444444  0.2731481481  0.2231481481  18.518518518  0.2473878503  1.3703549910  0.2164559364  500           0.1775235844 
0.2824074074  0.2777777778  0.2500000000  0.2407407407  0.2858796296  0.2685185185  0.2824074074  0.3055555556  0.2416666667  20.370370370  0.2316351414  1.3689921832  0.2164559364  550           0.1807002831 
0.2777777778  0.2314814815  0.2500000000  0.2638888889  0.2835648148  0.2824074074  0.2858796296  0.3472222222  0.2564814815  22.222222222  0.2136896729  1.3732978106  0.2164559364  600           0.1782737970 
0.2997685185  0.2685185185  0.2754629630  0.2500000000  0.3125000000  0.3101851852  0.3067129630  0.3425925926  0.2861111111  24.074074074  0.1917881727  1.3715292072  0.2164559364  650           0.1821636772 
0.3113425926  0.2638888889  0.2893518519  0.2777777778  0.3321759259  0.3055555556  0.3171296296  0.3518518519  0.2888888889  25.925925925  0.1793381333  1.3694344401  0.2164559364  700           0.1776201916 
0.2974537037  0.2777777778  0.2743055556  0.2777777778  0.3356481481  0.2916666667  0.3101851852  0.3564814815  0.2870370370  27.777777777  0.1835970044  1.3688956046  0.2164559364  750           0.1780548906 
0.3217592593  0.3148148148  0.3067129630  0.2824074074  0.3321759259  0.3009259259  0.3252314815  0.3472222222  0.3074074074  29.629629629  0.1678873301  1.3692527223  0.2164559364  800           0.1774865437 
0.3368055556  0.3287037037  0.3090277778  0.2777777778  0.3402777778  0.3148148148  0.3368055556  0.3796296296  0.3222222222  31.481481481  0.1835626841  1.3685602593  0.2164559364  850           0.1798936367 
0.3275462963  0.3287037037  0.3379629630  0.2731481481  0.3437500000  0.3425925926  0.3495370370  0.3611111111  0.3268518519  33.333333333  0.1592756271  1.3668829489  0.2164559364  900           0.1822893858 
0.3541666667  0.3935185185  0.3506944444  0.3472222222  0.3738425926  0.3750000000  0.3958333333  0.4351851852  0.3722222222  35.185185185  0.1489761949  1.3654477334  0.2164559364  950           0.1779588413 
0.3495370370  0.3472222222  0.3240740741  0.3333333333  0.3495370370  0.3425925926  0.3726851852  0.4074074074  0.3416666667  37.037037037  0.1318058491  1.3673994708  0.2164559364  1000          0.1808761883 
0.3437500000  0.3518518519  0.3506944444  0.3240740741  0.3518518519  0.3287037037  0.3715277778  0.3935185185  0.3361111111  38.888888888  0.1332298517  1.3684252620  0.2164559364  1050          0.1799184704 
0.3634259259  0.3425925926  0.3449074074  0.2962962963  0.3564814815  0.3472222222  0.3761574074  0.4027777778  0.3379629630  40.740740740  0.1397920728  1.3691220212  0.2164559364  1100          0.1763096905 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1982, in update
    gap = -self.hparams['t_lambda'] * self.loss_gap(minibatches, self, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1950, in loss_gap
    p = model.adv_classifier(model.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/pooling.py", line 90, in forward
    self.return_indices)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_jit_internal.py", line 365, in fn
    return if_false(*args, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 603, in _max_pool1d
    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0.5
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2465277778  0.2453703704  0.2685185185  0.2500000000  0.2708333333  0.2824074074  0.2731481481  0.2731481481  0.2740740741  0.0000000000  0.0631197095  1.4966689348  0.1991610527  0             0.4843077660 
0.4745370370  0.4444444444  0.4699074074  0.4722222222  0.4675925926  0.4861111111  0.4490740741  0.4675925926  0.4444444444  1.8518518519  0.0425358522  1.3906447840  0.2040100098  50            0.1770177841 
0.4861111111  0.4537037037  0.4745370370  0.4953703704  0.4918981481  0.5231481481  0.4675925926  0.4305555556  0.5074074074  3.7037037037  0.0468207800  1.3194911146  0.2040100098  100           0.1796480751 
0.6712962963  0.6481481481  0.6666666667  0.6712962963  0.6944444444  0.6805555556  0.6493055556  0.6018518519  0.5879629630  5.5555555556  0.0556780005  1.2195371437  0.2040100098  150           0.1795790577 
0.7118055556  0.7083333333  0.7141203704  0.6898148148  0.7210648148  0.7083333333  0.6828703704  0.6388888889  0.6092592593  7.4074074074  0.0714590704  1.0901428568  0.2041296959  200           0.1772796297 
0.7291666667  0.6898148148  0.7060185185  0.6990740741  0.7337962963  0.7129629630  0.6909722222  0.6296296296  0.6064814815  9.2592592593  0.0761136580  0.9701270092  0.2046518326  250           0.1765132475 
0.7175925926  0.6712962963  0.7118055556  0.6898148148  0.7256944444  0.7129629630  0.6921296296  0.6527777778  0.6342592593  11.111111111  0.0749991393  0.8765895593  0.2046723366  300           0.1778606224 
0.7800925926  0.7407407407  0.7673611111  0.7083333333  0.7812500000  0.7777777778  0.7893518519  0.7129629630  0.6416666667  12.962962963  0.0785894746  0.7933058190  0.2046723366  350           0.1801359177 
0.7812500000  0.7407407407  0.7881944444  0.7546296296  0.8009259259  0.7870370370  0.7974537037  0.7314814815  0.6074074074  14.814814814  0.0808225113  0.7445575154  0.2046723366  400           0.1752712011 
0.8217592593  0.7731481481  0.8275462963  0.7916666667  0.8310185185  0.8148148148  0.8252314815  0.7592592593  0.6185185185  16.666666666  0.0810983247  0.7101380134  0.2046723366  450           0.1756043911 
0.8553240741  0.8009259259  0.8333333333  0.8101851852  0.8402777778  0.8333333333  0.8368055556  0.7592592593  0.6148148148  18.518518518  0.0875718847  0.6706394470  0.2046723366  500           0.1773300409 
0.8726851852  0.8148148148  0.8506944444  0.8333333333  0.8530092593  0.8518518519  0.8530092593  0.7824074074  0.6064814815  20.370370370  0.0832725936  0.6324468148  0.2046723366  550           0.1767584944 
0.8958333333  0.8611111111  0.8842592593  0.8657407407  0.8900462963  0.8703703704  0.8923611111  0.8611111111  0.6500000000  22.222222222  0.0857021406  0.5962156403  0.2046723366  600           0.1770651340 
0.9085648148  0.8796296296  0.8935185185  0.8703703704  0.9004629630  0.8888888889  0.8935185185  0.8518518519  0.6361111111  24.074074074  0.0778794220  0.5725703871  0.2046723366  650           0.1787279034 
0.8993055556  0.8657407407  0.8796296296  0.8379629630  0.8935185185  0.8796296296  0.9027777778  0.8564814815  0.6666666667  25.925925925  0.0863417017  0.5332069683  0.2046723366  700           0.1781112576 
0.9108796296  0.8750000000  0.8993055556  0.8703703704  0.9108796296  0.8935185185  0.9074074074  0.8750000000  0.6305555556  27.777777777  0.0818460184  0.4991644096  0.2046723366  750           0.1786873198 
0.9131944444  0.8842592593  0.9004629630  0.8518518519  0.9108796296  0.8935185185  0.9062500000  0.8611111111  0.6398148148  29.629629629  0.0796503723  0.4768772846  0.2046723366  800           0.1758979750 
0.9074074074  0.8657407407  0.8854166667  0.8333333333  0.9085648148  0.8750000000  0.9039351852  0.8657407407  0.6638888889  31.481481481  0.0916354266  0.4624876666  0.2046723366  850           0.1764226580 
0.9155092593  0.8888888889  0.9108796296  0.8750000000  0.9201388889  0.8981481481  0.9050925926  0.8703703704  0.6148148148  33.333333333  0.0763214889  0.4152388346  0.2138919830  900           0.1783029032 
0.9236111111  0.8796296296  0.9027777778  0.8703703704  0.9143518519  0.8981481481  0.9247685185  0.8842592593  0.6138888889  35.185185185  0.0744378811  0.3988925892  0.2138919830  950           0.1811683798 
0.9189814815  0.8796296296  0.9120370370  0.8750000000  0.9189814815  0.8981481481  0.9224537037  0.8842592593  0.5814814815  37.037037037  0.0814183921  0.3759542441  0.2138919830  1000          0.1791008520 
0.9317129630  0.8842592593  0.9189814815  0.8750000000  0.9201388889  0.8981481481  0.9351851852  0.8796296296  0.5703703704  38.888888888  0.0752439065  0.3440018177  0.2138919830  1050          0.1812734842 
0.9166666667  0.8796296296  0.9120370370  0.8750000000  0.9189814815  0.8981481481  0.9236111111  0.8935185185  0.5953703704  40.740740740  0.0762606701  0.3282940716  0.2138919830  1100          0.1779222775 
0.9525462963  0.9166666667  0.9293981481  0.8750000000  0.9375000000  0.9166666667  0.9560185185  0.9259259259  0.5824074074  42.592592592  0.0676780115  0.3072171551  0.2138919830  1150          0.1802435064 
0.9328703704  0.8796296296  0.8993055556  0.8518518519  0.9143518519  0.8981481481  0.9351851852  0.8935185185  0.6305555556  44.444444444  0.0768719393  0.2931373844  0.2138919830  1200          0.1786263943 
0.9375000000  0.8888888889  0.9212962963  0.8796296296  0.9212962963  0.8981481481  0.9328703704  0.8750000000  0.5694444444  46.296296296  0.0839527440  0.2632179290  0.2138919830  1250          0.1763271284 
0.9687500000  0.9398148148  0.9513888889  0.9027777778  0.9525462963  0.9212962963  0.9675925926  0.9259259259  0.5555555556  48.148148148  0.0754017623  0.2566755429  0.2138919830  1300          0.1791104841 
0.9259259259  0.8796296296  0.9016203704  0.8564814815  0.9189814815  0.8981481481  0.9317129630  0.8935185185  0.6222222222  50.000000000  0.0679714392  0.2426340374  0.2138919830  1350          0.1794915104 
0.9687500000  0.9351851852  0.9398148148  0.8935185185  0.9583333333  0.9212962963  0.9710648148  0.9490740741  0.5898148148  51.851851851  0.0695141550  0.2237768137  0.2138919830  1400          0.1799229097 
0.9583333333  0.9166666667  0.9351851852  0.8888888889  0.9351851852  0.8981481481  0.9606481481  0.9120370370  0.5629629630  53.703703703  0.0683916831  0.2145818853  0.2138919830  1450          0.1768536520 
0.9768518519  0.9444444444  0.9606481481  0.9351851852  0.9606481481  0.9259259259  0.9733796296  0.9398148148  0.5212962963  55.555555555  0.0600503573  0.1991130638  0.2138919830  1500          0.1776497984 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2500000000  0.2129629630  0.2291666667  0.2175925926  0.2314814815  0.2407407407  0.2152777778  0.2268518519  0.2435185185  0.0000000000  0.0000000000  1.4966689348  0.1991610527  0             0.4957313538 
0.8043981481  0.7592592593  0.8020833333  0.7453703704  0.8043981481  0.7777777778  0.7812500000  0.6759259259  0.6268518519  1.8518518519  0.0000000000  1.0865720761  0.2041316032  50            0.1777611208 
0.8854166667  0.8425925926  0.8784722222  0.8287037037  0.8981481481  0.8657407407  0.9004629630  0.8425925926  0.6740740741  3.7037037037  0.0000000000  0.6387880647  0.2041316032  100           0.1772373915 
0.9166666667  0.8657407407  0.9039351852  0.8611111111  0.9108796296  0.8981481481  0.9212962963  0.8888888889  0.6740740741  5.5555555556  0.0000000000  0.4504803401  0.2041893005  150           0.1786301708 
0.9247685185  0.8888888889  0.9131944444  0.8842592593  0.9201388889  0.8981481481  0.9131944444  0.8935185185  0.5907407407  7.4074074074  0.0000000000  0.2838171300  0.2041893005  200           0.1801076460 
0.9826388889  0.9629629630  0.9756944444  0.9444444444  0.9652777778  0.9351851852  0.9722222222  0.9444444444  0.5351851852  9.2592592593  0.0000000000  0.1847886205  0.2041893005  250           0.1781154156 
0.9895833333  0.9814814815  0.9895833333  0.9722222222  0.9814814815  0.9583333333  0.9791666667  0.9537037037  0.5148148148  11.111111111  0.0000000000  0.1255969863  0.2041912079  300           0.1796387434 
0.9918981481  0.9814814815  0.9976851852  0.9814814815  0.9930555556  0.9722222222  0.9849537037  0.9629629630  0.5592592593  12.962962963  0.0000000000  0.0964570606  0.2041912079  350           0.1798050976 
0.9953703704  0.9861111111  0.9988425926  0.9814814815  0.9988425926  0.9861111111  0.9861111111  0.9537037037  0.5157407407  14.814814814  0.0000000000  0.0755463961  0.2041912079  400           0.1909652662 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1983, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 0.0005
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2650462963  0.2407407407  0.2488425926  0.2962962963  0.2962962963  0.2916666667  0.2731481481  0.2685185185  0.2768518519  0.0000000000  0.0000000000  1.4966689348  0.1991610527  0             0.4772727489 
0.9791666667  0.9629629630  0.9710648148  0.9490740741  0.9618055556  0.9351851852  0.9675925926  0.9583333333  0.5898148148  1.8518518519  0.0000000000  0.6430362630  0.2040090561  50            0.1823676300 
0.9942129630  0.9861111111  0.9988425926  0.9907407407  1.0000000000  1.0000000000  0.9942129630  0.9907407407  0.6148148148  3.7037037037  0.0000000000  0.0749819917  0.2041893005  100           0.1784066534 
0.9988425926  1.0000000000  1.0000000000  0.9907407407  1.0000000000  1.0000000000  0.9953703704  0.9861111111  0.5981481481  5.5555555556  0.0000000000  0.0227722642  0.2048511505  150           0.1799130964 
0.9976851852  0.9907407407  1.0000000000  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5870370370  7.4074074074  0.0000000000  0.0212477299  0.2048511505  200           0.1812457991 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-06
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2442129630  0.2453703704  0.2604166667  0.2453703704  0.2754629630  0.2777777778  0.2708333333  0.2824074074  0.2722222222  0.0000000000  0.0000000000  1.4966689348  0.1991610527  0             0.4940431118 
0.4201388889  0.3703703704  0.3773148148  0.4212962963  0.3993055556  0.4444444444  0.3912037037  0.4074074074  0.3851851852  1.8518518519  0.0000000000  1.4087469459  0.2039504051  50            0.1796435547 
0.4930555556  0.4675925926  0.4525462963  0.4722222222  0.4641203704  0.5092592593  0.4340277778  0.4444444444  0.4805555556  3.7037037037  0.0000000000  1.3447068214  0.2039504051  100           0.1798753643 
0.6122685185  0.6064814815  0.5833333333  0.5833333333  0.5972222222  0.5925925926  0.5648148148  0.5555555556  0.5472222222  5.5555555556  0.0000000000  1.2642985320  0.2041296959  150           0.1801531649 
0.6840277778  0.6527777778  0.6585648148  0.6388888889  0.6736111111  0.6759259259  0.6331018519  0.6064814815  0.5685185185  7.4074074074  0.0000000000  1.1549804139  0.2041296959  200           0.1810217381 
0.7268518519  0.6944444444  0.7002314815  0.6898148148  0.7187500000  0.6944444444  0.6689814815  0.6296296296  0.5925925926  9.2592592593  0.0000000000  1.0495648527  0.2041296959  250           0.1784889889 
0.7268518519  0.6990740741  0.7199074074  0.6898148148  0.7407407407  0.7361111111  0.6828703704  0.6342592593  0.5824074074  11.111111111  0.0000000000  0.9545166743  0.2041296959  300           0.1756640291 
0.7731481481  0.7175925926  0.7638888889  0.7083333333  0.7662037037  0.7546296296  0.7557870370  0.6851851852  0.6250000000  12.962962963  0.0000000000  0.8655463576  0.2041296959  350           0.1803683901 
0.7916666667  0.7314814815  0.7812500000  0.7222222222  0.7881944444  0.7824074074  0.7476851852  0.6805555556  0.6222222222  14.814814814  0.0000000000  0.8112688398  0.2041296959  400           0.1799430704 
0.8217592593  0.7500000000  0.7986111111  0.7453703704  0.8090277778  0.7916666667  0.7974537037  0.7129629630  0.6175925926  16.666666666  0.0000000000  0.7719962704  0.2041296959  450           0.1788736105 
0.8391203704  0.7824074074  0.8194444444  0.7824074074  0.8252314815  0.7962962963  0.8067129630  0.7222222222  0.6259259259  18.518518518  0.0000000000  0.7276259172  0.2041902542  500           0.1816672659 
0.8611111111  0.8194444444  0.8402777778  0.7824074074  0.8379629630  0.8194444444  0.8217592593  0.7731481481  0.6166666667  20.370370370  0.0000000000  0.6872146261  0.2041902542  550           0.1814577246 
0.8807870370  0.8240740741  0.8576388889  0.8240740741  0.8680555556  0.8240740741  0.8541666667  0.8055555556  0.6518518519  22.222222222  0.0000000000  0.6543310773  0.2155551910  600           0.1801875925 
0.8923611111  0.8518518519  0.8703703704  0.8287037037  0.8738425926  0.8564814815  0.8715277778  0.8148148148  0.6370370370  24.074074074  0.0000000000  0.6348861277  0.2155551910  650           0.1804694891 
0.8912037037  0.8518518519  0.8715277778  0.8379629630  0.8842592593  0.8564814815  0.8854166667  0.8425925926  0.6527777778  25.925925925  0.0000000000  0.5959009409  0.2155551910  700           0.1790343904 
0.8958333333  0.8564814815  0.8888888889  0.8425925926  0.8946759259  0.8564814815  0.8923611111  0.8611111111  0.6527777778  27.777777777  0.0000000000  0.5617702377  0.2155551910  750           0.1813689041 
0.9027777778  0.8703703704  0.8981481481  0.8518518519  0.9027777778  0.8842592593  0.8981481481  0.8657407407  0.6425925926  29.629629629  0.0000000000  0.5476466531  0.2155551910  800           0.1789737272 
0.9027777778  0.8611111111  0.8935185185  0.8472222222  0.9016203704  0.8888888889  0.8981481481  0.8796296296  0.6500000000  31.481481481  0.0000000000  0.5421172512  0.2155551910  850           0.1800697470 
0.9131944444  0.8842592593  0.9062500000  0.8611111111  0.9166666667  0.8935185185  0.8969907407  0.8611111111  0.6166666667  33.333333333  0.0000000000  0.4950538135  0.2155551910  900           0.1785415173 
0.9027777778  0.8657407407  0.8900462963  0.8425925926  0.9050925926  0.8935185185  0.9039351852  0.8750000000  0.6611111111  35.185185185  0.0000000000  0.4864510584  0.2155551910  950           0.1800720692 
0.9074074074  0.8796296296  0.8969907407  0.8518518519  0.9108796296  0.8935185185  0.9039351852  0.8796296296  0.6407407407  37.037037037  0.0000000000  0.4658445179  0.2155551910  1000          0.1799638700 
0.9131944444  0.8842592593  0.9004629630  0.8518518519  0.9166666667  0.8981481481  0.9027777778  0.8750000000  0.6212962963  38.888888888  0.0000000000  0.4371321106  0.2155551910  1050          0.1844179201 
0.9074074074  0.8796296296  0.8969907407  0.8518518519  0.9131944444  0.8981481481  0.9085648148  0.8796296296  0.6435185185  40.740740740  0.0000000000  0.4275015396  0.2157363892  1100          0.1821278811 
0.9166666667  0.8611111111  0.8969907407  0.8518518519  0.9097222222  0.8981481481  0.9143518519  0.8935185185  0.6351851852  42.592592592  0.0000000000  0.4033416533  0.2157363892  1150          0.2176752710 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1987, in update
    return {'loss': loss.item(), 'gap': -gap.item()}
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-06
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2465277778  0.2500000000  0.2627314815  0.2453703704  0.2777777778  0.2870370370  0.2743055556  0.2824074074  0.2712962963  0.0000000000  0.1475051641  1.4966689348  0.1991610527  0             126.00550103 
0.3101851852  0.2962962963  0.2581018519  0.2962962963  0.2916666667  0.3194444444  0.2789351852  0.2638888889  0.2518518519  1.8518518519  0.0958700633  1.4252806377  0.2053880692  50            1.3998684120 
0.3368055556  0.2916666667  0.3101851852  0.3379629630  0.3136574074  0.3611111111  0.3217592593  0.3194444444  0.2916666667  3.7037037037  0.0932275987  1.3973443389  0.2053880692  100           0.1807413292 
0.3599537037  0.3148148148  0.3310185185  0.3842592593  0.3564814815  0.3796296296  0.3530092593  0.3425925926  0.3120370370  5.5555555556  0.0890006089  1.3718033314  0.2053880692  150           0.1840683937 
0.3923611111  0.3657407407  0.3807870370  0.3796296296  0.3842592593  0.4305555556  0.3969907407  0.4027777778  0.3657407407  7.4074074074  0.0937014341  1.3483535433  0.2053880692  200           0.1807772207 
0.4224537037  0.3796296296  0.4120370370  0.3981481481  0.3981481481  0.4444444444  0.3958333333  0.3981481481  0.3916666667  9.2592592593  0.0865199685  1.3261123252  0.2053880692  250           0.1794961405 
0.4826388889  0.4398148148  0.4618055556  0.4583333333  0.4687500000  0.4861111111  0.4560185185  0.4537037037  0.4851851852  11.111111111  0.0893881059  1.3090156698  0.2053880692  300           0.1833287001 
0.5370370370  0.5509259259  0.5532407407  0.5231481481  0.5810185185  0.5370370370  0.5486111111  0.5138888889  0.5472222222  12.962962963  0.0801559925  1.2833690310  0.2053880692  350           0.1783402967 
0.6018518519  0.6296296296  0.6087962963  0.5787037037  0.6377314815  0.6157407407  0.6099537037  0.5648148148  0.5555555556  14.814814814  0.0840476012  1.2616141701  0.2053880692  400           0.1781163454 
0.5879629630  0.5601851852  0.5925925926  0.5740740741  0.5983796296  0.5972222222  0.5636574074  0.5231481481  0.5592592593  16.666666666  0.0790606976  1.2383985043  0.2053880692  450           0.1810135698 
0.6631944444  0.6388888889  0.6701388889  0.6388888889  0.6990740741  0.6851851852  0.6516203704  0.5972222222  0.5990740741  18.518518518  0.0972122002  1.2066871691  0.2053880692  500           0.1879496861 
0.6608796296  0.6250000000  0.6840277778  0.6574074074  0.7013888889  0.6898148148  0.6481481481  0.6157407407  0.5944444444  20.370370370  0.1044757605  1.1724599004  0.2053880692  550           0.1830575275 
0.6805555556  0.6527777778  0.6898148148  0.6851851852  0.7025462963  0.6851851852  0.6585648148  0.6111111111  0.5601851852  22.222222222  0.1071511817  1.1400687790  0.2053880692  600           0.1854923391 
0.6782407407  0.6435185185  0.6990740741  0.6759259259  0.7094907407  0.6898148148  0.6747685185  0.6435185185  0.5851851852  24.074074074  0.1076851451  1.1023551798  0.2053880692  650           0.1968100595 
0.6875000000  0.6620370370  0.6724537037  0.6712962963  0.7152777778  0.7222222222  0.6898148148  0.6712962963  0.6027777778  25.925925925  0.1263814378  1.0660054421  0.2053880692  700           0.1945048714 
0.6712962963  0.6388888889  0.6863425926  0.6620370370  0.7060185185  0.7083333333  0.6666666667  0.6435185185  0.5879629630  27.777777777  0.1183245885  1.0268727005  0.2053880692  750           0.1852389717 
0.6898148148  0.6666666667  0.6840277778  0.6759259259  0.7083333333  0.7222222222  0.6770833333  0.6342592593  0.5870370370  29.629629629  0.1207351971  0.9977817523  0.2053880692  800           0.1819518566 
0.6967592593  0.6805555556  0.6944444444  0.6574074074  0.7106481481  0.7453703704  0.6932870370  0.6620370370  0.5898148148  31.481481481  0.1372344398  0.9694115806  0.2053880692  850           0.1812113571 
0.6909722222  0.6759259259  0.7037037037  0.7083333333  0.7094907407  0.7222222222  0.6643518519  0.6388888889  0.5731481481  33.333333333  0.1278514850  0.9276983690  0.2148103714  900           0.1767227125 
0.7025462963  0.6851851852  0.7106481481  0.6898148148  0.7233796296  0.7685185185  0.7071759259  0.6574074074  0.5898148148  35.185185185  0.1323803163  0.9013048577  0.2148103714  950           0.1874738598 
0.6875000000  0.6805555556  0.6898148148  0.6620370370  0.7060185185  0.7453703704  0.6828703704  0.6250000000  0.5805555556  37.037037037  0.1412485671  0.8713056290  0.2148103714  1000          0.1788577509 
0.6990740741  0.7037037037  0.7037037037  0.6805555556  0.7071759259  0.7500000000  0.6944444444  0.6435185185  0.5824074074  38.888888888  0.1353671885  0.8462847221  0.2169346809  1050          0.1794129848 
0.7222222222  0.6990740741  0.7129629630  0.7129629630  0.7349537037  0.7731481481  0.7395833333  0.7083333333  0.5907407407  40.740740740  0.1460569119  0.8312087452  0.2169346809  1100          0.1817167139 
0.7164351852  0.7037037037  0.7071759259  0.7222222222  0.7245370370  0.7638888889  0.7199074074  0.6898148148  0.5768518519  42.592592592  0.1492049325  0.8031380498  0.2169346809  1150          0.1819424152 
0.7384259259  0.7268518519  0.7372685185  0.7314814815  0.7465277778  0.7500000000  0.7465277778  0.7175925926  0.5777777778  44.444444444  0.1474088132  0.7902609479  0.2169346809  1200          0.1788560343 
0.7222222222  0.7083333333  0.7268518519  0.7037037037  0.7141203704  0.7731481481  0.7164351852  0.6620370370  0.5888888889  46.296296296  0.1745638633  0.7684843826  0.2169346809  1250          0.1748468685 
0.7592592593  0.7361111111  0.7592592593  0.7175925926  0.7650462963  0.7638888889  0.7581018519  0.6805555556  0.6083333333  48.148148148  0.1684728026  0.7567203426  0.2169346809  1300          0.1777578497 
0.8055555556  0.7685185185  0.7893518519  0.7500000000  0.7928240741  0.7962962963  0.8055555556  0.7361111111  0.6111111111  50.000000000  0.1294895327  0.7526940084  0.2169346809  1350          0.1802246332 
0.7951388889  0.8009259259  0.7916666667  0.7592592593  0.8055555556  0.7824074074  0.7893518519  0.7129629630  0.6277777778  51.851851851  0.1467609918  0.7226546729  0.2169346809  1400          0.1778983068 
0.8159722222  0.7731481481  0.7916666667  0.7546296296  0.8078703704  0.7916666667  0.8055555556  0.7361111111  0.6138888889  53.703703703  0.1377923620  0.7134397435  0.2169346809  1450          0.1817867613 
0.8113425926  0.7638888889  0.7962962963  0.7592592593  0.7962962963  0.7962962963  0.7997685185  0.7268518519  0.5888888889  55.555555555  0.1436419642  0.7110285437  0.2169346809  1500          0.1801487684 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-06
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.16.1

Out[1]: 
tensor([[ 0.0000e+00,  1.5553e-07,  7.4506e-08,  4.4703e-08, -1.7881e-07,
          3.5390e-07, -1.9372e-07,  1.7881e-07, -4.4703e-08,  3.8743e-07,
         -1.4901e-07,  7.1526e-07, -7.4506e-09,  2.9802e-08,  6.2585e-07,
          8.9407e-08,  8.9407e-08, -2.9802e-08,  2.9802e-08, -7.4506e-08,
          8.1956e-08,  3.7253e-07,  5.2154e-07,  5.1036e-07, -2.9802e-08,
          3.5763e-07, -3.5763e-07, -3.7253e-08,  3.7253e-07, -4.3213e-07,
          2.2352e-08,  7.4506e-08, -5.9605e-08, -1.7881e-07,  1.4156e-07,
         -8.0327e-08,  8.9407e-08,  1.0990e-07, -2.6077e-08,  1.1921e-07,
         -1.9372e-07,  1.2666e-07, -1.7881e-07,  5.6624e-07, -1.2666e-07,
          3.2783e-07,  3.5763e-07,  4.8429e-08,  3.2783e-07,  1.0431e-07,
          1.6391e-07,  8.9407e-08, -4.4703e-07,  1.4901e-08, -1.9372e-07,
         -2.9802e-08,  2.6077e-07, -5.9605e-08,  6.8918e-08, -1.7881e-07,
         -1.1921e-07, -5.9605e-08,  4.4703e-08, -4.4703e-08],
        [ 0.0000e+00, -1.4156e-07, -1.4901e-08,  2.3842e-07,  2.7567e-07,
         -7.4506e-07,  2.2352e-07, -1.3411e-07, -7.4506e-08, -3.4273e-07,
         -4.6194e-07, -6.4075e-07,  0.0000e+00, -3.1292e-07, -8.4937e-07,
         -3.5763e-07, -1.4901e-08, -2.9802e-08, -7.4506e-08, -3.2783e-07,
          2.2352e-07, -1.4156e-07, -3.7812e-07, -1.3262e-06, -2.3842e-07,
         -4.5449e-07, -3.7253e-07,  1.0431e-07, -5.7369e-07, -5.9605e-07,
         -7.4506e-08, -1.5050e-06, -1.2666e-07, -1.7881e-07, -2.9802e-07,
         -8.1211e-07, -3.7998e-07, -2.3469e-07,  2.9802e-08, -3.9116e-08,
         -4.0978e-08, -1.1325e-06,  1.0431e-07, -1.1325e-06,  7.4506e-08,
         -9.2387e-07, -9.5367e-07, -1.4529e-07, -4.3213e-07, -7.3342e-08,
         -1.1921e-07, -1.3411e-07, -1.3411e-07, -2.5332e-07,  1.3411e-07,
          1.4901e-07, -7.8231e-07, -1.4901e-08, -1.4901e-07, -4.4703e-08,
          1.0431e-07, -1.4901e-08,  2.6822e-07, -1.4901e-08],
        [ 0.0000e+00,  1.1921e-07, -8.5682e-08,  4.4703e-07, -1.1921e-07,
          6.6310e-07,  5.5507e-07,  3.5763e-07,  2.0862e-07,  1.0431e-07,
          8.0466e-07,  1.8626e-07,  0.0000e+00,  4.7684e-07,  5.0664e-07,
          4.1723e-07,  1.3411e-07,  2.0862e-07,  1.4901e-08,  5.5134e-07,
          2.5332e-07, -5.9605e-08,  2.9802e-08,  9.1642e-07,  1.9558e-07,
          1.0431e-07,  7.6368e-07, -4.4703e-08,  1.4901e-07,  6.5751e-07,
          7.4506e-08,  2.3991e-06,  4.7684e-07,  4.6194e-07,  3.8743e-07,
          7.7486e-07,  2.0117e-07,  6.7055e-07,  1.4901e-08, -2.9802e-08,
          1.5646e-07,  9.7603e-07,  1.7881e-07,  1.0093e-06,  1.4901e-07,
          1.5944e-06,  7.6741e-07,  1.4156e-07,  1.7881e-07, -5.9605e-08,
         -1.1921e-07,  1.9372e-07,  5.3644e-07,  8.9407e-08, -5.2154e-08,
         -5.9605e-08,  1.0729e-06, -2.9802e-08,  7.0781e-08,  4.6194e-07,
          1.9372e-07,  1.1921e-07,  1.9372e-07,  7.4506e-08],
        [ 0.0000e+00, -1.1921e-07,  2.2352e-08, -7.1526e-07,  1.8626e-08,
         -2.6822e-07, -5.7928e-07, -4.0233e-07, -8.9407e-08, -1.4901e-07,
         -1.9372e-07, -2.6822e-07,  1.4901e-08, -1.7881e-07, -2.6822e-07,
         -1.4901e-07, -2.0862e-07, -1.5274e-07,  1.4901e-08, -1.5274e-07,
         -5.6624e-07, -1.7881e-07, -1.5646e-07, -8.9407e-08,  5.9605e-08,
          0.0000e+00, -2.9802e-08, -2.9802e-08,  5.9605e-08,  3.5763e-07,
         -1.4901e-08, -9.8348e-07, -2.8312e-07, -1.1921e-07, -2.3842e-07,
          1.1921e-07,  9.6858e-08, -5.3644e-07, -2.2352e-08, -5.2154e-08,
          8.9407e-08,  2.9802e-08, -1.0431e-07, -4.3213e-07, -8.9407e-08,
         -9.9838e-07, -1.6391e-07, -4.4703e-08, -8.9407e-08,  2.9802e-08,
          7.4506e-08, -1.4156e-07,  3.7253e-08,  1.6391e-07,  1.0431e-07,
         -5.9605e-08, -5.6624e-07,  1.1176e-07,  1.4901e-08, -2.3842e-07,
         -1.9372e-07, -4.4703e-08, -5.1409e-07,  0.0000e+00]], device='cuda:0',
       grad_fn=<SubBackward0>)
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2465277778  0.2500000000  0.2627314815  0.2453703704  0.2777777778  0.2870370370  0.2743055556  0.2824074074  0.2712962963  0.0000000000  0.1474319696  1.4966689348  0.1991610527  0             153.34424352 
0.3136574074  0.2731481481  0.2662037037  0.3055555556  0.2812500000  0.3194444444  0.2881944444  0.2731481481  0.2481481481  1.8518518519  0.0958150625  1.4252798605  0.2041330338  50            0.1884752035 
0.3414351852  0.2870370370  0.3125000000  0.3379629630  0.3136574074  0.3518518519  0.3206018519  0.3148148148  0.2981481481  3.7037037037  0.0931440163  1.3972392845  0.2041330338  100           0.1831759548 
0.3668981481  0.3194444444  0.3368055556  0.3796296296  0.3576388889  0.3750000000  0.3495370370  0.3472222222  0.3185185185  5.5555555556  0.0888452148  1.3718369484  0.2041926384  150           0.1861730337 
0.4039351852  0.3842592593  0.3865740741  0.3842592593  0.3900462963  0.4398148148  0.4097222222  0.4120370370  0.3740740741  7.4074074074  0.0937521791  1.3483732486  0.2041926384  200           0.1804942942 
0.4166666667  0.3842592593  0.4085648148  0.3981481481  0.3923611111  0.4490740741  0.3877314815  0.3888888889  0.3805555556  9.2592592593  0.0858050489  1.3265476775  0.2041926384  250           0.1812062979 
0.4861111111  0.4675925926  0.4791666667  0.4861111111  0.4884259259  0.4907407407  0.4583333333  0.4583333333  0.5055555556  11.111111111  0.0888087177  1.3095995402  0.2041926384  300           0.1950824738 
0.5520833333  0.5555555556  0.5625000000  0.5416666667  0.5856481481  0.5462962963  0.5555555556  0.5231481481  0.5527777778  12.962962963  0.0795827723  1.2838962245  0.2041926384  350           0.1995551538 
0.5879629630  0.6203703704  0.5902777778  0.5601851852  0.6226851852  0.5925925926  0.5879629630  0.5509259259  0.5574074074  14.814814814  0.0843368244  1.2628451276  0.2043738365  400           0.1907200623 
0.5856481481  0.5833333333  0.6099537037  0.5787037037  0.6111111111  0.6157407407  0.5694444444  0.5324074074  0.5527777778  16.666666666  0.0793933201  1.2408506203  0.2045540810  450           0.1919485569 
0.6597222222  0.6342592593  0.6782407407  0.6666666667  0.6990740741  0.6805555556  0.6458333333  0.6111111111  0.5944444444  18.518518518  0.0971899319  1.2073164225  0.2048721313  500           0.1878562737 
0.6655092593  0.6296296296  0.6851851852  0.6574074074  0.6990740741  0.6944444444  0.6539351852  0.6111111111  0.5861111111  20.370370370  0.1018583465  1.1737613726  0.2048721313  550           0.1959333324 
0.6840277778  0.6435185185  0.6840277778  0.6851851852  0.7002314815  0.6944444444  0.6666666667  0.6157407407  0.5546296296  22.222222222  0.1073414969  1.1402808499  0.2048721313  600           0.2133240747 
0.6828703704  0.6435185185  0.6979166667  0.6898148148  0.7071759259  0.6898148148  0.6770833333  0.6574074074  0.5750000000  24.074074074  0.1079700327  1.1024308181  0.2048721313  650           0.1845623350 
0.6898148148  0.6527777778  0.6759259259  0.6527777778  0.7083333333  0.7083333333  0.6817129630  0.6712962963  0.6000000000  25.925925925  0.1269250965  1.0655778646  0.2048721313  700           0.1902853918 
0.6712962963  0.6481481481  0.6770833333  0.6712962963  0.6990740741  0.7083333333  0.6585648148  0.6157407407  0.5768518519  27.777777777  0.1176757407  1.0282544613  0.2048721313  750           0.1790224504 
0.6851851852  0.6712962963  0.6840277778  0.6712962963  0.7002314815  0.7175925926  0.6805555556  0.6342592593  0.5888888889  29.629629629  0.1193357420  0.9996732116  0.2048721313  800           0.1800209284 
0.6921296296  0.6666666667  0.6944444444  0.6574074074  0.7106481481  0.7407407407  0.6898148148  0.6620370370  0.5898148148  31.481481481  0.1382661235  0.9698859477  0.2048721313  850           0.1799781704 
0.6886574074  0.6666666667  0.7071759259  0.6990740741  0.7083333333  0.7314814815  0.6678240741  0.6388888889  0.5759259259  33.333333333  0.1282527077  0.9288535821  0.2098627090  900           0.1803187704 
0.6944444444  0.6712962963  0.7083333333  0.6805555556  0.7118055556  0.7638888889  0.7002314815  0.6481481481  0.5925925926  35.185185185  0.1323164976  0.9015910733  0.2098627090  950           0.1825948000 
0.6805555556  0.6805555556  0.6956018519  0.6620370370  0.7037037037  0.7314814815  0.6840277778  0.6296296296  0.5861111111  37.037037037  0.1426318312  0.8722056818  0.2098627090  1000          0.1820940351 
0.6990740741  0.6944444444  0.7060185185  0.6851851852  0.7037037037  0.7314814815  0.6851851852  0.6203703704  0.5787037037  38.888888888  0.1364631057  0.8473136699  0.2098627090  1050          0.1798314238 
0.7222222222  0.7129629630  0.7233796296  0.7037037037  0.7361111111  0.7731481481  0.7407407407  0.6898148148  0.5907407407  40.740740740  0.1469636619  0.8324664497  0.2098627090  1100          0.1837705898 
0.7118055556  0.6898148148  0.7002314815  0.7222222222  0.7210648148  0.7546296296  0.7152777778  0.6898148148  0.5777777778  42.592592592  0.1500356627  0.8040499115  0.2098627090  1150          0.1796198893 
0.7268518519  0.7175925926  0.7256944444  0.7268518519  0.7442129630  0.7407407407  0.7337962963  0.7037037037  0.5750000000  44.444444444  0.1466223907  0.7908472049  0.2098627090  1200          0.1809962416 
0.7071759259  0.6944444444  0.7129629630  0.7222222222  0.7129629630  0.7592592593  0.7094907407  0.6481481481  0.5851851852  46.296296296  0.1748047328  0.7688194180  0.2098627090  1250          0.1767744923 
0.7546296296  0.7314814815  0.7534722222  0.7129629630  0.7638888889  0.7685185185  0.7569444444  0.6851851852  0.6064814815  48.148148148  0.1692633736  0.7583171248  0.2098627090  1300          0.1809799194 
0.7986111111  0.7546296296  0.7777777778  0.7546296296  0.7881944444  0.7777777778  0.7974537037  0.7129629630  0.6120370370  50.000000000  0.1292538071  0.7534576023  0.2136740685  1350          0.1788533449 
0.7881944444  0.8009259259  0.7939814815  0.7638888889  0.7974537037  0.7824074074  0.7824074074  0.7129629630  0.6222222222  51.851851851  0.1474185455  0.7236370134  0.2136740685  1400          0.1823573017 
0.8113425926  0.7731481481  0.7939814815  0.7592592593  0.8043981481  0.8009259259  0.8067129630  0.7222222222  0.6175925926  53.703703703  0.1388393044  0.7145682359  0.2136740685  1450          0.1928027630 
0.7905092593  0.7546296296  0.7974537037  0.7777777778  0.7962962963  0.7916666667  0.7893518519  0.7083333333  0.6018518519  55.555555555  0.1440721178  0.7116714144  0.2136740685  1500          0.1954572725 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2500000000  0.2083333333  0.2291666667  0.2453703704  0.2523148148  0.2453703704  0.2245370370  0.2268518519  0.2425925926  0.0000000000  0.0749977827  1.4966689348  0.1991610527  0             0.5093381405 
0.6388888889  0.6342592593  0.6701388889  0.6574074074  0.7037037037  0.6712962963  0.6666666667  0.6712962963  0.5518518519  1.8518518519  0.0734253740  1.3089309406  0.2041926384  50            0.1961758518 
0.6770833333  0.6898148148  0.6712962963  0.6342592593  0.6956018519  0.6805555556  0.6944444444  0.6574074074  0.6685185185  3.7037037037  0.1114066625  1.0527608764  0.2041926384  100           0.1968635082 
0.8067129630  0.7777777778  0.7916666667  0.7824074074  0.8136574074  0.7824074074  0.7905092593  0.7083333333  0.6259259259  5.5555555556  0.1561307728  0.8038889253  0.2041926384  150           0.2030733728 
0.8449074074  0.8009259259  0.8414351852  0.7870370370  0.8657407407  0.8379629630  0.8831018519  0.8425925926  0.6694444444  7.4074074074  0.1602482080  0.6603488433  0.2041926384  200           0.1983816385 
0.8923611111  0.8564814815  0.8877314815  0.8518518519  0.9097222222  0.8935185185  0.9039351852  0.8657407407  0.6296296296  9.2592592593  0.1533269012  0.5685074908  0.2041926384  250           0.1868651772 
0.9155092593  0.8703703704  0.8935185185  0.8425925926  0.9178240741  0.8888888889  0.9328703704  0.8796296296  0.6296296296  11.111111111  0.1377112025  0.5002610600  0.2119345665  300           0.1811350393 
0.9062500000  0.8703703704  0.8819444444  0.8472222222  0.9143518519  0.8888888889  0.9131944444  0.8750000000  0.6722222222  12.962962963  0.1476596913  0.4099422175  0.2119345665  350           0.1791178179 
0.9143518519  0.8842592593  0.9108796296  0.8796296296  0.9189814815  0.8981481481  0.9074074074  0.8611111111  0.6064814815  14.814814814  0.1417225826  0.3474078208  0.2119345665  400           0.2001737309 
0.9166666667  0.8842592593  0.9039351852  0.8750000000  0.9178240741  0.8981481481  0.9201388889  0.8888888889  0.6287037037  16.666666666  0.1311189711  0.2904720747  0.2119345665  450           0.1908807325 
0.9571759259  0.9027777778  0.9282407407  0.8842592593  0.9317129630  0.8981481481  0.9594907407  0.9166666667  0.5703703704  18.518518518  0.1539403045  0.2519894326  0.2119345665  500           0.1894407701 
0.9837962963  0.9444444444  0.9641203704  0.9537037037  0.9618055556  0.9120370370  0.9560185185  0.9120370370  0.4814814815  20.370370370  0.1303475487  0.2071792403  0.2119345665  550           0.1854961538 
0.9814814815  0.9583333333  0.9664351852  0.9444444444  0.9629629630  0.9259259259  0.9733796296  0.9259259259  0.5388888889  22.222222222  0.1340716858  0.1802536242  0.2119345665  600           0.1880427456 
0.9525462963  0.8981481481  0.9317129630  0.8981481481  0.9270833333  0.8981481481  0.9247685185  0.8518518519  0.5064814815  24.074074074  0.1136602187  0.1537042335  0.2119345665  650           0.1990663528 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2300765) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2857142857  0.2559523810  0.2946428571  0.2619047619  0.2589285714  0.2976190476  0.2723214286  0.2738095238  0.2797619048  0.0000000000  0.1090521812  1.4120990038  0.0563254356  0             0.5062057972 
0.6562500000  0.6250000000  0.6458333333  0.6488095238  0.6636904762  0.6845238095  0.6502976190  0.6011904762  0.5630952381  2.3809523810  0.0776335192  1.3111753058  0.0604329109  50            0.1831041479 
0.6592261905  0.6726190476  0.6636904762  0.6250000000  0.6741071429  0.6785714286  0.6622023810  0.6726190476  0.5952380952  4.7619047619  0.1024912989  1.0553838754  0.0604329109  100           0.1677306795 
0.7142857143  0.6607142857  0.7023809524  0.6488095238  0.7500000000  0.7083333333  0.7767857143  0.7023809524  0.5916666667  7.1428571429  0.1459407806  0.8448204720  0.0604329109  150           0.1709194708 
0.7782738095  0.7440476190  0.7827380952  0.7321428571  0.7752976190  0.7261904762  0.7619047619  0.7619047619  0.6214285714  9.5238095238  0.1499955761  0.7194474912  0.0604486465  200           0.1695960665 
0.7738095238  0.7500000000  0.7589285714  0.7083333333  0.7633928571  0.7261904762  0.7500000000  0.7678571429  0.6238095238  11.904761904  0.1446087271  0.6504834390  0.0604486465  250           0.1699279928 
0.8288690476  0.8273809524  0.8244047619  0.7976190476  0.8288690476  0.8214285714  0.8333333333  0.8095238095  0.6619047619  14.285714285  0.1348070663  0.5852976942  0.0604505539  300           0.1803925657 
0.8601190476  0.8630952381  0.8586309524  0.8273809524  0.8705357143  0.8571428571  0.8705357143  0.8630952381  0.7178571429  16.666666666  0.1331698495  0.5283112592  0.0604505539  350           0.1766759443 
0.9122023810  0.8571428571  0.9047619048  0.8392857143  0.9017857143  0.8511904762  0.9285714286  0.8571428571  0.6607142857  19.047619047  0.1501687890  0.4676769519  0.0604653358  400           0.1703269148 
0.8824404762  0.8750000000  0.8898809524  0.8690476190  0.8690476190  0.8809523810  0.8928571429  0.8333333333  0.5654761905  21.428571428  0.1538452876  0.4312988991  0.0604653358  450           0.1735797215 
0.9479166667  0.8988095238  0.9345238095  0.8928571429  0.9181547619  0.8750000000  0.9464285714  0.8511904762  0.5547619048  23.809523809  0.1448643628  0.3627793181  0.0604653358  500           0.1740128279 
0.9449404762  0.8928571429  0.9389880952  0.8750000000  0.9255952381  0.8750000000  0.9449404762  0.8988095238  0.6083333333  26.190476190  0.1227928016  0.2996225092  0.0604653358  550           0.1800757885 
0.9523809524  0.9285714286  0.9553571429  0.8988095238  0.9389880952  0.8988095238  0.9523809524  0.8750000000  0.5666666667  28.571428571  0.1205876651  0.2684695089  0.0604662895  600           0.1759762001 
0.9598214286  0.9345238095  0.9538690476  0.8988095238  0.9657738095  0.8928571429  0.9642857143  0.8988095238  0.6261904762  30.952380952  0.1359950697  0.2322977510  0.0605120659  650           0.1752088356 
0.9791666667  0.9345238095  0.9732142857  0.9166666667  0.9732142857  0.9226190476  0.9717261905  0.9047619048  0.5750000000  33.333333333  0.1176731513  0.1974597418  0.0605120659  700           0.1700309277 
0.9791666667  0.9107142857  0.9732142857  0.9166666667  0.9776785714  0.9166666667  0.9776785714  0.9047619048  0.5976190476  35.714285714  0.1043520103  0.1741472694  0.0605120659  750           0.1739976025 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1982, in update
    gap = -self.hparams['t_lambda'] * self.loss_gap(minibatches, self, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1950, in loss_gap
    p = model.adv_classifier(model.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 94, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 1753, in linear
    return torch._C._nn.linear(input, weight, bias)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2857142857  0.2559523810  0.2946428571  0.2619047619  0.2589285714  0.2976190476  0.2723214286  0.2738095238  0.2797619048  0.0000000000  0.1090677977  1.4120990038  0.0563254356  0             0.5029013157 
0.6458333333  0.6369047619  0.6502976190  0.6428571429  0.6860119048  0.6785714286  0.6547619048  0.6428571429  0.5714285714  2.3809523810  0.0767424655  1.3109350538  0.0604491234  50            0.1749834108 
0.6815476190  0.6369047619  0.6666666667  0.6488095238  0.7053571429  0.6904761905  0.6666666667  0.7083333333  0.5976190476  4.7619047619  0.1038577580  1.0606568718  0.0604491234  100           0.1759731102 
0.7529761905  0.6845238095  0.7142857143  0.7023809524  0.7559523810  0.7380952381  0.7976190476  0.7321428571  0.6285714286  7.1428571429  0.1429357278  0.8472729719  0.0607929230  150           0.1734412289 
0.7842261905  0.7738095238  0.7961309524  0.7738095238  0.7961309524  0.7500000000  0.7738095238  0.7619047619  0.6250000000  9.5238095238  0.1483408308  0.7217072439  0.0607929230  200           0.1835566807 
0.8229166667  0.8095238095  0.8125000000  0.7797619048  0.8139880952  0.7976190476  0.8154761905  0.8035714286  0.6452380952  11.904761904  0.1399695683  0.6483961558  0.0607929230  250           0.1714746475 
0.8437500000  0.8511904762  0.8452380952  0.7916666667  0.8422619048  0.8214285714  0.8407738095  0.8273809524  0.6821428571  14.285714285  0.1361006457  0.5837614816  0.0607929230  300           0.1689708757 
0.8571428571  0.8571428571  0.8541666667  0.8273809524  0.8645833333  0.8630952381  0.8690476190  0.8452380952  0.7130952381  16.666666666  0.1373012829  0.5276889074  0.0607929230  350           0.1681281614 
0.9211309524  0.8571428571  0.9107142857  0.8511904762  0.9151785714  0.8392857143  0.9136904762  0.8511904762  0.5940476190  19.047619047  0.1536531609  0.4751572120  0.0607929230  400           0.1662202311 
0.8735119048  0.8571428571  0.8824404762  0.8809523810  0.8571428571  0.8571428571  0.8675595238  0.8154761905  0.5738095238  21.428571428  0.1521438646  0.4307885092  0.0607929230  450           0.1725025511 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
KeyboardInterrupt
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2324183) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2323902) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2324183) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 1590, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__
  File "_pydevd_bundle/pydevd_cython.pyx", line 933, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2323902) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1132, in do_wait_suspend
    thread_stack_str = cmd.thread_stack_str  # @UnusedVariable -- `make_get_thread_stack_message` uses it later.
AttributeError: 'NetCommand' object has no attribute 'thread_stack_str'
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 1590, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__
  File "_pydevd_bundle/pydevd_cython.pyx", line 933, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1132, in do_wait_suspend
    thread_stack_str = cmd.thread_stack_str  # @UnusedVariable -- `make_get_thread_stack_message` uses it later.
AttributeError: 'NetCommand' object has no attribute 'thread_stack_str'
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2323749) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 1590, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__
  File "_pydevd_bundle/pydevd_cython.pyx", line 933, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2323749) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2339175) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 1590, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__
  File "_pydevd_bundle/pydevd_cython.pyx", line 933, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2339175) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2857142857  0.2559523810  0.2946428571  0.2619047619  0.2589285714  0.2976190476  0.2723214286  0.2738095238  0.2797619048  0.0000000000  0.1090677977  1.4120990038  0.0563254356  0             0.4971807003 
0.6458333333  0.6369047619  0.6502976190  0.6428571429  0.6860119048  0.6785714286  0.6547619048  0.6428571429  0.5714285714  2.3809523810  0.0767424655  1.3109350538  0.0604305267  50            0.1720393085 
0.6815476190  0.6369047619  0.6666666667  0.6488095238  0.7053571429  0.6904761905  0.6666666667  0.7083333333  0.5976190476  4.7619047619  0.1038577580  1.0606568718  0.0604486465  100           0.1711863899 
0.7529761905  0.6845238095  0.7142857143  0.7023809524  0.7559523810  0.7380952381  0.7976190476  0.7321428571  0.6285714286  7.1428571429  0.1429357278  0.8472729719  0.0604929924  150           0.1704929733 
0.7842261905  0.7738095238  0.7961309524  0.7738095238  0.7961309524  0.7500000000  0.7738095238  0.7619047619  0.6250000000  9.5238095238  0.1483408308  0.7217072439  0.0604929924  200           0.1742020559 
0.8229166667  0.8095238095  0.8125000000  0.7797619048  0.8139880952  0.7976190476  0.8154761905  0.8035714286  0.6452380952  11.904761904  0.1399695683  0.6483961558  0.0604929924  250           0.1689382362 
0.8437500000  0.8511904762  0.8452380952  0.7916666667  0.8422619048  0.8214285714  0.8407738095  0.8273809524  0.6821428571  14.285714285  0.1361006457  0.5837614816  0.0604929924  300           0.1728933907 
0.8571428571  0.8571428571  0.8541666667  0.8273809524  0.8645833333  0.8630952381  0.8690476190  0.8452380952  0.7130952381  16.666666666  0.1373012829  0.5276889074  0.0629491806  350           0.1684267712 
0.9211309524  0.8571428571  0.9107142857  0.8511904762  0.9151785714  0.8392857143  0.9136904762  0.8511904762  0.5940476190  19.047619047  0.1536531609  0.4751572120  0.0629491806  400           0.1701137590 
0.8735119048  0.8571428571  0.8824404762  0.8809523810  0.8571428571  0.8571428571  0.8675595238  0.8154761905  0.5738095238  21.428571428  0.1521438646  0.4307885092  0.0629491806  450           0.1740057564 
0.9449404762  0.8928571429  0.9285714286  0.8869047619  0.9017857143  0.8750000000  0.9270833333  0.8511904762  0.5547619048  23.809523809  0.1495554534  0.3748740280  0.0629491806  500           0.1663510418 
0.9375000000  0.9047619048  0.9226190476  0.8809523810  0.9107142857  0.8690476190  0.9300595238  0.8690476190  0.6107142857  26.190476190  0.1228302163  0.3142915064  0.0629491806  550           0.1696398306 
0.9479166667  0.9226190476  0.9479166667  0.8988095238  0.9255952381  0.8928571429  0.9375000000  0.8690476190  0.5738095238  28.571428571  0.1312704769  0.2888384235  0.0629491806  600           0.1720969200 
0.9583333333  0.9226190476  0.9523809524  0.8809523810  0.9508928571  0.8750000000  0.9523809524  0.8869047619  0.6166666667  30.952380952  0.1488638225  0.2565051857  0.0629491806  650           0.1691984415 
0.9538690476  0.9166666667  0.9508928571  0.9107142857  0.9464285714  0.9226190476  0.9479166667  0.8869047619  0.5464285714  33.333333333  0.1297726589  0.2184622136  0.0629491806  700           0.1743248415 
0.9776785714  0.9226190476  0.9613095238  0.9107142857  0.9702380952  0.9226190476  0.9717261905  0.8988095238  0.6071428571  35.714285714  0.1177410406  0.1908589116  0.0634050369  750           0.1755806446 
0.9776785714  0.9107142857  0.9553571429  0.9285714286  0.9687500000  0.9285714286  0.9732142857  0.9107142857  0.5785714286  38.095238095  0.0988523880  0.1699875638  0.0634050369  800           0.1703472281 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    self.adv_classifier = self.proj(self.hparams['delta'], self.adv_classifier, self.classifier)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1935, in proj
    dist = self.distance(adv_h, h)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1929, in distance
    dist += torch.norm(h1_param - h2_param) ** 2  # use Frobenius norms for matrices
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: True
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2485119048  0.2261904762  0.2500000000  0.2559523810  0.2470238095  0.2678571429  0.2425595238  0.2202380952  0.2452380952  0.0000000000  0.0926939249  1.4120990038  0.0539793968  0             0.4847638607 
0.2440476190  0.2202380952  0.2514880952  0.2559523810  0.2440476190  0.2619047619  0.2410714286  0.2142857143  0.2440476190  2.3809523810  0.1206574488  1.4351828551  0.0557417870  50            0.1673014498 
0.2455357143  0.2202380952  0.2514880952  0.2500000000  0.2395833333  0.2678571429  0.2410714286  0.2142857143  0.2380952381  4.7619047619  0.1133295131  1.4405762148  0.0557417870  100           0.1729650831 
0.2455357143  0.2261904762  0.2529761905  0.2559523810  0.2455357143  0.2619047619  0.2425595238  0.2202380952  0.2452380952  7.1428571429  0.0995846510  1.4392316294  0.0557417870  150           0.1749645424 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: True
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2470238095  0.2261904762  0.2500000000  0.2559523810  0.2470238095  0.2678571429  0.2425595238  0.2202380952  0.2452380952  0.0000000000  0.0924161673  1.4120990038  0.0539793968  0             0.5176935196 
0.2589285714  0.1964285714  0.2529761905  0.2559523810  0.2425595238  0.2738095238  0.2380952381  0.2142857143  0.2476190476  2.3809523810  0.1145798635  1.4304619694  0.0557408333  50            0.1740496778 
0.2708333333  0.2202380952  0.2633928571  0.2261904762  0.2514880952  0.2738095238  0.2440476190  0.2619047619  0.2464285714  4.7619047619  0.0964358497  1.4273868871  0.0557408333  100           0.1733646917 
0.2738095238  0.2142857143  0.2693452381  0.2321428571  0.2440476190  0.2619047619  0.2380952381  0.2678571429  0.2547619048  7.1428571429  0.0837219071  1.4205556130  0.0557575226  150           0.1727367449 
0.2827380952  0.2321428571  0.2619047619  0.2559523810  0.2485119048  0.2678571429  0.2351190476  0.2738095238  0.2464285714  9.5238095238  0.0854501343  1.4108636189  0.0558032990  200           0.1730616808 
0.2723214286  0.2261904762  0.2604166667  0.2500000000  0.2470238095  0.2678571429  0.2217261905  0.2797619048  0.2416666667  11.904761904  0.0812705469  1.4088992047  0.0558032990  250           0.1764376402 
0.2782738095  0.2142857143  0.2604166667  0.2559523810  0.2619047619  0.2440476190  0.2261904762  0.2797619048  0.2476190476  14.285714285  0.0807606125  1.4083805084  0.0558032990  300           0.1697050571 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 34, in poll
    break
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 34, in poll
    break
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_trace_dispatch.py", line 59, in trace_dispatch
    return _trace_dispatch(py_db, frame, event, arg)
  File "_pydevd_bundle/pydevd_cython.pyx", line 1324, in _pydevd_bundle.pydevd_cython.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 1207, in _pydevd_bundle.pydevd_cython.fix_top_level_trace_and_get_trace_func
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 123, in splitext
    if isinstance(p, bytes):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
    return filename_to_in_scope_cache[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/pytest-lazy-fixture'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 230, in _NormPaths
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/pytest-lazy-fixture'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
    if debugger.in_project_scope(filename) and '_pydevd' not in filename:
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
    return pydevd_utils.in_project_roots(filename)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
    library_roots = _get_library_roots()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 391, in realpath
    def realpath(filename):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
RuntimeError: DataLoader worker (pid 2371764) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2372023) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: True
	lr: 0.0005
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2470238095  0.2261904762  0.2529761905  0.2559523810  0.2425595238  0.2738095238  0.2455357143  0.2202380952  0.2464285714  0.0000000000  0.0905129910  1.4120990038  0.0539793968  0             0.4991893768 
0.3125000000  0.2380952381  0.2529761905  0.2797619048  0.2827380952  0.2083333333  0.2604166667  0.2738095238  0.2357142857  2.3809523810  0.0825411439  1.4095502257  0.0557584763  50            0.1688213587 
0.3392857143  0.3154761905  0.2991071429  0.2738095238  0.3139880952  0.2619047619  0.3095238095  0.3095238095  0.2559523810  4.7619047619  0.0556115007  1.3917858458  0.0557584763  100           0.1705496073 
0.3616071429  0.3392857143  0.3199404762  0.3214285714  0.3392857143  0.2678571429  0.3303571429  0.3095238095  0.2845238095  7.1428571429  0.0628750014  1.3793066692  0.0557584763  150           0.1718467808 
0.4211309524  0.3630952381  0.3824404762  0.4107142857  0.4211309524  0.3095238095  0.3750000000  0.3392857143  0.3345238095  9.5238095238  0.0607324648  1.3627733660  0.0557584763  200           0.1698827028 
0.4181547619  0.3392857143  0.4017857143  0.4047619048  0.4449404762  0.4345238095  0.3958333333  0.3869047619  0.3500000000  11.904761904  0.0600800133  1.3525732303  0.0557584763  250           0.1724615908 
0.4851190476  0.4345238095  0.4523809524  0.4880952381  0.5074404762  0.4702380952  0.4702380952  0.4583333333  0.4369047619  14.285714285  0.0578822255  1.3382519531  0.0587081909  300           0.1689174461 
0.4568452381  0.4047619048  0.4300595238  0.4880952381  0.4732142857  0.4404761905  0.4479166667  0.4583333333  0.3928571429  16.666666666  0.0559119582  1.3264432120  0.0587081909  350           0.1700358009 
0.5491071429  0.4880952381  0.5208333333  0.5654761905  0.5684523810  0.5476190476  0.5416666667  0.5059523810  0.4761904762  19.047619047  0.0626888752  1.3139194751  0.0587081909  400           0.1710279560 
0.5848214286  0.5238095238  0.5520833333  0.6071428571  0.6041666667  0.5297619048  0.5654761905  0.5476190476  0.5392857143  21.428571428  0.0594893074  1.2977827024  0.0587081909  450           0.1716619349 
0.5848214286  0.5357142857  0.5684523810  0.6250000000  0.6160714286  0.5952380952  0.5967261905  0.5357142857  0.5464285714  23.809523809  0.0671602058  1.2765273666  0.0587081909  500           0.1696706057 
0.6339285714  0.5952380952  0.6279761905  0.6666666667  0.6369047619  0.6488095238  0.6324404762  0.6011904762  0.5702380952  26.190476190  0.0706684947  1.2512950230  0.0587081909  550           0.1697533751 
0.6547619048  0.6011904762  0.6577380952  0.6488095238  0.6681547619  0.6547619048  0.6488095238  0.6488095238  0.5690476190  28.571428571  0.0735251331  1.2344951868  0.0587081909  600           0.1737460184 
0.6651785714  0.6130952381  0.6577380952  0.6666666667  0.6741071429  0.6666666667  0.6681547619  0.6428571429  0.5750000000  30.952380952  0.0775752854  1.2075799704  0.0587081909  650           0.1697912645 
0.6696428571  0.6369047619  0.6860119048  0.6845238095  0.6830357143  0.6607142857  0.6562500000  0.5952380952  0.5571428571  33.333333333  0.0763726497  1.1784306049  0.0587081909  700           0.1719068718 
0.6785714286  0.6309523810  0.6815476190  0.6964285714  0.6726190476  0.6666666667  0.6815476190  0.6785714286  0.5809523810  35.714285714  0.0708423996  1.1487813187  0.0587081909  750           0.1706017160 
0.6726190476  0.6369047619  0.6845238095  0.6845238095  0.6741071429  0.6666666667  0.6755952381  0.6488095238  0.5833333333  38.095238095  0.0886115098  1.1207426405  0.0587081909  800           0.1709996128 
0.6785714286  0.6369047619  0.6815476190  0.6726190476  0.6815476190  0.7023809524  0.6919642857  0.6666666667  0.6023809524  40.476190476  0.0845232058  1.0896136069  0.0587081909  850           0.1677608061 
0.6681547619  0.6369047619  0.6711309524  0.6666666667  0.6830357143  0.6845238095  0.6741071429  0.6607142857  0.6035714286  42.857142857  0.1008101749  1.0618793607  0.0587081909  900           0.1705999994 
0.6830357143  0.6428571429  0.6860119048  0.6785714286  0.6800595238  0.7023809524  0.6785714286  0.6666666667  0.5880952381  45.238095238  0.0954517090  1.0302485228  0.0587081909  950           0.1678214836 
0.6800595238  0.6428571429  0.6770833333  0.6904761905  0.6815476190  0.6904761905  0.6696428571  0.6726190476  0.5857142857  47.619047619  0.1024922311  0.9872880268  0.0587081909  1000          0.1719472933 
0.6711309524  0.6785714286  0.6830357143  0.6726190476  0.7053571429  0.7023809524  0.6949404762  0.6666666667  0.6095238095  50.000000000  0.1064350832  0.9720906019  0.0587081909  1050          0.1731643867 
0.6741071429  0.6369047619  0.6696428571  0.6666666667  0.6815476190  0.6726190476  0.6651785714  0.6547619048  0.5940476190  52.380952381  0.1064581001  0.9344277143  0.0587081909  1100          0.1708037424 
0.6666666667  0.6488095238  0.6592261905  0.6547619048  0.6696428571  0.6666666667  0.6696428571  0.6488095238  0.5940476190  54.761904761  0.1342895424  0.8954203987  0.0587081909  1150          0.1861544561 
0.6696428571  0.6547619048  0.6785714286  0.6904761905  0.6875000000  0.6785714286  0.6875000000  0.6726190476  0.6000000000  57.142857142  0.1190176737  0.8853539920  0.0587081909  1200          0.1759750605 
0.6696428571  0.6488095238  0.6755952381  0.6785714286  0.6949404762  0.7142857143  0.6889880952  0.6904761905  0.6047619048  59.523809523  0.1239662313  0.8675702322  0.0587081909  1250          0.1814003706 
0.6726190476  0.6547619048  0.6726190476  0.6785714286  0.6919642857  0.6904761905  0.6845238095  0.6785714286  0.5964285714  61.904761904  0.1330066741  0.8507161987  0.0587081909  1300          0.1805158472 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: True
	lr: 0.001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2514880952  0.2321428571  0.2574404762  0.2559523810  0.2440476190  0.2678571429  0.2455357143  0.2142857143  0.2500000000  0.0000000000  0.0886206627  1.4120990038  0.0539793968  0             0.4984073639 
0.3363095238  0.2916666667  0.3005952381  0.3095238095  0.3020833333  0.2559523810  0.3035714286  0.2916666667  0.2488095238  2.3809523810  0.0708020043  1.3993802381  0.0557417870  50            0.1694094896 
0.3720238095  0.3392857143  0.3348214286  0.3214285714  0.3630952381  0.3392857143  0.3616071429  0.3630952381  0.3154761905  4.7619047619  0.0542633772  1.3727298713  0.0557584763  100           0.1724458981 
0.4642857143  0.4404761905  0.4404761905  0.4761904762  0.5014880952  0.4404761905  0.4761904762  0.4702380952  0.4261904762  7.1428571429  0.0619911480  1.3485633540  0.0557584763  150           0.1741976595 
0.5773809524  0.5595238095  0.5431547619  0.5595238095  0.5937500000  0.5357142857  0.5669642857  0.4880952381  0.5250000000  9.5238095238  0.0616706276  1.3151641083  0.0558199883  200           0.1759778643 
0.5997023810  0.5476190476  0.5714285714  0.5416666667  0.6205357143  0.5892857143  0.6354166667  0.5654761905  0.5333333333  11.904761904  0.0665927458  1.2875522947  0.0558199883  250           0.1775486612 
0.6800595238  0.6071428571  0.6607142857  0.6666666667  0.6919642857  0.6607142857  0.6785714286  0.6250000000  0.5678571429  14.285714285  0.0659829021  1.2438776541  0.0558376312  300           0.1751905680 
0.6830357143  0.6130952381  0.6592261905  0.6547619048  0.6726190476  0.6964285714  0.6741071429  0.6726190476  0.5702380952  16.666666666  0.0716354942  1.1988514638  0.0558376312  350           0.1788995171 
0.6815476190  0.6309523810  0.6994047619  0.6726190476  0.6919642857  0.7083333333  0.6904761905  0.6726190476  0.5845238095  19.047619047  0.0876778221  1.1375429463  0.0558376312  400           0.1758456326 
0.6622023810  0.6071428571  0.6875000000  0.6726190476  0.6830357143  0.6666666667  0.6577380952  0.6607142857  0.5619047619  21.428571428  0.0921309698  1.0845585489  0.0558376312  450           0.1811949587 
0.6741071429  0.6488095238  0.6875000000  0.6607142857  0.6964285714  0.6785714286  0.6800595238  0.6607142857  0.5940476190  23.809523809  0.1025984800  1.0150552142  0.0558376312  500           0.1774587917 
0.6696428571  0.6369047619  0.6785714286  0.6607142857  0.6904761905  0.6607142857  0.6815476190  0.6607142857  0.5952380952  26.190476190  0.1065717292  0.9400210989  0.0558376312  550           0.1761564636 
0.6532738095  0.6607142857  0.6711309524  0.6488095238  0.6830357143  0.6666666667  0.6622023810  0.6547619048  0.5952380952  28.571428571  0.0992655861  0.9158150351  0.0558376312  600           0.1790539980 
0.6979166667  0.6488095238  0.6994047619  0.7023809524  0.7172619048  0.7083333333  0.7023809524  0.6726190476  0.6095238095  30.952380952  0.1240942240  0.8741693509  0.0558376312  650           0.1796551991 
0.6562500000  0.6369047619  0.6547619048  0.6547619048  0.6726190476  0.6726190476  0.6592261905  0.6428571429  0.5773809524  33.333333333  0.1260264182  0.8309711123  0.0558376312  700           0.1837118149 
0.7306547619  0.7142857143  0.7306547619  0.7261904762  0.7514880952  0.7380952381  0.7514880952  0.7321428571  0.6333333333  35.714285714  0.1059215939  0.7979354322  0.0558376312  750           0.1756367826 
0.7202380952  0.6964285714  0.7261904762  0.6904761905  0.7351190476  0.7202380952  0.7366071429  0.7142857143  0.6202380952  38.095238095  0.1128760874  0.7795167899  0.0558376312  800           0.1797281742 
0.7425595238  0.7142857143  0.7425595238  0.7261904762  0.7619047619  0.7380952381  0.7500000000  0.7202380952  0.6273809524  40.476190476  0.1192464328  0.7582980096  0.0558853149  850           0.1820158148 
0.7232142857  0.7023809524  0.7291666667  0.7202380952  0.7410714286  0.7202380952  0.7291666667  0.7023809524  0.6035714286  42.857142857  0.1295961964  0.7468735588  0.0558862686  900           0.1836797571 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2559523810  0.2455357143  0.2202380952  0.2366071429  0.2500000000  0.2351190476  0.2142857143  0.2500000000  0.0000000000  4.2432036400  0.1006202698  0             0.3809635639 
0.4360119048  0.3750000000  0.4017857143  0.3630952381  0.4047619048  0.3392857143  0.3660714286  0.4047619048  0.3714285714  2.3809523810  4.1748859262  0.2653427124  50            0.0605949688 
0.5788690476  0.5297619048  0.5312500000  0.5654761905  0.5625000000  0.5595238095  0.5401785714  0.4940476190  0.5130952381  4.7619047619  3.9855802250  0.2653427124  100           0.0615608072 
0.6622023810  0.6488095238  0.6473214286  0.6488095238  0.6830357143  0.6369047619  0.6175595238  0.6190476190  0.5583333333  7.1428571429  3.7688214064  0.2653427124  150           0.0597862577 
0.6904761905  0.6726190476  0.6800595238  0.6607142857  0.7113095238  0.6785714286  0.6488095238  0.6130952381  0.5690476190  9.5238095238  3.4765828991  0.2653603554  200           0.0612465143 
0.7127976190  0.6666666667  0.7098214286  0.6785714286  0.7217261905  0.7142857143  0.6889880952  0.6726190476  0.5690476190  11.904761904  3.0738410378  0.2653603554  250           0.0597418165 
0.7261904762  0.6904761905  0.7261904762  0.7142857143  0.7470238095  0.7738095238  0.7172619048  0.7202380952  0.6071428571  14.285714285  2.8220202875  0.2653603554  300           0.0605505276 
0.7485119048  0.7083333333  0.7366071429  0.7023809524  0.7574404762  0.7559523810  0.7336309524  0.7142857143  0.6333333333  16.666666666  2.5993496037  0.2653603554  350           0.0600209951 
0.7767857143  0.7321428571  0.7723214286  0.7440476190  0.8005952381  0.8035714286  0.7619047619  0.7678571429  0.6321428571  19.047619047  2.4248070717  0.2653603554  400           0.0611975098 
0.7812500000  0.7559523810  0.7872023810  0.7500000000  0.8139880952  0.8214285714  0.7842261905  0.7857142857  0.6571428571  21.428571428  2.2673595405  0.2653603554  450           0.0615067482 
0.7961309524  0.7619047619  0.8080357143  0.7738095238  0.8273809524  0.8333333333  0.7961309524  0.8154761905  0.6488095238  23.809523809  2.1618327117  0.2653603554  500           0.0610145998 
0.8095238095  0.7738095238  0.8110119048  0.7797619048  0.8377976190  0.8214285714  0.7991071429  0.8214285714  0.6464285714  26.190476190  2.0210743809  0.2653603554  550           0.0621270609 
0.8229166667  0.8095238095  0.8214285714  0.8035714286  0.8437500000  0.8333333333  0.8139880952  0.8511904762  0.6511904762  28.571428571  2.0041569924  0.2653603554  600           0.0605801392 
0.8348214286  0.8333333333  0.8333333333  0.8095238095  0.8541666667  0.8273809524  0.8288690476  0.8511904762  0.6583333333  30.952380952  1.9410879469  0.2653603554  650           0.0594721556 
0.8467261905  0.8392857143  0.8348214286  0.8154761905  0.8630952381  0.8392857143  0.8377976190  0.8511904762  0.6726190476  33.333333333  1.8434048271  0.2653603554  700           0.0598021078 
0.8318452381  0.8333333333  0.8348214286  0.8214285714  0.8586309524  0.8273809524  0.8303571429  0.8392857143  0.6500000000  35.714285714  1.7987796307  0.2653603554  750           0.0592234802 
0.8348214286  0.8333333333  0.8377976190  0.8214285714  0.8705357143  0.8630952381  0.8392857143  0.8333333333  0.6750000000  38.095238095  1.6664311719  0.2653603554  800           0.0602687883 
0.8526785714  0.8511904762  0.8482142857  0.8273809524  0.8705357143  0.8392857143  0.8511904762  0.8452380952  0.6750000000  40.476190476  1.5949444389  0.2653603554  850           0.0609697294 
0.8556547619  0.8511904762  0.8511904762  0.8154761905  0.8794642857  0.8511904762  0.8526785714  0.8392857143  0.6750000000  42.857142857  1.6198873162  0.2653603554  900           0.0621685266 
0.8601190476  0.8571428571  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8571428571  0.8452380952  0.6785714286  45.238095238  1.5103637481  0.2653603554  950           0.0620573997 
0.8630952381  0.8452380952  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8735119048  0.8571428571  0.6964285714  47.619047619  1.4238694859  0.2653603554  1000          0.0617701626 
0.8720238095  0.8571428571  0.8571428571  0.8273809524  0.8854166667  0.8690476190  0.8735119048  0.8571428571  0.6821428571  50.000000000  1.4215958619  0.2653603554  1050          0.0628167343 
0.8809523810  0.8750000000  0.8586309524  0.8392857143  0.8824404762  0.8690476190  0.8794642857  0.8392857143  0.6464285714  52.380952381  1.3599819136  0.2654051781  1100          0.0613064528 
0.8839285714  0.8809523810  0.8645833333  0.8511904762  0.8839285714  0.8690476190  0.8854166667  0.8630952381  0.6666666667  54.761904761  1.2630624235  0.2654051781  1150          0.0603938770 
0.8898809524  0.8809523810  0.8854166667  0.8452380952  0.8854166667  0.8571428571  0.8898809524  0.8392857143  0.6261904762  57.142857142  1.2216589046  0.2654051781  1200          0.0600447512 
0.8883928571  0.8869047619  0.8720238095  0.8452380952  0.8898809524  0.8630952381  0.8913690476  0.8690476190  0.6750000000  59.523809523  1.1974547815  0.2654051781  1250          0.0626679897 
0.8943452381  0.8928571429  0.8809523810  0.8690476190  0.8898809524  0.8690476190  0.8928571429  0.8571428571  0.6130952381  61.904761904  1.1354165912  0.2654051781  1300          0.0622710180 
0.8958333333  0.8869047619  0.8764880952  0.8571428571  0.8928571429  0.8630952381  0.8958333333  0.8630952381  0.6607142857  64.285714285  1.0966089582  0.2654051781  1350          0.0632659912 
0.9136904762  0.8869047619  0.8988095238  0.8571428571  0.9107142857  0.8690476190  0.9032738095  0.8571428571  0.6285714286  66.666666666  1.0762026703  0.2654051781  1400          0.0601807737 
0.9270833333  0.8869047619  0.9181547619  0.8630952381  0.9166666667  0.8690476190  0.9092261905  0.8571428571  0.5880952381  69.047619047  0.9852190566  0.2654051781  1450          0.0612097406 
0.9196428571  0.8869047619  0.9092261905  0.8630952381  0.9181547619  0.8750000000  0.9092261905  0.8690476190  0.6297619048  71.428571428  0.9552123129  0.2654051781  1500          0.0608670855 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2589285714  0.2559523810  0.2529761905  0.2619047619  0.2619047619  0.2619047619  0.2574404762  0.2619047619  0.2523809524  0.0000000000  4.2432036400  0.1006202698  0             0.3968605995 
0.8750000000  0.8988095238  0.8630952381  0.8392857143  0.8735119048  0.8750000000  0.8794642857  0.8869047619  0.7011904762  2.3809523810  2.0587791228  0.2653427124  50            0.0613334179 
0.9642857143  0.9285714286  0.9538690476  0.9404761905  0.9613095238  0.9226190476  0.9613095238  0.9464285714  0.5904761905  4.7619047619  0.7559245276  0.2653427124  100           0.0605942202 
0.9910714286  0.9642857143  0.9851190476  0.9464285714  0.9970238095  0.9642857143  0.9880952381  0.9642857143  0.5880952381  7.1428571429  0.3857739460  0.2653427124  150           0.0612256622 
0.9955357143  0.9464285714  0.9955357143  0.9702380952  1.0000000000  0.9702380952  0.9985119048  0.9821428571  0.6119047619  9.5238095238  0.1911753768  0.2653427124  200           0.0608860779 
0.9970238095  0.9702380952  0.9940476190  0.9761904762  1.0000000000  0.9761904762  0.9940476190  0.9583333333  0.6357142857  11.904761904  0.1454765240  0.2653427124  250           0.0614889717 
1.0000000000  0.9821428571  0.9970238095  0.9821428571  1.0000000000  0.9642857143  1.0000000000  0.9821428571  0.5773809524  14.285714285  0.1197839643  0.2653427124  300           0.0615336704 
1.0000000000  0.9821428571  1.0000000000  0.9821428571  1.0000000000  0.9821428571  0.9985119048  0.9821428571  0.5845238095  16.666666666  0.0725650797  0.2653427124  350           0.0617153120 
0.9985119048  0.9821428571  0.9985119048  0.9821428571  0.9985119048  0.9821428571  0.9985119048  0.9821428571  0.5845238095  19.047619047  0.1156875419  0.2653427124  400           0.0613074493 
0.9910714286  0.9404761905  0.9910714286  0.9523809524  0.9940476190  0.9702380952  0.9970238095  0.9761904762  0.6142857143  21.428571428  0.2110672346  0.2653427124  450           0.0609807158 
1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  0.9821428571  1.0000000000  0.9821428571  0.5714285714  23.809523809  0.0845914430  0.2653594017  500           0.0609509230 
1.0000000000  0.9702380952  1.0000000000  0.9880952381  1.0000000000  0.9702380952  1.0000000000  0.9761904762  0.5666666667  26.190476190  0.0437216798  0.2653594017  550           0.0611398220 
1.0000000000  0.9642857143  1.0000000000  0.9583333333  1.0000000000  0.9880952381  1.0000000000  0.9761904762  0.6226190476  28.571428571  0.0302892025  0.2654051781  600           0.0612641239 
1.0000000000  0.9583333333  1.0000000000  0.9583333333  1.0000000000  0.9583333333  0.9985119048  0.9821428571  0.5273809524  30.952380952  0.0556546801  0.2654051781  650           0.0612294245 
1.0000000000  0.9761904762  1.0000000000  0.9821428571  1.0000000000  0.9880952381  1.0000000000  0.9821428571  0.6250000000  33.333333333  0.0443387964  0.2654051781  700           0.0612489128 
0.9925595238  0.9226190476  0.9866071429  0.9464285714  0.9955357143  0.9702380952  0.9955357143  0.9761904762  0.5904761905  35.714285714  0.0396017646  0.2654051781  750           0.0619411278 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2257, in update
    temp_old_featurizer = networks.CNN(pretrained=False, in_channel=self.input_shape[0], out_channel=self.num_classes).cuda()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 273, in __init__
    nn.Linear(64*32, 256),   # (64*64, 256)cwru   (64*64,1024)pu
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 84, in __init__
    self.reset_parameters()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in reset_parameters
    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/init.py", line 379, in kaiming_uniform_
    return tensor.uniform_(-bound, bound)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2559523810  0.2619047619  0.2574404762  0.2440476190  0.2514880952  0.2559523810  0.2500000000  0.2619047619  0.2511904762  0.0000000000  4.2432036400  0.1006202698  0             0.3791394234 
0.7470238095  0.7738095238  0.7604166667  0.7500000000  0.7916666667  0.7678571429  0.7589285714  0.7261904762  0.6535714286  2.3809523810  3.2844169807  0.2653427124  50            0.0607485294 
0.8258928571  0.8273809524  0.8288690476  0.8095238095  0.8556547619  0.8035714286  0.8244047619  0.8095238095  0.6702380952  4.7619047619  1.9680056000  0.2653427124  100           0.0594687557 
0.8898809524  0.8809523810  0.8824404762  0.8452380952  0.9002976190  0.8690476190  0.9032738095  0.8511904762  0.6297619048  7.1428571429  1.4719681215  0.2653427124  150           0.0604017878 
0.9642857143  0.9047619048  0.9449404762  0.8869047619  0.9583333333  0.8809523810  0.9449404762  0.8869047619  0.5678571429  9.5238095238  1.0624264216  0.2653427124  200           0.0602456617 
0.9747023810  0.9166666667  0.9642857143  0.8928571429  0.9702380952  0.9107142857  0.9613095238  0.9166666667  0.5880952381  11.904761904  0.7372862625  0.2653427124  250           0.0595020533 
0.9880952381  0.9404761905  0.9732142857  0.9345238095  0.9866071429  0.9166666667  0.9702380952  0.9345238095  0.5880952381  14.285714285  0.5887559426  0.2653427124  300           0.0605706072 
0.9806547619  0.9226190476  0.9821428571  0.9226190476  0.9880952381  0.9404761905  0.9702380952  0.9345238095  0.5797619048  16.666666666  0.4256147972  0.2653427124  350           0.0605397463 
0.9925595238  0.9523809524  0.9955357143  0.9345238095  0.9940476190  0.9404761905  0.9821428571  0.9464285714  0.6011904762  19.047619047  0.3410130098  0.2653427124  400           0.0604400396 
0.9940476190  0.9702380952  0.9955357143  0.9523809524  0.9925595238  0.9464285714  0.9880952381  0.9642857143  0.6000000000  21.428571428  0.2532823531  0.2653427124  450           0.0601721668 
0.9925595238  0.9523809524  0.9895833333  0.9345238095  0.9925595238  0.9583333333  0.9866071429  0.9523809524  0.6107142857  23.809523809  0.1963867992  0.2653427124  500           0.0604322815 
0.9970238095  0.9702380952  0.9985119048  0.9523809524  0.9985119048  0.9761904762  0.9925595238  0.9642857143  0.5809523810  26.190476190  0.1557773139  0.2653427124  550           0.0620240021 
0.9955357143  0.9642857143  0.9985119048  0.9523809524  0.9985119048  0.9702380952  0.9895833333  0.9583333333  0.5738095238  28.571428571  0.1398392516  0.2653427124  600           0.0604280901 
0.9985119048  0.9761904762  1.0000000000  0.9642857143  0.9985119048  0.9702380952  0.9940476190  0.9761904762  0.5869047619  30.952380952  0.1184653673  0.2653427124  650           0.0603537750 
0.9985119048  0.9761904762  1.0000000000  0.9702380952  0.9985119048  0.9702380952  0.9970238095  0.9761904762  0.5785714286  33.333333333  0.0949967365  0.2653603554  700           0.0620722961 
0.9985119048  0.9761904762  1.0000000000  0.9583333333  1.0000000000  0.9583333333  1.0000000000  0.9761904762  0.6095238095  35.714285714  0.0909016535  0.2653603554  750           0.0612966919 
0.9985119048  0.9702380952  1.0000000000  0.9761904762  1.0000000000  0.9821428571  0.9955357143  0.9702380952  0.5940476190  38.095238095  0.0759453064  0.2653603554  800           0.0623092270 
1.0000000000  0.9702380952  1.0000000000  0.9642857143  1.0000000000  0.9464285714  1.0000000000  0.9702380952  0.6011904762  40.476190476  0.0631859614  0.2653603554  850           0.0615699339 
1.0000000000  0.9761904762  1.0000000000  0.9642857143  1.0000000000  0.9761904762  1.0000000000  0.9761904762  0.6095238095  42.857142857  0.0486972424  0.2653603554  900           0.0691878748 
1.0000000000  0.9761904762  1.0000000000  0.9642857143  1.0000000000  0.9702380952  1.0000000000  0.9821428571  0.6190476190  45.238095238  0.0591784140  0.2653603554  950           0.0620212173 
1.0000000000  0.9761904762  1.0000000000  0.9642857143  1.0000000000  0.9702380952  1.0000000000  0.9880952381  0.6119047619  47.619047619  0.0437680566  0.2653603554  1000          0.0613281822 
1.0000000000  0.9761904762  1.0000000000  0.9702380952  1.0000000000  0.9761904762  1.0000000000  0.9880952381  0.6166666667  50.000000000  0.0332305534  0.2653603554  1050          0.0694692659 
1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  0.9821428571  1.0000000000  0.9761904762  0.6154761905  52.380952381  0.0384420003  0.2653603554  1100          0.0629691935 
1.0000000000  0.9761904762  1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9761904762  0.5809523810  54.761904761  0.0366487449  0.2653603554  1150          0.0632653713 
1.0000000000  0.9761904762  1.0000000000  0.9642857143  1.0000000000  0.9642857143  1.0000000000  0.9821428571  0.5988095238  57.142857142  0.0255051835  0.2653603554  1200          0.0645156908 
1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  0.9821428571  1.0000000000  0.9880952381  0.6250000000  59.523809523  0.0306269789  0.2653603554  1250          0.0632780600 
1.0000000000  0.9761904762  1.0000000000  0.9702380952  1.0000000000  0.9702380952  1.0000000000  0.9821428571  0.5916666667  61.904761904  0.0265163014  0.2653603554  1300          0.0616439486 
1.0000000000  0.9761904762  1.0000000000  0.9583333333  1.0000000000  0.9702380952  1.0000000000  0.9880952381  0.6059523810  64.285714285  0.0251532598  0.2653603554  1350          0.0615696144 
1.0000000000  0.9880952381  1.0000000000  0.9821428571  1.0000000000  0.9761904762  1.0000000000  0.9821428571  0.6071428571  66.666666666  0.0251747046  0.2653603554  1400          0.0618769360 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2216, in update
    meta_train_loss_main.backward(retain_graph=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2559523810  0.2455357143  0.2202380952  0.2366071429  0.2500000000  0.2351190476  0.2142857143  0.2500000000  0.0000000000  4.2432036400  0.1006202698  0             0.3735048771 
0.4360119048  0.3750000000  0.4017857143  0.3630952381  0.4047619048  0.3392857143  0.3660714286  0.4047619048  0.3714285714  2.3809523810  4.1748859262  0.2653427124  50            0.0598563194 
0.5788690476  0.5297619048  0.5312500000  0.5654761905  0.5625000000  0.5595238095  0.5401785714  0.4940476190  0.5130952381  4.7619047619  3.9855802250  0.2653594017  100           0.0606115723 
0.6622023810  0.6488095238  0.6473214286  0.6488095238  0.6830357143  0.6369047619  0.6175595238  0.6190476190  0.5583333333  7.1428571429  3.7688214064  0.2653594017  150           0.0597165203 
0.6904761905  0.6726190476  0.6800595238  0.6607142857  0.7113095238  0.6785714286  0.6488095238  0.6130952381  0.5690476190  9.5238095238  3.4765828991  0.2653770447  200           0.0588771152 
0.7127976190  0.6666666667  0.7098214286  0.6785714286  0.7217261905  0.7142857143  0.6889880952  0.6726190476  0.5690476190  11.904761904  3.0738410378  0.2653770447  250           0.0605928898 
0.7261904762  0.6904761905  0.7261904762  0.7142857143  0.7470238095  0.7738095238  0.7172619048  0.7202380952  0.6071428571  14.285714285  2.8220202875  0.2653770447  300           0.0606395340 
0.7485119048  0.7083333333  0.7366071429  0.7023809524  0.7574404762  0.7559523810  0.7336309524  0.7142857143  0.6333333333  16.666666666  2.5993496037  0.2653770447  350           0.0596155167 
0.7767857143  0.7321428571  0.7723214286  0.7440476190  0.8005952381  0.8035714286  0.7619047619  0.7678571429  0.6321428571  19.047619047  2.4248070717  0.2653770447  400           0.0600738716 
0.7812500000  0.7559523810  0.7872023810  0.7500000000  0.8139880952  0.8214285714  0.7842261905  0.7857142857  0.6571428571  21.428571428  2.2673595405  0.2653770447  450           0.0606320858 
0.7961309524  0.7619047619  0.8080357143  0.7738095238  0.8273809524  0.8333333333  0.7961309524  0.8154761905  0.6488095238  23.809523809  2.1618327117  0.2653770447  500           0.0601289034 
0.8095238095  0.7738095238  0.8110119048  0.7797619048  0.8377976190  0.8214285714  0.7991071429  0.8214285714  0.6464285714  26.190476190  2.0210743809  0.2653770447  550           0.0605142164 
0.8229166667  0.8095238095  0.8214285714  0.8035714286  0.8437500000  0.8333333333  0.8139880952  0.8511904762  0.6511904762  28.571428571  2.0041569924  0.2653770447  600           0.0593993759 
0.8348214286  0.8333333333  0.8333333333  0.8095238095  0.8541666667  0.8273809524  0.8288690476  0.8511904762  0.6583333333  30.952380952  1.9410879469  0.2653770447  650           0.0601044273 
0.8467261905  0.8392857143  0.8348214286  0.8154761905  0.8630952381  0.8392857143  0.8377976190  0.8511904762  0.6726190476  33.333333333  1.8434048271  0.2653770447  700           0.0597071362 
0.8318452381  0.8333333333  0.8348214286  0.8214285714  0.8586309524  0.8273809524  0.8303571429  0.8392857143  0.6500000000  35.714285714  1.7987796307  0.2653770447  750           0.0593417645 
0.8348214286  0.8333333333  0.8377976190  0.8214285714  0.8705357143  0.8630952381  0.8392857143  0.8333333333  0.6750000000  38.095238095  1.6664311719  0.2653770447  800           0.0600309896 
0.8526785714  0.8511904762  0.8482142857  0.8273809524  0.8705357143  0.8392857143  0.8511904762  0.8452380952  0.6750000000  40.476190476  1.5949444389  0.2653927803  850           0.0596830225 
0.8556547619  0.8511904762  0.8511904762  0.8154761905  0.8794642857  0.8511904762  0.8526785714  0.8392857143  0.6750000000  42.857142857  1.6198873162  0.2653927803  900           0.0595360374 
0.8601190476  0.8571428571  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8571428571  0.8452380952  0.6785714286  45.238095238  1.5103637481  0.2653927803  950           0.0606388903 
0.8630952381  0.8452380952  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8735119048  0.8571428571  0.6964285714  47.619047619  1.4238694859  0.2653927803  1000          0.0599181986 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2178, in update
    self.classifier.parameters(),
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 948, in __getattr__
    type(self).__name__, name))
AttributeError: 'FC' object has no attribute 'classifier'
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2559523810  0.2455357143  0.2202380952  0.2366071429  0.2500000000  0.2351190476  0.2142857143  0.2500000000  0.0000000000  4.2432036400  0.1006202698  0             0.3872702122 
0.4360119048  0.3750000000  0.4017857143  0.3630952381  0.4047619048  0.3392857143  0.3660714286  0.4047619048  0.3714285714  2.3809523810  4.1748859262  0.2653427124  50            0.0611762094 
0.5788690476  0.5297619048  0.5312500000  0.5654761905  0.5625000000  0.5595238095  0.5401785714  0.4940476190  0.5130952381  4.7619047619  3.9855802250  0.2653427124  100           0.0611125469 
0.6622023810  0.6488095238  0.6473214286  0.6488095238  0.6830357143  0.6369047619  0.6175595238  0.6190476190  0.5583333333  7.1428571429  3.7688214064  0.2653427124  150           0.0604779243 
0.6904761905  0.6726190476  0.6800595238  0.6607142857  0.7113095238  0.6785714286  0.6488095238  0.6130952381  0.5690476190  9.5238095238  3.4765828991  0.2653594017  200           0.0603076172 
0.7127976190  0.6666666667  0.7098214286  0.6785714286  0.7217261905  0.7142857143  0.6889880952  0.6726190476  0.5690476190  11.904761904  3.0738410378  0.2653594017  250           0.0602747154 
0.7261904762  0.6904761905  0.7261904762  0.7142857143  0.7470238095  0.7738095238  0.7172619048  0.7202380952  0.6071428571  14.285714285  2.8220202875  0.2653603554  300           0.0601851416 
0.7485119048  0.7083333333  0.7366071429  0.7023809524  0.7574404762  0.7559523810  0.7336309524  0.7142857143  0.6333333333  16.666666666  2.5993496037  0.2653603554  350           0.0606979609 
0.7767857143  0.7321428571  0.7723214286  0.7440476190  0.8005952381  0.8035714286  0.7619047619  0.7678571429  0.6321428571  19.047619047  2.4248070717  0.2653603554  400           0.0604748106 
0.7812500000  0.7559523810  0.7872023810  0.7500000000  0.8139880952  0.8214285714  0.7842261905  0.7857142857  0.6571428571  21.428571428  2.2673595405  0.2653603554  450           0.0604961300 
0.7961309524  0.7619047619  0.8080357143  0.7738095238  0.8273809524  0.8333333333  0.7961309524  0.8154761905  0.6488095238  23.809523809  2.1618327117  0.2653603554  500           0.0604896975 
0.8095238095  0.7738095238  0.8110119048  0.7797619048  0.8377976190  0.8214285714  0.7991071429  0.8214285714  0.6464285714  26.190476190  2.0210743809  0.2653603554  550           0.0608985233 
0.8229166667  0.8095238095  0.8214285714  0.8035714286  0.8437500000  0.8333333333  0.8139880952  0.8511904762  0.6511904762  28.571428571  2.0041569924  0.2653603554  600           0.0606265211 
0.8348214286  0.8333333333  0.8333333333  0.8095238095  0.8541666667  0.8273809524  0.8288690476  0.8511904762  0.6583333333  30.952380952  1.9410879469  0.2653603554  650           0.0601454639 
0.8467261905  0.8392857143  0.8348214286  0.8154761905  0.8630952381  0.8392857143  0.8377976190  0.8511904762  0.6726190476  33.333333333  1.8434048271  0.2653603554  700           0.0603369522 
0.8318452381  0.8333333333  0.8348214286  0.8214285714  0.8586309524  0.8273809524  0.8303571429  0.8392857143  0.6500000000  35.714285714  1.7987796307  0.2654395103  750           0.0592939949 
0.8348214286  0.8333333333  0.8377976190  0.8214285714  0.8705357143  0.8630952381  0.8392857143  0.8333333333  0.6750000000  38.095238095  1.6664311719  0.2654395103  800           0.0586345053 
0.8526785714  0.8511904762  0.8482142857  0.8273809524  0.8705357143  0.8392857143  0.8511904762  0.8452380952  0.6750000000  40.476190476  1.5949444389  0.2654395103  850           0.0613754654 
0.8556547619  0.8511904762  0.8511904762  0.8154761905  0.8794642857  0.8511904762  0.8526785714  0.8392857143  0.6750000000  42.857142857  1.6198873162  0.2654395103  900           0.0609091520 
0.8601190476  0.8571428571  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8571428571  0.8452380952  0.6785714286  45.238095238  1.5103637481  0.2654395103  950           0.0596849537 
0.8630952381  0.8452380952  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8735119048  0.8571428571  0.6964285714  47.619047619  1.4238694859  0.2654395103  1000          0.0597676325 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8764880952  0.8630952381  0.7166666667  50.000000000  1.4516454649  0.2654395103  1050          0.0594383955 
0.8630952381  0.8392857143  0.8601190476  0.8273809524  0.8839285714  0.8571428571  0.8720238095  0.8511904762  0.6904761905  52.380952381  1.4488302612  0.2654395103  1100          0.0599355555 
0.8630952381  0.8452380952  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8720238095  0.8511904762  0.6904761905  54.761904761  1.4002842903  0.2654395103  1150          0.0594517994 
0.8645833333  0.8392857143  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8645833333  0.8333333333  0.6845238095  57.142857142  1.4211681843  0.2654395103  1200          0.0599840689 
0.8660714286  0.8452380952  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8690476190  0.8571428571  0.7011904762  59.523809523  1.4415053844  0.2654395103  1250          0.0601073170 
0.8645833333  0.8750000000  0.8571428571  0.8214285714  0.8839285714  0.8630952381  0.8601190476  0.8511904762  0.6666666667  61.904761904  1.4217705393  0.2654395103  1300          0.0601343298 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8735119048  0.8571428571  0.7047619048  64.285714285  1.4162626195  0.2654395103  1350          0.0610333633 
0.8660714286  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8705357143  0.8571428571  0.7059523810  66.666666666  1.4537877107  0.2654395103  1400          0.0594268799 
0.8645833333  0.8452380952  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8690476190  0.8571428571  0.6952380952  69.047619047  1.4059500599  0.2654395103  1450          0.0595145798 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8824404762  0.8630952381  0.8750000000  0.8630952381  0.7202380952  71.428571428  1.4123412681  0.2654395103  1500          0.0596020842 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2559523810  0.2455357143  0.2202380952  0.2366071429  0.2500000000  0.2351190476  0.2142857143  0.2500000000  0.0000000000  4.2432036400  0.1006202698  0             0.3735852242 
0.4360119048  0.3750000000  0.4017857143  0.3630952381  0.4047619048  0.3392857143  0.3660714286  0.4047619048  0.3714285714  2.3809523810  4.1748859262  0.2653427124  50            0.0596951056 
0.5788690476  0.5297619048  0.5312500000  0.5654761905  0.5625000000  0.5595238095  0.5401785714  0.4940476190  0.5130952381  4.7619047619  3.9855802250  0.2653427124  100           0.0604068184 
0.6622023810  0.6488095238  0.6473214286  0.6488095238  0.6830357143  0.6369047619  0.6175595238  0.6190476190  0.5583333333  7.1428571429  3.7688214064  0.2653427124  150           0.0609318542 
0.6904761905  0.6726190476  0.6800595238  0.6607142857  0.7113095238  0.6785714286  0.6488095238  0.6130952381  0.5690476190  9.5238095238  3.4765828991  0.2653594017  200           0.0587533712 
0.7127976190  0.6666666667  0.7098214286  0.6785714286  0.7217261905  0.7142857143  0.6889880952  0.6726190476  0.5690476190  11.904761904  3.0738410378  0.2653594017  250           0.0597794485 
0.7261904762  0.6904761905  0.7261904762  0.7142857143  0.7470238095  0.7738095238  0.7172619048  0.7202380952  0.6071428571  14.285714285  2.8220202875  0.2653594017  300           0.0591498327 
0.7485119048  0.7083333333  0.7366071429  0.7023809524  0.7574404762  0.7559523810  0.7336309524  0.7142857143  0.6333333333  16.666666666  2.5993496037  0.2653594017  350           0.0614120245 
0.7767857143  0.7321428571  0.7723214286  0.7440476190  0.8005952381  0.8035714286  0.7619047619  0.7678571429  0.6321428571  19.047619047  2.4248070717  0.2653594017  400           0.0604564476 
0.7812500000  0.7559523810  0.7872023810  0.7500000000  0.8139880952  0.8214285714  0.7842261905  0.7857142857  0.6571428571  21.428571428  2.2673595405  0.2653594017  450           0.0612996197 
0.7961309524  0.7619047619  0.8080357143  0.7738095238  0.8273809524  0.8333333333  0.7961309524  0.8154761905  0.6488095238  23.809523809  2.1618327117  0.2653594017  500           0.0601981449 
0.8095238095  0.7738095238  0.8110119048  0.7797619048  0.8377976190  0.8214285714  0.7991071429  0.8214285714  0.6464285714  26.190476190  2.0210743809  0.2653594017  550           0.0608295870 
0.8229166667  0.8095238095  0.8214285714  0.8035714286  0.8437500000  0.8333333333  0.8139880952  0.8511904762  0.6511904762  28.571428571  2.0041569924  0.2653594017  600           0.0607833672 
0.8348214286  0.8333333333  0.8333333333  0.8095238095  0.8541666667  0.8273809524  0.8288690476  0.8511904762  0.6583333333  30.952380952  1.9410879469  0.2653594017  650           0.0602885389 
0.8467261905  0.8392857143  0.8348214286  0.8154761905  0.8630952381  0.8392857143  0.8377976190  0.8511904762  0.6726190476  33.333333333  1.8434048271  0.2653594017  700           0.0608159971 
0.8318452381  0.8333333333  0.8348214286  0.8214285714  0.8586309524  0.8273809524  0.8303571429  0.8392857143  0.6500000000  35.714285714  1.7987796307  0.2653594017  750           0.0606540203 
0.8348214286  0.8333333333  0.8377976190  0.8214285714  0.8705357143  0.8630952381  0.8392857143  0.8333333333  0.6750000000  38.095238095  1.6664311719  0.2653594017  800           0.0603202677 
0.8526785714  0.8511904762  0.8482142857  0.8273809524  0.8705357143  0.8392857143  0.8511904762  0.8452380952  0.6750000000  40.476190476  1.5949444389  0.2653594017  850           0.0596023846 
0.8556547619  0.8511904762  0.8511904762  0.8154761905  0.8794642857  0.8511904762  0.8526785714  0.8392857143  0.6750000000  42.857142857  1.6198873162  0.2653594017  900           0.0605419731 
0.8601190476  0.8571428571  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8571428571  0.8452380952  0.6785714286  45.238095238  1.5103637481  0.2653594017  950           0.0598581171 
0.8630952381  0.8452380952  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8735119048  0.8571428571  0.6964285714  47.619047619  1.4238694859  0.2653594017  1000          0.0691574335 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8764880952  0.8630952381  0.7166666667  50.000000000  1.4516454649  0.2653594017  1050          0.0603070593 
0.8630952381  0.8392857143  0.8601190476  0.8273809524  0.8839285714  0.8571428571  0.8720238095  0.8511904762  0.6904761905  52.380952381  1.4488302612  0.2653594017  1100          0.0597223377 
0.8630952381  0.8452380952  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8720238095  0.8511904762  0.6904761905  54.761904761  1.4002842903  0.2653594017  1150          0.0602177143 
0.8645833333  0.8392857143  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8645833333  0.8333333333  0.6845238095  57.142857142  1.4211681843  0.2653594017  1200          0.0590710211 
0.8660714286  0.8452380952  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8690476190  0.8571428571  0.7011904762  59.523809523  1.4415053844  0.2653594017  1250          0.0597979593 
0.8645833333  0.8750000000  0.8571428571  0.8214285714  0.8839285714  0.8630952381  0.8601190476  0.8511904762  0.6666666667  61.904761904  1.4217705393  0.2653594017  1300          0.0615907097 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8735119048  0.8571428571  0.7047619048  64.285714285  1.4162626195  0.2653594017  1350          0.0610526800 
0.8660714286  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8705357143  0.8571428571  0.7059523810  66.666666666  1.4537877107  0.2653594017  1400          0.0597405434 
0.8645833333  0.8452380952  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8690476190  0.8571428571  0.6952380952  69.047619047  1.4059500599  0.2653594017  1450          0.0591868162 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8824404762  0.8630952381  0.8750000000  0.8630952381  0.7202380952  71.428571428  1.4123412681  0.2655954361  1500          0.0599205828 
0.8601190476  0.8690476190  0.8571428571  0.8273809524  0.8764880952  0.8571428571  0.8571428571  0.8511904762  0.6595238095  73.809523809  1.4553270006  0.2655954361  1550          0.0634341764 
0.8645833333  0.8511904762  0.8556547619  0.8214285714  0.8809523810  0.8630952381  0.8645833333  0.8511904762  0.6678571429  76.190476190  1.4536577439  0.2655954361  1600          0.0605154657 
0.8645833333  0.8511904762  0.8556547619  0.8273809524  0.8839285714  0.8630952381  0.8720238095  0.8511904762  0.6869047619  78.571428571  1.3913273764  0.2655954361  1650          0.0607279396 
0.8660714286  0.8571428571  0.8571428571  0.8214285714  0.8824404762  0.8690476190  0.8645833333  0.8511904762  0.6761904762  80.952380952  1.4335188866  0.2655954361  1700          0.0610099649 
0.8645833333  0.8750000000  0.8556547619  0.8273809524  0.8839285714  0.8571428571  0.8586309524  0.8511904762  0.6642857143  83.333333333  1.4223965883  0.2655954361  1750          0.0589348602 
0.8645833333  0.8750000000  0.8556547619  0.8273809524  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6750000000  85.714285714  1.4245845532  0.2655954361  1800          0.0599556351 
0.8645833333  0.8690476190  0.8556547619  0.8273809524  0.8839285714  0.8571428571  0.8616071429  0.8511904762  0.6702380952  88.095238095  1.4195254588  0.2655954361  1850          0.0593312836 
0.8660714286  0.8571428571  0.8556547619  0.8273809524  0.8824404762  0.8630952381  0.8675595238  0.8630952381  0.6892857143  90.476190476  1.4121724868  0.2655954361  1900          0.0594989872 
0.8645833333  0.8690476190  0.8556547619  0.8273809524  0.8809523810  0.8571428571  0.8616071429  0.8511904762  0.6595238095  92.857142857  1.3802344441  0.2655954361  1950          0.0618544149 
0.8645833333  0.8511904762  0.8556547619  0.8273809524  0.8824404762  0.8571428571  0.8705357143  0.8511904762  0.6857142857  95.238095238  1.3988559008  0.2655954361  2000          0.0613446140 
0.8690476190  0.8511904762  0.8556547619  0.8214285714  0.8839285714  0.8630952381  0.8675595238  0.8511904762  0.6785714286  97.619047619  1.3786905193  0.2655954361  2050          0.0619401455 
0.8645833333  0.8809523810  0.8556547619  0.8273809524  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6714285714  100.00000000  1.4614115214  0.2655954361  2100          0.0602215195 
0.8645833333  0.8750000000  0.8571428571  0.8273809524  0.8854166667  0.8571428571  0.8601190476  0.8511904762  0.6642857143  102.38095238  1.4133603477  0.2655954361  2150          0.0601167774 
0.8660714286  0.8809523810  0.8556547619  0.8333333333  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6738095238  104.76190476  1.3655906403  0.2655954361  2200          0.0597832775 
0.8675595238  0.8690476190  0.8541666667  0.8273809524  0.8824404762  0.8690476190  0.8660714286  0.8571428571  0.6880952381  107.14285714  1.4332359338  0.2655954361  2250          0.0617451382 
0.8645833333  0.8750000000  0.8556547619  0.8273809524  0.8794642857  0.8630952381  0.8586309524  0.8511904762  0.6619047619  109.52380952  1.4481203866  0.2655954361  2300          0.0604287100 
0.8601190476  0.8809523810  0.8586309524  0.8392857143  0.8794642857  0.8571428571  0.8556547619  0.8452380952  0.6511904762  111.90476190  1.4038777924  0.2655954361  2350          0.0661071587 
0.8660714286  0.8809523810  0.8556547619  0.8333333333  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6690476190  114.28571428  1.3987627661  0.2655954361  2400          0.0599472904 
0.8645833333  0.8511904762  0.8556547619  0.8214285714  0.8839285714  0.8630952381  0.8660714286  0.8511904762  0.6809523810  116.66666666  1.4294066525  0.2655954361  2450          0.0595468903 
0.8675595238  0.8690476190  0.8541666667  0.8273809524  0.8809523810  0.8630952381  0.8675595238  0.8630952381  0.6904761905  119.04761904  1.4132846284  0.2655954361  2500          0.0597903109 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 1e-05
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 1e-05
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2559523810  0.2455357143  0.2202380952  0.2366071429  0.2500000000  0.2351190476  0.2142857143  0.2500000000  0.0000000000  4.2432036400  0.1006202698  0             0.3752598763 
0.4464285714  0.3928571429  0.3913690476  0.3809523810  0.3973214286  0.3392857143  0.3571428571  0.3928571429  0.3714285714  2.3809523810  4.1757586336  0.2653427124  50            0.0616209126 
0.5610119048  0.5297619048  0.5357142857  0.5178571429  0.5401785714  0.5476190476  0.5282738095  0.5000000000  0.4904761905  4.7619047619  3.9912742138  0.2653770447  100           0.0604211617 
0.6413690476  0.6190476190  0.6339285714  0.6488095238  0.6622023810  0.6250000000  0.6026785714  0.6190476190  0.5392857143  7.1428571429  3.7857280922  0.2653770447  150           0.0684879255 
0.6875000000  0.6666666667  0.6741071429  0.7023809524  0.6934523810  0.6785714286  0.6279761905  0.6309523810  0.5583333333  9.5238095238  3.5111364031  0.2654228210  200           0.0592500496 
0.7127976190  0.6428571429  0.7098214286  0.6904761905  0.7232142857  0.6845238095  0.6666666667  0.6726190476  0.5702380952  11.904761904  3.1248034859  0.2654228210  250           0.0634807396 
0.7366071429  0.7023809524  0.7217261905  0.7321428571  0.7604166667  0.7380952381  0.7261904762  0.6845238095  0.6202380952  14.285714285  2.8702504206  0.2654228210  300           0.0609962320 
0.7291666667  0.7261904762  0.7142857143  0.7321428571  0.7485119048  0.7261904762  0.7202380952  0.7202380952  0.6630952381  16.666666666  2.6457519722  0.2654228210  350           0.0604751492 
0.7678571429  0.7500000000  0.7589285714  0.7559523810  0.8125000000  0.7738095238  0.7708333333  0.7142857143  0.6726190476  19.047619047  2.4724703455  0.2654228210  400           0.0604824305 
0.7366071429  0.7559523810  0.7648809524  0.7500000000  0.7827380952  0.7738095238  0.7514880952  0.7261904762  0.6761904762  21.428571428  2.3157320786  0.2654228210  450           0.0628152895 
0.7574404762  0.7678571429  0.7886904762  0.7738095238  0.8214285714  0.7916666667  0.7782738095  0.7440476190  0.6797619048  23.809523809  2.2136949277  0.2654404640  500           0.0600892973 
0.8035714286  0.7857142857  0.8095238095  0.7857142857  0.8437500000  0.8095238095  0.8065476190  0.7619047619  0.6690476190  26.190476190  2.0856729984  0.2654404640  550           0.0608056164 
0.8214285714  0.8035714286  0.8154761905  0.7916666667  0.8556547619  0.8095238095  0.8214285714  0.7976190476  0.6714285714  28.571428571  2.0665167403  0.2654404640  600           0.0624623156 
0.8333333333  0.8154761905  0.8273809524  0.8095238095  0.8526785714  0.8154761905  0.8288690476  0.8035714286  0.6702380952  30.952380952  2.0063093281  0.2654404640  650           0.0600776625 
0.8497023810  0.8392857143  0.8392857143  0.8333333333  0.8616071429  0.8333333333  0.8407738095  0.8154761905  0.6773809524  33.333333333  1.9232070112  0.2654404640  700           0.0606167316 
0.8452380952  0.8214285714  0.8348214286  0.8333333333  0.8616071429  0.8273809524  0.8273809524  0.8095238095  0.6547619048  35.714285714  1.8695024276  0.2654404640  750           0.0603837729 
0.8437500000  0.8452380952  0.8407738095  0.8214285714  0.8645833333  0.8511904762  0.8363095238  0.8333333333  0.6750000000  38.095238095  1.7485097790  0.2654404640  800           0.0619388247 
0.8556547619  0.8333333333  0.8452380952  0.8273809524  0.8720238095  0.8511904762  0.8541666667  0.8452380952  0.6654761905  40.476190476  1.6778315759  0.2654404640  850           0.0615048742 
0.8556547619  0.8333333333  0.8526785714  0.8333333333  0.8735119048  0.8511904762  0.8586309524  0.8571428571  0.6845238095  42.857142857  1.7130096149  0.2654404640  900           0.0601899338 
0.8586309524  0.8571428571  0.8571428571  0.8333333333  0.8750000000  0.8690476190  0.8556547619  0.8452380952  0.6833333333  45.238095238  1.5974807501  0.2654552460  950           0.0620748329 
0.8645833333  0.8571428571  0.8616071429  0.8273809524  0.8779761905  0.8630952381  0.8705357143  0.8690476190  0.6880952381  47.619047619  1.5245520282  0.2654552460  1000          0.0594451523 
0.8645833333  0.8452380952  0.8586309524  0.8452380952  0.8735119048  0.8571428571  0.8705357143  0.8630952381  0.6952380952  50.000000000  1.5416361213  0.2654552460  1050          0.0616997385 
0.8645833333  0.8452380952  0.8601190476  0.8333333333  0.8750000000  0.8630952381  0.8660714286  0.8630952381  0.6809523810  52.380952381  1.5420196915  0.2655301094  1100          0.0598541641 
0.8645833333  0.8511904762  0.8586309524  0.8273809524  0.8750000000  0.8630952381  0.8720238095  0.8690476190  0.6845238095  54.761904761  1.4938677430  0.2655301094  1150          0.0593967485 
0.8645833333  0.8452380952  0.8601190476  0.8333333333  0.8735119048  0.8571428571  0.8630952381  0.8452380952  0.6785714286  57.142857142  1.5190168333  0.2655301094  1200          0.0626034498 
0.8630952381  0.8690476190  0.8571428571  0.8452380952  0.8720238095  0.8571428571  0.8735119048  0.8630952381  0.6952380952  59.523809523  1.5327688098  0.2655301094  1250          0.0596236420 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 1000
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 264, in <module>
    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes, domain_num, hparams)  # 算法初始化：模型、优化器
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2173, in __init__
    self.sd_reg = hparams["sd_reg"]
KeyError: 'sd_reg'
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 1000
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2559523810  0.2455357143  0.2202380952  0.2366071429  0.2500000000  0.2351190476  0.2142857143  0.2500000000  0.0000000000  4.2432036400  0.1006202698  0             0.3839697838 
0.4360119048  0.3750000000  0.4017857143  0.3630952381  0.4047619048  0.3392857143  0.3660714286  0.4047619048  0.3714285714  2.3809523810  4.1748859262  0.2653427124  50            0.0624558640 
0.5788690476  0.5297619048  0.5312500000  0.5654761905  0.5625000000  0.5595238095  0.5401785714  0.4940476190  0.5130952381  4.7619047619  3.9855802250  0.2653594017  100           0.0604845428 
0.6622023810  0.6488095238  0.6473214286  0.6488095238  0.6830357143  0.6369047619  0.6175595238  0.6190476190  0.5583333333  7.1428571429  3.7688214064  0.2653594017  150           0.0617145205 
0.6904761905  0.6726190476  0.6800595238  0.6607142857  0.7113095238  0.6785714286  0.6488095238  0.6130952381  0.5690476190  9.5238095238  3.4765828991  0.2653594017  200           0.0615818548 
0.7127976190  0.6666666667  0.7098214286  0.6785714286  0.7217261905  0.7142857143  0.6889880952  0.6726190476  0.5690476190  11.904761904  3.0738410378  0.2653594017  250           0.0607694674 
0.7261904762  0.6904761905  0.7261904762  0.7142857143  0.7470238095  0.7738095238  0.7172619048  0.7202380952  0.6071428571  14.285714285  2.8220202875  0.2653594017  300           0.0607527590 
0.7485119048  0.7083333333  0.7366071429  0.7023809524  0.7574404762  0.7559523810  0.7336309524  0.7142857143  0.6333333333  16.666666666  2.5993496037  0.2653594017  350           0.0600961781 
0.7767857143  0.7321428571  0.7723214286  0.7440476190  0.8005952381  0.8035714286  0.7619047619  0.7678571429  0.6321428571  19.047619047  2.4248070717  0.2653594017  400           0.0597887659 
0.7812500000  0.7559523810  0.7872023810  0.7500000000  0.8139880952  0.8214285714  0.7842261905  0.7857142857  0.6571428571  21.428571428  2.2673595405  0.2653594017  450           0.0602955198 
0.7961309524  0.7619047619  0.8080357143  0.7738095238  0.8273809524  0.8333333333  0.7961309524  0.8154761905  0.6488095238  23.809523809  2.1618327117  0.2653594017  500           0.0593084097 
0.8095238095  0.7738095238  0.8110119048  0.7797619048  0.8377976190  0.8214285714  0.7991071429  0.8214285714  0.6464285714  26.190476190  2.0210743809  0.2653594017  550           0.0611857605 
0.8229166667  0.8095238095  0.8214285714  0.8035714286  0.8437500000  0.8333333333  0.8139880952  0.8511904762  0.6511904762  28.571428571  2.0041569924  0.2653594017  600           0.0611686516 
0.8348214286  0.8333333333  0.8333333333  0.8095238095  0.8541666667  0.8273809524  0.8288690476  0.8511904762  0.6583333333  30.952380952  1.9410879469  0.2653594017  650           0.0622237539 
0.8467261905  0.8392857143  0.8348214286  0.8154761905  0.8630952381  0.8392857143  0.8377976190  0.8511904762  0.6726190476  33.333333333  1.8434048271  0.2653594017  700           0.0601228666 
0.8318452381  0.8333333333  0.8348214286  0.8214285714  0.8586309524  0.8273809524  0.8303571429  0.8392857143  0.6500000000  35.714285714  1.7987796307  0.2653594017  750           0.0600888205 
0.8348214286  0.8333333333  0.8377976190  0.8214285714  0.8705357143  0.8630952381  0.8392857143  0.8333333333  0.6750000000  38.095238095  1.6664311719  0.2653594017  800           0.0604517412 
0.8526785714  0.8511904762  0.8482142857  0.8273809524  0.8705357143  0.8392857143  0.8511904762  0.8452380952  0.6750000000  40.476190476  1.5949444389  0.2653594017  850           0.0663939190 
0.8556547619  0.8511904762  0.8511904762  0.8154761905  0.8794642857  0.8511904762  0.8526785714  0.8392857143  0.6750000000  42.857142857  1.6198873162  0.2653594017  900           0.0613591766 
0.8601190476  0.8571428571  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8571428571  0.8452380952  0.6785714286  45.238095238  1.5103637481  0.2653594017  950           0.0698741722 
0.8630952381  0.8452380952  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8735119048  0.8571428571  0.6964285714  47.619047619  1.4238694859  0.2653594017  1000          0.0611615276 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8764880952  0.8630952381  0.7166666667  50.000000000  1.4516454649  0.2653594017  1050          0.0616409254 
0.8630952381  0.8392857143  0.8601190476  0.8273809524  0.8839285714  0.8571428571  0.8720238095  0.8511904762  0.6904761905  52.380952381  1.4488302612  0.2653594017  1100          0.0614745522 
0.8630952381  0.8452380952  0.8586309524  0.8214285714  0.8839285714  0.8630952381  0.8720238095  0.8511904762  0.6904761905  54.761904761  1.4002842903  0.2653594017  1150          0.0613586473 
0.8645833333  0.8392857143  0.8586309524  0.8273809524  0.8824404762  0.8630952381  0.8645833333  0.8333333333  0.6845238095  57.142857142  1.4211681843  0.2653594017  1200          0.0600107431 
0.8660714286  0.8452380952  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8690476190  0.8571428571  0.7011904762  59.523809523  1.4415053844  0.2653594017  1250          0.0615607500 
0.8645833333  0.8750000000  0.8571428571  0.8214285714  0.8839285714  0.8630952381  0.8601190476  0.8511904762  0.6666666667  61.904761904  1.4217705393  0.2653594017  1300          0.0608389091 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8735119048  0.8571428571  0.7047619048  64.285714285  1.4162626195  0.2653594017  1350          0.0686369562 
0.8660714286  0.8392857143  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8705357143  0.8571428571  0.7059523810  66.666666666  1.4537877107  0.2653594017  1400          0.0611227512 
0.8645833333  0.8452380952  0.8571428571  0.8273809524  0.8809523810  0.8630952381  0.8690476190  0.8571428571  0.6952380952  69.047619047  1.4059500599  0.2653594017  1450          0.0694572592 
0.8645833333  0.8392857143  0.8571428571  0.8273809524  0.8824404762  0.8630952381  0.8750000000  0.8630952381  0.7202380952  71.428571428  1.4123412681  0.2653594017  1500          0.0728446722 
0.8601190476  0.8690476190  0.8571428571  0.8273809524  0.8764880952  0.8571428571  0.8571428571  0.8511904762  0.6595238095  73.809523809  1.4553270006  0.2653594017  1550          0.0676656008 
0.8645833333  0.8511904762  0.8556547619  0.8214285714  0.8809523810  0.8630952381  0.8645833333  0.8511904762  0.6678571429  76.190476190  1.4536577439  0.2653603554  1600          0.0717822504 
0.8645833333  0.8511904762  0.8556547619  0.8273809524  0.8839285714  0.8630952381  0.8720238095  0.8511904762  0.6869047619  78.571428571  1.3913273764  0.2653603554  1650          0.0593875504 
0.8660714286  0.8571428571  0.8571428571  0.8214285714  0.8824404762  0.8690476190  0.8645833333  0.8511904762  0.6761904762  80.952380952  1.4335188866  0.2653603554  1700          0.0656620502 
0.8645833333  0.8750000000  0.8556547619  0.8273809524  0.8839285714  0.8571428571  0.8586309524  0.8511904762  0.6642857143  83.333333333  1.4223965883  0.2653603554  1750          0.0611150265 
0.8645833333  0.8750000000  0.8556547619  0.8273809524  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6750000000  85.714285714  1.4245845532  0.2653603554  1800          0.0606513500 
0.8645833333  0.8690476190  0.8556547619  0.8273809524  0.8839285714  0.8571428571  0.8616071429  0.8511904762  0.6702380952  88.095238095  1.4195254588  0.2653603554  1850          0.0583173323 
0.8660714286  0.8571428571  0.8556547619  0.8273809524  0.8824404762  0.8630952381  0.8675595238  0.8630952381  0.6892857143  90.476190476  1.4121724868  0.2653603554  1900          0.0618914318 
0.8645833333  0.8690476190  0.8556547619  0.8273809524  0.8809523810  0.8571428571  0.8616071429  0.8511904762  0.6595238095  92.857142857  1.3802344441  0.2653603554  1950          0.0638984823 
0.8645833333  0.8511904762  0.8556547619  0.8273809524  0.8824404762  0.8571428571  0.8705357143  0.8511904762  0.6857142857  95.238095238  1.3988559008  0.2653603554  2000          0.0667967415 
0.8690476190  0.8511904762  0.8556547619  0.8214285714  0.8839285714  0.8630952381  0.8675595238  0.8511904762  0.6785714286  97.619047619  1.3786905193  0.2653603554  2050          0.0634215736 
0.8645833333  0.8809523810  0.8556547619  0.8273809524  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6714285714  100.00000000  1.4614115214  0.2653603554  2100          0.0602184057 
0.8645833333  0.8750000000  0.8571428571  0.8273809524  0.8854166667  0.8571428571  0.8601190476  0.8511904762  0.6642857143  102.38095238  1.4133603477  0.2653603554  2150          0.0610160017 
0.8660714286  0.8809523810  0.8556547619  0.8333333333  0.8824404762  0.8630952381  0.8601190476  0.8511904762  0.6738095238  104.76190476  1.3655906403  0.2653603554  2200          0.0613599253 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 999, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 2739011) exited unexpectedly
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2260, in update
    meta_train_loss_main += penalty
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2559523810  0.2559523810  0.2455357143  0.2321428571  0.2440476190  0.2619047619  0.2455357143  0.2202380952  0.2476190476  0.0000000000  4.2379879951  0.1362590790  0             15.182272911 
0.4389880952  0.3750000000  0.3854166667  0.3630952381  0.3943452381  0.3452380952  0.3675595238  0.3988095238  0.3666666667  2.3809523810  4.1812548923  0.3009815216  50            0.0741892672 
0.5505952381  0.5357142857  0.5267857143  0.5297619048  0.5476190476  0.5297619048  0.5163690476  0.4880952381  0.4869047619  4.7619047619  3.9946244431  0.3010149002  100           0.0729646492 
0.6428571429  0.6071428571  0.6369047619  0.6488095238  0.6681547619  0.6369047619  0.6160714286  0.5714285714  0.5511904762  7.1428571429  3.7793965626  0.3010149002  150           0.0747886133 
0.6919642857  0.6547619048  0.6875000000  0.6666666667  0.7142857143  0.7023809524  0.6547619048  0.6369047619  0.5773809524  9.5238095238  3.4982922459  0.3010149002  200           0.0788503933 
0.6964285714  0.6309523810  0.6979166667  0.6785714286  0.7023809524  0.6964285714  0.6562500000  0.6547619048  0.5607142857  11.904761904  3.0968607569  0.3010149002  250           0.0788724136 
0.7217261905  0.6904761905  0.7098214286  0.6964285714  0.7410714286  0.7619047619  0.7127976190  0.7083333333  0.6023809524  14.285714285  2.8447276974  0.3010149002  300           0.0852484608 
0.7380952381  0.6904761905  0.7247023810  0.7202380952  0.7544642857  0.7500000000  0.7187500000  0.6904761905  0.6130952381  16.666666666  2.6079414511  0.3010149002  350           0.0732509089 
0.7693452381  0.7321428571  0.7589285714  0.7380952381  0.7931547619  0.8095238095  0.7663690476  0.7797619048  0.6380952381  19.047619047  2.4543990040  0.3010149002  400           0.0745580196 
0.7812500000  0.7321428571  0.7827380952  0.7380952381  0.8050595238  0.8214285714  0.7708333333  0.7678571429  0.6416666667  21.428571428  2.3009966326  0.3010149002  450           0.0730637407 
0.7931547619  0.7738095238  0.7976190476  0.7619047619  0.8258928571  0.8333333333  0.7991071429  0.8154761905  0.6523809524  23.809523809  2.1837529635  0.3010149002  500           0.0730002403 
0.7961309524  0.7678571429  0.8050595238  0.7678571429  0.8244047619  0.8273809524  0.7946428571  0.8214285714  0.6345238095  26.190476190  2.0527174950  0.3010149002  550           0.0742476559 
0.8199404762  0.8035714286  0.8229166667  0.7916666667  0.8377976190  0.8214285714  0.8035714286  0.8392857143  0.6392857143  28.571428571  2.0171909571  0.3010149002  600           0.0775826836 
0.8407738095  0.8452380952  0.8422619048  0.8154761905  0.8601190476  0.8392857143  0.8363095238  0.8392857143  0.6785714286  30.952380952  1.9550070858  0.3010149002  650           0.0744717598 
0.8541666667  0.8571428571  0.8422619048  0.8214285714  0.8645833333  0.8333333333  0.8452380952  0.8452380952  0.6714285714  33.333333333  1.8795699382  0.3010149002  700           0.0744055080 
0.8422619048  0.8511904762  0.8422619048  0.8392857143  0.8660714286  0.8333333333  0.8422619048  0.8511904762  0.6678571429  35.714285714  1.8161648011  0.3010149002  750           0.0729036379 
0.8377976190  0.8392857143  0.8363095238  0.8214285714  0.8675595238  0.8571428571  0.8392857143  0.8452380952  0.6630952381  38.095238095  1.6907383585  0.3010149002  800           0.0737970257 
0.8422619048  0.8511904762  0.8377976190  0.8333333333  0.8705357143  0.8452380952  0.8422619048  0.8392857143  0.6500000000  40.476190476  1.6344740152  0.3010149002  850           0.0739009142 
0.8482142857  0.8571428571  0.8422619048  0.8333333333  0.8720238095  0.8511904762  0.8452380952  0.8273809524  0.6380952381  42.857142857  1.6280148101  0.3010149002  900           0.0730269814 
0.8601190476  0.8690476190  0.8556547619  0.8214285714  0.8809523810  0.8571428571  0.8526785714  0.8392857143  0.6714285714  45.238095238  1.5455803823  0.3010149002  950           0.0723531437 
0.8645833333  0.8630952381  0.8541666667  0.8273809524  0.8794642857  0.8571428571  0.8735119048  0.8571428571  0.6940476190  47.619047619  1.4602187943  0.3010149002  1000          0.0722967386 
0.8630952381  0.8630952381  0.8541666667  0.8273809524  0.8794642857  0.8630952381  0.8764880952  0.8630952381  0.7023809524  50.000000000  1.4932066035  0.3010149002  1050          0.0733041382 
0.8645833333  0.8690476190  0.8526785714  0.8273809524  0.8779761905  0.8571428571  0.8705357143  0.8571428571  0.6869047619  52.380952381  1.4657474685  0.3010149002  1100          0.0734530210 
0.8645833333  0.8571428571  0.8556547619  0.8333333333  0.8779761905  0.8571428571  0.8720238095  0.8571428571  0.6928571429  54.761904761  1.4432711411  0.3010149002  1150          0.0724915695 
0.8675595238  0.8511904762  0.8660714286  0.8273809524  0.8794642857  0.8511904762  0.8779761905  0.8452380952  0.6880952381  57.142857142  1.4463847113  0.3010149002  1200          0.0720996189 
0.8645833333  0.8630952381  0.8541666667  0.8273809524  0.8794642857  0.8571428571  0.8750000000  0.8571428571  0.7000000000  59.523809523  1.4727593565  0.3010149002  1250          0.0718549919 
0.8645833333  0.8750000000  0.8526785714  0.8333333333  0.8809523810  0.8571428571  0.8660714286  0.8452380952  0.6714285714  61.904761904  1.4485218096  0.3010149002  1300          0.0732951736 
0.8645833333  0.8630952381  0.8556547619  0.8273809524  0.8809523810  0.8571428571  0.8735119048  0.8511904762  0.7023809524  64.285714285  1.4568822098  0.3010149002  1350          0.0724499226 
0.8645833333  0.8630952381  0.8541666667  0.8273809524  0.8779761905  0.8571428571  0.8720238095  0.8571428571  0.6940476190  66.666666666  1.4784745264  0.3010149002  1400          0.0724834204 
0.8630952381  0.8630952381  0.8556547619  0.8333333333  0.8809523810  0.8630952381  0.8750000000  0.8571428571  0.6988095238  69.047619047  1.4510248041  0.3010149002  1450          0.0721059561 
0.8630952381  0.8630952381  0.8556547619  0.8333333333  0.8824404762  0.8511904762  0.8645833333  0.8333333333  0.6642857143  71.428571428  1.4487706542  0.3010149002  1500          0.0724663496 
0.8645833333  0.8690476190  0.8541666667  0.8333333333  0.8779761905  0.8571428571  0.8616071429  0.8392857143  0.6547619048  73.809523809  1.4941827893  0.3010149002  1550          0.0728101778 
0.8630952381  0.8630952381  0.8601190476  0.8273809524  0.8779761905  0.8571428571  0.8705357143  0.8392857143  0.6773809524  76.190476190  1.4937977481  0.3010149002  1600          0.0728190231 
0.8645833333  0.8809523810  0.8526785714  0.8333333333  0.8809523810  0.8630952381  0.8645833333  0.8511904762  0.6702380952  78.571428571  1.4287488198  0.3010149002  1650          0.0721971035 
0.8630952381  0.8809523810  0.8556547619  0.8273809524  0.8750000000  0.8630952381  0.8571428571  0.8333333333  0.6500000000  80.952380952  1.4848717356  0.3010149002  1700          0.0724263668 
0.8645833333  0.8690476190  0.8571428571  0.8333333333  0.8779761905  0.8571428571  0.8556547619  0.8452380952  0.6547619048  83.333333333  1.4464781761  0.3010149002  1750          0.0729966927 
0.8645833333  0.8571428571  0.8556547619  0.8273809524  0.8809523810  0.8571428571  0.8690476190  0.8571428571  0.6916666667  85.714285714  1.4602951789  0.3010149002  1800          0.0718814516 
0.8630952381  0.8750000000  0.8541666667  0.8333333333  0.8824404762  0.8511904762  0.8660714286  0.8452380952  0.6690476190  88.095238095  1.4538862014  0.3010149002  1850          0.0735290718 
0.8645833333  0.8630952381  0.8556547619  0.8273809524  0.8809523810  0.8571428571  0.8690476190  0.8511904762  0.6809523810  90.476190476  1.4328203058  0.3010149002  1900          0.0725644207 
0.8660714286  0.8809523810  0.8541666667  0.8333333333  0.8809523810  0.8630952381  0.8616071429  0.8452380952  0.6654761905  92.857142857  1.4063788748  0.3010149002  1950          0.0732916832 
0.8645833333  0.8571428571  0.8541666667  0.8273809524  0.8779761905  0.8571428571  0.8705357143  0.8571428571  0.6940476190  95.238095238  1.4469005919  0.3010149002  2000          0.0716023111 
0.8645833333  0.8750000000  0.8541666667  0.8333333333  0.8824404762  0.8571428571  0.8660714286  0.8392857143  0.6642857143  97.619047619  1.4152365971  0.3010149002  2050          0.0713902664 
0.8630952381  0.8750000000  0.8571428571  0.8273809524  0.8750000000  0.8630952381  0.8556547619  0.8333333333  0.6535714286  100.00000000  1.4828013206  0.3010149002  2100          0.0730967093 
0.8660714286  0.8869047619  0.8526785714  0.8333333333  0.8809523810  0.8630952381  0.8630952381  0.8452380952  0.6678571429  102.38095238  1.4482879066  0.3010149002  2150          0.0722829676 
0.8630952381  0.8571428571  0.8541666667  0.8273809524  0.8794642857  0.8571428571  0.8690476190  0.8630952381  0.6988095238  104.76190476  1.4201635432  0.3010149002  2200          0.0722747087 
0.8645833333  0.8630952381  0.8541666667  0.8273809524  0.8809523810  0.8630952381  0.8735119048  0.8571428571  0.6976190476  107.14285714  1.4751178575  0.3010149002  2250          0.0716605854 
0.8660714286  0.8750000000  0.8541666667  0.8333333333  0.8824404762  0.8571428571  0.8675595238  0.8452380952  0.6726190476  109.52380952  1.4743137383  0.3010149002  2300          0.0732209015 
0.8422619048  0.8571428571  0.8497023810  0.8511904762  0.8675595238  0.8511904762  0.8467261905  0.8214285714  0.6107142857  111.90476190  1.4462906313  0.3010149002  2350          0.0727205992 
0.8645833333  0.8869047619  0.8541666667  0.8333333333  0.8824404762  0.8571428571  0.8645833333  0.8511904762  0.6738095238  114.28571428  1.4280643964  0.3010149002  2400          0.0730412865 
0.8645833333  0.8750000000  0.8586309524  0.8333333333  0.8779761905  0.8630952381  0.8601190476  0.8392857143  0.6559523810  116.66666666  1.4743264818  0.3010149002  2450          0.0718708611 
0.8660714286  0.8809523810  0.8541666667  0.8333333333  0.8809523810  0.8630952381  0.8630952381  0.8452380952  0.6642857143  119.04761904  1.4647024560  0.3010149002  2500          0.0728349161 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 357, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2559523810  0.2559523810  0.2455357143  0.2321428571  0.2440476190  0.2619047619  0.2455357143  0.2202380952  0.2476190476  0.0000000000  4.2907848358  0.1362590790  0             0.6093366146 
0.4285714286  0.3690476190  0.3928571429  0.3452380952  0.3988095238  0.3392857143  0.3497023810  0.3869047619  0.3523809524  2.3809523810  4.2193031311  0.3009815216  50            0.0737685823 
0.5446428571  0.5357142857  0.5267857143  0.4940476190  0.5223214286  0.5178571429  0.5014880952  0.4702380952  0.4785714286  4.7619047619  4.0400450706  0.3009815216  100           0.0733780336 
0.6294642857  0.6071428571  0.6220238095  0.6250000000  0.6547619048  0.6309523810  0.6011904762  0.5595238095  0.5428571429  7.1428571429  3.8481000042  0.3009815216  150           0.0736312532 
0.6845238095  0.6369047619  0.6860119048  0.6666666667  0.7008928571  0.6785714286  0.6354166667  0.6071428571  0.5583333333  9.5238095238  3.5893422890  0.3009815216  200           0.0744110155 
0.6845238095  0.6428571429  0.6830357143  0.6666666667  0.6964285714  0.6785714286  0.6398809524  0.6369047619  0.5547619048  11.904761904  3.2108838844  0.3009815216  250           0.0736148596 
0.7202380952  0.6666666667  0.7083333333  0.6904761905  0.7306547619  0.7440476190  0.6979166667  0.6964285714  0.5928571429  14.285714285  2.9659577084  0.3009815216  300           0.0731449318 
0.7351190476  0.6666666667  0.7157738095  0.7142857143  0.7440476190  0.7500000000  0.7023809524  0.7142857143  0.6226190476  16.666666666  2.7373739338  0.3009982109  350           0.0738059044 
0.7648809524  0.7321428571  0.7559523810  0.7559523810  0.7886904762  0.8214285714  0.7663690476  0.7797619048  0.6547619048  19.047619047  2.5860392523  0.3009982109  400           0.0766928625 
0.7827380952  0.7321428571  0.7708333333  0.7500000000  0.8050595238  0.8154761905  0.7663690476  0.7916666667  0.6511904762  21.428571428  2.4404171467  0.3009982109  450           0.0746107531 
0.7961309524  0.7678571429  0.7946428571  0.7678571429  0.8154761905  0.8273809524  0.7886904762  0.8154761905  0.6547619048  23.809523809  2.3352358627  0.3010616302  500           0.0739121962 
0.7961309524  0.7797619048  0.7976190476  0.7678571429  0.8214285714  0.8214285714  0.7886904762  0.8035714286  0.6440476190  26.190476190  2.2041482282  0.3010616302  550           0.0721970844 
0.8110119048  0.8095238095  0.8169642857  0.7976190476  0.8437500000  0.8333333333  0.8095238095  0.8392857143  0.6559523810  28.571428571  2.1768178535  0.3010616302  600           0.0736195183 
0.8452380952  0.8571428571  0.8348214286  0.8154761905  0.8616071429  0.8511904762  0.8422619048  0.8333333333  0.6928571429  30.952380952  2.1192553639  0.3010616302  650           0.0740149450 
0.8482142857  0.8630952381  0.8392857143  0.8273809524  0.8630952381  0.8452380952  0.8467261905  0.8333333333  0.6904761905  33.333333333  2.0483919549  0.3010616302  700           0.0737516546 
0.8452380952  0.8571428571  0.8392857143  0.8273809524  0.8645833333  0.8571428571  0.8452380952  0.8333333333  0.6845238095  35.714285714  2.0039143586  0.3010616302  750           0.0729137611 
0.8363095238  0.8452380952  0.8407738095  0.8154761905  0.8645833333  0.8571428571  0.8348214286  0.8392857143  0.6750000000  38.095238095  1.8748578835  0.3010616302  800           0.0745091200 
0.8437500000  0.8392857143  0.8348214286  0.8333333333  0.8660714286  0.8392857143  0.8452380952  0.8392857143  0.6619047619  40.476190476  1.8457424736  0.3010616302  850           0.0740160608 
0.8422619048  0.8571428571  0.8363095238  0.8214285714  0.8660714286  0.8392857143  0.8437500000  0.8392857143  0.6428571429  42.857142857  1.8380082750  0.3010616302  900           0.0749448967 
0.8541666667  0.8571428571  0.8497023810  0.8214285714  0.8764880952  0.8571428571  0.8541666667  0.8392857143  0.6833333333  45.238095238  1.7607655454  0.3010616302  950           0.0754974079 
0.8601190476  0.8571428571  0.8511904762  0.8214285714  0.8764880952  0.8630952381  0.8660714286  0.8452380952  0.7047619048  47.619047619  1.6806307340  0.3010616302  1000          0.0727923918 
0.8571428571  0.8630952381  0.8497023810  0.8214285714  0.8764880952  0.8630952381  0.8660714286  0.8452380952  0.7130952381  50.000000000  1.7292075634  0.3010616302  1050          0.0755542183 
0.8616071429  0.8571428571  0.8511904762  0.8214285714  0.8764880952  0.8571428571  0.8645833333  0.8511904762  0.7023809524  52.380952381  1.6993957496  0.3010616302  1100          0.0722889042 
0.8571428571  0.8630952381  0.8497023810  0.8214285714  0.8764880952  0.8630952381  0.8660714286  0.8452380952  0.7047619048  54.761904761  1.6742402387  0.3010616302  1150          0.0734841633 
0.8511904762  0.8511904762  0.8467261905  0.8214285714  0.8735119048  0.8571428571  0.8645833333  0.8452380952  0.7130952381  57.142857142  1.6810385990  0.3010616302  1200          0.0744248199 
0.8601190476  0.8571428571  0.8497023810  0.8214285714  0.8764880952  0.8630952381  0.8660714286  0.8511904762  0.7059523810  59.523809523  1.7108780456  0.3010616302  1250          0.0731449556 
0.8616071429  0.8690476190  0.8497023810  0.8273809524  0.8764880952  0.8571428571  0.8616071429  0.8452380952  0.6821428571  61.904761904  1.6861619616  0.3010616302  1300          0.0723651600 
0.8556547619  0.8571428571  0.8482142857  0.8214285714  0.8750000000  0.8630952381  0.8645833333  0.8571428571  0.7142857143  64.285714285  1.6905339050  0.3010616302  1350          0.0743814564 
0.8601190476  0.8630952381  0.8511904762  0.8214285714  0.8764880952  0.8630952381  0.8660714286  0.8452380952  0.7071428571  66.666666666  1.7162271094  0.3010616302  1400          0.0733515882 
0.8556547619  0.8571428571  0.8482142857  0.8214285714  0.8764880952  0.8630952381  0.8645833333  0.8511904762  0.7154761905  69.047619047  1.6919700956  0.3010616302  1450          0.0734668541 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
KeyboardInterrupt
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2916904) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3620689655  0.3706896552  0.3333333333  0.3333333333  0.3353174603  0.3333333333  0.3353174603  0.3333333333  0.3412698413  0.0000000000  4.0290365219  0.1006202698  0             0.4198160172 
0.4224137931  0.4913793103  0.3948412698  0.4047619048  0.4007936508  0.4206349206  0.3988095238  0.4365079365  0.3920634921  3.4482758621  3.7610314608  0.2653427124  50            0.0601724815 
0.5581896552  0.6293103448  0.5615079365  0.5476190476  0.5476190476  0.5952380952  0.5694444444  0.6031746032  0.5238095238  6.8965517241  3.3266778708  0.2654013634  100           0.0620641994 
0.6551724138  0.6465517241  0.6825396825  0.6746031746  0.6765873016  0.6507936508  0.6527777778  0.6904761905  0.6190476190  10.344827586  3.0306681013  0.2654013634  150           0.0606829119 
0.7176724138  0.7068965517  0.7579365079  0.7301587302  0.7301587302  0.7380952381  0.6924603175  0.7619047619  0.6634920635  13.793103448  2.7598169279  0.2654013634  200           0.0605524731 
0.7931034483  0.8017241379  0.8313492063  0.7857142857  0.7857142857  0.7777777778  0.7579365079  0.7936507937  0.6984126984  17.241379310  2.4245534086  0.2654013634  250           0.0597582912 
0.8340517241  0.8706896552  0.8789682540  0.8174603175  0.8412698413  0.8015873016  0.8035714286  0.8253968254  0.7698412698  20.689655172  2.0812618494  0.2654013634  300           0.0606270599 
0.8448275862  0.8879310345  0.8769841270  0.8650793651  0.8353174603  0.8412698413  0.8194444444  0.8253968254  0.7619047619  24.137931034  1.8190317202  0.2654013634  350           0.0594067907 
0.8943965517  0.8965517241  0.9087301587  0.8571428571  0.8670634921  0.8412698413  0.8492063492  0.8492063492  0.7984126984  27.586206896  1.6103505969  0.2654013634  400           0.0600396156 
0.9461206897  0.9137931034  0.9146825397  0.8809523810  0.8829365079  0.8571428571  0.8571428571  0.8571428571  0.8047619048  31.034482758  1.4124723911  0.2654013634  450           0.0601942730 
0.9633620690  0.9396551724  0.9186507937  0.8888888889  0.8888888889  0.8650793651  0.8551587302  0.8492063492  0.8031746032  34.482758620  1.2633383942  0.2654013634  500           0.0597985888 
0.9784482759  0.9568965517  0.9404761905  0.9047619048  0.9166666667  0.8888888889  0.8968253968  0.8888888889  0.8190476190  37.931034482  1.1507767463  0.3474483490  550           0.0598578691 
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 379, in select
    for fd, event in fd_event_list:
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2936109) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 269, in <module>
    algorithm.to(device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3685344828  0.3620689655  0.3194444444  0.3095238095  0.3015873016  0.2936507937  0.3015873016  0.3095238095  0.3095238095  0.0000000000  3.3020548820  0.1006202698  0             0.3835473061 
0.5560344828  0.5862068966  0.5595238095  0.5079365079  0.5158730159  0.5317460317  0.5059523810  0.5000000000  0.4761904762  3.4482758621  3.2386993551  0.2653427124  50            0.0599728155 
0.6465517241  0.6810344828  0.6488095238  0.6269841270  0.6230158730  0.6587301587  0.6051587302  0.6269841270  0.5730158730  6.8965517241  3.0627084780  0.2653427124  100           0.0607150936 
0.7327586207  0.7672413793  0.7361111111  0.7142857143  0.7083333333  0.7063492063  0.6865079365  0.7222222222  0.6047619048  10.344827586  2.8191842365  0.2653427124  150           0.0613732815 
0.7866379310  0.7758620690  0.7896825397  0.7619047619  0.7519841270  0.7539682540  0.7420634921  0.7380952381  0.7206349206  13.793103448  2.5366495848  0.2654600143  200           0.0598649693 
0.7995689655  0.7931034483  0.8154761905  0.7619047619  0.7797619048  0.7698412698  0.7777777778  0.7301587302  0.7571428571  17.241379310  2.1892192149  0.2654600143  250           0.0615048838 
0.8556034483  0.8620689655  0.8551587302  0.8095238095  0.8115079365  0.8571428571  0.8075396825  0.8095238095  0.7619047619  20.689655172  1.9303710699  0.2654600143  300           0.0593889141 
0.8706896552  0.8965517241  0.8789682540  0.8253968254  0.8373015873  0.8730158730  0.8273809524  0.8412698413  0.7666666667  24.137931034  1.6566065717  0.2654600143  350           0.0603088903 
0.9331896552  0.9224137931  0.8968253968  0.8730158730  0.8630952381  0.8730158730  0.8492063492  0.8650793651  0.7841269841  27.586206896  1.4717425203  0.2654600143  400           0.0597111559 
0.9418103448  0.9224137931  0.9265873016  0.8809523810  0.8849206349  0.9047619048  0.8630952381  0.8730158730  0.7809523810  31.034482758  1.3409105897  0.2654600143  450           0.0595235586 
0.9676724138  0.9310344828  0.9325396825  0.8809523810  0.9027777778  0.9126984127  0.8968253968  0.8888888889  0.7936507937  34.482758620  1.2002587461  0.2654600143  500           0.0607775545 
0.9784482759  0.9655172414  0.9444444444  0.9206349206  0.9107142857  0.9126984127  0.8789682540  0.8730158730  0.7539682540  37.931034482  1.0983375418  0.2654600143  550           0.0607604218 
0.9762931034  0.9655172414  0.9563492063  0.9206349206  0.9246031746  0.9365079365  0.9067460317  0.8968253968  0.7634920635  41.379310344  0.9469708359  0.2654600143  600           0.0598298693 
0.9784482759  0.9655172414  0.9583333333  0.9365079365  0.9305555556  0.9365079365  0.9206349206  0.9047619048  0.7650793651  44.827586206  0.8585098386  0.2654600143  650           0.0609557867 
0.9784482759  0.9655172414  0.9742063492  0.9603174603  0.9503968254  0.9444444444  0.9305555556  0.9126984127  0.7380952381  48.275862069  0.7943207836  0.2654600143  700           0.0598061275 
0.9784482759  0.9568965517  0.9642857143  0.9523809524  0.9503968254  0.9523809524  0.9484126984  0.9206349206  0.7666666667  51.724137931  0.7192168999  0.2662019730  750           0.0591386938 
0.9806034483  0.9655172414  0.9722222222  0.9682539683  0.9603174603  0.9603174603  0.9444444444  0.9206349206  0.7619047619  55.172413793  0.6121513975  0.2662019730  800           0.0589920473 
0.9827586207  0.9827586207  0.9821428571  0.9761904762  0.9702380952  0.9603174603  0.9444444444  0.9285714286  0.7317460317  58.620689655  0.5800058717  0.2662019730  850           0.0591174698 
0.9827586207  0.9655172414  0.9801587302  0.9841269841  0.9702380952  0.9603174603  0.9563492063  0.9285714286  0.7476190476  62.068965517  0.5269917947  0.2662019730  900           0.0587845898 
0.9849137931  0.9827586207  0.9801587302  0.9841269841  0.9742063492  0.9603174603  0.9563492063  0.9285714286  0.7460317460  65.517241379  0.4710298961  0.2662019730  950           0.0595078516 
0.9827586207  0.9741379310  0.9821428571  0.9841269841  0.9702380952  0.9603174603  0.9603174603  0.9285714286  0.7555555556  68.965517241  0.4389390755  0.2662019730  1000          0.0598202419 
0.9849137931  0.9827586207  0.9821428571  0.9761904762  0.9722222222  0.9603174603  0.9563492063  0.9285714286  0.7460317460  72.413793103  0.4020145333  0.2662019730  1050          0.0601081038 
0.9849137931  0.9827586207  0.9821428571  0.9761904762  0.9742063492  0.9603174603  0.9563492063  0.9285714286  0.7444444444  75.862068965  0.4254396102  0.2662019730  1100          0.0603173113 
0.9849137931  0.9827586207  0.9821428571  0.9841269841  0.9722222222  0.9603174603  0.9523809524  0.9285714286  0.7412698413  79.310344827  0.4087945452  0.2662019730  1150          0.0598649359 
0.9827586207  0.9827586207  0.9821428571  0.9841269841  0.9742063492  0.9603174603  0.9603174603  0.9285714286  0.7555555556  82.758620689  0.4285109925  0.2662019730  1200          0.0599603033 
0.9849137931  0.9827586207  0.9821428571  0.9841269841  0.9742063492  0.9603174603  0.9523809524  0.9285714286  0.7412698413  86.206896551  0.4241442794  0.2662019730  1250          0.0600458527 
0.9827586207  0.9827586207  0.9821428571  0.9841269841  0.9742063492  0.9603174603  0.9583333333  0.9285714286  0.7507936508  89.655172413  0.4019148481  0.2662019730  1300          0.0587759972 
0.9806034483  0.9741379310  0.9801587302  0.9761904762  0.9682539683  0.9603174603  0.9623015873  0.9285714286  0.7650793651  93.103448275  0.4156301272  0.2662019730  1350          0.0601824522 
0.9827586207  0.9827586207  0.9821428571  0.9841269841  0.9742063492  0.9603174603  0.9583333333  0.9285714286  0.7555555556  96.551724137  0.4229752535  0.2662019730  1400          0.0592545938 
0.9849137931  0.9827586207  0.9821428571  0.9841269841  0.9761904762  0.9603174603  0.9583333333  0.9285714286  0.7507936508  100.00000000  0.4192125329  0.2662019730  1450          0.0604543734 
0.9827586207  0.9827586207  0.9821428571  0.9841269841  0.9742063492  0.9603174603  0.9563492063  0.9285714286  0.7523809524  103.44827586  0.4383118922  0.2662019730  1500          0.0590891361 
0.9827586207  0.9827586207  0.9841269841  0.9841269841  0.9722222222  0.9603174603  0.9563492063  0.9285714286  0.7492063492  106.89655172  0.4238075256  0.2662019730  1550          0.0613694715 
0.9827586207  0.9827586207  0.9821428571  0.9841269841  0.9722222222  0.9603174603  0.9583333333  0.9285714286  0.7539682540  110.34482758  0.4009270453  0.3474483490  1600          0.0594563675 
0.9827586207  0.9827586207  0.9821428571  0.9841269841  0.9742063492  0.9603174603  0.9583333333  0.9285714286  0.7523809524  113.79310344  0.4032847583  0.3474483490  1650          0.0606986666 
0.9849137931  0.9827586207  0.9821428571  0.9841269841  0.9761904762  0.9603174603  0.9603174603  0.9285714286  0.7460317460  117.24137931  0.4053558743  0.3474483490  1700          0.0611677217 
0.9849137931  0.9827586207  0.9821428571  0.9841269841  0.9761904762  0.9603174603  0.9563492063  0.9285714286  0.7523809524  120.68965517  0.3970736668  0.3474483490  1750          0.0622380543 
0.9827586207  0.9827586207  0.9841269841  0.9841269841  0.9742063492  0.9603174603  0.9563492063  0.9285714286  0.7507936508  124.13793103  0.4204630721  0.3474926949  1800          0.0611636496 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
    return filename_to_in_scope_cache[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/pyaudio'
During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
      File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
    if debugger.in_project_scope(filename) and '_pydevd' not in filename:
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
    return pydevd_utils.in_project_roots(filename)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
    library_roots = _get_library_roots()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
    return _get_roots(library_roots_cache, 'LIBRARY_ROOTS', set_library_roots, _get_default_library_roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2938389) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3620689655  0.3706896552  0.3333333333  0.3333333333  0.3353174603  0.3333333333  0.3353174603  0.3333333333  0.3428571429  0.0000000000  4.0290365219  0.1006202698  0             0.4112129211 
0.6788793103  0.6982758621  0.6825396825  0.6904761905  0.6706349206  0.6825396825  0.6805555556  0.6984126984  0.6730158730  3.4482758621  3.1031230974  0.2653427124  50            0.0633872986 
0.8965517241  0.8965517241  0.8968253968  0.8809523810  0.8769841270  0.8571428571  0.8353174603  0.8333333333  0.7793650794  6.8965517241  1.8822312164  0.2653908730  100           0.0604069185 
0.9784482759  0.9655172414  0.9623015873  0.9603174603  0.9404761905  0.9206349206  0.9345238095  0.8888888889  0.7761904762  10.344827586  1.1226235366  0.2653908730  150           0.0608709526 
0.9784482759  0.9655172414  0.9761904762  0.9841269841  0.9623015873  0.9523809524  0.9404761905  0.9206349206  0.7428571429  13.793103448  0.6982552075  0.2653908730  200           0.0601781797 
0.9762931034  0.9741379310  0.9841269841  0.9761904762  0.9682539683  0.9603174603  0.9365079365  0.9206349206  0.6984126984  17.241379310  0.4619737867  0.2653908730  250           0.0602373457 
0.9892241379  0.9741379310  0.9960317460  0.9920634921  0.9841269841  0.9682539683  0.9801587302  0.9603174603  0.7841269841  20.689655172  0.3075842687  0.2663016319  300           0.0619146585 
0.9935344828  0.9655172414  0.9980158730  0.9920634921  0.9940476190  0.9841269841  0.9900793651  0.9682539683  0.8095238095  24.137931034  0.2328871520  0.2663016319  350           0.0628749514 
0.9935344828  0.9827586207  1.0000000000  0.9920634921  0.9980158730  0.9920634921  0.9940476190  0.9761904762  0.8253968254  27.586206896  0.1736111351  0.2663016319  400           0.0610408926 
0.9935344828  0.9568965517  1.0000000000  0.9920634921  0.9980158730  0.9841269841  1.0000000000  0.9841269841  0.8444444444  31.034482758  0.1162412190  0.2663016319  450           0.0592947817 
0.9935344828  0.9741379310  1.0000000000  0.9920634921  0.9980158730  0.9841269841  1.0000000000  0.9841269841  0.8380952381  34.482758620  0.1098723824  0.2663016319  500           0.0620146132 
0.9956896552  0.9741379310  1.0000000000  0.9920634921  0.9980158730  0.9841269841  1.0000000000  0.9920634921  0.8666666667  37.931034482  0.0868498265  0.2663016319  550           0.0596866846 
0.9978448276  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8444444444  41.379310344  0.0657472068  0.2663016319  600           0.0594451141 
0.9978448276  0.9827586207  1.0000000000  0.9920634921  1.0000000000  0.9920634921  0.9980158730  0.9841269841  0.8365079365  44.827586206  0.0570471699  0.2663016319  650           0.0602396679 
1.0000000000  0.9827586207  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8365079365  48.275862069  0.0456049682  0.2663016319  700           0.0613538265 
1.0000000000  0.9827586207  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8492063492  51.724137931  0.0465489123  0.2663016319  750           0.0625316334 
0.9978448276  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9920634921  0.8682539683  55.172413793  0.0396159594  0.2663016319  800           0.0646873808 
1.0000000000  0.9913793103  1.0000000000  0.9920634921  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.8539682540  58.620689655  0.0320529478  0.2663016319  850           0.0636910820 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9920634921  0.8571428571  62.068965517  0.0340143464  0.2663016319  900           0.0618972254 
1.0000000000  0.9655172414  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9920634921  0.8555555556  65.517241379  0.0214443925  0.2663016319  950           0.0613838148 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8650793651  68.965517241  0.0207639747  0.2663016319  1000          0.0607638454 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.8492063492  72.413793103  0.0219314000  0.2663016319  1050          0.0626380205 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.8492063492  75.862068965  0.0139211639  0.3474965096  1100          0.0602276134 
1.0000000000  0.9655172414  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9920634921  0.8523809524  79.310344827  0.0236291657  0.3474965096  1150          0.0616862106 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8666666667  82.758620689  0.0261404750  0.3474965096  1200          0.0607917690 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8650793651  86.206896551  0.0168472080  0.3474965096  1250          0.0619120550 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8555555556  89.655172413  0.0215338699  0.3475408554  1300          0.0613280010 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8539682540  93.103448275  0.0267258332  0.3475408554  1350          0.0605620480 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.8523809524  96.551724137  0.0241829106  0.3475408554  1400          0.0590128946 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8539682540  100.00000000  0.0183625980  0.3475408554  1450          0.0621806049 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8634920635  103.44827586  0.0175266748  0.3475408554  1500          0.0603668118 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8650793651  106.89655172  0.0195725038  0.3475408554  1550          0.0609371233 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8650793651  110.34482758  0.0208149643  0.3475408554  1600          0.0608805037 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8650793651  113.79310344  0.0178215899  0.3475408554  1650          0.0603422976 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8571428571  117.24137931  0.0157442286  0.3475408554  1700          0.0605352116 
1.0000000000  0.9913793103  1.0000000000  0.9920634921  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.8444444444  120.68965517  0.0195839524  0.3475408554  1750          0.0600446224 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.8492063492  124.13793103  0.0176863459  0.3475408554  1800          0.0609201097 
1.0000000000  0.9741379310  1.0000000000  0.9920634921  1.0000000000  0.9920634921  1.0000000000  0.9841269841  0.8603174603  127.58620689  0.0200928021  0.3475408554  1850          0.0606084824 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 171, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4196428571  0.3684210526  0.3640000000  0.3650793651  0.3600000000  0.3650793651  0.3760000000  0.3650793651  0.3706070288  0.0000000000  4.2211179733  0.1006202698  0             0.3924539089 
0.7187500000  0.6315789474  0.7240000000  0.7142857143  0.7040000000  0.6666666667  0.6960000000  0.5714285714  0.6421725240  7.1428571429  3.0241894293  0.2653427124  50            0.0603658628 
0.8660714286  0.8421052632  0.9360000000  0.9047619048  0.8840000000  0.8095238095  0.8400000000  0.8412698413  0.6198083067  14.285714285  1.7188359523  0.2653427124  100           0.0592681885 
0.9776785714  0.9473684211  0.9400000000  0.9047619048  0.9240000000  0.8571428571  0.9040000000  0.8730158730  0.6517571885  21.428571428  1.1337462854  0.2653427124  150           0.0610924673 
0.9821428571  0.9649122807  0.9840000000  0.9841269841  0.9560000000  0.9206349206  0.9520000000  0.8888888889  0.6677316294  28.571428571  0.7425881588  0.2653427124  200           0.0604440355 
0.9955357143  0.9824561404  0.9920000000  0.9682539683  0.9920000000  0.9682539683  0.9880000000  0.9365079365  0.6964856230  35.714285714  0.4388715035  0.2653427124  250           0.0594193172 
0.9910714286  0.9824561404  0.9960000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9523809524  0.7667731629  42.857142857  0.2661384654  0.2653427124  300           0.0607818317 
0.9910714286  0.9649122807  1.0000000000  0.9682539683  1.0000000000  0.9841269841  1.0000000000  0.9841269841  0.7092651757  50.000000000  0.2003996530  0.2653427124  350           0.0613430691 
1.0000000000  0.9824561404  0.9960000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9682539683  0.7987220447  57.142857142  0.1214573446  0.2653427124  400           0.0620839024 
1.0000000000  0.9824561404  1.0000000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9682539683  0.7667731629  64.285714285  0.0912848807  0.2653427124  450           0.0597605562 
1.0000000000  0.9824561404  0.9960000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9682539683  0.8019169329  71.428571428  0.0721042944  0.2653427124  500           0.0643796492 
1.0000000000  0.9824561404  1.0000000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9682539683  0.8115015974  78.571428571  0.0704887839  0.2653427124  550           0.0631528473 
1.0000000000  0.9824561404  1.0000000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9682539683  0.8115015974  85.714285714  0.0522231589  0.2653427124  600           0.0623273802 
1.0000000000  0.9824561404  1.0000000000  0.9841269841  1.0000000000  1.0000000000  1.0000000000  0.9682539683  0.8115015974  92.857142857  0.0383177288  0.2653427124  650           0.0636333561 
1.0000000000  0.9824561404  1.0000000000  0.9682539683  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.7571884984  100.00000000  0.0260450386  0.2653427124  700           0.0628714275 
1.0000000000  0.9824561404  1.0000000000  0.9682539683  1.0000000000  1.0000000000  1.0000000000  0.9841269841  0.7412140575  107.14285714  0.0330828645  0.2653427124  750           0.0616360998 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 999, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 3042643, 3042652, 3042657, 3042661, 3042667, 3042678) exited unexpectedly
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1967592593  0.2018348624  0.1855895197  0.1913043478  0.1855895197  0.1913043478  0.1855895197  0.1913043478  0.1937172775  0.0000000000  4.6061019897  0.1006202698  0             0.3790960312 
0.4606481481  0.4954128440  0.4934497817  0.4608695652  0.4475982533  0.4782608696  0.4672489083  0.4347826087  0.3926701571  3.7037037037  4.0396868229  0.2653427124  50            0.0598176956 
0.7523148148  0.6972477064  0.7467248908  0.7304347826  0.6965065502  0.6695652174  0.7379912664  0.7217391304  0.6247818499  7.4074074074  3.3975956631  0.2653427124  100           0.0592489862 
0.8101851852  0.7706422018  0.7903930131  0.7913043478  0.7641921397  0.7304347826  0.7729257642  0.7652173913  0.6178010471  11.111111111  2.4538513350  0.2653427124  150           0.0599003744 
0.9189814815  0.8899082569  0.8427947598  0.8347826087  0.7925764192  0.7391304348  0.7751091703  0.8260869565  0.5951134380  14.814814814  1.7985119677  0.2653427124  200           0.0591887856 
0.9375000000  0.8990825688  0.8689956332  0.8608695652  0.8165938865  0.7565217391  0.7991266376  0.8260869565  0.6108202443  18.518518518  1.4796643186  0.2653427124  250           0.0591977644 
0.9467592593  0.9174311927  0.8886462882  0.8695652174  0.8427947598  0.7826086957  0.8275109170  0.8434782609  0.6369982548  22.222222222  1.2071773052  0.2653427124  300           0.0592505503 
0.9328703704  0.9266055046  0.9148471616  0.8434782609  0.8930131004  0.8260869565  0.8689956332  0.8434782609  0.6178010471  25.925925925  1.0478530526  0.2653427124  350           0.0589791918 
0.9537037037  0.9266055046  0.9366812227  0.8869565217  0.8951965066  0.8086956522  0.8668122271  0.8434782609  0.6247818499  29.629629629  0.8776228237  0.2653427124  400           0.0589549780 
0.9444444444  0.9266055046  0.9563318777  0.8956521739  0.9344978166  0.8173913043  0.9126637555  0.8782608696  0.6387434555  33.333333333  0.8212447107  0.2653427124  450           0.0607737827 
0.9606481481  0.9174311927  0.9672489083  0.9130434783  0.9301310044  0.8173913043  0.9126637555  0.8434782609  0.6579406632  37.037037037  0.7425408959  0.2653803825  500           0.0593924046 
0.9652777778  0.9266055046  0.9650655022  0.9217391304  0.9344978166  0.8000000000  0.9257641921  0.8347826087  0.6509598604  40.740740740  0.6835745960  0.2653803825  550           0.0620086575 
0.9722222222  0.9266055046  0.9694323144  0.9130434783  0.9432314410  0.8434782609  0.8995633188  0.8434782609  0.6509598604  44.444444444  0.5907487148  0.2653803825  600           0.0607826900 
0.9675925926  0.9266055046  0.9803493450  0.8956521739  0.9628820961  0.8260869565  0.9192139738  0.8695652174  0.6352530541  48.148148148  0.5865547502  0.2653803825  650           0.0612013674 
0.9814814815  0.9266055046  0.9825327511  0.9130434783  0.9650655022  0.8521739130  0.9301310044  0.8521739130  0.6387434555  51.851851851  0.5139596581  0.2653803825  700           0.0600842714 
0.9791666667  0.9357798165  0.9868995633  0.9304347826  0.9672489083  0.8434782609  0.9192139738  0.8521739130  0.6579406632  55.555555555  0.4357079384  0.2653803825  750           0.0594439554 
0.9652777778  0.9266055046  0.9847161572  0.9304347826  0.9847161572  0.8173913043  0.9716157205  0.8869565217  0.6561954625  59.259259259  0.4117194757  0.2653803825  800           0.0599726534 
0.9722222222  0.9266055046  0.9934497817  0.9130434783  0.9890829694  0.8260869565  0.9694323144  0.8608695652  0.6369982548  62.962962963  0.3723259467  0.2653803825  850           0.0605229807 
0.9722222222  0.9266055046  0.9956331878  0.9391304348  0.9847161572  0.8347826087  0.9454148472  0.8782608696  0.6282722513  66.666666666  0.3770982555  0.2653803825  900           0.0598073339 
0.9722222222  0.9266055046  0.9978165939  0.9217391304  0.9890829694  0.8347826087  0.9759825328  0.8782608696  0.6387434555  70.370370370  0.3491165367  0.2653803825  950           0.0600960684 
0.9837962963  0.9266055046  0.9978165939  0.9217391304  0.9803493450  0.8260869565  0.9781659389  0.8695652174  0.6404886562  74.074074074  0.3447594726  0.2653803825  1000          0.0606196785 
0.9768518519  0.9266055046  0.9978165939  0.9304347826  0.9847161572  0.8347826087  0.9716157205  0.8608695652  0.6352530541  77.777777777  0.3153550839  0.2653803825  1050          0.0621706533 
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.16.1

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-2-5338d80b81ed>", line 5, in <module>
    C2= confusion_matrix(y_true, y_pred, labels=[0, 1, 2])
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py", line 299, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py", line 84, in _check_targets
    type_true = type_of_target(y_true)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/multiclass.py", line 261, in type_of_target
    if is_multilabel(y):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/multiclass.py", line 147, in is_multilabel
    y = np.asarray(y)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/core/_asarray.py", line 83, in asarray
    return array(a, dtype, copy=False, order=order)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 621, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-3-77c7834a3587>", line 3, in <module>
    y_true = y.item()
ValueError: only one element tensors can be converted to Python scalars
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-4-e5d4c4819fe9>", line 3, in <module>
    y_true = y.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-5-8a5a02cbc793>", line 5, in <module>
    C2= confusion_matrix(y_true, y_pred, labels=[0, 1, 2])
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py", line 299, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py", line 93, in _check_targets
    "and {1} targets".format(type_true, type_pred))
ValueError: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-6-3b94385377d8>", line 3, in <module>
    C = confusion_matrix(y_true, y_pred, labels=[0,1,2])
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py", line 299, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py", line 83, in _check_targets
    check_consistent_length(y_true, y_pred)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/validation.py", line 316, in check_consistent_length
    lengths = [_num_samples(X) for X in arrays if X is not None]
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/validation.py", line 316, in <listcomp>
    lengths = [_num_samples(X) for X in arrays if X is not None]
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/utils/validation.py", line 260, in _num_samples
    " a valid collection." % x)
TypeError: Singleton array 0 cannot be considered a valid collection.
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-11-f9945f55c797>", line 1, in <module>
    all_p = network.predict(all_x)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2343, in predict
    return self.phi(self.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-15-f9485980865d>", line 1, in <module>
    cm2(loader, network)
NameError: name 'cm2' is not defined
  File "<ipython-input-16-5458aae5be53>", line 2
    all_y = torch.cat([y for x, y in loader])
    ^
IndentationError: unexpected indent

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-17-763fdea4ab0c>", line 3, in <module>
    all_p = network.predict(all_x)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2343, in predict
    return self.phi(self.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-18-f154bc7469c8>", line 3, in <module>
    all_p = network.predict(all_x)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2343, in predict
    return self.phi(self.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-19-ce77f60126f4>", line 3, in <module>
    all_p = network.predict(all_x)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2343, in predict
    return self.phi(self.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-20-d9e252f2b28d>", line 5, in <module>
    y_pred = np.argmax(all_p.cpu().numpy(), axis=-1)
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 165, in accuracy
KeyboardInterrupt
trails: 0
Args:
	algorithm: ARM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 8
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
C->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2514880952  0.2440476190  0.2559523810  0.2380952381  0.2544642857  0.2500000000  0.2559523810  0.2500000000  0.2428571429  0.0000000000  1.4200680256  0.0401010513  0             0.3406631947 
0.4464285714  0.4523809524  0.4613095238  0.4940476190  0.4880952381  0.5059523810  0.4553571429  0.4761904762  0.4571428571  0.5952380952  1.3627817154  0.0493288040  50            0.0160730791 
0.5029761905  0.5000000000  0.5252976190  0.5416666667  0.5193452381  0.4583333333  0.4717261905  0.4642857143  0.4416666667  1.1904761905  1.2712911057  0.0493288040  100           0.0157944059 
0.5907738095  0.5892857143  0.6235119048  0.6190476190  0.5744047619  0.5773809524  0.5208333333  0.4821428571  0.5071428571  1.7857142857  1.0760395432  0.0503053665  150           0.0161530304 
0.6547619048  0.6666666667  0.6815476190  0.6785714286  0.6622023810  0.6547619048  0.6011904762  0.5714285714  0.5619047619  2.3809523810  0.9597720158  0.0503053665  200           0.0156019545 
0.6934523810  0.7261904762  0.6696428571  0.7202380952  0.7291666667  0.7261904762  0.7008928571  0.6488095238  0.6511904762  2.9761904762  0.8311989176  0.0503053665  250           0.0150496864 
0.6875000000  0.7202380952  0.6979166667  0.7023809524  0.7083333333  0.6964285714  0.6785714286  0.6428571429  0.6047619048  3.5714285714  0.7671280909  0.0503053665  300           0.0155034256 
0.7470238095  0.7797619048  0.7127976190  0.7142857143  0.7514880952  0.7797619048  0.7544642857  0.6964285714  0.6630952381  4.1666666667  0.7560166359  0.0503053665  350           0.0153142977 
0.7738095238  0.7857142857  0.7514880952  0.7559523810  0.7842261905  0.8035714286  0.7619047619  0.7380952381  0.7000000000  4.7619047619  0.7130427068  0.0503053665  400           0.0158093405 
0.8035714286  0.7976190476  0.7782738095  0.8035714286  0.8169642857  0.8154761905  0.7976190476  0.8095238095  0.7392857143  5.3571428571  0.7092138064  0.0503053665  450           0.0158611059 
0.7946428571  0.8035714286  0.7901785714  0.8035714286  0.8154761905  0.8273809524  0.7827380952  0.8035714286  0.7142857143  5.9523809524  0.6292841351  0.0503053665  500           0.0151792765 
0.8125000000  0.7857142857  0.8125000000  0.7857142857  0.8348214286  0.8035714286  0.7991071429  0.7857142857  0.6988095238  6.5476190476  0.6163621265  0.0503053665  550           0.0157386112 
0.7886904762  0.7916666667  0.8005952381  0.8095238095  0.8169642857  0.8214285714  0.7723214286  0.7678571429  0.7023809524  7.1428571429  0.6349668455  0.0503053665  600           0.0154918718 
0.8377976190  0.8273809524  0.8080357143  0.8273809524  0.8392857143  0.8333333333  0.8392857143  0.8511904762  0.7714285714  7.7380952381  0.5997203124  0.0503053665  650           0.0154745245 
0.8303571429  0.8214285714  0.8273809524  0.8154761905  0.8497023810  0.8452380952  0.8214285714  0.8273809524  0.7428571429  8.3333333333  0.5578716713  0.0503053665  700           0.0156774998 
0.8467261905  0.8392857143  0.8303571429  0.8333333333  0.8526785714  0.8452380952  0.8363095238  0.8571428571  0.7583333333  8.9285714286  0.5083784771  0.0503053665  750           0.0155324125 
0.8616071429  0.8452380952  0.8482142857  0.8273809524  0.8630952381  0.8511904762  0.8407738095  0.8392857143  0.7130952381  9.5238095238  0.4988701919  0.0503053665  800           0.0155099821 
0.8392857143  0.8452380952  0.8229166667  0.8214285714  0.8511904762  0.8333333333  0.8392857143  0.8571428571  0.7619047619  10.119047619  0.5046497720  0.0503053665  850           0.0160399771 
0.8541666667  0.8630952381  0.8497023810  0.8273809524  0.8705357143  0.8630952381  0.8422619048  0.8511904762  0.7630952381  10.714285714  0.4627676368  0.0503053665  900           0.0161577511 
0.8511904762  0.8750000000  0.8616071429  0.8273809524  0.8809523810  0.8452380952  0.8437500000  0.8511904762  0.7250000000  11.309523809  0.4612474337  0.0503053665  950           0.0158407116 
0.8645833333  0.8809523810  0.8556547619  0.8333333333  0.8735119048  0.8630952381  0.8556547619  0.8630952381  0.7559523810  11.904761904  0.4173042935  0.0503053665  1000          0.0159129763 
0.8779761905  0.8690476190  0.8720238095  0.8273809524  0.8869047619  0.8571428571  0.8630952381  0.8571428571  0.7321428571  12.500000000  0.4348266536  0.0503053665  1050          0.0155212927 
0.8779761905  0.8869047619  0.8690476190  0.8511904762  0.8794642857  0.8690476190  0.8675595238  0.8630952381  0.7571428571  13.095238095  0.3916165328  0.0503053665  1100          0.0153911209 
0.8839285714  0.8809523810  0.8705357143  0.8273809524  0.8898809524  0.8630952381  0.8675595238  0.8511904762  0.7595238095  13.690476190  0.3978045350  0.0503053665  1150          0.0156653309 
0.9062500000  0.8630952381  0.8973214286  0.8511904762  0.8958333333  0.8750000000  0.8720238095  0.8511904762  0.6952380952  14.285714285  0.3727826953  0.0503053665  1200          0.0156360149 
0.9122023810  0.8869047619  0.9107142857  0.8750000000  0.9002976190  0.8750000000  0.8883928571  0.8571428571  0.6928571429  14.880952381  0.3603524455  0.0503053665  1250          0.0154331112 
0.8973214286  0.8928571429  0.8705357143  0.8392857143  0.8928571429  0.8809523810  0.8750000000  0.8571428571  0.7559523810  15.476190476  0.3438189897  0.0503053665  1300          0.0149848223 
0.8973214286  0.8928571429  0.8913690476  0.8690476190  0.9002976190  0.9047619048  0.8809523810  0.8750000000  0.7642857143  16.071428571  0.3458058411  0.0503053665  1350          0.0155102968 
0.9226190476  0.8869047619  0.9151785714  0.8750000000  0.9151785714  0.8690476190  0.8958333333  0.8630952381  0.6988095238  16.666666666  0.2988733000  0.0503053665  1400          0.0153874540 
0.8958333333  0.8928571429  0.8824404762  0.8750000000  0.8988095238  0.8690476190  0.8779761905  0.8750000000  0.7595238095  17.261904761  0.2883991069  0.0503053665  1450          0.0156705713 
0.9270833333  0.8988095238  0.9166666667  0.8809523810  0.9166666667  0.8690476190  0.8973214286  0.8690476190  0.7047619048  17.857142857  0.2770779511  0.0503053665  1500          0.0153409290 
0.9375000000  0.9047619048  0.9092261905  0.8511904762  0.9166666667  0.8690476190  0.9002976190  0.8750000000  0.7095238095  18.452380952  0.2789054295  0.0503053665  1550          0.0155914402 
0.9404761905  0.9107142857  0.9255952381  0.8571428571  0.9226190476  0.8928571429  0.9077380952  0.8690476190  0.6821428571  19.047619047  0.2834441099  0.0503053665  1600          0.0160675001 
0.9464285714  0.8988095238  0.9464285714  0.8690476190  0.9449404762  0.8928571429  0.9092261905  0.8273809524  0.6511904762  19.642857142  0.2837305731  0.0503053665  1650          0.0147216558 
0.9389880952  0.9107142857  0.9241071429  0.8869047619  0.9151785714  0.9047619048  0.9122023810  0.8928571429  0.7214285714  20.238095238  0.2423515910  0.0503053665  1700          0.0153653479 
0.9508928571  0.9107142857  0.9523809524  0.8750000000  0.9583333333  0.8809523810  0.9136904762  0.8333333333  0.6273809524  20.833333333  0.2146870036  0.0503053665  1750          0.0154344034 
0.9508928571  0.9166666667  0.9315476190  0.8750000000  0.9300595238  0.8988095238  0.9226190476  0.8988095238  0.6940476190  21.428571428  0.2254798684  0.0503053665  1800          0.0156104040 
0.9598214286  0.9345238095  0.9538690476  0.8869047619  0.9523809524  0.9047619048  0.9360119048  0.8750000000  0.6559523810  22.023809523  0.2361029571  0.0503053665  1850          0.0152198505 
0.9627976190  0.9404761905  0.9568452381  0.8988095238  0.9538690476  0.8928571429  0.9449404762  0.8809523810  0.6357142857  22.619047619  0.2007505405  0.0503053665  1900          0.0152279377 
0.9687500000  0.9404761905  0.9583333333  0.8690476190  0.9553571429  0.8928571429  0.9508928571  0.8928571429  0.6285714286  23.214285714  0.2193567529  0.0503053665  1950          0.0156339264 
0.9717261905  0.9345238095  0.9627976190  0.8988095238  0.9553571429  0.9166666667  0.9479166667  0.9047619048  0.6726190476  23.809523809  0.2169485889  0.0503053665  2000          0.0155287552 
0.9747023810  0.9404761905  0.9672619048  0.9047619048  0.9538690476  0.9166666667  0.9449404762  0.9166666667  0.6630952381  24.404761904  0.1972416568  0.0503053665  2050          0.0161426973 
0.9747023810  0.9345238095  0.9687500000  0.9047619048  0.9717261905  0.9226190476  0.9583333333  0.8928571429  0.6607142857  25.000000000  0.1880009654  0.0503053665  2100          0.0160994816 
0.9776785714  0.9404761905  0.9732142857  0.9285714286  0.9687500000  0.9107142857  0.9568452381  0.9107142857  0.6523809524  25.595238095  0.1582825638  0.0503053665  2150          0.0154580069 
0.9717261905  0.9583333333  0.9791666667  0.9226190476  0.9821428571  0.9345238095  0.9553571429  0.8809523810  0.6321428571  26.190476190  0.1670982333  0.0503053665  2200          0.0156918573 
0.9791666667  0.9464285714  0.9761904762  0.9166666667  0.9761904762  0.9345238095  0.9657738095  0.9226190476  0.6523809524  26.785714285  0.1515198608  0.0503053665  2250          0.0156170273 
0.9776785714  0.9702380952  0.9761904762  0.9226190476  0.9806547619  0.9464285714  0.9672619048  0.9166666667  0.6500000000  27.380952381  0.1359672916  0.0503053665  2300          0.0157874584 
0.9806547619  0.9761904762  0.9791666667  0.9285714286  0.9821428571  0.9226190476  0.9672619048  0.8988095238  0.6404761905  27.976190476  0.1688403294  0.0503053665  2350          0.0159032869 
0.9791666667  0.9702380952  0.9732142857  0.9166666667  0.9821428571  0.9404761905  0.9672619048  0.9107142857  0.6392857143  28.571428571  0.1253506698  0.0503053665  2400          0.0161747932 
0.9866071429  0.9761904762  0.9821428571  0.9404761905  0.9836309524  0.9226190476  0.9776785714  0.9107142857  0.6178571429  29.166666666  0.1238129783  0.0503053665  2450          0.0154722548 
0.9821428571  0.9583333333  0.9761904762  0.9404761905  0.9776785714  0.9345238095  0.9613095238  0.9166666667  0.6214285714  29.761904761  0.1278895254  0.0503053665  2500          0.0158392668 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2514880952  0.2500000000  0.2500000000  0.0000000000  0.0540161133  1.3966554403  0             0.3202331066  0.0000000000 
0.8407738095  0.8571428571  0.8050595238  0.8571428571  0.8392857143  0.8571428571  0.8571428571  0.8630952381  0.7750000000  2.3809523810  0.0604844093  0.9796865082  50            0.0133032894  0.0000000000 
0.9241071429  0.9345238095  0.8869047619  0.9285714286  0.9151785714  0.8928571429  0.9255952381  0.8869047619  0.6928571429  4.7619047619  0.0605459213  0.4154581273  100           0.0131936693  0.0000000000 
0.9360119048  0.9464285714  0.9181547619  0.9523809524  0.9300595238  0.9285714286  0.9345238095  0.8928571429  0.6690476190  7.1428571429  0.0605459213  0.2228664659  150           0.0131292772  0.0000000000 
0.9776785714  0.9761904762  0.9776785714  0.9880952381  0.9866071429  0.9702380952  0.9761904762  0.9345238095  0.6238095238  9.5238095238  0.0605459213  0.1186418075  200           0.0135040998  0.0000000000 
0.9821428571  0.9642857143  0.9880952381  0.9821428571  0.9880952381  0.9702380952  0.9880952381  0.9166666667  0.6464285714  11.904761904  0.0621571541  0.0806028598  250           0.0134632730  0.0000000000 
0.9851190476  0.9761904762  0.9880952381  0.9821428571  0.9940476190  0.9761904762  0.9880952381  0.9464285714  0.6535714286  14.285714285  0.0621571541  0.0552968629  300           0.0133570337  0.0000000000 
0.9940476190  0.9761904762  0.9940476190  0.9821428571  0.9985119048  0.9761904762  0.9985119048  0.9464285714  0.6440476190  16.666666666  0.0621571541  0.0447179689  350           0.0135116577  0.0000000000 
0.7916666667  0.7738095238  0.8363095238  0.8273809524  0.8154761905  0.7976190476  0.7767857143  0.7559523810  0.4797619048  19.047619047  0.0621571541  0.0548123112  400           0.0332334614  0.3963260733 
0.3988095238  0.3869047619  0.4360119048  0.4345238095  0.4196428571  0.4226190476  0.3973214286  0.3809523810  0.2976190476  21.428571428  0.0621571541  6.6806606591  450           0.0990660191  1224.3202932 
0.5699404762  0.5238095238  0.5729166667  0.5654761905  0.5639880952  0.5416666667  0.5520833333  0.5059523810  0.3821428571  23.809523809  0.0621571541  4.9962573147  500           0.0894830704  705.79518317 
0.5401785714  0.4940476190  0.5520833333  0.5357142857  0.5520833333  0.5238095238  0.5178571429  0.4642857143  0.3690476190  26.190476190  0.0621571541  2.1363877845  550           0.0930696917  550.93324417 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1491, in update
    opt.zero_grad()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/optim/optimizer.py", line 217, in zero_grad
    p.grad.zero_()
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.0000000000  0.0460753441  1.3970789909  0             0.3287732601  0.0000000000 
0.8288690476  0.8392857143  0.8169642857  0.8452380952  0.8392857143  0.8571428571  0.8511904762  0.8333333333  0.7595238095  2.0089285714  0.0525593758  0.9650015903  50            0.0126376057  0.0000000000 
0.9241071429  0.9166666667  0.9002976190  0.9226190476  0.9166666667  0.8988095238  0.9330357143  0.8928571429  0.6785714286  4.0178571429  0.0542683601  0.4262877899  100           0.0128298807  0.0000000000 
0.9375000000  0.9047619048  0.9166666667  0.8690476190  0.9211309524  0.8750000000  0.9136904762  0.8690476190  0.6428571429  6.0267857143  0.0542683601  0.2322816175  150           0.0129917049  0.0000000000 
0.9791666667  0.9583333333  0.9747023810  0.9702380952  0.9806547619  0.9523809524  0.9672619048  0.9107142857  0.6571428571  8.0357142857  0.0542683601  0.1424391643  200           0.0129935360  0.0000000000 
0.9821428571  0.9821428571  0.9836309524  0.9761904762  0.9866071429  0.9642857143  0.9761904762  0.9285714286  0.6642857143  10.044642857  0.0542683601  0.0825529233  250           0.0128437567  0.0000000000 
0.9866071429  0.9821428571  0.9866071429  0.9940476190  0.9925595238  0.9761904762  0.9851190476  0.9345238095  0.6488095238  12.053571428  0.0542683601  0.0665534186  300           0.0131423616  0.0000000000 
0.9955357143  0.9761904762  0.9970238095  0.9821428571  0.9985119048  0.9761904762  0.9970238095  0.9404761905  0.6392857143  14.062500000  0.0542683601  0.0477375298  350           0.0134330606  0.0000000000 
0.7797619048  0.7738095238  0.7976190476  0.7916666667  0.7738095238  0.7797619048  0.7767857143  0.7440476190  0.5261904762  16.071428571  0.0542683601  0.1648656234  400           0.0351064730  0.2292181213 
0.6488095238  0.6726190476  0.6383928571  0.6904761905  0.6398809524  0.6607142857  0.6488095238  0.6428571429  0.5428571429  18.080357142  0.0542683601  1.4696970853  450           0.1158042049  66.636796987 
0.4241071429  0.4226190476  0.4598214286  0.4761904762  0.4538690476  0.4523809524  0.4479166667  0.3869047619  0.3035714286  20.089285714  0.0542683601  2.0159898007  500           0.1039576626  479.08648015 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.1855895197  0.2173913043  0.1899563319  0.1913043478  0.1921397380  0.2000000000  0.1943231441  0.2000000000  0.1902268761  0.0000000000  0.0460753441  1.4577460289  0             0.3363511562  0.0000000000 
0.8340611354  0.8260869565  0.8187772926  0.7652173913  0.8406113537  0.8608695652  0.8231441048  0.8521739130  0.7068062827  2.9475982533  0.0525512695  1.1272152340  50            0.0131232071  0.0000000000 
0.9301310044  0.8956521739  0.9235807860  0.8434782609  0.9279475983  0.9043478261  0.9235807860  0.9043478261  0.6684118674  5.8951965066  0.0526700020  0.4597643903  100           0.0131235218  0.0000000000 
0.9672489083  0.9043478261  0.9737991266  0.9043478261  0.9716157205  0.9304347826  0.9475982533  0.9217391304  0.5828970332  8.8427947598  0.0526700020  0.2124215922  150           0.0128812742  0.0000000000 
0.9716157205  0.9478260870  0.9759825328  0.9217391304  0.9825327511  0.9304347826  0.9694323144  0.9391304348  0.6230366492  11.790393013  0.0526700020  0.1252894240  200           0.0131504440  0.0000000000 
0.9737991266  0.9391304348  0.9825327511  0.9478260870  0.9890829694  0.9304347826  0.9803493450  0.9478260870  0.6108202443  14.737991266  0.0526700020  0.0768807306  250           0.0130238581  0.0000000000 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2233796296  0.2592592593  0.2106481481  0.1990740741  0.2002314815  0.2083333333  0.2152777778  0.2268518519  0.2527777778  0.0000000000  0.1715073586  1.4822944403  0             0.3331542015  0.0000000000 
0.8703703704  0.8657407407  0.8611111111  0.8518518519  0.8865740741  0.9027777778  0.8923611111  0.8796296296  0.6796296296  1.5625000000  0.1751184464  1.0240650594  50            0.0159245634  0.0000000000 
0.9004629630  0.9074074074  0.9143518519  0.9166666667  0.9143518519  0.9120370370  0.8912037037  0.8703703704  0.5972222222  3.1250000000  0.1816062927  0.3857138866  100           0.0157211685  0.0000000000 
0.9884259259  0.9861111111  0.9907407407  0.9907407407  0.9849537037  0.9768518519  0.9745370370  0.9583333333  0.5546296296  4.6875000000  0.1816062927  0.1515403964  150           0.0156312656  0.0000000000 
0.9918981481  0.9861111111  0.9942129630  1.0000000000  0.9918981481  0.9861111111  0.9861111111  0.9675925926  0.5750000000  6.2500000000  0.1816062927  0.0785690156  200           0.0162497044  0.0000000000 
0.9895833333  0.9814814815  0.9953703704  0.9907407407  0.9976851852  1.0000000000  0.9918981481  0.9814814815  0.6027777778  7.8125000000  0.1816062927  0.0451184351  250           0.0159721565  0.0000000000 
0.9942129630  0.9953703704  0.9988425926  1.0000000000  1.0000000000  1.0000000000  0.9965277778  0.9768518519  0.5944444444  9.3750000000  0.1816062927  0.0300512677  300           0.0161148739  0.0000000000 
0.9930555556  0.9953703704  0.9988425926  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9861111111  0.5712962963  10.937500000  0.1816062927  0.0248387554  350           0.0163093042  0.0000000000 
0.8981481481  0.8611111111  0.9097222222  0.9166666667  0.9224537037  0.9074074074  0.9039351852  0.8888888889  0.5962962963  12.500000000  0.1816062927  0.0320665085  400           0.0376160383  0.0155226745 
0.6377314815  0.6203703704  0.6631944444  0.6620370370  0.6203703704  0.6111111111  0.5787037037  0.5694444444  0.6462962963  14.062500000  0.1816062927  2.8717697006  450           0.1192050457  207.85199878 
0.6759259259  0.6574074074  0.6666666667  0.6666666667  0.6666666667  0.6620370370  0.6574074074  0.6574074074  0.6462962963  15.625000000  0.1816062927  3.0705907488  500           0.1307542324  3.8979086804 
0.6018518519  0.5972222222  0.5740740741  0.6018518519  0.5891203704  0.5740740741  0.6111111111  0.6481481481  0.5842592593  17.187500000  0.1816062927  1.5482256973  550           0.1185868931  229.60766383 
0.3587962963  0.3564814815  0.3101851852  0.3287037037  0.3321759259  0.3055555556  0.3935185185  0.3657407407  0.4268518519  18.750000000  0.1816062927  2.3106660056  600           0.1039033699  226.56276634 
0.4166666667  0.4166666667  0.4166666667  0.4166666667  0.4166666667  0.4166666667  0.4189814815  0.4212962963  0.5009259259  20.312500000  0.1816062927  1.5828581381  650           0.1096438551  580.03671244 
0.4305555556  0.4259259259  0.4166666667  0.4259259259  0.4212962963  0.4166666667  0.4432870370  0.4259259259  0.5046296296  21.875000000  0.1816062927  1.4155486262  700           0.0979173183  1094.9282129 
0.4016203704  0.3935185185  0.4398148148  0.4305555556  0.4421296296  0.4074074074  0.4247685185  0.3842592593  0.3490740741  23.437500000  0.1816062927  1.1859753561  750           0.0878071260  4510.2718786 
0.4513888889  0.4537037037  0.4490740741  0.4305555556  0.4594907407  0.4490740741  0.4606481481  0.4537037037  0.4962962963  25.000000000  0.1816062927  1.0480854082  800           0.0988713598  1065.4850138 
0.4826388889  0.4953703704  0.5069444444  0.4907407407  0.4849537037  0.4675925926  0.4629629630  0.4722222222  0.4120370370  26.562500000  0.1816062927  1.0050910676  850           0.1100639439  322.44859899 
0.4675925926  0.4629629630  0.5219907407  0.5555555556  0.4826388889  0.4675925926  0.4444444444  0.4259259259  0.4555555556  28.125000000  0.1816062927  0.9975365758  900           0.1138354301  71.473005809 
0.5046296296  0.5092592593  0.5532407407  0.5462962963  0.5300925926  0.5092592593  0.5185185185  0.5046296296  0.6694444444  29.687500000  0.1816062927  0.9326942623  950           0.1115405321  138.78032910 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2233796296  0.2592592593  0.2106481481  0.1990740741  0.2002314815  0.2083333333  0.2152777778  0.2268518519  0.2527777778  0.0000000000  0.1715073586  1.4822944403  0             0.3565285206  0.0000000000 
0.8703703704  0.8657407407  0.8611111111  0.8518518519  0.8865740741  0.9027777778  0.8923611111  0.8796296296  0.6796296296  1.5625000000  0.1751174927  1.0240650594  50            0.0161768818  0.0000000000 
0.9004629630  0.9074074074  0.9143518519  0.9166666667  0.9143518519  0.9120370370  0.8912037037  0.8703703704  0.5972222222  3.1250000000  0.1751174927  0.3857138866  100           0.0161993790  0.0000000000 
0.9884259259  0.9861111111  0.9907407407  0.9907407407  0.9849537037  0.9768518519  0.9745370370  0.9583333333  0.5546296296  4.6875000000  0.1755247116  0.1515403964  150           0.0160181665  0.0000000000 
0.9918981481  0.9861111111  0.9942129630  1.0000000000  0.9918981481  0.9861111111  0.9861111111  0.9675925926  0.5750000000  6.2500000000  0.1755247116  0.0785690156  200           0.0156790113  0.0000000000 
0.9895833333  0.9814814815  0.9953703704  0.9907407407  0.9976851852  1.0000000000  0.9918981481  0.9814814815  0.6027777778  7.8125000000  0.1755247116  0.0451184351  250           0.0160130119  0.0000000000 
0.9942129630  0.9953703704  0.9988425926  1.0000000000  1.0000000000  1.0000000000  0.9965277778  0.9768518519  0.5944444444  9.3750000000  0.1755247116  0.0300512677  300           0.0159676743  0.0000000000 
0.9930555556  0.9953703704  0.9988425926  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9861111111  0.5712962963  10.937500000  0.1755247116  0.0248387554  350           0.0158979654  0.0000000000 
0.8981481481  0.8611111111  0.9097222222  0.9166666667  0.9224537037  0.9074074074  0.9039351852  0.8888888889  0.5962962963  12.500000000  0.1755247116  0.0320665085  400           0.0358318520  0.0155226745 
0.6377314815  0.6203703704  0.6631944444  0.6620370370  0.6203703704  0.6111111111  0.5787037037  0.5694444444  0.6462962963  14.062500000  0.1755247116  2.8717697006  450           0.1185817194  207.85199878 
0.6759259259  0.6574074074  0.6666666667  0.6666666667  0.6666666667  0.6620370370  0.6574074074  0.6574074074  0.6462962963  15.625000000  0.1755247116  3.0705907488  500           0.1205735064  3.8979086804 
0.6018518519  0.5972222222  0.5740740741  0.6018518519  0.5891203704  0.5740740741  0.6111111111  0.6481481481  0.5842592593  17.187500000  0.1755247116  1.5482256973  550           0.1111786413  229.60766383 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3248800) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.16.1

Out[1]: array([[False, False, False, ..., False, False, False]])
Out[2]: array([[False, False, False, ..., False, False, False]])
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 554, in cwru_domain
    Bx, By, numB = CWRU(self.dir, domain='B', balance=2).get_files()
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2233796296  0.2592592593  0.2106481481  0.1990740741  0.2002314815  0.2083333333  0.2152777778  0.2268518519  0.2527777778  0.0000000000  0.1715073586  1.4822944403  0             0.3359358311  0.0000000000 
0.8703703704  0.8657407407  0.8611111111  0.8518518519  0.8865740741  0.9027777778  0.8923611111  0.8796296296  0.6796296296  1.5625000000  0.1852908134  1.0240650594  50            0.0158324671  0.0000000000 
0.9004629630  0.9074074074  0.9143518519  0.9166666667  0.9143518519  0.9120370370  0.8912037037  0.8703703704  0.5972222222  3.1250000000  0.1852908134  0.3857138866  100           0.0180633783  0.0000000000 
0.9884259259  0.9861111111  0.9907407407  0.9907407407  0.9849537037  0.9768518519  0.9745370370  0.9583333333  0.5546296296  4.6875000000  0.1852908134  0.1515403964  150           0.0162655878  0.0000000000 
0.9918981481  0.9861111111  0.9942129630  1.0000000000  0.9918981481  0.9861111111  0.9861111111  0.9675925926  0.5750000000  6.2500000000  0.1852908134  0.0785690156  200           0.0158025932  0.0000000000 
0.9895833333  0.9814814815  0.9953703704  0.9907407407  0.9976851852  1.0000000000  0.9918981481  0.9814814815  0.6027777778  7.8125000000  0.1852908134  0.0451184351  250           0.0160505819  0.0000000000 
0.9942129630  0.9953703704  0.9988425926  1.0000000000  1.0000000000  1.0000000000  0.9965277778  0.9768518519  0.5944444444  9.3750000000  0.1852908134  0.0300512677  300           0.0160382605  0.0000000000 
0.9930555556  0.9953703704  0.9988425926  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9861111111  0.5712962963  10.937500000  0.1852908134  0.0248387554  350           0.0163829613  0.0000000000 
0.8981481481  0.8611111111  0.9097222222  0.9166666667  0.9224537037  0.9074074074  0.9039351852  0.8888888889  0.5962962963  12.500000000  0.1852908134  0.0320665085  400           0.0373610401  0.0155226745 
0.6377314815  0.6203703704  0.6631944444  0.6620370370  0.6203703704  0.6111111111  0.5787037037  0.5694444444  0.6462962963  14.062500000  0.1852908134  2.8717697006  450           0.1197252321  207.85199878 
0.6759259259  0.6574074074  0.6666666667  0.6666666667  0.6666666667  0.6620370370  0.6574074074  0.6574074074  0.6462962963  15.625000000  0.1852908134  3.0705907488  500           0.1192840147  3.8979086804 
0.6018518519  0.5972222222  0.5740740741  0.6018518519  0.5891203704  0.5740740741  0.6111111111  0.6481481481  0.5842592593  17.187500000  0.1852908134  1.5482256973  550           0.1129034519  229.60766383 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1535, in update
    all_feature = self.featurizer(all_x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/normalization.py", line 171, in forward
    input, self.normalized_shape, self.weight, self.bias, self.eps)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2205, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Given normalized_shape=[1998], expected input with shape [*, 1998], but got input of size[108, 16, 3998]
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	cos_lambda: 0.49452107045980365
	data_augmentation: True
	groupdro_eta: 0.013378423587817576
	iters: 392
	lr: 0.00018486359452623148
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	weight_decay: 2.812885384798702e-06
Load Data.
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2589285714  0.2619047619  0.2589285714  0.2559523810  0.2604166667  0.2380952381  0.2574404762  0.2500000000  0.2738095238  0.0000000000  0.1715073586  1.4167699814  0             0.3259372711  0.0000000000 
0.8467261905  0.8809523810  0.8630952381  0.8571428571  0.8392857143  0.8333333333  0.8110119048  0.7857142857  0.5904761905  2.0089285714  0.1826581955  0.9405352014  50            0.0159174013  0.0000000000 
0.9910714286  0.9761904762  0.9821428571  0.9880952381  0.9806547619  0.9523809524  0.9702380952  0.9464285714  0.4773809524  4.0178571429  0.1826581955  0.3425107244  100           0.0162104321  0.0000000000 
0.9880952381  0.9821428571  0.9955357143  0.9940476190  0.9955357143  0.9940476190  0.9895833333  0.9821428571  0.4369047619  6.0267857143  0.1826581955  0.1013339569  150           0.0159621859  0.0000000000 
0.9985119048  0.9761904762  0.9985119048  1.0000000000  1.0000000000  1.0000000000  0.9925595238  0.9880952381  0.4107142857  8.0357142857  0.1826581955  0.0431744655  200           0.0180399132  0.0000000000 
0.9985119048  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9955357143  0.9940476190  0.3940476190  10.044642857  0.1897501945  0.0278231359  250           0.0173072386  0.0000000000 
0.9985119048  0.9880952381  0.9985119048  0.9940476190  1.0000000000  1.0000000000  0.9985119048  0.9880952381  0.3928571429  12.053571428  0.1897501945  0.0167515920  300           0.0170565510  0.0000000000 
0.9970238095  0.9880952381  0.9985119048  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9940476190  0.3797619048  14.062500000  0.1897501945  0.0164834748  350           0.0188935280  0.0000000000 
0.9985119048  0.9821428571  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9955357143  0.9880952381  0.3857142857  16.071428571  0.1897501945  0.0114697962  400           0.0410493326  0.0156094600 
0.6607142857  0.6130952381  0.6279761905  0.5773809524  0.6190476190  0.5833333333  0.6904761905  0.6904761905  0.5083333333  18.080357142  0.1897501945  0.5445624988  450           0.1330873299  35.388096649 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
    return filename_to_in_scope_cache[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/aiofiles'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
    if debugger.in_project_scope(filename) and '_pydevd' not in filename:
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
    return pydevd_utils.in_project_roots(filename)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
    library_roots = _get_library_roots()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
    return _get_roots(library_roots_cache, 'LIBRARY_ROOTS', set_library_roots, _get_default_library_roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 572, in get_abs_path_real_path_and_base_from_file
    base = basename(real_path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 144, in basename
    def basename(p):  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3292822) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3292598) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3292566) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 6
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 1441721782
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 27
	class_balanced: False
	d_steps_per_g: 2
	data_augmentation: True
	delta: 2.1458260446338375
	gda: True
	lr: 0.00018486359452623148
	lr_d: 0.0009658011483823038
	lr_iter: 1750
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.1
	t_lambda: 0.018069222822422647
	weight_decay: 2.812885384798702e-06
	weight_decay_d: 0.004128658159026448
Load Data.
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2872023810  0.2857142857  0.2425595238  0.2321428571  0.2663690476  0.2678571429  0.2842261905  0.2797619048  0.2869047619  0.0000000000  0.0034165459  1.4349983931  0.1714754105  0             0.6540632248 
0.2976190476  0.3154761905  0.2559523810  0.2321428571  0.2678571429  0.2797619048  0.2782738095  0.3095238095  0.3071428571  2.0089285714  0.0024873562  1.4264845562  0.1715536118  50            0.0731355381 
0.3377976190  0.3214285714  0.2723214286  0.2559523810  0.2857142857  0.3035714286  0.2991071429  0.2976190476  0.3357142857  4.0178571429  0.0022666855  1.4001879621  0.1718273163  100           0.0674807024 
0.3660714286  0.3273809524  0.2976190476  0.2857142857  0.2931547619  0.3095238095  0.3184523810  0.2797619048  0.3309523810  6.0267857143  0.0021018470  1.3997742724  0.1718273163  150           0.0673197460 
0.3928571429  0.3511904762  0.3125000000  0.3273809524  0.3065476190  0.3392857143  0.3199404762  0.2797619048  0.3571428571  8.0357142857  0.0019150233  1.3861017704  0.1718273163  200           0.0679744864 
0.3883928571  0.3869047619  0.3392857143  0.2976190476  0.3035714286  0.2857142857  0.3005952381  0.2976190476  0.3535714286  10.044642857  0.0019945829  1.3858847690  0.1766815186  250           0.0679020834 
0.4136904762  0.3750000000  0.3645833333  0.3571428571  0.3273809524  0.2976190476  0.3258928571  0.3154761905  0.3666666667  12.053571428  0.0019352365  1.3784655881  0.1766815186  300           0.0673629618 
0.4270833333  0.3928571429  0.3735119048  0.3750000000  0.3363095238  0.3154761905  0.3437500000  0.3333333333  0.3869047619  14.062500000  0.0019060251  1.3613234973  0.1766815186  350           0.0671257257 
0.4449404762  0.3988095238  0.3883928571  0.3869047619  0.3556547619  0.3630952381  0.3601190476  0.3392857143  0.4130952381  16.071428571  0.0017865604  1.3537699914  0.1766815186  400           0.0669171858 
0.4613095238  0.4464285714  0.4002976190  0.4345238095  0.3750000000  0.3928571429  0.3794642857  0.3571428571  0.4357142857  18.080357142  0.0023133427  1.3483804798  0.1800074577  450           0.0669115353 
0.4761904762  0.4702380952  0.4166666667  0.4345238095  0.3824404762  0.3988095238  0.3988095238  0.3809523810  0.4583333333  20.089285714  0.0020829602  1.3502434206  0.1800074577  500           0.0722870016 
0.5208333333  0.4880952381  0.4568452381  0.4761904762  0.4285714286  0.4285714286  0.4479166667  0.4107142857  0.4821428571  22.098214285  0.0018891317  1.3360322118  0.1800074577  550           0.0671514273 
0.5357142857  0.4940476190  0.4806547619  0.4940476190  0.4449404762  0.4345238095  0.4717261905  0.4404761905  0.5071428571  24.107142857  0.0021949306  1.3284374237  0.1800074577  600           0.0677103281 
0.5446428571  0.5178571429  0.4955357143  0.5059523810  0.4508928571  0.4523809524  0.4761904762  0.4345238095  0.5154761905  26.116071428  0.0022966285  1.3206318092  0.1800074577  650           0.0674330187 
0.5520833333  0.5178571429  0.5044642857  0.5178571429  0.4657738095  0.4642857143  0.4940476190  0.4583333333  0.5142857143  28.125000000  0.0019399674  1.3013094378  0.1800074577  700           0.0688560152 
0.5625000000  0.5297619048  0.5089285714  0.5059523810  0.4866071429  0.4702380952  0.5119047619  0.4702380952  0.5333333333  30.133928571  0.0021478025  1.2938497066  0.1800074577  750           0.0671863937 
0.5773809524  0.5595238095  0.5401785714  0.5178571429  0.5029761905  0.4702380952  0.5223214286  0.4940476190  0.5380952381  32.142857142  0.0020474647  1.2925876617  0.1800074577  800           0.0668781853 
0.5684523810  0.5595238095  0.5476190476  0.5416666667  0.5074404762  0.5059523810  0.5178571429  0.4940476190  0.5380952381  34.151785714  0.0023178440  1.2771154165  0.1815648079  850           0.0683242464 
0.5877976190  0.5773809524  0.5610119048  0.5178571429  0.5193452381  0.4880952381  0.5193452381  0.5119047619  0.5428571429  36.160714285  0.0021797693  1.2602084684  0.1815648079  900           0.0685170746 
0.6175595238  0.6250000000  0.5788690476  0.5535714286  0.5476190476  0.5119047619  0.5520833333  0.5178571429  0.5678571429  38.169642857  0.0024726591  1.2512175465  0.1815648079  950           0.0670309305 
0.6175595238  0.6250000000  0.5788690476  0.5654761905  0.5580357143  0.5059523810  0.5520833333  0.5119047619  0.5595238095  40.178571428  0.0024882519  1.2386000752  0.1815648079  1000          0.0674812603 
0.6354166667  0.6250000000  0.5967261905  0.5535714286  0.5669642857  0.5178571429  0.5595238095  0.5119047619  0.5666666667  42.187500000  0.0021568229  1.2140743423  0.1815648079  1050          0.0742268229 
0.6383928571  0.6428571429  0.5892857143  0.5595238095  0.5714285714  0.5297619048  0.5565476190  0.5119047619  0.5714285714  44.196428571  0.0023808690  1.2124889827  0.1815648079  1100          0.0727895403 
0.6473214286  0.6607142857  0.6205357143  0.5773809524  0.5922619048  0.5476190476  0.5744047619  0.5297619048  0.5869047619  46.205357142  0.0025915173  1.2051029420  0.1815648079  1150          0.0692924213 
0.6488095238  0.6547619048  0.6130952381  0.5892857143  0.5877976190  0.5476190476  0.5639880952  0.5178571429  0.5952380952  48.214285714  0.0025261964  1.1879748249  0.1815648079  1200          0.0717534399 
0.6830357143  0.6845238095  0.6562500000  0.6428571429  0.6339285714  0.5892857143  0.5982142857  0.5773809524  0.6011904762  50.223214285  0.0027081378  1.1642505503  0.1815648079  1250          0.0678769159 
0.6889880952  0.6964285714  0.6636904762  0.6547619048  0.6354166667  0.6011904762  0.6116071429  0.5892857143  0.6083333333  52.232142857  0.0024529832  1.1499535728  0.1815648079  1300          0.0679554605 
0.7127976190  0.7202380952  0.6860119048  0.6666666667  0.6607142857  0.6130952381  0.6324404762  0.5952380952  0.6023809524  54.241071428  0.0026795308  1.1398225141  0.1815648079  1350          0.0670806122 
0.7157738095  0.7083333333  0.6860119048  0.6785714286  0.6562500000  0.6130952381  0.6383928571  0.5952380952  0.6142857143  56.250000000  0.0026745288  1.1141266537  0.1815648079  1400          0.0671369791 
0.7529761905  0.7440476190  0.7291666667  0.7023809524  0.7008928571  0.6607142857  0.6711309524  0.6369047619  0.6071428571  58.258928571  0.0030336148  1.0893042123  0.1815648079  1450          0.0675179148 
0.7514880952  0.7619047619  0.7321428571  0.7202380952  0.7023809524  0.6488095238  0.6726190476  0.6369047619  0.6119047619  60.267857142  0.0030130238  1.0815392065  0.1815648079  1500          0.0673458290 
0.7619047619  0.7678571429  0.7306547619  0.7142857143  0.7008928571  0.6488095238  0.6770833333  0.6428571429  0.6226190476  62.276785714  0.0030539627  1.0525168371  0.1815648079  1550          0.0676515675 
0.7529761905  0.7619047619  0.7395833333  0.7023809524  0.7023809524  0.6488095238  0.6711309524  0.6488095238  0.6107142857  64.285714285  0.0032686803  1.0446871507  0.1815648079  1600          0.0672289133 
0.7678571429  0.7797619048  0.7366071429  0.7142857143  0.6994047619  0.6428571429  0.6800595238  0.6369047619  0.6107142857  66.294642857  0.0028864224  1.0233016527  0.1815648079  1650          0.0717977905 
0.7842261905  0.8035714286  0.7693452381  0.7738095238  0.7261904762  0.6666666667  0.7202380952  0.6845238095  0.6154761905  68.303571428  0.0034612265  1.0126545262  0.1815648079  1700          0.0745990467 
0.7767857143  0.7738095238  0.7380952381  0.7142857143  0.7217261905  0.6607142857  0.7098214286  0.6666666667  0.6357142857  70.312500000  0.0032784455  0.9868808794  0.1815648079  1750          0.0684010220 
0.8511904762  0.8750000000  0.8586309524  0.8452380952  0.8229166667  0.8035714286  0.8214285714  0.7857142857  0.6250000000  72.321428571  0.0035308235  0.8455833960  0.1815648079  1800          0.0677121449 
0.8541666667  0.8809523810  0.8824404762  0.8809523810  0.8497023810  0.8392857143  0.8318452381  0.8095238095  0.5690476190  74.330357142  0.0040539350  0.6819853187  0.1815648079  1850          0.0681491327 
0.8705357143  0.9166666667  0.8958333333  0.9226190476  0.8675595238  0.8809523810  0.8720238095  0.8630952381  0.5666666667  76.339285714  0.0042505155  0.5453939575  0.1846103668  1900          0.0682350588 
0.8809523810  0.8869047619  0.9002976190  0.9404761905  0.8928571429  0.9047619048  0.8869047619  0.8452380952  0.5273809524  78.348214285  0.0043276717  0.4623422229  0.1846103668  1950          0.0689479733 
0.9627976190  0.9583333333  0.9717261905  0.9523809524  0.9508928571  0.9345238095  0.9375000000  0.9226190476  0.5035714286  80.357142857  0.0037278629  0.3702019465  0.1846103668  2000          0.0679982615 
0.9702380952  0.9642857143  0.9806547619  0.9761904762  0.9523809524  0.9404761905  0.9479166667  0.9464285714  0.4964285714  82.366071428  0.0031790655  0.2937446430  0.1846103668  2050          0.0712851143 
0.9717261905  0.9583333333  0.9598214286  0.9642857143  0.9419642857  0.9345238095  0.9434523810  0.9047619048  0.4964285714  84.375000000  0.0033068812  0.2279514295  0.1846103668  2100          0.0784960508 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 896, in __init__
    index_queue = multiprocessing_context.Queue()  # type: ignore
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 102, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 42, in __init__
    self._rlock = ctx.Lock()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 67, in Lock
    return Lock(ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 58, in __init__
    kind, value, maxvalue, self._make_name(),
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/joblib/externals/loky/backend/__init__.py", line 9, in _make_name
    name = '/loky-%i-%s' % (os.getpid(), next(synchronize.SemLock._rand))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tempfile.py", line 160, in __next__
    letters = [choose(c) for dummy in range(8)]
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tempfile.py", line 160, in <listcomp>
    letters = [choose(c) for dummy in range(8)]
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/random.py", line 258, in choice
    i = self._randbelow(len(seq))
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tokenize.py", line 381, in read_or_stop
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3308575) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1984, in handle_keyboard_interrupt
    traceback.print_exception(type(value), value, tb, limit=limit)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 104, in print_exception
    type(value), value, tb, limit=limit).format(chain=chain):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 509, in __init__
    capture_locals=capture_locals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 364, in extract
    f.line
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 286, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tokenize.py", line 454, in open
    encoding, lines = detect_encoding(buffer.readline)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tokenize.py", line 423, in detect_encoding
    first = read_or_stop()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tokenize.py", line 381, in read_or_stop
    return readline()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
RuntimeError: DataLoader worker (pid 3309295) is killed by signal: Terminated. 
We've got an error while stopping in post-mortem: <class 'RuntimeError'>

trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2589285714  0.2440476190  0.3110119048  0.2083333333  0.2619047619  0.3154761905  0.2782738095  0.2083333333  0.2392857143  0.0000000000  0.1370134354  1.4855653048  0.1991610527  0             0.7359452248 
0.6101190476  0.6250000000  0.6339285714  0.6785714286  0.6175595238  0.5833333333  0.5684523810  0.5416666667  0.4809523810  2.3809523810  0.0817377067  1.3241595006  0.2038311958  50            0.1828902578 
0.6726190476  0.6488095238  0.6502976190  0.6547619048  0.6681547619  0.6726190476  0.6086309524  0.6250000000  0.6238095238  4.7619047619  0.1159535658  1.1189353442  0.2115249634  100           0.1824148178 
0.7544642857  0.7142857143  0.7142857143  0.6964285714  0.7395833333  0.7261904762  0.7380952381  0.6964285714  0.5738095238  7.1428571429  0.1408194685  0.8843303871  0.2115249634  150           0.1828184175 
0.8437500000  0.8273809524  0.8422619048  0.8869047619  0.8437500000  0.8035714286  0.8214285714  0.8035714286  0.5619047619  9.5238095238  0.1747901976  0.7228520977  0.2116341591  200           0.1819213486 
0.8586309524  0.8750000000  0.8482142857  0.8809523810  0.8601190476  0.8392857143  0.8675595238  0.8452380952  0.5702380952  11.904761904  0.1382094991  0.6105119753  0.2116341591  250           0.1834676790 
0.8794642857  0.8869047619  0.8869047619  0.9166666667  0.8854166667  0.8750000000  0.8928571429  0.9166666667  0.5476190476  14.285714285  0.1346721798  0.5039009875  0.2116341591  300           0.1803745222 
0.8943452381  0.8988095238  0.9002976190  0.9404761905  0.9077380952  0.9345238095  0.9017857143  0.9226190476  0.5142857143  16.666666666  0.1180922401  0.4032649148  0.2116341591  350           0.1875973940 
0.9598214286  0.9404761905  0.9419642857  0.9404761905  0.9285714286  0.9345238095  0.9642857143  0.9642857143  0.4333333333  19.047619047  0.1392782030  0.3152234519  0.2116341591  400           0.1927679682 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2901785714  0.3095238095  0.3199404762  0.2619047619  0.3050595238  0.2976190476  0.3199404762  0.2797619048  0.2309523810  0.0000000000  0.1255550385  1.4855653048  0.1991610527  0             0.7305607796 
0.7127976190  0.6964285714  0.7247023810  0.7083333333  0.7202380952  0.6904761905  0.6577380952  0.6250000000  0.4904761905  2.3809523810  0.0934726369  1.2624786806  0.2038302422  50            0.1841162252 
0.7827380952  0.7738095238  0.7127976190  0.7023809524  0.7574404762  0.7500000000  0.7440476190  0.6785714286  0.5654761905  4.7619047619  0.1394617212  0.8704545546  0.2038326263  100           0.1856542206 
0.8541666667  0.8630952381  0.8511904762  0.8809523810  0.8511904762  0.8750000000  0.8690476190  0.8988095238  0.6440476190  7.1428571429  0.1510275394  0.5849226689  0.2041974068  150           0.1812019873 
0.8690476190  0.8750000000  0.8779761905  0.8988095238  0.8794642857  0.9047619048  0.8913690476  0.9226190476  0.6202380952  9.5238095238  0.1645164490  0.4197213548  0.2041974068  200           0.1837248707 
0.9047619048  0.9226190476  0.9032738095  0.9345238095  0.9062500000  0.9285714286  0.9107142857  0.9464285714  0.5607142857  11.904761904  0.1308578214  0.3060040969  0.2043752670  250           0.1873544645 
0.9821428571  0.9821428571  0.9895833333  0.9821428571  0.9821428571  0.9761904762  0.9836309524  0.9761904762  0.4583333333  14.285714285  0.1052106924  0.1999270645  0.2046780586  300           0.1963324690 
0.9776785714  0.9642857143  0.9583333333  0.9523809524  0.9434523810  0.9583333333  0.9851190476  0.9821428571  0.4476190476  16.666666666  0.0819004358  0.1283588314  0.2047400475  350           0.1921250772 
0.9955357143  0.9821428571  0.9985119048  1.0000000000  1.0000000000  0.9940476190  0.9910714286  0.9940476190  0.3523809524  19.047619047  0.0701416613  0.0831213146  0.2050418854  400           0.2134524632 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 300, in <module>
    for x, y in next(train_minibatches_iterator)]
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/fast_data_loader.py", line 46, in __iter__
    yield next(self._infinite_iterator)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 0.0001
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 554, in cwru_domain
    Bx, By, numB = CWRU(self.dir, domain='B', balance=3).get_files()
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2443181818  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.0000000000  0.1516457796  1.6161950827  0.1991610527  0             0.6380405426 
0.3721590909  0.3636363636  0.3664772727  0.4318181818  0.3494318182  0.3295454545  0.3892045455  0.3068181818  0.2818181818  4.5454545455  0.1136317110  1.4022380543  0.2039508820  50            0.1868140697 
0.5312500000  0.5340909091  0.5568181818  0.5340909091  0.5426136364  0.5000000000  0.5227272727  0.4659090909  0.3886363636  9.0909090909  0.0775000358  1.3492006183  0.2041907310  100           0.1855671167 
0.6164772727  0.6022727273  0.6335227273  0.6136363636  0.6335227273  0.6590909091  0.6136363636  0.5568181818  0.4250000000  13.636363636  0.0867398930  1.3079704070  0.2102818489  150           0.1854533482 
0.6988636364  0.6477272727  0.7159090909  0.6704545455  0.7215909091  0.7727272727  0.6505681818  0.6590909091  0.4431818182  18.181818181  0.0736346650  1.2625368810  0.2102818489  200           0.1816316080 
0.7215909091  0.7159090909  0.7244318182  0.7272727273  0.7386363636  0.7272727273  0.6988636364  0.6931818182  0.4931818182  22.727272727  0.0937464619  1.1952837801  0.2102818489  250           0.1986116362 
0.9090909091  0.9318181818  0.9119318182  0.9204545455  0.9346590909  0.9318181818  0.9176136364  0.9545454545  0.6727272727  27.272727272  0.0890481865  1.1154523230  0.2102818489  300           0.1840024662 
0.8096590909  0.8409090909  0.8210227273  0.8181818182  0.8295454545  0.8181818182  0.8011363636  0.8409090909  0.5886363636  31.818181818  0.0928427279  1.0018849337  0.2102818489  350           0.1831846380 
0.9772727273  0.9886363636  0.9744318182  0.9772727273  0.9687500000  0.9772727273  0.9772727273  0.9659090909  0.7295454545  36.363636363  0.1027627730  0.8640675437  0.2136721611  400           0.1845414257 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7704545455  40.909090909  0.0971422899  0.6932891977  0.2136721611  450           0.1810960245 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8340909091  45.454545454  0.1029266149  0.5293038642  0.2136721611  500           0.1963913345 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8272727273  50.000000000  0.0961233491  0.3882312226  0.2136721611  550           0.1824603319 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8181818182  54.545454545  0.0789040259  0.2780302548  0.2136721611  600           0.1815568018 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8818181818  59.090909090  0.0598734510  0.2004356214  0.2136721611  650           0.1978527355 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8704545455  63.636363636  0.0677866296  0.1364569503  0.2136721611  700           0.1919662285 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8863636364  68.181818181  0.0487189370  0.0994911623  0.2136721611  750           0.1834894085 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8454545455  72.727272727  0.0428558669  0.0754070222  0.2136721611  800           0.2055488253 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8840909091  77.272727272  0.0449730756  0.0582527423  0.2136721611  850           0.1850606346 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8090909091  81.818181818  0.0338209827  0.0444130914  0.2136721611  900           0.2051473665 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9181818182  86.363636363  0.0257874878  0.0336138129  0.2140326500  950           0.1903346968 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8250000000  90.909090909  0.0308953619  0.0274954613  0.2140326500  1000          0.2085754061 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1984, in update
    gap = -self.hparams['t_lambda'] * self.loss_gap(minibatches, self, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1952, in loss_gap
    p = model.adv_classifier(model.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.0000000000  1.6161950827  0.1991591454  0             0.3579738140 
0.4659090909  0.4545454545  0.4943181818  0.4659090909  0.4659090909  0.4318181818  0.4545454545  0.3181818182  0.3750000000  4.5454545455  1.3967896032  0.2039470673  50            0.0159665489 
0.6761363636  0.6818181818  0.6818181818  0.6818181818  0.6960227273  0.6704545455  0.6534090909  0.6363636364  0.4727272727  9.0909090909  1.2888011026  0.2044262886  100           0.0161802769 
0.7670454545  0.7727272727  0.7727272727  0.7840909091  0.7926136364  0.7727272727  0.7642045455  0.7840909091  0.5181818182  13.636363636  1.1637621713  0.2044262886  150           0.0162730265 
0.9602272727  0.9659090909  0.9517045455  0.9772727273  0.9517045455  0.9659090909  0.9630681818  0.9431818182  0.7181818182  18.181818181  0.9553330874  0.2047276497  200           0.0163611412 
1.0000000000  1.0000000000  0.9943181818  1.0000000000  1.0000000000  1.0000000000  0.9914772727  0.9886363636  0.7454545455  22.727272727  0.6918345606  0.2049078941  250           0.0163067341 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7636363636  27.272727272  0.4443321580  0.2049078941  300           0.0163330746 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7818181818  31.818181818  0.2700581127  0.2049078941  350           0.0162378883 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7931818182  36.363636363  0.1717849594  0.2051477432  400           0.0159856272 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8363636364  40.909090909  0.1086843394  0.2051477432  450           0.0166962051 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8545454545  45.454545454  0.0736791226  0.2051477432  500           0.0162365103 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8636363636  50.000000000  0.0540715659  0.2133102417  550           0.0161624050 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8659090909  54.545454545  0.0413701982  0.2133102417  600           0.0161802721 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8727272727  59.090909090  0.0309798267  0.2133102417  650           0.0162873077 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8772727273  63.636363636  0.0244798238  0.2133102417  700           0.0167076445 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8750000000  68.181818181  0.0210693003  0.2133102417  750           0.0167703342 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8909090909  72.727272727  0.0169810751  0.2133102417  800           0.0164281702 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8772727273  77.272727272  0.0146020208  0.2133102417  850           0.0163680744 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8863636364  81.818181818  0.0121791123  0.2133102417  900           0.0164265108 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8840909091  86.363636363  0.0107083382  0.2133102417  950           0.0164639950 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9045454545  90.909090909  0.0099700967  0.2133102417  1000          0.0161866713 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9000000000  95.454545454  0.0087394180  0.2133102417  1050          0.0158809471 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8909090909  100.00000000  0.0076132114  0.2133102417  1100          0.0156080008 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9000000000  104.54545454  0.0070347763  0.2133102417  1150          0.0160122633 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8954545455  109.09090909  0.0062373311  0.2171745300  1200          0.0167073631 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9068181818  113.63636363  0.0054567155  0.2171745300  1250          0.0186170816 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8977272727  118.18181818  0.0050742861  0.2171745300  1300          0.0159779072 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9090909091  122.72727272  0.0046669960  0.2171745300  1350          0.0159231567 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8886363636  127.27272727  0.0042581570  0.2171745300  1400          0.0163214922 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9090909091  131.81818181  0.0036015104  0.2171745300  1450          0.0160610056 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8954545455  136.36363636  0.0036599345  0.2171745300  1500          0.0160646200 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9068181818  140.90909090  0.0031735791  0.2171745300  1550          0.0164297771 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 300, in <module>
    for x, y in next(train_minibatches_iterator)]
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/fast_data_loader.py", line 46, in __iter__
    yield next(self._infinite_iterator)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 88, in get_connection
    c.send((key, os.getpid()))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 369, in _send
    remaining -= n
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.0000000000  1.6101249456  0.1991591454  0             0.5742661953 
0.3607954545  0.3636363636  0.3352272727  0.3409090909  0.3437500000  0.3522727273  0.3238636364  0.3409090909  0.2454545455  4.5454545455  1.4255877757  0.2037658691  50            0.0174788523 
0.4517045455  0.4659090909  0.3892045455  0.3750000000  0.4204545455  0.3863636364  0.3892045455  0.3636363636  0.2181818182  9.0909090909  1.3219269156  0.2041273117  100           0.0161890459 
0.5710227273  0.4772727273  0.5227272727  0.4431818182  0.5142045455  0.5909090909  0.4659090909  0.4204545455  0.2454545455  13.636363636  1.2373522902  0.2159852982  150           0.0162707663 
0.7500000000  0.6363636364  0.6562500000  0.6022727273  0.6448863636  0.6022727273  0.5482954545  0.5340909091  0.3250000000  18.181818181  1.1184143329  0.2159852982  200           0.0160738802 
0.8153409091  0.6704545455  0.7102272727  0.6250000000  0.6846590909  0.6704545455  0.5767045455  0.5909090909  0.3613636364  22.727272727  0.9745184171  0.2159852982  250           0.0163451242 
0.9034090909  0.8295454545  0.8863636364  0.8863636364  0.8579545455  0.8295454545  0.7897727273  0.7613636364  0.4045454545  27.272727272  0.8350468206  0.2159852982  300           0.0161637831 
0.9232954545  0.8636363636  0.9232954545  0.9204545455  0.8750000000  0.8636363636  0.8011363636  0.8181818182  0.4000000000  31.818181818  0.7156641936  0.2159852982  350           0.0164908981 
0.9176136364  0.8409090909  0.9375000000  0.9090909091  0.9176136364  0.8750000000  0.8437500000  0.8522727273  0.3818181818  36.363636363  0.6004733598  0.2159852982  400           0.0160781765 
0.9375000000  0.8750000000  0.9801136364  0.9659090909  0.9488636364  0.9204545455  0.8806818182  0.8636363636  0.4090909091  40.909090909  0.5126828665  0.2159852982  450           0.0166019392 
0.9403409091  0.8863636364  0.9829545455  0.9772727273  0.9744318182  0.9318181818  0.9034090909  0.8977272727  0.4136363636  45.454545454  0.4231956702  0.2159852982  500           0.0172356892 
0.9318181818  0.8863636364  0.9857954545  0.9772727273  0.9715909091  0.9204545455  0.9119318182  0.8977272727  0.4068181818  50.000000000  0.3537187672  0.2159852982  550           0.0161456919 
0.9431818182  0.8863636364  0.9857954545  0.9886363636  0.9772727273  0.9318181818  0.9176136364  0.8977272727  0.4204545455  54.545454545  0.3081060115  0.2159852982  600           0.0163295269 
0.9517045455  0.8863636364  0.9886363636  0.9886363636  0.9801136364  0.9318181818  0.9204545455  0.9090909091  0.4204545455  59.090909090  0.2678931415  0.2159852982  650           0.0159709358 
0.9375000000  0.8863636364  0.9857954545  0.9886363636  0.9715909091  0.9204545455  0.9232954545  0.8977272727  0.4136363636  63.636363636  0.2366535410  0.2159852982  700           0.0175649738 
0.9488636364  0.8863636364  0.9971590909  0.9886363636  0.9801136364  0.9545454545  0.9318181818  0.9090909091  0.4204545455  68.181818181  0.2052227166  0.2159852982  750           0.0174770451 
0.9517045455  0.8863636364  0.9971590909  1.0000000000  0.9801136364  0.9545454545  0.9318181818  0.9204545455  0.4204545455  72.727272727  0.1825507283  0.2159852982  800           0.0163107967 
0.9573863636  0.9090909091  0.9971590909  1.0000000000  0.9943181818  0.9659090909  0.9431818182  0.9204545455  0.4250000000  77.272727272  0.1676321821  0.2159852982  850           0.0181801748 
0.9517045455  0.8863636364  0.9943181818  0.9886363636  0.9744318182  0.9431818182  0.9375000000  0.9204545455  0.4159090909  81.818181818  0.1474410456  0.2159852982  900           0.0165196323 
0.9517045455  0.8977272727  0.9971590909  1.0000000000  0.9801136364  0.9431818182  0.9375000000  0.9204545455  0.4181818182  86.363636363  0.1463945529  0.2159852982  950           0.0180949688 
0.9573863636  0.9204545455  0.9971590909  1.0000000000  0.9943181818  0.9659090909  0.9573863636  0.9204545455  0.4250000000  90.909090909  0.1295158513  0.2159852982  1000          0.0170961905 
0.9573863636  0.9204545455  1.0000000000  1.0000000000  0.9971590909  0.9772727273  0.9630681818  0.9318181818  0.4272727273  95.454545454  0.1130704911  0.2159852982  1050          0.0176819992 
0.9573863636  0.9204545455  1.0000000000  1.0000000000  0.9971590909  0.9772727273  0.9630681818  0.9431818182  0.4295454545  100.00000000  0.1125606568  0.2159852982  1100          0.0169243479 
0.9573863636  0.9204545455  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.9659090909  0.9431818182  0.4295454545  104.54545454  0.1011345232  0.2159852982  1150          0.0169410563 
0.9573863636  0.9204545455  0.9971590909  1.0000000000  0.9971590909  0.9772727273  0.9687500000  0.9318181818  0.4250000000  109.09090909  0.0911416204  0.2159852982  1200          0.0163639069 
0.9573863636  0.9204545455  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.9715909091  0.9431818182  0.4295454545  113.63636363  0.0859254079  0.2159852982  1250          0.0159232664 
0.9659090909  0.9204545455  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9829545455  0.9431818182  0.4431818182  118.18181818  0.0818796684  0.2159852982  1300          0.0153873348 
0.9573863636  0.9204545455  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.9801136364  0.9431818182  0.4250000000  122.72727272  0.0788596430  0.2159852982  1350          0.0159070826 
0.9630681818  0.9204545455  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.9857954545  0.9431818182  0.4295454545  127.27272727  0.0698214673  0.2159852982  1400          0.0163356066 
0.9659090909  0.9204545455  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.9857954545  0.9431818182  0.4340909091  131.81818181  0.0685785517  0.2159852982  1450          0.0162028122 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2642045455  0.2613636364  0.2670454545  0.2613636364  0.2556818182  0.2613636364  0.2528409091  0.2500000000  0.2500000000  0.0000000000  1.6101249456  0.1991591454  0             0.5578057766 
0.6619318182  0.6022727273  0.5653409091  0.5227272727  0.5681818182  0.5681818182  0.4943181818  0.4772727273  0.3181818182  4.5454545455  1.2339411521  0.2041273117  50            0.0160133886 
0.9289772727  0.8522727273  0.9659090909  0.9545454545  0.9431818182  0.8977272727  0.8863636364  0.8863636364  0.3863636364  9.0909090909  0.7088960361  0.2044878006  100           0.0161209631 
0.9403409091  0.8750000000  0.9801136364  0.9886363636  0.9687500000  0.9204545455  0.9119318182  0.8977272727  0.4068181818  13.636363636  0.3211815539  0.2159862518  150           0.0163124990 
0.9573863636  0.8977272727  0.9971590909  1.0000000000  0.9943181818  0.9772727273  0.9318181818  0.9204545455  0.4181818182  18.181818181  0.1735793293  0.2159862518  200           0.0161363649 
0.9573863636  0.9090909091  0.9971590909  1.0000000000  0.9943181818  0.9886363636  0.9488636364  0.9204545455  0.4250000000  22.727272727  0.1189197850  0.2159862518  250           0.0163488913 
0.9545454545  0.9204545455  0.9971590909  1.0000000000  0.9886363636  0.9545454545  0.9573863636  0.9204545455  0.4136363636  27.272727272  0.0979829083  0.2159862518  300           0.0162151432 
0.9744318182  0.9204545455  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9914772727  0.9431818182  0.4386363636  31.818181818  0.0704133812  0.2159862518  350           0.0163925266 
0.9715909091  0.9204545455  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.9943181818  0.9431818182  0.4204545455  36.363636363  0.0478380831  0.2159862518  400           0.0163528919 
0.9914772727  0.9204545455  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9971590909  0.9659090909  0.4340909091  40.909090909  0.0393857092  0.2159862518  450           0.0160610771 
1.0000000000  0.9318181818  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9971590909  0.9772727273  0.4295454545  45.454545454  0.0311782693  0.2159862518  500           0.0160265303 
1.0000000000  0.9318181818  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9971590909  0.9772727273  0.4295454545  50.000000000  0.0222732433  0.2159862518  550           0.0170677185 
1.0000000000  0.9545454545  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9971590909  0.9886363636  0.4227272727  54.545454545  0.0193405323  0.2159862518  600           0.0167226887 
1.0000000000  0.9545454545  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9971590909  0.9772727273  0.4159090909  59.090909090  0.0153203491  0.2159862518  650           0.0164871120 
1.0000000000  0.9659090909  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.4204545455  63.636363636  0.0124074278  0.2159862518  700           0.0175815058 
1.0000000000  0.9431818182  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9772727273  0.3977272727  68.181818181  0.0110797595  0.2159862518  750           0.0190003920 
1.0000000000  0.9659090909  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.3977272727  72.727272727  0.0076663657  0.2159862518  800           0.0163527441 
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.16.1

1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.4159090909  77.272727272  0.0064903087  0.2159862518  850           0.0163256121 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.3954545455  81.818181818  0.0059513993  0.2159862518  900           0.0165442562 
1.0000000000  0.9659090909  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3954545455  86.363636363  0.0049536240  0.2159862518  950           0.0163955545 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3954545455  90.909090909  0.0045244698  0.2159862518  1000          0.0166545343 
1.0000000000  0.9431818182  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9886363636  0.3818181818  95.454545454  0.0038187681  0.2159862518  1050          0.0164134502 
1.0000000000  0.9659090909  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3977272727  100.00000000  0.0037338120  0.2159862518  1100          0.0163888025 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4022727273  104.54545454  0.0027504464  0.2159862518  1150          0.0211086369 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3977272727  109.09090909  0.0029096100  0.2159862518  1200          0.0201175642 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3863636364  113.63636363  0.0029524672  0.2159862518  1250          0.0211737394 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3909090909  118.18181818  0.0020327679  0.2159862518  1300          0.0226058054 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3909090909  122.72727272  0.0021899364  0.2159862518  1350          0.0180294180 
1.0000000000  0.9772727273  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3931818182  127.27272727  0.0019416267  0.2159862518  1400          0.0209113264 
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/history.py", line 578, in end_session
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
    len(self.input_hist_parsed)-1, self.session_number))
sqlite3.DatabaseError: file is not a database
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 315, in _exit_function
    p._popen.terminate()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f4689313ae8>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/weakref.py", line 109, in remove
    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
RuntimeError: DataLoader worker (pid 3517865) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.2500000000  0.0000000000  1.5745837688  0.1991591454  0             0.5328135490 
0.4346590909  0.4318181818  0.4204545455  0.3977272727  0.4375000000  0.2954545455  0.3863636364  0.4204545455  0.3340909091  4.5454545455  1.3824684072  0.2039461136  50            0.0159536076 
0.6931818182  0.6704545455  0.6732954545  0.5795454545  0.6392045455  0.6022727273  0.6392045455  0.6022727273  0.4750000000  9.0909090909  1.2604367924  0.2043681145  100           0.0157684326 
0.8011363636  0.7613636364  0.7357954545  0.7045454545  0.7301136364  0.6704545455  0.6818181818  0.6704545455  0.4636363636  13.636363636  1.0999460983  0.2043681145  150           0.0161788273 
0.9630681818  0.9090909091  0.9062500000  0.8863636364  0.9062500000  0.8409090909  0.8892045455  0.8750000000  0.6068181818  18.181818181  0.8872567475  0.2046484947  200           0.0162068844 
0.9801136364  0.9772727273  0.9346590909  0.8977272727  0.9289772727  0.8863636364  0.9232954545  0.9318181818  0.6295454545  22.727272727  0.6793415427  0.2047286034  250           0.0161662865 
0.9886363636  0.9772727273  0.9687500000  0.9772727273  0.9602272727  0.9545454545  0.9857954545  0.9659090909  0.6636363636  27.272727272  0.5136761236  0.2047286034  300           0.0159594631 
0.9971590909  0.9772727273  0.9857954545  0.9772727273  0.9914772727  0.9772727273  1.0000000000  0.9886363636  0.6863636364  31.818181818  0.3848114932  0.2047286034  350           0.0160196495 
0.9971590909  0.9886363636  0.9914772727  0.9886363636  0.9971590909  0.9886363636  1.0000000000  1.0000000000  0.7090909091  36.363636363  0.2865008596  0.2047286034  400           0.0162493515 
1.0000000000  1.0000000000  0.9914772727  0.9886363636  1.0000000000  0.9886363636  1.0000000000  1.0000000000  0.6818181818  40.909090909  0.2173045591  0.2047286034  450           0.0158859491 
1.0000000000  0.9886363636  0.9914772727  0.9886363636  1.0000000000  0.9886363636  1.0000000000  1.0000000000  0.6909090909  45.454545454  0.1624480036  0.2047286034  500           0.0157434988 
1.0000000000  0.9886363636  0.9914772727  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7068181818  50.000000000  0.1272570923  0.2047286034  550           0.0169397688 
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.16.1

1.0000000000  0.9886363636  0.9943181818  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6909090909  54.545454545  0.1033042632  0.2047286034  600           0.0185498619 
1.0000000000  1.0000000000  0.9971590909  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6886363636  59.090909090  0.0835746424  0.2047286034  650           0.0166175365 
1.0000000000  1.0000000000  0.9971590909  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6840909091  63.636363636  0.0665558990  0.2050695419  700           0.0159537792 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6772727273  68.181818181  0.0569843519  0.2160925865  750           0.0161550045 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6909090909  72.727272727  0.0500684623  0.2160925865  800           0.0178839636 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6795454545  77.272727272  0.0423470039  0.2160925865  850           0.0161837530 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6931818182  81.818181818  0.0359750734  0.2160925865  900           0.0162707996 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6863636364  86.363636363  0.0314355717  0.2160925865  950           0.0184976149 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6840909091  90.909090909  0.0285499502  0.2160925865  1000          0.0215848780 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6795454545  95.454545454  0.0248405476  0.2160925865  1050          0.0217724705 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6681818182  100.00000000  0.0229082515  0.2160925865  1100          0.0188617992 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6681818182  104.54545454  0.0194103928  0.2160925865  1150          0.0225539064 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6704545455  109.09090909  0.0177286709  0.2160925865  1200          0.0219480753 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6681818182  113.63636363  0.0167009650  0.2160925865  1250          0.0178364468 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6704545455  118.18181818  0.0139045435  0.2160925865  1300          0.0162041664 
1.0000000000  1.0000000000  1.0000000000  0.9886363636  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6818181818  122.72727272  0.0130862188  0.2160925865  1350          0.0175191832 
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
KeyboardInterrupt
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 896, in __init__
    index_queue = multiprocessing_context.Queue()  # type: ignore
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 102, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 42, in __init__
    self._rlock = ctx.Lock()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 64, in Lock
    def Lock(self):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7faab97a20d0>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/_weakrefset.py", line 38, in _remove
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3560442) is killed by signal: Terminated. 
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fa9a045f3c8>>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1324, in __del__
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1291, in _shutdown_workers
    if self._persistent_workers or self._workers_status[worker_id]:
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
Exception ignored in: '_pydevd_frame_eval.pydevd_frame_evaluator.get_bytecode_while_frame_eval'
Traceback (most recent call last):
  File "_pydevd_frame_eval/pydevd_frame_evaluator_common.pyx", line 159, in _pydevd_frame_eval.pydevd_frame_evaluator_common.get_func_code_info
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 429, in _joinrealpath
    if not islink(newpath):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 171, in islink
    st = os.lstat(path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3560083) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
SystemError: <bound method ScriptMagics.kill_bg_processes of <IPython.core.magics.script.ScriptMagics object at 0x7fa9a072fdd8>> returned NULL without setting an error
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.0000000000  1.5735400915  0.1991591454  0             0.5326819420 
0.3363363363  0.4047619048  0.4144144144  0.3333333333  0.3993993994  0.2976190476  0.3753753754  0.3571428571  0.3621103118  4.8048048048  1.4017233944  0.2037758827  50            0.0162556028 
0.5645645646  0.4761904762  0.5465465465  0.5238095238  0.5375375375  0.5238095238  0.5345345345  0.4523809524  0.5131894484  9.6096096096  1.3089624119  0.2039265633  100           0.0160682821 
0.7507507508  0.6666666667  0.7267267267  0.6547619048  0.7267267267  0.7380952381  0.7297297297  0.5833333333  0.6666666667  14.414414414  1.2149158382  0.2039265633  150           0.0161006117 
0.8888888889  0.8809523810  0.8318318318  0.7976190476  0.8468468468  0.8452380952  0.8228228228  0.7500000000  0.7386091127  19.219219219  1.0695037115  0.2039265633  200           0.0158834267 
0.9339339339  0.9404761905  0.9009009009  0.8690476190  0.8828828829  0.8690476190  0.8948948949  0.7857142857  0.7865707434  24.024024024  0.8784003270  0.2043528557  250           0.0162701988 
0.9459459459  0.9642857143  0.9459459459  0.8928571429  0.9279279279  0.9404761905  0.9489489489  0.8809523810  0.8105515588  28.828828828  0.6666821921  0.2043528557  300           0.0159238672 
0.9879879880  0.9880952381  0.9879879880  0.9523809524  0.9879879880  0.9880952381  0.9849849850  0.9880952381  0.8297362110  33.633633633  0.4880729544  0.2043528557  350           0.0162610912 
0.9969969970  1.0000000000  0.9969969970  0.9642857143  0.9969969970  0.9880952381  0.9939939940  0.9880952381  0.8129496403  38.438438438  0.3645251131  0.2043528557  400           0.0161484528 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8009592326  43.243243243  0.2637057933  0.2043528557  450           0.0163509703 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  48.048048048  0.2091905618  0.2043528557  500           0.0163728333 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  52.852852852  0.1568812254  0.2043528557  550           0.0156830359 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  57.657657657  0.1249069791  0.2043528557  600           0.0162281799 
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
KeyboardInterrupt
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
KeyboardInterrupt
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3621330) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: TRM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	cos_lambda: 0.0001
	data_augmentation: True
	groupdro_eta: 0.01
	iters: 70
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         mem_gb        nll           step          step_time     trm_loss     
0.2612612613  0.2500000000  0.2762762763  0.2738095238  0.2732732733  0.2857142857  0.2642642643  0.2857142857  0.2685851319  0.0000000000  0.1991977692  1.4163659811  0             0.5562782288  0.0000000000 
0.4594594595  0.4880952381  0.4264264264  0.4642857143  0.4144144144  0.3809523810  0.4294294294  0.3690476190  0.4316546763  4.8048048048  0.2038145065  1.3786093616  50            0.0172108459  0.0000000000 
0.5855855856  0.5476190476  0.5675675676  0.5476190476  0.5645645646  0.5714285714  0.5165165165  0.4523809524  0.4916067146  9.6096096096  0.2039327621  1.3167703772  100           0.0905619192  0.6751006079 
0.7837837838  0.7857142857  0.7987987988  0.7619047619  0.7537537538  0.7261904762  0.7417417417  0.7142857143  0.5419664269  14.414414414  0.2041354179  1.2311308742  150           0.1342577744  0.6809188867 
0.9339339339  0.9523809524  0.9489489489  0.9285714286  0.9129129129  0.8690476190  0.8558558559  0.8333333333  0.6211031175  19.219219219  0.2041354179  1.1483106852  200           0.1355021906  0.4098772645 
0.9879879880  1.0000000000  0.9909909910  0.9761904762  0.9879879880  0.9642857143  0.9699699700  0.9404761905  0.7170263789  24.024024024  0.2041354179  1.0669045162  250           0.1418664837  0.2395736003 
0.9909909910  1.0000000000  0.9909909910  0.9761904762  0.9969969970  0.9761904762  0.9789789790  0.9761904762  0.7266187050  28.828828828  0.2041354179  0.9930739725  300           0.1397764015  0.1450161684 
0.9849849850  0.9880952381  0.9939939940  0.9761904762  0.9909909910  1.0000000000  0.9759759760  0.9523809524  0.7553956835  33.633633633  0.2168960571  0.9231393743  350           0.1364120102  0.0987495935 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9909909910  0.9761904762  0.7601918465  38.438438438  0.2168960571  0.8574267745  400           0.1367884445  0.0702120256 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.7601918465  43.243243243  0.2168960571  0.7929409766  450           0.1331388855  0.0560619879 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  48.048048048  0.2168960571  0.7248967397  500           0.1323751974  0.0502544343 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7625899281  52.852852852  0.2168960571  0.6588605320  550           0.1327533340  0.0335707498 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7673860911  57.657657657  0.2168960571  0.5928930318  600           0.1342778444  0.0312966657 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  62.462462462  0.2168960571  0.5323969495  650           0.1335998583  0.0165680116 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  67.267267267  0.2168960571  0.4808707964  700           0.1428938961  0.0257364851 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7673860911  72.072072072  0.2168960571  0.4305054981  750           0.1340108919  0.0167582726 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  76.876876876  0.2168960571  0.3872000819  800           0.1339917660  0.0188332957 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  81.681681681  0.2168960571  0.3437750548  850           0.1387320757  0.0170263737 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.0000000000  4.6887679100  0.3691520691  0             0.6165742874 
0.2972972973  0.2976190476  0.3453453453  0.3809523810  0.3213213213  0.2738095238  0.3273273273  0.3214285714  0.3645083933  4.8048048048  4.2260762215  0.9715895653  50            0.0635933113 
0.4264264264  0.4523809524  0.4654654655  0.4642857143  0.4924924925  0.3333333333  0.4774774775  0.3690476190  0.5059952038  9.6096096096  3.9657986736  0.9715895653  100           0.0621422148 
0.6816816817  0.6190476190  0.7027027027  0.6428571429  0.6546546547  0.6190476190  0.6396396396  0.5119047619  0.6067146283  14.414414414  3.7244779348  0.9715895653  150           0.0623596859 
0.8498498498  0.8214285714  0.8498498498  0.7857142857  0.8048048048  0.7738095238  0.7987987988  0.6904761905  0.7362110312  19.219219219  3.4527709866  0.9715895653  200           0.0632136393 
0.9129129129  0.9166666667  0.8528528529  0.8214285714  0.8348348348  0.8571428571  0.8528528529  0.7380952381  0.7841726619  24.024024024  3.0211958265  0.9715895653  250           0.0629937553 
0.9639639640  0.9642857143  0.9459459459  0.9047619048  0.9249249249  0.9523809524  0.9279279279  0.8928571429  0.7937649880  28.828828828  2.4918513155  0.9715895653  300           0.0622564745 
0.9759759760  0.9642857143  0.9789789790  0.9166666667  0.9609609610  0.9642857143  0.9639639640  0.9642857143  0.7817745803  33.633633633  2.0180355573  0.9715895653  350           0.0623840332 
0.9879879880  0.9761904762  0.9849849850  0.9523809524  0.9879879880  0.9880952381  0.9759759760  0.9761904762  0.7769784173  38.438438438  1.5698044753  0.9715895653  400           0.0618816900 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  0.9880952381  0.9879879880  0.9880952381  0.7817745803  43.243243243  1.2136703551  0.9715895653  450           0.0629440403 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  0.9939939940  1.0000000000  0.7817745803  48.048048048  0.9307482338  0.9715895653  500           0.0647715425 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3649081) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3649224) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.0000000000  4.6887679100  0.3691520691  0             0.7619614601 
0.2582582583  0.2738095238  0.2432432432  0.2857142857  0.2672672673  0.3333333333  0.2642642643  0.2500000000  0.2781774580  0.9609609610  4.4708806515  0.9694972038  10            0.0631752014 
0.2882882883  0.2976190476  0.2822822823  0.2857142857  0.3063063063  0.2857142857  0.2672672673  0.3214285714  0.2853717026  1.9219219219  4.2003325939  0.9694972038  20            0.0608967781 
0.2552552553  0.2976190476  0.3243243243  0.3095238095  0.2732732733  0.2380952381  0.2732732733  0.2857142857  0.2853717026  2.8828828829  4.2088155746  0.9694972038  30            0.0605041504 
0.2762762763  0.2738095238  0.3213213213  0.3214285714  0.2852852853  0.2380952381  0.2882882883  0.3095238095  0.2973621103  3.8438438438  4.1184447765  0.9694972038  40            0.0612068415 
0.2882882883  0.2738095238  0.3333333333  0.3809523810  0.3003003003  0.2976190476  0.3063063063  0.3214285714  0.3477218225  4.8048048048  4.1114599228  0.9694972038  50            0.0614835024 
0.3543543544  0.3095238095  0.4144144144  0.3928571429  0.3723723724  0.3214285714  0.3513513514  0.3095238095  0.4124700240  5.7657657658  4.0651668549  0.9694972038  60            0.0604119778 
0.3843843844  0.4166666667  0.4264264264  0.3690476190  0.4234234234  0.3928571429  0.4054054054  0.3452380952  0.4508393285  6.7267267267  4.0065803528  0.9694972038  70            0.0606047630 
0.4174174174  0.4285714286  0.4474474474  0.3928571429  0.4534534535  0.4047619048  0.4204204204  0.3928571429  0.4628297362  7.6876876877  3.9767865181  0.9714236259  80            0.0607913733 
0.4774774775  0.4523809524  0.4804804805  0.4523809524  0.4954954955  0.4404761905  0.4714714715  0.4166666667  0.4916067146  8.6486486486  3.9364018917  0.9714236259  90            0.0591524839 
0.4624624625  0.4523809524  0.4924924925  0.4761904762  0.5045045045  0.3809523810  0.4924924925  0.4285714286  0.4964028777  9.6096096096  3.8955984354  0.9714236259  100           0.0607703209 
0.4834834835  0.4761904762  0.5285285285  0.5000000000  0.5135135135  0.4166666667  0.4864864865  0.4523809524  0.5155875300  10.570570570  3.8792038679  0.9714236259  110           0.0592640877 
0.4594594595  0.4166666667  0.4924924925  0.4880952381  0.4924924925  0.4047619048  0.4924924925  0.4166666667  0.4988009592  11.531531531  3.8297351360  0.9714236259  120           0.0613935232 
0.4504504505  0.4285714286  0.4834834835  0.4285714286  0.4834834835  0.3809523810  0.4504504505  0.3690476190  0.4868105516  12.492492492  3.7283160448  0.9714236259  130           0.0597599983 
0.5765765766  0.5476190476  0.5855855856  0.5238095238  0.5825825826  0.5000000000  0.5585585586  0.5000000000  0.5371702638  13.453453453  3.6793029785  0.9714236259  140           0.0601933718 
0.6306306306  0.6309523810  0.6246246246  0.5357142857  0.6396396396  0.5714285714  0.6306306306  0.5119047619  0.5779376499  14.414414414  3.6389620781  0.9715538025  150           0.0609886408 
0.6216216216  0.6309523810  0.6336336336  0.6190476190  0.6366366366  0.5952380952  0.6516516517  0.4880952381  0.5803357314  15.375375375  3.5618988991  0.9715538025  160           0.0628708363 
0.6876876877  0.6904761905  0.6726726727  0.6309523810  0.6756756757  0.6904761905  0.6756756757  0.5595238095  0.6091127098  16.336336336  3.5058094025  0.9715538025  170           0.0542075157 
0.7147147147  0.7142857143  0.7297297297  0.6785714286  0.6906906907  0.6309523810  0.7057057057  0.5952380952  0.6354916067  17.297297297  3.4047626495  0.9721355438  180           0.0623852015 
0.8468468468  0.8095238095  0.8288288288  0.7142857143  0.7837837838  0.7619047619  0.7597597598  0.6428571429  0.6762589928  18.258258258  3.3674618006  0.9721355438  190           0.0621796370 
0.8528528529  0.8452380952  0.8408408408  0.7738095238  0.7897897898  0.7619047619  0.7807807808  0.6785714286  0.6786570743  19.219219219  3.3112822771  0.9721355438  200           0.0612508774 
0.8678678679  0.8571428571  0.8288288288  0.8214285714  0.7987987988  0.8095238095  0.7897897898  0.7142857143  0.7002398082  20.180180180  3.1790643215  0.9721355438  210           0.0623354435 
0.8738738739  0.8809523810  0.8768768769  0.8452380952  0.8228228228  0.8214285714  0.8108108108  0.7619047619  0.7386091127  21.141141141  3.1534762859  0.9721355438  220           0.0609932899 
0.8918918919  0.9166666667  0.8438438438  0.8452380952  0.8048048048  0.8214285714  0.8108108108  0.6666666667  0.7505995204  22.102102102  2.9900621653  0.9721355438  230           0.0586911678 
0.8918918919  0.9047619048  0.8288288288  0.8214285714  0.8138138138  0.8214285714  0.8108108108  0.7142857143  0.7290167866  23.063063063  2.9582798004  0.9721355438  240           0.0664278507 
0.8888888889  0.8928571429  0.8198198198  0.8214285714  0.8078078078  0.8333333333  0.8018018018  0.6904761905  0.7290167866  24.024024024  2.8099304199  0.9721355438  250           0.0611556530 
0.9279279279  0.9404761905  0.9039039039  0.8571428571  0.8828828829  0.8928571429  0.8828828829  0.7976190476  0.7721822542  24.984984985  2.6948347330  0.9721355438  260           0.0591348171 
0.9489489489  0.9642857143  0.9249249249  0.8809523810  0.9039039039  0.9166666667  0.9009009009  0.8214285714  0.7937649880  25.945945945  2.5764033079  0.9723849297  270           0.0608708620 
0.9489489489  0.9523809524  0.9369369369  0.8928571429  0.9099099099  0.9404761905  0.9069069069  0.8452380952  0.7577937650  26.906906906  2.4306632280  0.9723849297  280           0.0599033594 
0.9579579580  0.9642857143  0.9519519520  0.9166666667  0.9249249249  0.9523809524  0.9219219219  0.8928571429  0.7769784173  27.867867867  2.4113046885  0.9723849297  290           0.0613012075 
0.9459459459  0.9404761905  0.9279279279  0.8928571429  0.8948948949  0.9166666667  0.9039039039  0.8214285714  0.7721822542  28.828828828  2.3263947964  0.9723849297  300           0.0601381302 
0.9609609610  0.9523809524  0.9519519520  0.9285714286  0.9339339339  0.9523809524  0.9429429429  0.8928571429  0.7673860911  29.789789789  2.1825922728  1.2893729210  310           0.0633781910 
0.9759759760  0.9642857143  0.9699699700  0.9404761905  0.9549549550  0.9642857143  0.9489489489  0.9047619048  0.7841726619  30.750750750  2.1013339043  1.2893729210  320           0.0605978966 
0.9819819820  0.9642857143  0.9699699700  0.9523809524  0.9609609610  0.9642857143  0.9609609610  0.9523809524  0.7913669065  31.711711711  1.9597212672  1.2893729210  330           0.0624949217 
0.9849849850  0.9642857143  0.9849849850  0.9404761905  0.9759759760  0.9642857143  0.9699699700  0.9642857143  0.7889688249  32.672672672  1.8608343124  1.2893729210  340           0.0621727467 
0.9789789790  0.9642857143  0.9639639640  0.9166666667  0.9609609610  0.9642857143  0.9549549550  0.9285714286  0.7673860911  33.633633633  1.7959705234  1.2893729210  350           0.0610457182 
0.9939939940  1.0000000000  0.9969969970  0.9761904762  0.9909909910  0.9880952381  0.9729729730  0.9761904762  0.7937649880  34.594594594  1.6979421139  1.2893729210  360           0.0642203331 
0.9939939940  1.0000000000  0.9939939940  0.9642857143  0.9849849850  0.9880952381  0.9789789790  0.9880952381  0.7817745803  35.555555555  1.6055884242  1.2893729210  370           0.0597397566 
0.9789789790  0.9642857143  0.9639639640  0.9285714286  0.9669669670  0.9642857143  0.9669669670  0.9523809524  0.7505995204  36.516516516  1.5257306099  1.2893729210  380           0.0588416815 
0.9939939940  1.0000000000  0.9909909910  0.9523809524  0.9879879880  0.9880952381  0.9849849850  0.9880952381  0.7913669065  37.477477477  1.4840608597  1.2893729210  390           0.0602604866 
0.9969969970  1.0000000000  0.9969969970  0.9761904762  0.9939939940  0.9880952381  0.9879879880  0.9880952381  0.7577937650  38.438438438  1.3759138823  1.2893729210  400           0.0614952087 
0.9969969970  1.0000000000  0.9939939940  0.9642857143  0.9939939940  1.0000000000  0.9879879880  0.9880952381  0.7937649880  39.399399399  1.3388915300  1.2893729210  410           0.0601444721 
0.9969969970  1.0000000000  0.9939939940  0.9642857143  0.9909909910  1.0000000000  0.9879879880  0.9880952381  0.7913669065  40.360360360  1.2578907132  1.2893729210  420           0.0586742640 
0.9969969970  1.0000000000  0.9939939940  0.9642857143  0.9969969970  1.0000000000  0.9879879880  0.9880952381  0.8009592326  41.321321321  1.1996759653  1.2893729210  430           0.0610211372 
0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.7577937650  42.282282282  1.0913424373  1.2893729210  440           0.0615696192 
0.9939939940  1.0000000000  0.9909909910  0.9642857143  0.9909909910  1.0000000000  0.9879879880  0.9880952381  0.7529976019  43.243243243  1.1289621413  1.2893729210  450           0.0613707542 
0.9969969970  1.0000000000  0.9939939940  0.9642857143  0.9969969970  1.0000000000  0.9879879880  0.9880952381  0.7889688249  44.204204204  1.0156898201  1.2893729210  460           0.0622624397 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.7985611511  45.165165165  1.0137663901  1.2893729210  470           0.0624875546 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.8009592326  46.126126126  0.9500641346  1.2893729210  480           0.0582648039 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.7721822542  47.087087087  0.9186296701  1.2893729210  490           0.0609949827 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.7721822542  48.048048048  0.8273079395  1.2893729210  500           0.0612891674 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8081534772  49.009009009  0.7827510834  1.2893729210  510           0.0599277496 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7817745803  49.969969970  0.7825598657  1.2893729210  520           0.0608703852 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8105515588  50.930930930  0.7442965746  1.2893729210  530           0.0598990202 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8033573141  51.891891891  0.7257821679  1.2893729210  540           0.0662184238 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7865707434  52.852852852  0.6754313886  1.2893729210  550           0.0609066963 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7745803357  53.813813813  0.7032272160  1.2893729210  560           0.0612217426 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  54.774774774  0.5998920470  1.2893729210  570           0.0610414267 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  55.735735735  0.5957170188  1.2893729210  580           0.0595115423 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7817745803  56.696696696  0.5804046988  1.2893729210  590           0.0622123480 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7769784173  57.657657657  0.5427566618  1.2893729210  600           0.0626022100 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  58.618618618  0.5136240602  1.2893729210  610           0.0591202974 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  59.579579579  0.4646668792  1.2893729210  620           0.0612134457 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  60.540540540  0.4551503807  1.2893729210  630           0.0611818075 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  61.501501501  0.4925683647  1.2893729210  640           0.0624063969 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7745803357  62.462462462  0.4351144403  1.2893729210  650           0.0615010500 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  63.423423423  0.4340911031  1.2893729210  660           0.0612240553 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  64.384384384  0.4335741013  1.2893729210  670           0.0631942272 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  65.345345345  0.3982000768  1.2893729210  680           0.0637179613 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7673860911  66.306306306  0.3575954497  1.2893729210  690           0.0618658304 
1.0000000000  1.0000000000  0.9909909910  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  67.267267267  0.3647042215  1.2893729210  700           0.0627470970 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  68.228228228  0.3437548786  1.2893729210  710           0.0613543272 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  69.189189189  0.3284411788  1.2893729210  720           0.0602695704 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  70.150150150  0.3110792875  1.2893729210  730           0.0600290775 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  71.111111111  0.3390365213  1.2893729210  740           0.0605164766 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  72.072072072  0.3051710963  1.2893729210  750           0.0619527102 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  73.033033033  0.3205868736  1.2893729210  760           0.0616289616 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  73.993993994  0.3072647333  1.2893729210  770           0.0656633139 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7745803357  74.954954955  0.3012701765  1.2893729210  780           0.0618805170 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  75.915915915  0.2661158800  1.2893729210  790           0.0613333464 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  76.876876876  0.2621362150  1.2893729210  800           0.0606090546 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  77.837837837  0.2400175765  1.2893729210  810           0.0619226694 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  78.798798798  0.2376900375  1.2893729210  820           0.0619022846 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  79.759759759  0.2666104674  1.2893729210  830           0.0587117910 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7769784173  80.720720720  0.2331143364  1.2893729210  840           0.0617817879 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7410071942  81.681681681  0.2466050744  1.2893729210  850           0.0636041164 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  82.642642642  0.2414103150  1.2893729210  860           0.0614185095 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  83.603603603  0.2140015289  1.2893729210  870           0.0608868361 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  84.564564564  0.2067028850  1.2893729210  880           0.0641614676 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  85.525525525  0.1977285549  1.2893729210  890           0.0662684917 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  86.486486486  0.1967307553  1.2893729210  900           0.0615429401 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7769784173  87.447447447  0.1950744659  1.2893729210  910           0.0614555597 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  88.408408408  0.1748585388  1.2893729210  920           0.0641841412 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  89.369369369  0.1538847655  1.2893729210  930           0.0684021473 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  90.330330330  0.2021827310  1.2893729210  940           0.0658711910 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  91.291291291  0.1598022766  1.2893729210  950           0.0709278345 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3665589) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3666337) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2552552553  0.2500000000  0.2522522523  0.2500000000  0.2492492492  0.2500000000  0.2522522523  0.2500000000  0.2541966427  0.0000000000  1.5766522884  0.2142271996  0             0.7023451328 
0.3393393393  0.3571428571  0.3543543544  0.3214285714  0.3183183183  0.2619047619  0.3603603604  0.3095238095  0.3333333333  4.8048048048  1.4227219677  0.2187752724  50            0.0166234350 
0.4024024024  0.4047619048  0.4054054054  0.3928571429  0.3873873874  0.3214285714  0.3603603604  0.3095238095  0.3717026379  9.6096096096  1.3550565290  0.2187843323  100           0.0170758200 
0.4954954955  0.4642857143  0.4354354354  0.3571428571  0.4684684685  0.3928571429  0.4384384384  0.3690476190  0.4316546763  14.414414414  1.3061663818  0.2189249992  150           0.0166446066 
0.6126126126  0.5595238095  0.5225225225  0.3809523810  0.5195195195  0.4642857143  0.5435435435  0.4523809524  0.4868105516  19.219219219  1.2539604545  0.2189249992  200           0.0170537472 
0.6636636637  0.6666666667  0.5885885886  0.4404761905  0.5705705706  0.5833333333  0.5675675676  0.4642857143  0.4892086331  24.024024024  1.1929056239  0.2189259529  250           0.0183832979 
0.7657657658  0.7023809524  0.6966966967  0.5357142857  0.6906906907  0.5952380952  0.6396396396  0.5595238095  0.5755395683  28.828828828  1.1167988253  0.2189259529  300           0.0183946133 
0.8078078078  0.8095238095  0.7447447447  0.6428571429  0.7027027027  0.7261904762  0.6966966967  0.6190476190  0.5731414868  33.633633633  1.0492208254  0.2189259529  350           0.0182200098 
0.8168168168  0.8095238095  0.7657657658  0.6785714286  0.7237237237  0.7261904762  0.6966966967  0.5833333333  0.5851318945  38.438438438  0.9740809453  0.2189259529  400           0.0167200661 
0.8048048048  0.8452380952  0.7837837838  0.6904761905  0.7447447447  0.7380952381  0.7177177177  0.6428571429  0.6091127098  43.243243243  0.8964629662  0.2189259529  450           0.0171453094 
0.8948948949  0.8928571429  0.8468468468  0.7380952381  0.8438438438  0.7857142857  0.8258258258  0.6785714286  0.6498800959  48.048048048  0.8200144541  0.2189259529  500           0.0188027954 
0.9189189189  0.9285714286  0.8798798799  0.7619047619  0.8678678679  0.8333333333  0.8648648649  0.7023809524  0.6666666667  52.852852852  0.7426653218  0.2190141678  550           0.0179416609 
0.9219219219  0.9404761905  0.9039039039  0.7976190476  0.8828828829  0.8333333333  0.8618618619  0.7857142857  0.7194244604  57.657657657  0.6808537424  0.2190141678  600           0.0179263210 
0.9579579580  0.9642857143  0.9519519520  0.8571428571  0.9429429429  0.9166666667  0.9429429429  0.8095238095  0.7290167866  62.462462462  0.6270442533  0.2190141678  650           0.0174571896 
0.9609609610  0.9642857143  0.9579579580  0.8690476190  0.9639639640  0.9047619048  0.9489489489  0.8333333333  0.7577937650  67.267267267  0.5636386347  0.2190141678  700           0.0168492937 
0.9549549550  0.9642857143  0.9549549550  0.8571428571  0.9579579580  0.9285714286  0.9549549550  0.8571428571  0.7505995204  72.072072072  0.5082991165  0.2197055817  750           0.0166878748 
0.9819819820  0.9761904762  0.9849849850  0.9523809524  0.9849849850  0.9523809524  0.9759759760  0.8928571429  0.7841726619  76.876876876  0.4648862708  0.2197055817  800           0.0164027929 
0.9909909910  1.0000000000  0.9939939940  0.9523809524  0.9969969970  0.9880952381  0.9939939940  0.9523809524  0.8321342926  81.681681681  0.4207576489  0.2197055817  850           0.0166258764 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  0.9939939940  0.9880952381  0.9939939940  0.9642857143  0.8177458034  86.486486486  0.3714732653  0.2197055817  900           0.0166345835 
0.9909909910  1.0000000000  0.9939939940  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9642857143  0.8105515588  91.291291291  0.3281710339  0.2197055817  950           0.0166508484 
0.9939939940  1.0000000000  0.9939939940  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9642857143  0.7961630695  96.096096096  0.2987514311  0.2197055817  1000          0.0165092659 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8081534772  100.90090090  0.2631580719  0.2197055817  1050          0.0167636251 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7985611511  105.70570570  0.2366879332  0.2248353958  1100          0.0175965214 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  110.51051051  0.2136515889  0.2248353958  1150          0.0181498241 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7913669065  115.31531531  0.1909284136  0.2319369316  1200          0.0167410278 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  120.12012012  0.1701483411  0.2319369316  1250          0.0172939110 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  124.92492492  0.1542881764  0.2319369316  1300          0.0187441063 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  129.72972972  0.1435776062  0.2319369316  1350          0.0195392323 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7745803357  134.53453453  0.1321193211  0.2319369316  1400          0.0199193096 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  139.33933933  0.1191202433  0.2319369316  1450          0.0234339285 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  144.14414414  0.1123684067  0.2319369316  1500          0.0227752924 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  148.94894894  0.0976746711  0.2319369316  1550          0.0205849075 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  153.75375375  0.0927330394  0.2319369316  1600          0.0215948296 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  158.55855855  0.0841139115  0.2319369316  1650          0.0181132460 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  163.36336336  0.0798478369  0.2319369316  1700          0.0169956207 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  168.16816816  0.0708712903  0.2319369316  1750          0.0173889303 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  172.97297297  0.0691231064  0.2319369316  1800          0.0181806517 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  177.77777777  0.0639517181  0.2319369316  1850          0.0168164873 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  182.58258258  0.0595731010  0.2319369316  1900          0.0175258207 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  187.38738738  0.0554565997  0.2319369316  1950          0.0167422962 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  192.19219219  0.0525274553  0.2319369316  2000          0.0171191692 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  196.99699699  0.0520909738  0.2319369316  2050          0.0168656683 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  201.80180180  0.0467370194  0.2319369316  2100          0.0169345331 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  206.60660660  0.0445131005  0.2319369316  2150          0.0171683359 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  211.41141141  0.0402647334  0.2319369316  2200          0.0166706991 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7721822542  216.21621621  0.0413347562  0.2319369316  2250          0.0166235304 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7721822542  221.02102102  0.0367122715  0.2319369316  2300          0.0170894575 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  225.82582582  0.0361058339  0.2319369316  2350          0.0167605877 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  230.63063063  0.0350205606  0.2319369316  2400          0.0167120695 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  235.43543543  0.0319627289  0.2319369316  2450          0.0169469976 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  240.24024024  0.0305470050  0.2319369316  2500          0.0168603182 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.0000000000  1.4560132027  0.1990971565  0             0.4431641102 
0.6126126126  0.6190476190  0.6456456456  0.6190476190  0.6006006006  0.5714285714  0.5825825826  0.5952380952  0.5227817746  4.8048048048  1.2829847240  0.2036519051  50            0.0161034822 
0.7207207207  0.7023809524  0.6696696697  0.6309523810  0.6906906907  0.6547619048  0.6636636637  0.6666666667  0.5491606715  9.6096096096  1.0424426877  0.2036519051  100           0.0157675791 
0.8318318318  0.8452380952  0.8078078078  0.8095238095  0.7987987988  0.8095238095  0.7777777778  0.7500000000  0.6546762590  14.414414414  0.8238968384  0.2137441635  150           0.0159374952 
0.9369369369  0.9404761905  0.8828828829  0.8690476190  0.8828828829  0.8095238095  0.8558558559  0.8095238095  0.7050359712  19.219219219  0.6568484771  0.2137441635  200           0.0161238575 
0.9699699700  0.9404761905  0.9249249249  0.9047619048  0.9339339339  0.9761904762  0.9249249249  0.9285714286  0.7146282974  24.024024024  0.5031463629  0.2137441635  250           0.0158624649 
0.9759759760  0.9642857143  0.9429429429  0.9523809524  0.9639639640  0.9880952381  0.9729729730  0.9880952381  0.7146282974  28.828828828  0.3861261815  0.2137441635  300           0.0158175135 
0.9789789790  0.9880952381  0.9579579580  0.9523809524  0.9789789790  0.9880952381  0.9849849850  1.0000000000  0.7146282974  33.633633633  0.2901044130  0.2137441635  350           0.0162681341 
0.9819819820  0.9880952381  0.9669669670  0.9761904762  0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.7002398082  38.438438438  0.2274337962  0.2137441635  400           0.0161137247 
0.9819819820  0.9880952381  0.9699699700  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6930455635  43.243243243  0.1833602753  0.2137441635  450           0.0158854389 
0.9849849850  0.9880952381  0.9729729730  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6978417266  48.048048048  0.1530322300  0.2137441635  500           0.0160540867 
0.9849849850  0.9880952381  0.9729729730  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7074340528  52.852852852  0.1191839381  0.2137441635  550           0.0160309553 
0.9849849850  0.9880952381  0.9729729730  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7074340528  57.657657657  0.1048543939  0.2137441635  600           0.0160066223 
0.9849849850  0.9880952381  0.9729729730  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7218225420  62.462462462  0.0825057711  0.2207994461  650           0.0162112665 
0.9879879880  0.9880952381  0.9729729730  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7218225420  67.267267267  0.0761383468  0.2207994461  700           0.0161476564 
0.9879879880  0.9880952381  0.9759759760  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7146282974  72.072072072  0.0659439778  0.2207994461  750           0.0161998510 
0.9879879880  0.9880952381  0.9759759760  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7194244604  76.876876876  0.0599398262  0.2207994461  800           0.0164641809 
0.9879879880  0.9880952381  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7146282974  81.681681681  0.0622654347  0.2207994461  850           0.0165014648 
0.9879879880  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7146282974  86.486486486  0.0532950026  0.2207994461  900           0.0159640360 
0.9879879880  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7122302158  91.291291291  0.0464400202  0.2207994461  950           0.0160552740 
0.9879879880  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7098321343  96.096096096  0.0519373586  0.2207994461  1000          0.0160450697 
0.9879879880  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7122302158  100.90090090  0.0437773850  0.2207994461  1050          0.0158097029 
0.9909909910  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6954436451  105.70570570  0.0426146871  0.2207994461  1100          0.0159035587 
0.9909909910  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6978417266  110.51051051  0.0365007006  0.2207994461  1150          0.0158094740 
0.9879879880  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7146282974  115.31531531  0.0336189378  0.2207994461  1200          0.0164567566 
0.9909909910  1.0000000000  0.9789789790  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6978417266  120.12012012  0.0290055690  0.2207994461  1250          0.0182407522 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3900259) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.0000000000  1.5737870932  0.2304158211  0             0.5231568813 
0.3363363363  0.4047619048  0.4204204204  0.3333333333  0.3993993994  0.2976190476  0.3693693694  0.3571428571  0.3621103118  4.8048048048  1.4016593766  0.2350392342  50            0.0169218826 
0.5615615616  0.4761904762  0.5465465465  0.5238095238  0.5375375375  0.5357142857  0.5345345345  0.4523809524  0.5203836930  9.6096096096  1.3088823891  0.2352886200  100           0.0169755507 
0.7477477477  0.6547619048  0.7327327327  0.6666666667  0.7237237237  0.7380952381  0.7327327327  0.6071428571  0.6714628297  14.414414414  1.2143800640  0.2353405952  150           0.0172601223 
0.8888888889  0.8690476190  0.8318318318  0.7976190476  0.8468468468  0.8452380952  0.8198198198  0.7738095238  0.7386091127  19.219219219  1.0681495619  0.2353405952  200           0.0174147081 
0.9339339339  0.9404761905  0.9039039039  0.8690476190  0.8828828829  0.8809523810  0.9039039039  0.7857142857  0.7865707434  24.024024024  0.8746564937  0.2353405952  250           0.0170426989 
0.9459459459  0.9642857143  0.9489489489  0.8928571429  0.9309309309  0.9404761905  0.9519519520  0.8809523810  0.8081534772  28.828828828  0.6617908430  0.2444753647  300           0.0168638229 
0.9879879880  0.9880952381  0.9849849850  0.9523809524  0.9879879880  0.9880952381  0.9879879880  0.9880952381  0.8297362110  33.633633633  0.4838633472  0.2444753647  350           0.0169947338 
0.9969969970  1.0000000000  0.9969969970  0.9642857143  0.9969969970  0.9880952381  0.9969969970  0.9880952381  0.8177458034  38.438438438  0.3611716294  0.2444753647  400           0.0168643856 
0.9969969970  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8033573141  43.243243243  0.2612080300  0.2444753647  450           0.0171757030 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  48.048048048  0.2073599610  0.2444753647  500           0.0165876532 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  52.852852852  0.1555126026  0.2444753647  550           0.0169750786 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  57.657657657  0.1238363467  0.2444753647  600           0.0167096186 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  62.462462462  0.0968689150  0.2444753647  650           0.0177578020 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  67.267267267  0.0837016881  0.2444753647  700           0.0179736423 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  72.072072072  0.0694018807  0.2444753647  750           0.0172202015 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  76.876876876  0.0568762120  0.2444753647  800           0.0187013149 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  81.681681681  0.0518211669  0.2507219315  850           0.0187007284 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
KeyboardInterrupt
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7efad4281828>>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1323, in __del__
    def __del__(self):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3900694) is killed by signal: Terminated. 
Exception ignored in: '_pydevd_frame_eval.pydevd_frame_evaluator.get_bytecode_while_frame_eval'
Traceback (most recent call last):
  File "_pydevd_frame_eval/pydevd_frame_evaluator_common.pyx", line 159, in _pydevd_frame_eval.pydevd_frame_evaluator_common.get_func_code_info
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 415, in _joinrealpath
    name, _, rest = rest.partition(sep)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3901017) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
SystemError: <function _python_exit at 0x7efc0e3ce158> returned NULL without setting an error
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3900529) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2552552553  0.2500000000  0.2552552553  0.2500000000  0.2517985612  0.0000000000  1.5933904648  0.2455458641  0             0.4052643776 
0.2912912913  0.3452380952  0.3663663664  0.2976190476  0.3243243243  0.2142857143  0.3123123123  0.2500000000  0.3117505995  4.8048048048  1.4276164412  0.2501525879  50            0.0157520819 
0.3753753754  0.4047619048  0.3843843844  0.3333333333  0.3843843844  0.3095238095  0.3783783784  0.3333333333  0.3741007194  9.6096096096  1.3708279157  0.2501525879  100           0.0161463022 
0.4534534535  0.3928571429  0.4234234234  0.3333333333  0.3993993994  0.3928571429  0.4414414414  0.3333333333  0.3645083933  14.414414414  1.3326020789  0.2501525879  150           0.0160099936 
0.5165165165  0.4880952381  0.4804804805  0.3809523810  0.4804804805  0.4642857143  0.4864864865  0.3809523810  0.4028776978  19.219219219  1.2909787607  0.2501525879  200           0.0160040903 
0.5915915916  0.5357142857  0.5075075075  0.4523809524  0.5465465465  0.4404761905  0.5015015015  0.4642857143  0.4364508393  24.024024024  1.2459336519  0.2501525879  250           0.0160095406 
0.7177177177  0.6071428571  0.6306306306  0.4642857143  0.6276276276  0.5119047619  0.6096096096  0.5238095238  0.4556354916  28.828828828  1.1798997545  0.2501525879  300           0.0159290457 
0.7357357357  0.6428571429  0.6756756757  0.5119047619  0.6786786787  0.6428571429  0.6276276276  0.5833333333  0.4748201439  33.633633633  1.1270857072  0.2501525879  350           0.0160224009 
0.7597597598  0.6785714286  0.6996996997  0.5476190476  0.7057057057  0.6547619048  0.6366366366  0.6071428571  0.4916067146  38.438438438  1.0590021670  0.2501525879  400           0.0157985258 
0.7537537538  0.7023809524  0.7027027027  0.5952380952  0.7177177177  0.6547619048  0.6636636637  0.6547619048  0.5035971223  43.243243243  0.9927796996  0.2501525879  450           0.0158846092 
0.8288288288  0.7619047619  0.7987987988  0.7142857143  0.7747747748  0.7261904762  0.7507507508  0.6428571429  0.5683453237  48.048048048  0.9255913818  0.2501525879  500           0.0166377306 
0.8558558559  0.8214285714  0.8138138138  0.7619047619  0.7747747748  0.7142857143  0.7477477477  0.7023809524  0.5611510791  52.852852852  0.8539147377  0.2501525879  550           0.0158533907 
0.8558558559  0.8333333333  0.7987987988  0.7380952381  0.8108108108  0.7261904762  0.7507507508  0.7380952381  0.5755395683  57.657657657  0.7928528607  0.2501525879  600           0.0162365818 
0.9129129129  0.9404761905  0.8738738739  0.8214285714  0.8648648649  0.8095238095  0.8318318318  0.7500000000  0.6139088729  62.462462462  0.7356419921  0.2501525879  650           0.0160780144 
0.9099099099  0.8928571429  0.8618618619  0.8214285714  0.8438438438  0.7738095238  0.8138138138  0.7738095238  0.6354916067  67.267267267  0.6765250099  0.2501525879  700           0.0159239006 
0.9369369369  0.9404761905  0.9099099099  0.8095238095  0.8978978979  0.8452380952  0.8798798799  0.7738095238  0.6834532374  72.072072072  0.6299647248  0.2501525879  750           0.0160898781 
0.9699699700  0.9523809524  0.9219219219  0.8571428571  0.9129129129  0.8690476190  0.8918918919  0.8095238095  0.6786570743  76.876876876  0.5910068905  0.2501525879  800           0.0160819912 
0.9669669670  0.9880952381  0.9369369369  0.8809523810  0.9249249249  0.8928571429  0.9219219219  0.8452380952  0.7290167866  81.681681681  0.5469799775  0.2501525879  850           0.0160577774 
0.9789789790  1.0000000000  0.9429429429  0.8928571429  0.9369369369  0.8928571429  0.9339339339  0.8571428571  0.7386091127  86.486486486  0.5046053088  0.2501525879  900           0.0159033537 
0.9909909910  1.0000000000  0.9549549550  0.9047619048  0.9489489489  0.9166666667  0.9399399399  0.8928571429  0.7673860911  91.291291291  0.4619829899  0.2501525879  950           0.0159679222 
0.9939939940  1.0000000000  0.9699699700  0.9285714286  0.9609609610  0.9166666667  0.9759759760  0.9166666667  0.7410071942  96.096096096  0.4418732190  0.2501525879  1000          0.0185909176 
0.9939939940  1.0000000000  0.9729729730  0.9404761905  0.9609609610  0.9166666667  0.9789789790  0.9523809524  0.7649880096  100.90090090  0.4063296759  0.2501525879  1050          0.0158704567 
0.9969969970  1.0000000000  0.9789789790  0.9404761905  0.9639639640  0.9166666667  0.9819819820  0.9523809524  0.7745803357  105.70570570  0.3779861307  0.2501525879  1100          0.0159496689 
1.0000000000  1.0000000000  0.9849849850  0.9523809524  0.9669669670  0.9404761905  0.9819819820  0.9523809524  0.7985611511  110.51051051  0.3549771887  0.2501525879  1150          0.0159871912 
1.0000000000  1.0000000000  0.9879879880  0.9523809524  0.9699699700  0.9285714286  0.9849849850  0.9523809524  0.7841726619  115.31531531  0.3220490921  0.2501525879  1200          0.0193132687 
1.0000000000  1.0000000000  0.9939939940  0.9642857143  0.9819819820  0.9761904762  1.0000000000  0.9642857143  0.8153477218  120.12012012  0.2897351706  0.2501525879  1250          0.0161143255 
1.0000000000  1.0000000000  0.9939939940  0.9642857143  0.9909909910  0.9880952381  1.0000000000  0.9642857143  0.8249400480  124.92492492  0.2646871170  0.2501525879  1300          0.0159792805 
1.0000000000  1.0000000000  0.9969969970  0.9642857143  0.9969969970  1.0000000000  1.0000000000  0.9761904762  0.8249400480  129.72972972  0.2413736239  0.2501525879  1350          0.0160449028 
1.0000000000  1.0000000000  0.9969969970  0.9642857143  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8105515588  134.53453453  0.2149261490  0.2501525879  1400          0.0162876463 
1.0000000000  1.0000000000  0.9939939940  0.9642857143  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8273381295  139.33933933  0.1926710007  0.2501525879  1450          0.0160338783 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  144.14414414  0.1797121865  0.2501525879  1500          0.0161661434 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  148.94894894  0.1525579187  0.2501525879  1550          0.0164005423 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  153.75375375  0.1400715026  0.2501525879  1600          0.0161307526 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  158.55855855  0.1241873184  0.2501525879  1650          0.0160921335 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  163.36336336  0.1138489896  0.2501525879  1700          0.0161552811 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  168.16816816  0.0982867092  0.2501525879  1750          0.0163675785 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  172.97297297  0.0920499262  0.2501525879  1800          0.0170914507 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  177.77777777  0.0843677226  0.2501525879  1850          0.0161877537 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  182.58258258  0.0750781995  0.2501525879  1900          0.0161322832 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  187.38738738  0.0686484648  0.2501525879  1950          0.0202461147 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  192.19219219  0.0655824780  0.2501525879  2000          0.0171661520 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  196.99699699  0.0614704328  0.2501525879  2050          0.0160870838 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 851, in start
    self._started.wait()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 551, in wait
    signaled = self._cond.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 295, in wait
    waiter.acquire()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 3973070) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2552552553  0.2500000000  0.2552552553  0.2500000000  0.2517985612  0.0000000000  1.5932546854  0.2142891884  0             0.3381321430 
0.2912912913  0.3452380952  0.3663663664  0.2976190476  0.3243243243  0.2142857143  0.3123123123  0.2500000000  0.3165467626  4.8048048048  1.4274554181  0.2188892365  50            0.0150524426 
0.3873873874  0.4047619048  0.3873873874  0.3095238095  0.3783783784  0.3095238095  0.3723723724  0.3333333333  0.3621103118  9.6096096096  1.3706006551  0.2188892365  100           0.0151528215 
0.4564564565  0.3809523810  0.4264264264  0.3333333333  0.3993993994  0.3809523810  0.4354354354  0.3452380952  0.3693045564  14.414414414  1.3324498606  0.2188892365  150           0.0150940037 
0.5375375375  0.4642857143  0.4954954955  0.3809523810  0.4714714715  0.4404761905  0.4834834835  0.3928571429  0.4052757794  19.219219219  1.2907050681  0.2188892365  200           0.0152523756 
0.6066066066  0.5357142857  0.5135135135  0.4047619048  0.5465465465  0.4523809524  0.5045045045  0.4642857143  0.4316546763  24.024024024  1.2456177378  0.2188892365  250           0.0149150467 
0.6996996997  0.6071428571  0.6246246246  0.4642857143  0.6336336336  0.5119047619  0.5915915916  0.5476190476  0.4580335731  28.828828828  1.1796871495  0.2188892365  300           0.0150750303 
0.7567567568  0.6666666667  0.6696696697  0.5238095238  0.6966966967  0.6547619048  0.6186186186  0.5595238095  0.4796163070  33.633633633  1.1271525073  0.2188892365  350           0.0149449301 
0.7747747748  0.6785714286  0.6996996997  0.5476190476  0.7117117117  0.6547619048  0.6456456456  0.6071428571  0.5035971223  38.438438438  1.0590652430  0.2188892365  400           0.0150386429 
0.7687687688  0.7023809524  0.7147147147  0.5952380952  0.7177177177  0.6666666667  0.6546546547  0.6547619048  0.4964028777  43.243243243  0.9941674244  0.2188892365  450           0.0152319527 
0.8348348348  0.7380952381  0.8048048048  0.7023809524  0.7777777778  0.7261904762  0.7537537538  0.6547619048  0.5683453237  48.048048048  0.9256301868  0.2188892365  500           0.0151666880 
0.8498498498  0.8214285714  0.8168168168  0.7500000000  0.7717717718  0.7023809524  0.7537537538  0.7142857143  0.5587529976  52.852852852  0.8542109478  0.2188892365  550           0.0148313379 
0.8528528529  0.8452380952  0.8078078078  0.7261904762  0.8168168168  0.7261904762  0.7537537538  0.7380952381  0.5731414868  57.657657657  0.7928743470  0.2188892365  600           0.0149322128 
0.9129129129  0.9404761905  0.8798798799  0.8333333333  0.8738738739  0.8333333333  0.8288288288  0.7500000000  0.6091127098  62.462462462  0.7357703495  0.2188892365  650           0.0149111462 
0.9039039039  0.8928571429  0.8558558559  0.8095238095  0.8408408408  0.7619047619  0.8138138138  0.7976190476  0.6282973621  67.267267267  0.6768025482  0.2188892365  700           0.0154795170 
0.9369369369  0.9404761905  0.9069069069  0.8095238095  0.8888888889  0.8452380952  0.8798798799  0.7738095238  0.6834532374  72.072072072  0.6300416112  0.2188892365  750           0.0152376032 
0.9699699700  0.9523809524  0.9249249249  0.8690476190  0.9159159159  0.8809523810  0.8918918919  0.8095238095  0.6786570743  76.876876876  0.5913966227  0.2188892365  800           0.0152241802 
0.9669669670  0.9880952381  0.9309309309  0.8809523810  0.9279279279  0.8928571429  0.9159159159  0.8452380952  0.7338129496  81.681681681  0.5475318688  0.2188892365  850           0.0149983168 
0.9819819820  1.0000000000  0.9429429429  0.8928571429  0.9399399399  0.9047619048  0.9339339339  0.8690476190  0.7434052758  86.486486486  0.5048106885  0.2188892365  900           0.0148145485 
0.9879879880  1.0000000000  0.9549549550  0.9285714286  0.9489489489  0.9166666667  0.9459459459  0.8928571429  0.7649880096  91.291291291  0.4623503792  0.2188892365  950           0.0149991369 
0.9939939940  1.0000000000  0.9699699700  0.9285714286  0.9639639640  0.9166666667  0.9789789790  0.9166666667  0.7458033573  96.096096096  0.4425604028  0.2188892365  1000          0.0150895596 
0.9939939940  1.0000000000  0.9729729730  0.9404761905  0.9609609610  0.9166666667  0.9789789790  0.9523809524  0.7769784173  100.90090090  0.4070986539  0.2188892365  1050          0.0152287102 
0.9969969970  1.0000000000  0.9759759760  0.9404761905  0.9639639640  0.9166666667  0.9819819820  0.9523809524  0.7769784173  105.70570570  0.3784325147  0.2188892365  1100          0.0149385548 
1.0000000000  1.0000000000  0.9849849850  0.9523809524  0.9669669670  0.9285714286  0.9819819820  0.9523809524  0.7985611511  110.51051051  0.3556177384  0.2188892365  1150          0.0148705482 
1.0000000000  1.0000000000  0.9909909910  0.9523809524  0.9669669670  0.9285714286  0.9849849850  0.9523809524  0.7889688249  115.31531531  0.3228859937  0.2188892365  1200          0.0150742292 
1.0000000000  1.0000000000  0.9939939940  0.9642857143  0.9849849850  0.9761904762  1.0000000000  0.9642857143  0.8129496403  120.12012012  0.2904387170  0.2188892365  1250          0.0149946165 
1.0000000000  1.0000000000  0.9939939940  0.9642857143  0.9909909910  0.9880952381  1.0000000000  0.9642857143  0.8249400480  124.92492492  0.2656276715  0.2188892365  1300          0.0148373985 
1.0000000000  1.0000000000  0.9969969970  0.9642857143  0.9969969970  1.0000000000  1.0000000000  0.9761904762  0.8177458034  129.72972972  0.2430838230  0.2188892365  1350          0.0151702738 
1.0000000000  1.0000000000  0.9969969970  0.9642857143  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8081534772  134.53453453  0.2163811597  0.2188892365  1400          0.0152884722 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  139.33933933  0.1947607961  0.2188892365  1450          0.0150619650 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  144.14414414  0.1820954096  0.2188892365  1500          0.0151475048 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  148.94894894  0.1546085635  0.2188892365  1550          0.0153250122 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  153.75375375  0.1426651958  0.2188892365  1600          0.0153075075 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  158.55855855  0.1268199922  0.2188892365  1650          0.0148993015 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  163.36336336  0.1162468249  0.2188892365  1700          0.0149781799 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  168.16816816  0.1010720509  0.2188892365  1750          0.0150632095 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  172.97297297  0.0943737483  0.2188892365  1800          0.0148824215 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  177.77777777  0.0866069928  0.2188892365  1850          0.0152124119 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  182.58258258  0.0769505857  0.2188892365  1900          0.0150149012 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  187.38738738  0.0706030373  0.2188892365  1950          0.0149076986 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  192.19219219  0.0673575012  0.2188892365  2000          0.0149369240 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  196.99699699  0.0628678635  0.2188892365  2050          0.0150928545 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  201.80180180  0.0596761143  0.2188892365  2100          0.0149687290 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  206.60660660  0.0531357712  0.2188892365  2150          0.0150066566 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  211.41141141  0.0508430000  0.2188892365  2200          0.0152178478 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  216.21621621  0.0489126447  0.2188892365  2250          0.0150619841 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  221.02102102  0.0456112343  0.2188892365  2300          0.0149466848 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  225.82582582  0.0406010458  0.2188892365  2350          0.0152087307 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  230.63063063  0.0389480397  0.2188892365  2400          0.0149563265 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  235.43543543  0.0373118016  0.2188892365  2450          0.0150498009 
1.0000000000  1.0000000000  0.9969969970  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  240.24024024  0.0350891874  0.2188892365  2500          0.0150904417 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 269, in <module>
    algorithm.to(device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.0000000000  1.5735400915  0.1991591454  0             0.5324149132 
0.3363363363  0.4047619048  0.4144144144  0.3333333333  0.3993993994  0.2976190476  0.3753753754  0.3571428571  0.3621103118  4.8048048048  1.4017233944  0.2037758827  50            0.0163512707 
0.5645645646  0.4761904762  0.5465465465  0.5238095238  0.5375375375  0.5238095238  0.5345345345  0.4523809524  0.5131894484  9.6096096096  1.3089624119  0.2037758827  100           0.0159103346 
0.7507507508  0.6666666667  0.7267267267  0.6547619048  0.7267267267  0.7380952381  0.7297297297  0.5833333333  0.6666666667  14.414414414  1.2149158382  0.2117834091  150           0.0160580254 
0.8888888889  0.8809523810  0.8318318318  0.7976190476  0.8468468468  0.8452380952  0.8228228228  0.7500000000  0.7386091127  19.219219219  1.0695037115  0.2117834091  200           0.0162268019 
0.9339339339  0.9404761905  0.9009009009  0.8690476190  0.8828828829  0.8690476190  0.8948948949  0.7857142857  0.7865707434  24.024024024  0.8784003270  0.2117834091  250           0.0158728981 
0.9459459459  0.9642857143  0.9459459459  0.8928571429  0.9279279279  0.9404761905  0.9489489489  0.8809523810  0.8105515588  28.828828828  0.6666821921  0.2117834091  300           0.0160444069 
0.9879879880  0.9880952381  0.9879879880  0.9523809524  0.9879879880  0.9880952381  0.9849849850  0.9880952381  0.8297362110  33.633633633  0.4880729544  0.2173113823  350           0.0160888338 
0.9969969970  1.0000000000  0.9969969970  0.9642857143  0.9969969970  0.9880952381  0.9939939940  0.9880952381  0.8129496403  38.438438438  0.3645251131  0.2173113823  400           0.0162344456 
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fdae008fef0>>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1324, in __del__
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_trace_dispatch.py", line 56, in trace_dispatch
    def trace_dispatch(py_db, frame, event, arg):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
RuntimeError: DataLoader worker (pid 4029494) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 176, in accuracy
    p = network.predict(x)   # ARM在predict处不同
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 128, in predict
    return self.network(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 286, in forward
    x = self.layer3(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 230, in _NormPaths
    return NORM_PATHS_CONTAINER[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/six'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
    if debugger.in_project_scope(filename) and '_pydevd' not in filename:
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
    return pydevd_utils.in_project_roots(filename)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
    return _get_roots(library_roots_cache, 'LIBRARY_ROOTS', set_library_roots, _get_default_library_roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 429, in _joinrealpath
    if not islink(newpath):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 168, in islink
    def islink(path):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 4029050) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2762345679  0.2592592593  0.2916666667  0.2962962963  0.2854938272  0.3086419753  0.2932098765  0.2839506173  0.3123456790  0.0000000000  1.4342638254  0.1991591454  0             0.3599698544 
0.6080246914  0.5925925926  0.5725308642  0.5679012346  0.5817901235  0.6234567901  0.5524691358  0.5246913580  0.4925925926  2.4691358025  1.3469787383  0.2038431168  50            0.0184931898 
0.7854938272  0.7654320988  0.7222222222  0.7716049383  0.8101851852  0.8333333333  0.7098765432  0.6975308642  0.6000000000  4.9382716049  1.1759186268  0.2038431168  100           0.0157705307 
0.8719135802  0.8456790123  0.7746913580  0.8024691358  0.9104938272  0.9135802469  0.7824074074  0.7592592593  0.6925925926  7.4074074074  0.9563063478  0.2041172981  150           0.0158730125 
0.8996913580  0.9012345679  0.7978395062  0.7901234568  0.9104938272  0.9506172840  0.8317901235  0.7839506173  0.7518518519  9.8765432099  0.7571660972  0.2041172981  200           0.0174241972 
0.9490740741  0.9259259259  0.8333333333  0.8333333333  0.9444444444  0.9629629630  0.9290123457  0.9506172840  0.7962962963  12.345679012  0.6150966871  0.2041172981  250           0.0172420120 
0.9444444444  0.9074074074  0.8533950617  0.8641975309  0.9845679012  0.9876543210  0.9737654321  0.9753086420  0.7740740741  14.814814814  0.4949283201  0.2043561935  300           0.0158650446 
0.9598765432  0.9382716049  0.8703703704  0.8888888889  0.9876543210  0.9938271605  0.9845679012  0.9876543210  0.7777777778  17.283950617  0.4093317127  0.2043561935  350           0.0159623194 
0.9753086420  0.9691358025  0.9151234568  0.9135802469  0.9876543210  0.9938271605  0.9969135802  0.9938271605  0.7888888889  19.753086419  0.3364776218  0.2043561935  400           0.0168680716 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/first'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 230, in _NormPaths
    return NORM_PATHS_CONTAINER[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/first'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
    if debugger.in_project_scope(filename) and '_pydevd' not in filename:
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
    return pydevd_utils.in_project_roots(filename)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
    library_roots = _get_library_roots()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
    return _get_roots(library_roots_cache, 'LIBRARY_ROOTS', set_library_roots, _get_default_library_roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 428, in _joinrealpath
    newpath = join(path, name)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 81, in join
    sep = _get_sep(a)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 41, in _get_sep
    def _get_sep(path):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 25779) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 25461) is killed by signal: Terminated. 
We've got an error while stopping in post-mortem: <class 'RuntimeError'>

trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2870370370  0.2777777778  0.2808641975  0.2716049383  0.2793209877  0.2962962963  0.2993827160  0.2962962963  0.2925925926  0.0000000000  1.4167561531  0.1991591454  0             0.3312466145 
0.6450617284  0.6234567901  0.6203703704  0.6790123457  0.5679012346  0.5432098765  0.5679012346  0.4938271605  0.4987654321  2.4691358025  1.3417790818  0.2038431168  50            0.0166514826 
0.7577160494  0.7283950617  0.7700617284  0.8209876543  0.7746913580  0.8086419753  0.7237654321  0.6728395062  0.6370370370  4.9382716049  1.1745379925  0.2039823532  100           0.0186263704 
0.8518518519  0.8148148148  0.8580246914  0.8641975309  0.8317901235  0.8580246914  0.8040123457  0.7283950617  0.6814814815  7.4074074074  0.9635796678  0.2039823532  150           0.0178924751 
0.8657407407  0.8148148148  0.8734567901  0.8765432099  0.8580246914  0.9012345679  0.8441358025  0.7901234568  0.7185185185  9.8765432099  0.7696241224  0.2039823532  200           0.0170748711 
0.9598765432  0.9567901235  0.9382716049  0.9320987654  0.9382716049  0.9320987654  0.9367283951  0.9012345679  0.7814814815  12.345679012  0.6151438642  0.2039823532  250           0.0165248203 
0.9814814815  0.9629629630  0.9475308642  0.9320987654  0.9444444444  0.9444444444  0.9274691358  0.9012345679  0.7777777778  14.814814814  0.4940128648  0.2039823532  300           0.0160086870 
0.9953703704  0.9814814815  0.9398148148  0.9444444444  0.9506172840  0.9567901235  0.9567901235  0.9506172840  0.7851851852  17.283950617  0.3964576340  0.2039823532  350           0.0164088154 
0.9953703704  0.9814814815  0.9506172840  0.9567901235  0.9675925926  0.9814814815  0.9706790123  0.9691358025  0.8259259259  19.753086419  0.3259383106  0.2039823532  400           0.0158334684 
0.9969135802  0.9938271605  0.9567901235  0.9691358025  0.9938271605  0.9876543210  0.9783950617  0.9753086420  0.8518518519  22.222222222  0.2751638368  0.2039823532  450           0.0170418978 
1.0000000000  1.0000000000  0.9614197531  0.9691358025  0.9969135802  0.9938271605  0.9984567901  0.9876543210  0.8703703704  24.691358024  0.2344194961  0.2039823532  500           0.0162274027 
1.0000000000  1.0000000000  0.9567901235  0.9691358025  0.9969135802  0.9938271605  0.9984567901  0.9876543210  0.8629629630  27.160493827  0.1977958319  0.2098498344  550           0.0165080738 
1.0000000000  1.0000000000  0.9722222222  0.9814814815  1.0000000000  1.0000000000  0.9984567901  0.9876543210  0.8629629630  29.629629629  0.1669433479  0.2098498344  600           0.0178580332 
1.0000000000  1.0000000000  0.9660493827  0.9691358025  1.0000000000  1.0000000000  0.9984567901  0.9876543210  0.8592592593  32.098765432  0.1440511231  0.2098498344  650           0.0160145426 
1.0000000000  1.0000000000  0.9691358025  0.9753086420  1.0000000000  1.0000000000  0.9984567901  0.9876543210  0.8592592593  34.567901234  0.1284088205  0.2098498344  700           0.0157095146 
1.0000000000  1.0000000000  0.9722222222  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8629629630  37.037037037  0.1083442633  0.2098498344  750           0.0159907484 
1.0000000000  1.0000000000  0.9722222222  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  39.506172839  0.0942482609  0.2155232430  800           0.0158207989 
1.0000000000  1.0000000000  0.9768518519  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  41.975308642  0.0851933241  0.2155232430  850           0.0158772373 
1.0000000000  1.0000000000  0.9768518519  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8666666667  44.444444444  0.0782134267  0.2155232430  900           0.0159832096 
1.0000000000  1.0000000000  0.9814814815  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8629629630  46.913580246  0.0694685581  0.2155232430  950           0.0158699989 
1.0000000000  1.0000000000  0.9861111111  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8629629630  49.382716049  0.0647911737  0.2155232430  1000          0.0157392836 
1.0000000000  1.0000000000  0.9861111111  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  51.851851851  0.0522617789  0.2155232430  1050          0.0160900259 
1.0000000000  1.0000000000  0.9861111111  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8629629630  54.320987654  0.0487913658  0.2155232430  1100          0.0158002901 
1.0000000000  1.0000000000  0.9861111111  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  56.790123456  0.0446294488  0.2155232430  1150          0.0161945200 
1.0000000000  1.0000000000  0.9891975309  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  59.259259259  0.0424040980  0.2155232430  1200          0.0161285639 
1.0000000000  1.0000000000  0.9861111111  0.9814814815  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  61.728395061  0.0398102263  0.2155232430  1250          0.0159120178 
1.0000000000  1.0000000000  0.9938271605  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  64.197530864  0.0362291205  0.2156028748  1300          0.0164300776 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  66.666666666  0.0314791109  0.2156028748  1350          0.0162484264 
1.0000000000  1.0000000000  0.9938271605  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8629629630  69.135802469  0.0267597197  0.2156028748  1400          0.0159526634 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  71.604938271  0.0255319746  0.2156028748  1450          0.0157849455 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  74.074074074  0.0233899291  0.2156028748  1500          0.0160468674 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  76.543209876  0.0227506018  0.2156028748  1550          0.0160822821 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  79.012345679  0.0214520430  0.2156028748  1600          0.0161139059 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  81.481481481  0.0215708260  0.2156028748  1650          0.0162234068 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  83.950617284  0.0173677008  0.2156028748  1700          0.0156803846 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  86.419753086  0.0177753597  0.2156028748  1750          0.0167337132 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  88.888888888  0.0155882711  0.2156028748  1800          0.0159687519 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  91.358024691  0.0164129467  0.2156028748  1850          0.0160089874 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  93.827160493  0.0149694135  0.2156028748  1900          0.0160271120 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  96.296296296  0.0130418549  0.2156028748  1950          0.0156713963 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  98.765432098  0.0121294500  0.2156028748  2000          0.0161324596 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  101.23456790  0.0112700228  0.2156028748  2050          0.0160951185 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  103.70370370  0.0113539298  0.2156028748  2100          0.0159617949 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8518518519  106.17283950  0.0104940233  0.2156028748  2150          0.0160486603 
1.0000000000  1.0000000000  0.9984567901  0.9876543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  108.64197530  0.0110593532  0.2156028748  2200          0.0160292387 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  111.11111111  0.0090866340  0.2156028748  2250          0.0159652853 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  113.58024691  0.0096301426  0.2156028748  2300          0.0162338448 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  116.04938271  0.0088521795  0.2156028748  2350          0.0160414982 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  118.51851851  0.0081651350  0.2156028748  2400          0.0160561848 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  120.98765432  0.0084773783  0.2156028748  2450          0.0163172865 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  123.45679012  0.0069519337  0.2156028748  2500          0.0160847759 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2592592593  0.2530864198  0.2885802469  0.2716049383  0.2824074074  0.3086419753  0.3040123457  0.2962962963  0.3111111111  0.0000000000  1.4133514166  0.1991591454  0             0.3219234943 
0.7222222222  0.7283950617  0.6419753086  0.5864197531  0.5802469136  0.5864197531  0.6141975309  0.6049382716  0.5407407407  2.4691358025  1.3374689555  0.2188296318  50            0.0156330681 
0.8595679012  0.8395061728  0.8441358025  0.8395061728  0.7746913580  0.8086419753  0.7222222222  0.7222222222  0.6333333333  4.9382716049  1.1498717833  0.2188296318  100           0.0159751701 
0.9382716049  0.9135802469  0.8904320988  0.8765432099  0.8533950617  0.8641975309  0.7916666667  0.7592592593  0.6888888889  7.4074074074  0.9205116498  0.2188296318  150           0.0159217024 
0.9660493827  0.9691358025  0.9027777778  0.8888888889  0.8780864198  0.8950617284  0.8410493827  0.8024691358  0.7333333333  9.8765432099  0.7203695476  0.2188296318  200           0.0161395407 
0.9969135802  0.9938271605  0.9737654321  0.9753086420  0.9290123457  0.9320987654  0.8641975309  0.8395061728  0.7777777778  12.345679012  0.5760601068  0.2188296318  250           0.0154062653 
0.9891975309  0.9691358025  0.9753086420  0.9691358025  0.9660493827  0.9506172840  0.8703703704  0.8703703704  0.7777777778  14.814814814  0.4600913274  0.2188296318  300           0.0158590794 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  0.9753086420  0.9691358025  0.8873456790  0.8765432099  0.7777777778  17.283950617  0.3741916949  0.2188296318  350           0.0156634808 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  0.9830246914  0.9753086420  0.9120370370  0.9074074074  0.7851851852  19.753086419  0.3040308413  0.2188296318  400           0.0159501028 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  0.9969135802  0.9938271605  0.9413580247  0.9382716049  0.7851851852  22.222222222  0.2594237301  0.2188296318  450           0.0163358212 
0.9938271605  0.9876543210  0.9907407407  0.9814814815  1.0000000000  1.0000000000  0.9706790123  0.9691358025  0.8037037037  24.691358024  0.2144580647  0.2188296318  500           0.0164806890 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  0.9969135802  0.9938271605  0.9675925926  0.9629629630  0.8000000000  27.160493827  0.1788567019  0.2188296318  550           0.0159915352 
0.9938271605  0.9876543210  0.9907407407  0.9814814815  1.0000000000  1.0000000000  0.9969135802  0.9938271605  0.8185185185  29.629629629  0.1471252140  0.2188296318  600           0.0184941006 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  1.0000000000  1.0000000000  0.9969135802  0.9938271605  0.8148148148  32.098765432  0.1209553309  0.2188296318  650           0.0176359606 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  0.9969135802  0.9938271605  0.9969135802  0.9938271605  0.8148148148  34.567901234  0.1081714799  0.2188296318  700           0.0186422825 
0.9969135802  0.9938271605  0.9907407407  0.9814814815  1.0000000000  1.0000000000  0.9969135802  0.9938271605  0.8111111111  37.037037037  0.0876492444  0.2188296318  750           0.0161581802 
0.9969135802  0.9938271605  0.9938271605  0.9876543210  1.0000000000  1.0000000000  0.9969135802  0.9938271605  0.8222222222  39.506172839  0.0774051616  0.2188296318  800           0.0159680462 
0.9969135802  0.9938271605  0.9969135802  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8222222222  41.975308642  0.0617729954  0.2188296318  850           0.0181900978 
0.9969135802  0.9938271605  0.9969135802  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8222222222  44.444444444  0.0566018582  0.2188296318  900           0.0159586143 
0.9969135802  0.9938271605  0.9969135802  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8222222222  46.913580246  0.0504847956  0.2188296318  950           0.0184562635 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8185185185  49.382716049  0.0457920277  0.2188296318  1000          0.0182947731 
1.0000000000  1.0000000000  0.9969135802  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8222222222  51.851851851  0.0384673004  0.2188296318  1050          0.0161471701 
0.9969135802  0.9938271605  0.9969135802  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8222222222  54.320987654  0.0347008847  0.2188296318  1100          0.0159415340 
Process Process-1747:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 251, in _bootstrap
    util._run_after_forkers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 132, in _run_after_forkers
    func(obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 113, in _afterfork
    for key, (send, close) in self._cache.items():
KeyboardInterrupt
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_bundle/pydev_monkey.py", line 634, in new_fork
    child_process = getattr(os, original_name)()  # fork
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
    return filename_to_in_scope_cache[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/MarkupSafe'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 230, in _NormPaths
    return NORM_PATHS_CONTAINER[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/MarkupSafe'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 111258) is killed by signal: Terminated. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
    if debugger.in_project_scope(filename) and '_pydevd' not in filename:
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
    return pydevd_utils.in_project_roots(filename)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
    library_roots = _get_library_roots()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
    return _get_roots(library_roots_cache, 'LIBRARY_ROOTS', set_library_roots, _get_default_library_roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 429, in _joinrealpath
    if not islink(newpath):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 171, in islink
    st = os.lstat(path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
SystemError: <built-in function _error_if_any_worker_fails> returned a result with an error set
Exception ignored in: '_pydevd_frame_eval.pydevd_frame_evaluator.get_bytecode_while_frame_eval'
Traceback (most recent call last):
  File "_pydevd_frame_eval/pydevd_frame_evaluator_common.pyx", line 159, in _pydevd_frame_eval.pydevd_frame_evaluator_common.get_func_code_info
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 429, in _joinrealpath
    if not islink(newpath):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 171, in islink
    st = os.lstat(path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 111131) is killed by signal: Terminated. 
Exception ignored in: '_pydevd_frame_eval.pydevd_frame_evaluator.get_bytecode_while_frame_eval'
Traceback (most recent call last):
  File "_pydevd_frame_eval/pydevd_frame_evaluator_common.pyx", line 159, in _pydevd_frame_eval.pydevd_frame_evaluator_common.get_func_code_info
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 396, in realpath
    return abspath(path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 385, in abspath
    return normpath(path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 364, in normpath
    if (comp != dotdot or (not initial_slashes and not new_comps) or
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 110831) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
SystemError: <function _python_exit at 0x7f73c4edd158> returned NULL without setting an error
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 110845) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


0
1
2
3


env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3101851852  0.2716049383  0.2515432099  0.2345679012  0.2530864198  0.2839506173  0.3287037037  0.3209876543  0.2950617284  0.0000000000  1.4217422009  0.1991591454  0             0.3988125324 
0.7345679012  0.7469135802  0.6466049383  0.6543209877  0.6959876543  0.6728395062  0.6805555556  0.6543209877  0.5037037037  2.4691358025  1.3410856700  0.2038431168  50            0.0156234121 
0.8919753086  0.8580246914  0.8703703704  0.8456790123  0.8703703704  0.8703703704  0.8657407407  0.9074074074  0.7037037037  4.9382716049  1.1740261221  0.2039203644  100           0.0155584478 
0.9567901235  0.9506172840  0.9058641975  0.8950617284  0.9243827160  0.9506172840  0.9290123457  0.9506172840  0.7481481481  7.4074074074  0.9470641029  0.2039203644  150           0.0160603857 
0.9722222222  0.9629629630  0.9320987654  0.9382716049  0.9506172840  0.9753086420  0.9429012346  0.9691358025  0.7740740741  9.8765432099  0.7291409206  0.2039203644  200           0.0163748693 
1.0000000000  1.0000000000  0.9922839506  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8148148148  12.345679012  0.5412749559  0.2039203644  250           0.0159196615 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8037037037  14.814814814  0.4075406092  0.2039203644  300           0.0162262201 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8185185185  17.283950617  0.2994066685  0.2040972710  350           0.0161761236 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8407407407  19.753086419  0.2200408092  0.2188668251  400           0.0160472822 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8407407407  22.222222222  0.1699012260  0.2188668251  450           0.0159032679 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  24.691358024  0.1332736579  0.2188668251  500           0.0161101818 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8518518519  27.160493827  0.1039779286  0.2188668251  550           0.0167381144 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8481481481  29.629629629  0.0799140371  0.2188668251  600           0.0180943394 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8518518519  32.098765432  0.0646578898  0.2188668251  650           0.0172713614 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8481481481  34.567901234  0.0558000260  0.2188668251  700           0.0160897970 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8592592593  37.037037037  0.0425377220  0.2188668251  750           0.0163033485 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 487, in Client
    c = SocketClient(address)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 614, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 999, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 144276, 144286, 144291, 144297, 144301, 144312) exited unexpectedly
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[1.]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3101851852  0.2716049383  0.2515432099  0.2345679012  0.2530864198  0.2839506173  0.3287037037  0.3209876543  0.2950617284  0.0000000000  1.4217422009  0.1991591454  0             0.3324100971 
0.7345679012  0.7469135802  0.6466049383  0.6543209877  0.6959876543  0.6728395062  0.6805555556  0.6543209877  0.5037037037  2.4691358025  1.3410856700  0.2038431168  50            0.0159786892 
0.8919753086  0.8580246914  0.8703703704  0.8456790123  0.8703703704  0.8703703704  0.8657407407  0.9074074074  0.7037037037  4.9382716049  1.1740261221  0.2038607597  100           0.0157118464 
0.9567901235  0.9506172840  0.9058641975  0.8950617284  0.9243827160  0.9506172840  0.9290123457  0.9506172840  0.7481481481  7.4074074074  0.9470641029  0.2038607597  150           0.0164449883 
0.9722222222  0.9629629630  0.9320987654  0.9382716049  0.9506172840  0.9753086420  0.9429012346  0.9691358025  0.7740740741  9.8765432099  0.7291409206  0.2038607597  200           0.0162950563 
1.0000000000  1.0000000000  0.9922839506  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8148148148  12.345679012  0.5412749559  0.2038607597  250           0.0202783298 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8037037037  14.814814814  0.4075406092  0.2038607597  300           0.0201771688 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8185185185  17.283950617  0.2994066685  0.2038607597  350           0.0166343164 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8407407407  19.753086419  0.2200408092  0.2038607597  400           0.0165165949 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8407407407  22.222222222  0.1699012260  0.2038607597  450           0.0173872566 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8555555556  24.691358024  0.1332736579  0.2038607597  500           0.0168203020 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8518518519  27.160493827  0.1039779286  0.2041339874  550           0.0180410147 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
0
1
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
2
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
3
[[0.72589353]
 [0.27410647]]
[[0.71081862]
 [0.28918138]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2280092593  0.2314814815  0.2175925926  0.2037037037  0.2083333333  0.2175925926  0.2384259259  0.2222222222  0.2333333333  0.0000000000  1.5010986328  0.1991591454  0             0.6152396202 
0.4687500000  0.4583333333  0.4791666667  0.5046296296  0.4537037037  0.4120370370  0.4386574074  0.4212962963  0.3888888889  1.8518518519  1.3642278862  0.2041850090  50            0.0165335035 
0.7222222222  0.7453703704  0.6909722222  0.6898148148  0.7199074074  0.7314814815  0.6956018519  0.6851851852  0.6583333333  3.7037037037  1.2237172437  0.2041850090  100           0.0176767492 
0.8217592593  0.8611111111  0.8298611111  0.8240740741  0.8449074074  0.8333333333  0.8252314815  0.8148148148  0.7027777778  5.5555555556  1.0361035466  0.2041850090  150           0.0175445032 
0.9027777778  0.9444444444  0.8877314815  0.8888888889  0.9155092593  0.8935185185  0.8946759259  0.8935185185  0.7027777778  7.4074074074  0.8180097210  0.2041850090  200           0.0160452366 
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 186777) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 187218) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2280092593  0.2314814815  0.2175925926  0.2037037037  0.2083333333  0.2175925926  0.2384259259  0.2222222222  0.2333333333  0.0000000000  1.5010986328  0.1991591454  0             0.5521736145 
0.4687500000  0.4583333333  0.4791666667  0.5046296296  0.4537037037  0.4120370370  0.4386574074  0.4212962963  0.3888888889  1.8518518519  1.3642278862  0.2037658691  50            0.0161241865 
0.7222222222  0.7453703704  0.6909722222  0.6898148148  0.7199074074  0.7314814815  0.6956018519  0.6851851852  0.6583333333  3.7037037037  1.2237172437  0.2041273117  100           0.0159913206 
0.8217592593  0.8611111111  0.8298611111  0.8240740741  0.8449074074  0.8333333333  0.8252314815  0.8148148148  0.7027777778  5.5555555556  1.0361035466  0.2041273117  150           0.0165251350 
0.9027777778  0.9444444444  0.8877314815  0.8888888889  0.9155092593  0.8935185185  0.8946759259  0.8935185185  0.7027777778  7.4074074074  0.8180097210  0.2041273117  200           0.0162203979 
0.9479166667  0.9722222222  0.9571759259  0.9490740741  0.9629629630  0.9537037037  0.9618055556  0.9583333333  0.7444444444  9.2592592593  0.6372034252  0.2046098709  250           0.0164166641 
0.9398148148  0.9629629630  0.9467592593  0.9490740741  0.9479166667  0.9305555556  0.9513888889  0.9583333333  0.7055555556  11.111111111  0.4886558682  0.2046098709  300           0.0159840107 
0.9849537037  0.9907407407  0.9756944444  0.9722222222  0.9861111111  0.9722222222  0.9872685185  0.9814814815  0.7666666667  12.962962963  0.3839485037  0.2046098709  350           0.0161430931 
0.9895833333  1.0000000000  0.9756944444  0.9722222222  0.9861111111  0.9722222222  0.9872685185  0.9814814815  0.7472222222  14.814814814  0.2992670909  0.2046098709  400           0.0167513895 
1.0000000000  1.0000000000  0.9861111111  0.9861111111  0.9976851852  0.9953703704  0.9953703704  0.9907407407  0.7666666667  16.666666666  0.2392674097  0.2046098709  450           0.0162363577 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  1.0000000000  1.0000000000  0.9953703704  0.9907407407  0.7638888889  18.518518518  0.1999205378  0.2046098709  500           0.0164647007 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  1.0000000000  1.0000000000  0.9953703704  0.9907407407  0.7500000000  20.370370370  0.1547869402  0.2046098709  550           0.0164458418 
1.0000000000  1.0000000000  0.9988425926  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7666666667  22.222222222  0.1291128606  0.2046098709  600           0.0159548521 
1.0000000000  1.0000000000  0.9930555556  0.9861111111  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7472222222  24.074074074  0.1098614901  0.2046098709  650           0.0158434010 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7833333333  25.925925925  0.0942837739  0.2047305107  700           0.0159955549 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7666666667  27.777777777  0.0793186540  0.2047305107  750           0.0178455877 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7666666667  29.629629629  0.0709759783  0.2047305107  800           0.0159592628 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7611111111  31.481481481  0.0596156248  0.2047305107  850           0.0161991549 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7722222222  33.333333333  0.0536694994  0.2047305107  900           0.0163249731 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7527777778  35.185185185  0.0482891719  0.2047305107  950           0.0163782883 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7444444444  37.037037037  0.0439793829  0.2047305107  1000          0.0163093948 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7416666667  38.888888888  0.0387999630  0.2047305107  1050          0.0159778833 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7611111111  40.740740740  0.0362132325  0.2047305107  1100          0.0161050177 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7388888889  42.592592592  0.0308025138  0.2047305107  1150          0.0157681704 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7527777778  44.444444444  0.0273992567  0.2047305107  1200          0.0160756683 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7416666667  46.296296296  0.0264533340  0.2047305107  1250          0.0162218714 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7500000000  48.148148148  0.0231969927  0.2047305107  1300          0.0162470913 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7444444444  50.000000000  0.0214409568  0.2047305107  1350          0.0170312977 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 196247) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 195328) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 1e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
0
1
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
2
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
3
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2557870370  0.2500000000  0.2500000000  0.2592592593  0.2569444444  0.2962962963  0.2731481481  0.2962962963  0.2694444444  0.0000000000  0.1346085072  1.5010986328  0.1991610527  0             0.6087768078 
0.4247685185  0.4398148148  0.4155092593  0.4351851852  0.4108796296  0.3888888889  0.3877314815  0.3842592593  0.3768518519  1.8518518519  0.0905310893  1.3830572248  0.2039518356  50            0.1900853252 
0.4675925926  0.4953703704  0.5520833333  0.5694444444  0.5138888889  0.5000000000  0.4780092593  0.4629629630  0.4481481481  3.7037037037  0.0808623695  1.3232616353  0.2104625702  100           0.1983935690 
0.6562500000  0.6805555556  0.6747685185  0.6620370370  0.6493055556  0.6203703704  0.6319444444  0.5972222222  0.5796296296  5.5555555556  0.0888252211  1.2595233846  0.2104625702  150           0.2008499479 
0.7314814815  0.7546296296  0.7442129630  0.7685185185  0.7511574074  0.7314814815  0.7418981481  0.7175925926  0.6518518519  7.4074074074  0.0984608173  1.1616140652  0.2104625702  200           0.1818314075 
0.8796296296  0.8981481481  0.8958333333  0.9027777778  0.9143518519  0.8750000000  0.8969907407  0.8981481481  0.7305555556  9.2592592593  0.1000524688  1.0451954627  0.2104625702  250           0.1825383186 
0.8344907407  0.8703703704  0.8321759259  0.8287037037  0.8587962963  0.8379629630  0.8576388889  0.8564814815  0.7333333333  11.111111111  0.1074719918  0.9210272789  0.2104625702  300           0.1804416323 
0.9502314815  0.9675925926  0.9409722222  0.9444444444  0.9606481481  0.9444444444  0.9733796296  0.9722222222  0.7611111111  12.962962963  0.1110622811  0.7962864673  0.2104625702  350           0.1826287651 
0.9409722222  0.9629629630  0.9363425926  0.9444444444  0.9699074074  0.9675925926  0.9583333333  0.9537037037  0.7583333333  14.814814814  0.1092574263  0.6923142540  0.2104625702  400           0.1809413433 
0.9907407407  0.9953703704  0.9675925926  0.9722222222  0.9884259259  0.9768518519  0.9965277778  1.0000000000  0.7833333333  16.666666666  0.1163940924  0.5948794675  0.2104625702  450           0.1852460814 
0.9907407407  0.9953703704  0.9861111111  0.9861111111  0.9942129630  0.9814814815  0.9988425926  0.9907407407  0.7916666667  18.518518518  0.1203000242  0.5022392589  0.2104625702  500           0.1805135393 
0.9930555556  1.0000000000  0.9745370370  0.9768518519  0.9768518519  0.9675925926  0.9884259259  0.9907407407  0.7722222222  20.370370370  0.1156682402  0.4248144072  0.2104625702  550           0.1822923088 
0.9849537037  0.9907407407  0.9768518519  0.9814814815  0.9733796296  0.9675925926  0.9884259259  0.9907407407  0.7361111111  22.222222222  0.1283378816  0.3638712609  0.2104625702  600           0.1798492718 
0.9930555556  1.0000000000  0.9918981481  0.9907407407  0.9930555556  0.9861111111  1.0000000000  1.0000000000  0.7805555556  24.074074074  0.0932126561  0.3184555781  0.2104625702  650           0.1882755756 
0.9976851852  0.9953703704  0.9965277778  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7916666667  25.925925925  0.1024843016  0.2700639799  0.2117533684  700           0.1861516380 
1.0000000000  1.0000000000  0.9965277778  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7944444444  27.777777777  0.1004279822  0.2288525894  0.2117533684  750           0.1944214821 
0.9965277778  1.0000000000  0.9895833333  0.9861111111  0.9884259259  0.9768518519  0.9942129630  0.9953703704  0.7111111111  29.629629629  0.1020247638  0.1983768800  0.2117533684  800           0.1834680557 
1.0000000000  1.0000000000  0.9988425926  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7805555556  31.481481481  0.0951143311  0.1762321404  0.2117533684  850           0.1867718649 
1.0000000000  1.0000000000  0.9988425926  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7527777778  33.333333333  0.0939381798  0.1510987656  0.2117533684  900           0.1891028881 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7722222222  35.185185185  0.0746675707  0.1337616482  0.2117533684  950           0.1906309557 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7472222222  37.037037037  0.0691131881  0.1122968072  0.2117533684  1000          0.1923710489 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 205, in <module>
    te_splits.append(DataGenerate(args=args, domain_data=train_x[str(i)], labels=train_y[str(i)]))
KeyError: '4'
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2673611111  0.2824074074  0.2337962963  0.2268518519  0.2604166667  0.2962962963  0.2488425926  0.2638888889  0.2361111111  0.0000000000  0.0586678982  1.5010986328  0.1991610527  0             0.5390043259 
0.7141203704  0.7500000000  0.7662037037  0.7638888889  0.7569444444  0.7453703704  0.7604166667  0.7453703704  0.6203703704  1.8518518519  0.0888215256  1.2316606069  0.2039504051  50            0.1919185400 
0.9826388889  0.9861111111  0.9849537037  0.9768518519  0.9942129630  0.9953703704  0.9895833333  1.0000000000  0.8555555556  3.7037037037  0.1178019565  0.7371533847  0.2039518356  100           0.1838418388 
0.9872685185  0.9953703704  0.9837962963  0.9814814815  0.9907407407  0.9814814815  0.9907407407  0.9814814815  0.8305555556  5.5555555556  0.1091079369  0.3679049844  0.2098612785  150           0.1831801796 
0.9965277778  1.0000000000  0.9861111111  0.9861111111  0.9907407407  0.9814814815  0.9953703704  0.9907407407  0.8555555556  7.4074074074  0.0912843265  0.1922054031  0.2157378197  200           0.1821214199 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
KeyboardInterrupt
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 267503) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2673611111  0.2824074074  0.2337962963  0.2268518519  0.2604166667  0.2962962963  0.2488425926  0.2638888889  0.2907407407  0.0000000000  0.0586678982  1.5010986328  0.1991610527  0             0.5046346188 
0.7141203704  0.7500000000  0.7662037037  0.7638888889  0.7569444444  0.7453703704  0.7604166667  0.7453703704  0.6703703704  1.8518518519  0.0888215256  1.2316606069  0.2043714523  50            0.1808652401 
0.9826388889  0.9861111111  0.9849537037  0.9768518519  0.9942129630  0.9953703704  0.9895833333  1.0000000000  0.8000000000  3.7037037037  0.1178019565  0.7371533847  0.2050323486  100           0.1983398390 
0.9872685185  0.9953703704  0.9837962963  0.9814814815  0.9907407407  0.9814814815  0.9907407407  0.9814814815  0.7222222222  5.5555555556  0.1091079369  0.3679049844  0.2098612785  150           0.1858963346 
0.9965277778  1.0000000000  0.9861111111  0.9861111111  0.9907407407  0.9814814815  0.9953703704  0.9907407407  0.7250000000  7.4074074074  0.0912843265  0.1922054031  0.2098612785  200           0.1834798336 
0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7805555556  9.2592592593  0.0686859646  0.0976150902  0.2105236053  250           0.1857972050 
0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8138888889  11.111111111  0.0567325392  0.0601206166  0.2105236053  300           0.1824615669 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7555555556  12.962962963  0.0486287318  0.0404449522  0.2105236053  350           0.1824235106 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7638888889  14.814814814  0.0456041568  0.0296436211  0.2105236053  400           0.1909610605 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7805555556  16.666666666  0.0283517049  0.0175426427  0.2105236053  450           0.1892487335 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7638888889  18.518518518  0.0281199928  0.0145779422  0.2105236053  500           0.1871550035 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7250000000  20.370370370  0.0238101598  0.0100979871  0.2105236053  550           0.1921639109 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7111111111  22.222222222  0.0192013282  0.0080771419  0.2105236053  600           0.1876980543 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7305555556  24.074074074  0.0161583697  0.0064013775  0.2105236053  650           0.1969613028 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7888888889  25.925925925  0.0128049789  0.0047531468  0.2105236053  700           0.1922601318 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7361111111  27.777777777  0.0119148590  0.0039307045  0.2105236053  750           0.1947768736 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6611111111  29.629629629  0.0134324166  0.0032140297  0.2207980156  800           0.1963869238 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6944444444  31.481481481  0.0103329893  0.0029030466  0.2207980156  850           0.1850915718 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7055555556  33.333333333  0.0084005872  0.0021576567  0.2207980156  900           0.1874360561 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1984, in update
    gap = -self.hparams['t_lambda'] * self.loss_gap(minibatches, self, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1952, in loss_gap
    p = model.adv_classifier(model.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 285, in forward
    x = self.layer2(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2e-08
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 1
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2754629630  0.2777777778  0.2754629630  0.2638888889  0.2870370370  0.3287037037  0.2627314815  0.2638888889  0.2703703704  0.0000000000  0.1218522787  1.5111917257  0.1991610527  0             0.5125620365 
0.7523148148  0.7129629630  0.7812500000  0.7592592593  0.7638888889  0.7592592593  0.7500000000  0.7314814815  0.6194444444  1.8518518519  0.0946260810  1.2473386598  0.2098612785  50            0.1825524950 
0.8206018519  0.7870370370  0.8912037037  0.8935185185  0.8599537037  0.8240740741  0.8692129630  0.8287037037  0.6833333333  3.7037037037  0.1287490225  0.9064667940  0.2098612785  100           0.1827418613 
0.8495370370  0.8101851852  0.9247685185  0.8981481481  0.9050925926  0.9212962963  0.9247685185  0.8842592593  0.6944444444  5.5555555556  0.1407791078  0.5974534106  0.2098612785  150           0.1803737497 
0.8923611111  0.8611111111  0.9525462963  0.9259259259  0.9375000000  0.9444444444  0.9594907407  0.9398148148  0.7666666667  7.4074074074  0.1230449539  0.4287145472  0.2098612785  200           0.1802138042 
0.9120370370  0.8935185185  0.9583333333  0.9305555556  0.9560185185  0.9675925926  0.9849537037  0.9629629630  0.7972222222  9.2592592593  0.1149100745  0.3282589620  0.2098612785  250           0.1837389612 
0.8703703704  0.8518518519  0.9039351852  0.8564814815  0.8912037037  0.8935185185  0.9710648148  0.9351851852  0.7472222222  11.111111111  0.1218505815  0.2741006035  0.2098612785  300           0.1813674545 
0.9791666667  0.9583333333  0.9837962963  0.9675925926  0.9837962963  0.9814814815  0.9965277778  0.9861111111  0.7944444444  12.962962963  0.1175913064  0.2209983921  0.2098612785  350           0.1819527864 
0.9803240741  0.9537037037  0.9837962963  0.9675925926  0.9861111111  0.9722222222  0.9837962963  0.9675925926  0.7638888889  14.814814814  0.1202819882  0.1975437951  0.2098612785  400           0.1843726158 
0.9745370370  0.9490740741  0.9722222222  0.9583333333  0.9722222222  0.9722222222  0.9872685185  0.9675925926  0.6944444444  16.666666666  0.0940103525  0.1589064352  0.2098612785  450           0.1843542004 
0.9664351852  0.9537037037  0.9803240741  0.9675925926  0.9745370370  0.9907407407  0.9918981481  0.9907407407  0.7361111111  18.518518518  0.0874794436  0.1265319031  0.2098612785  500           0.1843769503 
0.9976851852  0.9953703704  0.9953703704  0.9907407407  0.9976851852  0.9953703704  0.9965277778  0.9861111111  0.8250000000  20.370370370  0.0663871567  0.1061732219  0.2098612785  550           0.1848091984 
1.0000000000  1.0000000000  0.9953703704  0.9907407407  1.0000000000  1.0000000000  0.9953703704  0.9768518519  0.8527777778  22.222222222  0.0775250691  0.0849516366  0.2155566216  600           0.1826162148 
1.0000000000  0.9861111111  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9918981481  0.9768518519  0.8277777778  24.074074074  0.0548669068  0.0671708290  0.2155566216  650           0.1847230434 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9814814815  0.8666666667  25.925925925  0.0630392679  0.0575269662  0.2155566216  700           0.1797548819 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 304211) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 317, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2465277778  0.2222222222  0.2025462963  0.1620370370  0.2256944444  0.2685185185  0.2060185185  0.1620370370  0.2342592593  0.0000000000  1.5111917257  0.1991591454  0             0.5684223175 
0.7847222222  0.7500000000  0.8020833333  0.8148148148  0.7905092593  0.8240740741  0.7361111111  0.7175925926  0.6000000000  1.8518518519  1.1099482346  0.2039470673  50            0.0164690971 
0.8912037037  0.8796296296  0.9618055556  0.9305555556  0.9224537037  0.9351851852  0.9479166667  0.9166666667  0.7694444444  3.7037037037  0.5317800921  0.2044906616  100           0.0162129831 
0.9004629630  0.8564814815  0.9641203704  0.9351851852  0.9409722222  0.9444444444  0.9421296296  0.9259259259  0.7388888889  5.5555555556  0.3003275222  0.2044906616  150           0.0161070108 
0.9467592593  0.9074074074  0.9768518519  0.9537037037  0.9768518519  0.9814814815  0.9953703704  0.9768518519  0.8472222222  7.4074074074  0.2266730005  0.2044906616  200           0.0163681746 
0.9641203704  0.9212962963  0.9837962963  0.9675925926  0.9803240741  0.9814814815  0.9976851852  0.9814814815  0.8138888889  9.2592592593  0.1638127185  0.2044906616  250           0.0162214661 
0.9803240741  0.9537037037  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8361111111  11.111111111  0.1228441049  0.2044906616  300           0.0162643671 
0.9942129630  0.9814814815  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.8083333333  12.962962963  0.0943559270  0.2044906616  350           0.0165831327 
1.0000000000  1.0000000000  0.9930555556  0.9861111111  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.8694444444  14.814814814  0.0677432183  0.2044906616  400           0.0164651632 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8694444444  16.666666666  0.0575675161  0.2044906616  450           0.0165316105 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8222222222  18.518518518  0.0461400711  0.2044906616  500           0.0159380484 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8472222222  20.370370370  0.0346091382  0.2044906616  550           0.0162871695 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8416666667  22.222222222  0.0273820584  0.2047882080  600           0.0163549089 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8361111111  24.074074074  0.0235586937  0.2047882080  650           0.0162246180 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8416666667  25.925925925  0.0220506530  0.2047882080  700           0.0160206413 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8416666667  27.777777777  0.0176409770  0.2047882080  750           0.0159668398 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8305555556  29.629629629  0.0140435390  0.2047882080  800           0.0163643837 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8166666667  31.481481481  0.0149537558  0.2047882080  850           0.0160463905 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8527777778  33.333333333  0.0140154896  0.2140893936  900           0.0162893486 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8111111111  35.185185185  0.0112375261  0.2140893936  950           0.0159023619 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8472222222  37.037037037  0.0099152840  0.2140893936  1000          0.0164745283 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8111111111  38.888888888  0.0077372824  0.2140893936  1050          0.0173167038 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8194444444  40.740740740  0.0085521672  0.2140893936  1100          0.0159937048 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8083333333  42.592592592  0.0075705258  0.2140893936  1150          0.0164809227 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8138888889  44.444444444  0.0059233130  0.2140893936  1200          0.0185781431 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8194444444  46.296296296  0.0054243892  0.2140893936  1250          0.0162013912 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 176, in accuracy
    p = network.predict(x)   # ARM在predict处不同
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 128, in predict
    return self.network(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 285, in forward
    x = self.layer2(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 874, in _call_impl
    self._forward_pre_hooks.values()):
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 2
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2754629630  0.2824074074  0.2754629630  0.2592592593  0.2835648148  0.3194444444  0.2534722222  0.2453703704  0.2722222222  0.0000000000  0.2310714722  1.5111917257  0.1991610527  0             0.4998741150 
0.5625000000  0.5370370370  0.5324074074  0.5092592593  0.5729166667  0.5694444444  0.5462962963  0.5509259259  0.4777777778  1.8518518519  0.1836448193  1.3417704439  0.2037692070  50            0.1776573229 
0.7442129630  0.7268518519  0.8229166667  0.7592592593  0.7662037037  0.7870370370  0.7604166667  0.7129629630  0.6009259259  3.7037037037  0.1910356331  1.2166439819  0.2212185860  100           0.1789481068 
0.6319444444  0.6250000000  0.6157407407  0.6342592593  0.6412037037  0.6018518519  0.5844907407  0.5601851852  0.5009259259  5.5555555556  0.1971253610  1.0164992952  0.2212185860  150           0.1768011475 
0.8067129630  0.8148148148  0.8553240741  0.8009259259  0.8518518519  0.8842592593  0.8159722222  0.7916666667  0.6138888889  7.4074074074  0.2090258741  0.8020561516  0.2212185860  200           0.1796113539 
0.8842592593  0.8657407407  0.9039351852  0.8842592593  0.8738425926  0.8935185185  0.8668981481  0.8657407407  0.7796296296  9.2592592593  0.2314917123  0.6440806997  0.2212185860  250           0.1774464273 
0.8518518519  0.8564814815  0.8738425926  0.8379629630  0.8750000000  0.8888888889  0.9571759259  0.9583333333  0.8879629630  11.111111111  0.2591560030  0.5472090811  0.2212185860  300           0.1778417921 
0.9166666667  0.8888888889  0.9502314815  0.9351851852  0.9432870370  0.9212962963  0.9432870370  0.9351851852  0.7435185185  12.962962963  0.2673481810  0.4696979064  0.2212185860  350           0.1790321159 
0.9131944444  0.8888888889  0.9490740741  0.9259259259  0.9583333333  0.9583333333  0.9733796296  0.9583333333  0.7546296296  14.814814814  0.2528968692  0.4252670938  0.2212185860  400           0.1777414942 
0.8912037037  0.8379629630  0.9328703704  0.9074074074  0.9305555556  0.9444444444  0.9409722222  0.9212962963  0.7185185185  16.666666666  0.2266227865  0.3844945341  0.2212185860  450           0.1763074017 
0.9375000000  0.9166666667  0.9687500000  0.9444444444  0.9594907407  0.9675925926  0.9849537037  0.9629629630  0.8500000000  18.518518518  0.2433757770  0.3312799001  0.2212185860  500           0.1759588957 
0.9571759259  0.9490740741  0.9849537037  0.9629629630  0.9803240741  0.9814814815  0.9930555556  0.9861111111  0.8388888889  20.370370370  0.2131360811  0.2903784218  0.2212185860  550           0.1777192020 
0.9699074074  0.9398148148  0.9849537037  0.9768518519  0.9733796296  0.9675925926  0.9791666667  0.9583333333  0.7583333333  22.222222222  0.2125024670  0.2574463397  0.2212185860  600           0.1808202314 
0.9849537037  0.9629629630  0.9872685185  0.9675925926  0.9733796296  0.9675925926  0.9849537037  0.9629629630  0.7694444444  24.074074074  0.1605771041  0.2190404114  0.2212185860  650           0.1881987476 
0.9768518519  0.9675925926  1.0000000000  1.0000000000  0.9953703704  0.9907407407  0.9942129630  0.9814814815  0.7916666667  25.925925925  0.2257739571  0.1976408026  0.2212185860  700           0.1832667303 
0.9872685185  0.9675925926  0.9907407407  0.9814814815  0.9930555556  1.0000000000  0.9942129630  0.9814814815  0.7777777778  27.777777777  0.1694632304  0.1787262714  0.2212185860  750           0.1816699886 
0.9826388889  0.9722222222  0.9907407407  0.9814814815  0.9814814815  0.9768518519  0.9780092593  0.9629629630  0.7138888889  29.629629629  0.1462303263  0.1518107949  0.2212185860  800           0.1762898016 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9930555556  0.9861111111  0.9884259259  0.9768518519  0.7583333333  31.481481481  0.1673685467  0.1328370535  0.2212185860  850           0.1791119099 
1.0000000000  0.9861111111  0.9942129630  0.9953703704  0.9965277778  0.9861111111  0.9918981481  0.9768518519  0.7888888889  33.333333333  0.1450340371  0.1102785203  0.2212185860  900           0.1782541466 
0.9953703704  0.9768518519  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8944444444  35.185185185  0.1356583850  0.1021264370  0.2212185860  950           0.1831292105 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 1985, in update
    gap.backward()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0.8
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2696759259  0.2870370370  0.2743055556  0.2546296296  0.2928240741  0.3148148148  0.2650462963  0.2685185185  0.2731481481  0.0000000000  0.0988366157  1.5111917257  0.1991610527  0             0.5016591549 
0.7361111111  0.6990740741  0.7858796296  0.7592592593  0.7685185185  0.7638888889  0.7187500000  0.7314814815  0.5638888889  1.8518518519  0.0792591346  1.2117696977  0.2041316032  50            0.1838515949 
0.8726851852  0.8287037037  0.9432870370  0.9212962963  0.9039351852  0.9120370370  0.9456018519  0.9120370370  0.7694444444  3.7037037037  0.1131685984  0.7776569867  0.2045536041  100           0.1807638884 
0.8715277778  0.8194444444  0.9375000000  0.9305555556  0.9293981481  0.9351851852  0.9363425926  0.9074074074  0.7138888889  5.5555555556  0.1201874514  0.4867354620  0.2045536041  150           0.1795296812 
0.9120370370  0.8796296296  0.9444444444  0.9166666667  0.9513888889  0.9583333333  0.9571759259  0.9490740741  0.7805555556  7.4074074074  0.1002911828  0.3508969364  0.2045536041  200           0.1803242683 
0.9375000000  0.9166666667  0.9745370370  0.9490740741  0.9652777778  0.9722222222  0.9861111111  0.9583333333  0.8138888889  9.2592592593  0.0921928776  0.2654740182  0.2104492188  250           0.1810480499 
0.9189814815  0.9074074074  0.9560185185  0.9259259259  0.9293981481  0.9351851852  0.9814814815  0.9629629630  0.7722222222  11.111111111  0.0937318911  0.2152236256  0.2128167152  300           0.1793857622 
0.9907407407  0.9675925926  0.9895833333  0.9722222222  0.9907407407  0.9953703704  0.9965277778  0.9861111111  0.8000000000  12.962962963  0.0918966884  0.1683209151  0.2128167152  350           0.1778327799 
0.9930555556  0.9722222222  0.9826388889  0.9722222222  0.9861111111  0.9861111111  0.9872685185  0.9675925926  0.7750000000  14.814814814  0.0844736814  0.1480269723  0.2128167152  400           0.1821609306 
1.0000000000  0.9861111111  0.9930555556  0.9861111111  0.9965277778  1.0000000000  0.9942129630  0.9814814815  0.8166666667  16.666666666  0.0665373554  0.1159368743  0.2128167152  450           0.1876172972 
0.9976851852  0.9814814815  0.9872685185  0.9814814815  0.9918981481  0.9907407407  0.9953703704  0.9907407407  0.7694444444  18.518518518  0.0570315710  0.0894382729  0.2128167152  500           0.1805622005 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.8722222222  20.370370370  0.0460995762  0.0712301056  0.2146363258  550           0.1841146612 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8944444444  22.222222222  0.0495252246  0.0555134479  0.2146363258  600           0.1932788181 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.9000000000  24.074074074  0.0355378705  0.0433875151  0.2146363258  650           0.1877227640 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9814814815  0.8722222222  25.925925925  0.0431584797  0.0375857927  0.2146363258  700           0.1985317898 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.8805555556  27.777777777  0.0362591764  0.0303697848  0.2146363258  750           0.1803570843 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8583333333  29.629629629  0.0273328526  0.0253996890  0.2146363258  800           0.1802107859 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9194444444  31.481481481  0.0253407604  0.0200476990  0.2146363258  850           0.1856809187 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9166666667  33.333333333  0.0206175457  0.0170533236  0.2146363258  900           0.1895901251 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9166666667  35.185185185  0.0224566853  0.0161684844  0.2146363258  950           0.1837063313 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    RuntimeError: DataLoader worker (pid 392028) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ARM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 8
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 591, in cwru_domain
    Bx, By, numB = AugCWRU(self.dir, domain='B', balance=2, alpha=1.).get_files()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 673, in get_files
    x = x[range(int(x.shape[0] / 2))]
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 593, in cwru_domain
    tr_x = Bx
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2465277778  0.2222222222  0.2025462963  0.1620370370  0.2256944444  0.2685185185  0.2060185185  0.1620370370  0.2000000000  0.0000000000  1.5111917257  0.1991591454  0             0.9765555859 
0.7847222222  0.7500000000  0.8020833333  0.8148148148  0.7905092593  0.8240740741  0.7361111111  0.7175925926  0.6759259259  1.8518518519  1.1099482346  0.2043075562  50            0.0163187361 
0.8912037037  0.8796296296  0.9618055556  0.9305555556  0.9224537037  0.9351851852  0.9479166667  0.9166666667  0.7092592593  3.7037037037  0.5317800921  0.2043075562  100           0.0162704468 
0.9004629630  0.8564814815  0.9641203704  0.9351851852  0.9409722222  0.9444444444  0.9421296296  0.9259259259  0.7268518519  5.5555555556  0.3003275222  0.2045469284  150           0.0161708117 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 420594) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 1590, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__
  File "_pydevd_bundle/pydevd_cython.pyx", line 933, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 420594) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 428634) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_bundle/pydevd_cython.pyx", line 1590, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__
  File "_pydevd_bundle/pydevd_cython.pyx", line 933, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 921, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch
  File "_pydevd_bundle/pydevd_cython.pyx", line 318, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1147, in do_wait_suspend
    self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1162, in _do_wait_suspend
    time.sleep(0.01)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 428634) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2465277778  0.2222222222  0.2025462963  0.1620370370  0.2256944444  0.2685185185  0.2060185185  0.1620370370  0.2000000000  0.0000000000  1.5111917257  0.1991591454  0             0.3389072418 
0.7847222222  0.7500000000  0.8020833333  0.8148148148  0.7905092593  0.8240740741  0.7361111111  0.7175925926  0.6759259259  1.8518518519  1.1099482346  0.2044377327  50            0.0160572052 
0.8912037037  0.8796296296  0.9618055556  0.9305555556  0.9224537037  0.9351851852  0.9479166667  0.9166666667  0.7092592593  3.7037037037  0.5317800921  0.2048587799  100           0.0159398127 
0.9004629630  0.8564814815  0.9641203704  0.9351851852  0.9409722222  0.9444444444  0.9421296296  0.9259259259  0.7268518519  5.5555555556  0.3003275222  0.2098560333  150           0.0161720848 
0.9467592593  0.9074074074  0.9768518519  0.9537037037  0.9768518519  0.9814814815  0.9953703704  0.9768518519  0.6953703704  7.4074074074  0.2266730005  0.2098560333  200           0.0161174917 
0.9641203704  0.9212962963  0.9837962963  0.9675925926  0.9803240741  0.9814814815  0.9976851852  0.9814814815  0.6962962963  9.2592592593  0.1638127185  0.2098560333  250           0.0159455013 
0.9803240741  0.9537037037  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.6851851852  11.111111111  0.1228441049  0.2098560333  300           0.0163402271 
0.9942129630  0.9814814815  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.6861111111  12.962962963  0.0943559270  0.2098560333  350           0.0161845922 
1.0000000000  1.0000000000  0.9930555556  0.9861111111  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.6648148148  14.814814814  0.0677432183  0.2098560333  400           0.0160052872 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6518518519  16.666666666  0.0575675161  0.2159719467  450           0.0164333439 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6388888889  18.518518518  0.0461400711  0.2159719467  500           0.0162827826 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6435185185  20.370370370  0.0346091382  0.2159719467  550           0.0157919550 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6388888889  22.222222222  0.0273820584  0.2159719467  600           0.0156793833 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6444444444  24.074074074  0.0235586937  0.2159719467  650           0.0158657455 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6388888889  25.925925925  0.0220506530  0.2159719467  700           0.0162252712 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6398148148  27.777777777  0.0176409770  0.2159719467  750           0.0161789799 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6425925926  29.629629629  0.0140435390  0.2159719467  800           0.0159119797 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6379629630  31.481481481  0.0149537558  0.2159719467  850           0.0157328320 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6379629630  33.333333333  0.0140154896  0.2159719467  900           0.0159906673 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6361111111  35.185185185  0.0112375261  0.2159719467  950           0.0160070086 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6351851852  37.037037037  0.0099152840  0.2159719467  1000          0.0161591434 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6425925926  38.888888888  0.0077372824  0.2159719467  1050          0.0158508158 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6462962963  40.740740740  0.0085521672  0.2159719467  1100          0.0163109207 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6407407407  42.592592592  0.0075705258  0.2159719467  1150          0.0161540318 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6398148148  44.444444444  0.0059233130  0.2159719467  1200          0.0161070585 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6416666667  46.296296296  0.0054243892  0.2159719467  1250          0.0161838865 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6425925926  48.148148148  0.0064432699  0.2159719467  1300          0.0161155558 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6351851852  50.000000000  0.0048623176  0.2159719467  1350          0.0157659435 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6379629630  51.851851851  0.0062615010  0.2159719467  1400          0.0158938408 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6388888889  53.703703703  0.0041490055  0.2159719467  1450          0.0160846281 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6407407407  55.555555555  0.0038940574  0.2159719467  1500          0.0161447763 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6314814815  57.407407407  0.0037199225  0.2159719467  1550          0.0162292671 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6361111111  59.259259259  0.0042159329  0.2159719467  1600          0.0159218740 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6425925926  61.111111111  0.0036783825  0.2159719467  1650          0.0162227583 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6342592593  62.962962963  0.0042342260  0.2159719467  1700          0.0158572865 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6361111111  64.814814814  0.0026421106  0.2159719467  1750          0.0159013510 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6333333333  66.666666666  0.0026281395  0.2159719467  1800          0.0161724949 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6416666667  68.518518518  0.0020903125  0.2159719467  1850          0.0159758997 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6370370370  70.370370370  0.0019482920  0.2159719467  1900          0.0161218786 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6342592593  72.222222222  0.0021436744  0.2159719467  1950          0.0162644243 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6379629630  74.074074074  0.0019753154  0.2159719467  2000          0.0162423325 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6342592593  75.925925925  0.0017203932  0.2159719467  2050          0.0158900118 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6333333333  77.777777777  0.0015814899  0.2159719467  2100          0.0160870886 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6370370370  79.629629629  0.0017591388  0.2159719467  2150          0.0159266996 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6388888889  81.481481481  0.0021308368  0.2159719467  2200          0.0161407661 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6361111111  83.333333333  0.0015610565  0.2159719467  2250          0.0161576605 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6287037037  85.185185185  0.0011587429  0.2159719467  2300          0.0160981226 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6333333333  87.037037037  0.0018302007  0.2159719467  2350          0.0161676121 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6333333333  88.888888888  0.0014392289  0.2159719467  2400          0.0159381390 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6296296296  90.740740740  0.0010567440  0.2159719467  2450          0.0159795332 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6314814815  92.592592592  0.0011433055  0.2159719467  2500          0.0159195566 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2465277778  0.2222222222  0.2025462963  0.1620370370  0.2256944444  0.2685185185  0.2060185185  0.1620370370  0.1833333333  0.0000000000  1.5111917257  0.1991591454  0             0.3489928246 
0.7847222222  0.7500000000  0.8020833333  0.8148148148  0.7905092593  0.8240740741  0.7361111111  0.7175925926  0.6601851852  1.8518518519  1.1099482346  0.2041282654  50            0.0161406231 
0.8912037037  0.8796296296  0.9618055556  0.9305555556  0.9224537037  0.9351851852  0.9479166667  0.9166666667  0.6740740741  3.7037037037  0.5317800921  0.2043094635  100           0.0158795786 
0.9004629630  0.8564814815  0.9641203704  0.9351851852  0.9409722222  0.9444444444  0.9421296296  0.9259259259  0.6898148148  5.5555555556  0.3003275222  0.2043094635  150           0.0162258387 
0.9467592593  0.9074074074  0.9768518519  0.9537037037  0.9768518519  0.9814814815  0.9953703704  0.9768518519  0.6435185185  7.4074074074  0.2266730005  0.2043094635  200           0.0160053587 
0.9641203704  0.9212962963  0.9837962963  0.9675925926  0.9803240741  0.9814814815  0.9976851852  0.9814814815  0.6509259259  9.2592592593  0.1638127185  0.2047891617  250           0.0170490742 
0.9803240741  0.9537037037  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.6333333333  11.111111111  0.1228441049  0.2104597092  300           0.0164149475 
0.9942129630  0.9814814815  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.6472222222  12.962962963  0.0943559270  0.2104597092  350           0.0162230778 
1.0000000000  1.0000000000  0.9930555556  0.9861111111  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.6138888889  14.814814814  0.0677432183  0.2104597092  400           0.0170745134 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5953703704  16.666666666  0.0575675161  0.2104597092  450           0.0164748240 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6351851852  18.518518518  0.0461400711  0.2104597092  500           0.0162858057 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6138888889  20.370370370  0.0346091382  0.2104597092  550           0.0165589571 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6129629630  22.222222222  0.0273820584  0.2104597092  600           0.0182754040 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2442129630  0.1851851852  0.2187500000  0.1990740741  0.2094907407  0.2222222222  0.2187500000  0.2129629630  0.2212962963  0.0000000000  1.5125107765  0.1991591454  0             0.3364377022 
0.6990740741  0.6898148148  0.5983796296  0.6203703704  0.5856481481  0.6296296296  0.6932870370  0.7129629630  0.6722222222  1.8518518519  1.2163970745  0.2039470673  50            0.0165549850 
0.8275462963  0.8148148148  0.6828703704  0.6990740741  0.7187500000  0.7083333333  0.8576388889  0.8750000000  0.6611111111  3.7037037037  0.8007590568  0.2049064636  100           0.0168724537 
0.9062500000  0.9027777778  0.7662037037  0.7546296296  0.7997685185  0.8287037037  0.9282407407  0.9259259259  0.7277777778  5.5555555556  0.6368815327  0.2102646828  150           0.0167016602 
0.9490740741  0.9398148148  0.8321759259  0.8657407407  0.8900462963  0.8981481481  0.9849537037  0.9768518519  0.7111111111  7.4074074074  0.5175266939  0.2102646828  200           0.0159519720 
0.9814814815  0.9629629630  0.8981481481  0.9074074074  0.9305555556  0.9444444444  0.9895833333  0.9861111111  0.7444444444  9.2592592593  0.4068767184  0.2102646828  250           0.0162721014 
0.9965277778  0.9861111111  0.9131944444  0.9027777778  0.9409722222  0.9583333333  0.9849537037  0.9768518519  0.7527777778  11.111111111  0.3378300083  0.2102785110  300           0.0161252975 
0.9907407407  0.9814814815  0.8460648148  0.8240740741  0.9097222222  0.9166666667  0.9814814815  0.9907407407  0.7527777778  12.962962963  0.2738229275  0.2102785110  350           0.0158984375 
1.0000000000  1.0000000000  0.9641203704  0.9629629630  0.9780092593  0.9768518519  0.9976851852  0.9953703704  0.6777777778  14.814814814  0.2183788723  0.2102785110  400           0.0159025002 
1.0000000000  1.0000000000  0.9652777778  0.9444444444  0.9803240741  0.9814814815  0.9976851852  0.9953703704  0.6722222222  16.666666666  0.1858990437  0.2102785110  450           0.0157997322 
1.0000000000  1.0000000000  0.9745370370  0.9629629630  0.9849537037  0.9907407407  1.0000000000  1.0000000000  0.6583333333  18.518518518  0.1542967245  0.2102785110  500           0.0155978155 
1.0000000000  1.0000000000  0.9872685185  0.9675925926  0.9780092593  0.9768518519  1.0000000000  1.0000000000  0.6722222222  20.370370370  0.1278603561  0.2102785110  550           0.0156618786 
1.0000000000  1.0000000000  0.9884259259  0.9768518519  0.9861111111  0.9861111111  1.0000000000  1.0000000000  0.6694444444  22.222222222  0.1131760427  0.2106256485  600           0.0160980892 
1.0000000000  1.0000000000  0.9953703704  0.9768518519  0.9918981481  0.9907407407  1.0000000000  1.0000000000  0.6305555556  24.074074074  0.0984981149  0.2106256485  650           0.0158637667 
1.0000000000  1.0000000000  0.9953703704  0.9907407407  0.9965277778  1.0000000000  1.0000000000  1.0000000000  0.6138888889  25.925925925  0.0881323490  0.2106256485  700           0.0161062002 
1.0000000000  1.0000000000  0.9965277778  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5555555556  27.777777777  0.0684425018  0.2106256485  750           0.0158513260 
1.0000000000  1.0000000000  0.9988425926  0.9907407407  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.5527777778  29.629629629  0.0683016001  0.2106256485  800           0.0157422352 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.5888888889  31.481481481  0.0573757937  0.2106256485  850           0.0158982277 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5888888889  33.333333333  0.0510426293  0.2106256485  900           0.0163678122 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5527777778  35.185185185  0.0424247282  0.2106256485  950           0.0161383200 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5416666667  37.037037037  0.0394083606  0.2106256485  1000          0.0160697603 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5388888889  38.888888888  0.0365138869  0.2114028931  1050          0.0158248949 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5638888889  40.740740740  0.0358101040  0.2168574333  1100          0.0161721516 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5500000000  42.592592592  0.0313251716  0.2168574333  1150          0.0157881117 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5305555556  44.444444444  0.0275568082  0.2168574333  1200          0.0160671473 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5250000000  46.296296296  0.0243719503  0.2168574333  1250          0.0160777235 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5333333333  48.148148148  0.0254468929  0.2168574333  1300          0.0163319588 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5361111111  50.000000000  0.0214135456  0.2168574333  1350          0.0161806345 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5166666667  51.851851851  0.0174821645  0.2168574333  1400          0.0159501934 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5416666667  53.703703703  0.0184073984  0.2168574333  1450          0.0159381914 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5388888889  55.555555555  0.0164571129  0.2168574333  1500          0.0163358021 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5222222222  57.407407407  0.0153435685  0.2168574333  1550          0.0159593868 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5222222222  59.259259259  0.0150374824  0.2168574333  1600          0.0184577131 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5444444444  61.111111111  0.0140624018  0.2168574333  1650          0.0189736891 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5277777778  62.962962963  0.0145550389  0.2168574333  1700          0.0173019075 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5222222222  64.814814814  0.0107406275  0.2168574333  1750          0.0184823990 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5194444444  66.666666666  0.0094976000  0.2168574333  1800          0.0158492041 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5222222222  68.518518518  0.0114931704  0.2168574333  1850          0.0181185579 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5194444444  70.370370370  0.0110211239  0.2168574333  1900          0.0159885311 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5166666667  72.222222222  0.0087123857  0.2202467918  1950          0.0165106773 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5222222222  74.074074074  0.0101197399  0.2202467918  2000          0.0161730480 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5138888889  75.925925925  0.0092880525  0.2202467918  2050          0.0161958599 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5305555556  77.777777777  0.0065781896  0.2202467918  2100          0.0157525158 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5305555556  79.629629629  0.0105307245  0.2202467918  2150          0.0160440922 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5083333333  81.481481481  0.0072355900  0.2202467918  2200          0.0158914423 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5083333333  83.333333333  0.0050972112  0.2202467918  2250          0.0162712049 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5222222222  85.185185185  0.0065878598  0.2202467918  2300          0.0161795855 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5194444444  87.037037037  0.0063788804  0.2202467918  2350          0.0159599018 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5055555556  88.888888888  0.0046940849  0.2202467918  2400          0.0160935211 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5166666667  90.740740740  0.0056705755  0.2202467918  2450          0.0163098335 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5027777778  92.592592592  0.0063681555  0.2202467918  2500          0.0161286736 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2280092593  0.2592592593  0.1967592593  0.2175925926  0.2083333333  0.2175925926  0.2083333333  0.1574074074  0.2166666667  0.0000000000  1.5011451244  0.1991591454  0             0.3331172466 
0.7129629630  0.6851851852  0.6307870370  0.6250000000  0.6319444444  0.5879629630  0.6550925926  0.6111111111  0.7222222222  1.8518518519  1.2122522700  0.2037658691  50            0.0164539957 
0.8275462963  0.8055555556  0.7395833333  0.7268518519  0.7581018519  0.7824074074  0.8078703704  0.8194444444  0.7444444444  3.7037037037  0.8115555620  0.2039470673  100           0.0162513828 
0.8831018519  0.8564814815  0.8078703704  0.8101851852  0.8553240741  0.8472222222  0.8819444444  0.8750000000  0.8333333333  5.5555555556  0.6402378583  0.2041878700  150           0.0160484219 
0.9305555556  0.9259259259  0.8310185185  0.8379629630  0.8831018519  0.8842592593  0.8958333333  0.9027777778  0.8583333333  7.4074074074  0.5439255422  0.2041878700  200           0.0160483456 
0.9629629630  0.9583333333  0.8981481481  0.8888888889  0.9004629630  0.9120370370  0.9178240741  0.9120370370  0.8333333333  9.2592592593  0.4308932269  0.2041878700  250           0.0161190224 
0.9791666667  0.9675925926  0.9444444444  0.9120370370  0.9178240741  0.9351851852  0.9502314815  0.9166666667  0.8472222222  11.111111111  0.3470736110  0.2045502663  300           0.0163894653 
0.9826388889  0.9814814815  0.9282407407  0.9074074074  0.9143518519  0.9259259259  0.9375000000  0.9212962963  0.8916666667  12.962962963  0.2871467406  0.2045502663  350           0.0162959814 
0.9861111111  0.9768518519  0.9884259259  0.9583333333  0.9710648148  0.9722222222  0.9930555556  0.9675925926  0.8027777778  14.814814814  0.2321935031  0.2051486969  400           0.0161239672 
0.9930555556  0.9814814815  0.9849537037  0.9537037037  0.9733796296  0.9814814815  0.9872685185  0.9814814815  0.8138888889  16.666666666  0.1938246965  0.2168736458  450           0.0160726166 
0.9953703704  0.9907407407  0.9918981481  0.9629629630  0.9756944444  0.9814814815  0.9918981481  0.9861111111  0.7944444444  18.518518518  0.1563325369  0.2168736458  500           0.0158837318 
0.9953703704  0.9861111111  0.9895833333  0.9583333333  0.9814814815  0.9861111111  0.9953703704  0.9861111111  0.7888888889  20.370370370  0.1384695359  0.2168736458  550           0.0159291506 
0.9965277778  0.9907407407  0.9976851852  0.9629629630  0.9884259259  0.9861111111  0.9953703704  0.9814814815  0.7750000000  22.222222222  0.1215775789  0.2168736458  600           0.0156733799 
0.9988425926  0.9907407407  0.9953703704  0.9675925926  0.9907407407  0.9907407407  0.9988425926  0.9814814815  0.7583333333  24.074074074  0.1024655385  0.2168736458  650           0.0161396980 
0.9976851852  0.9907407407  0.9965277778  0.9629629630  0.9803240741  0.9722222222  0.9976851852  0.9814814815  0.8000000000  25.925925925  0.0856260573  0.2168736458  700           0.0159993792 
0.9988425926  0.9953703704  0.9976851852  0.9814814815  0.9965277778  0.9814814815  0.9988425926  0.9814814815  0.6972222222  27.777777777  0.0778407598  0.2168736458  750           0.0161320400 
0.9965277778  0.9953703704  0.9965277778  0.9768518519  0.9942129630  0.9814814815  0.9965277778  0.9907407407  0.6944444444  29.629629629  0.0714961733  0.2168736458  800           0.0162059402 
0.9988425926  0.9953703704  0.9988425926  0.9722222222  0.9965277778  0.9861111111  0.9976851852  0.9907407407  0.7611111111  31.481481481  0.0679402290  0.2168736458  850           0.0161776209 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  0.9976851852  0.9861111111  0.9976851852  0.9861111111  0.7638888889  33.333333333  0.0591846816  0.2168736458  900           0.0174848223 
0.9988425926  0.9953703704  0.9988425926  0.9861111111  1.0000000000  0.9907407407  0.9988425926  0.9907407407  0.7333333333  35.185185185  0.0534677409  0.2168736458  950           0.0180553150 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  1.0000000000  0.9907407407  0.9988425926  0.9861111111  0.7638888889  37.037037037  0.0481544301  0.2168736458  1000          0.0160476017 
1.0000000000  0.9953703704  0.9988425926  0.9722222222  0.9988425926  0.9907407407  0.9988425926  0.9861111111  0.7416666667  38.888888888  0.0437170505  0.2168736458  1050          0.0162694740 
0.9988425926  1.0000000000  1.0000000000  0.9861111111  1.0000000000  0.9907407407  0.9988425926  0.9907407407  0.7555555556  40.740740740  0.0428659417  0.2168736458  1100          0.0160447788 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f511d646630>>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1323, in __del__
    def __del__(self):
KeyboardInterrupt: 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 851, in start
    self._started.wait()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 551, in wait
    signaled = self._cond.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 295, in wait
    waiter.acquire()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 592637) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 201, in _finalize_close
    notempty.notify()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 351, in notify
    waiter.release()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 593045) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 186, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 201, in _finalize_close
    notempty.notify()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 296, in _exit_function
    _run_finalizers(0)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 262, in _run_finalizers
    finalizer()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 592801) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2442129630  0.1851851852  0.2187500000  0.1990740741  0.2094907407  0.2222222222  0.2187500000  0.2129629630  0.1842592593  0.0000000000  1.5125107765  0.1991591454  0             0.6364843845 
0.6990740741  0.6898148148  0.5983796296  0.6203703704  0.5856481481  0.6296296296  0.6932870370  0.7129629630  0.6027777778  1.8518518519  1.2163970745  0.2039470673  50            0.0162461042 
0.8275462963  0.8148148148  0.6828703704  0.6990740741  0.7187500000  0.7083333333  0.8576388889  0.8750000000  0.5888888889  3.7037037037  0.8007590568  0.2043690681  100           0.0160068893 
0.9062500000  0.9027777778  0.7662037037  0.7546296296  0.7997685185  0.8287037037  0.9282407407  0.9259259259  0.6194444444  5.5555555556  0.6368815327  0.2043690681  150           0.0162190866 
0.9490740741  0.9398148148  0.8321759259  0.8657407407  0.8900462963  0.8981481481  0.9849537037  0.9768518519  0.6037037037  7.4074074074  0.5175266939  0.2043690681  200           0.0162194204 
0.9814814815  0.9629629630  0.8981481481  0.9074074074  0.9305555556  0.9444444444  0.9895833333  0.9861111111  0.6435185185  9.2592592593  0.4068767184  0.2043690681  250           0.0160797977 
0.9965277778  0.9861111111  0.9131944444  0.9027777778  0.9409722222  0.9583333333  0.9849537037  0.9768518519  0.6435185185  11.111111111  0.3378300083  0.2159738541  300           0.0159410143 
0.9907407407  0.9814814815  0.8460648148  0.8240740741  0.9097222222  0.9166666667  0.9814814815  0.9907407407  0.6583333333  12.962962963  0.2738229275  0.2159738541  350           0.0164816999 
1.0000000000  1.0000000000  0.9641203704  0.9629629630  0.9780092593  0.9768518519  0.9976851852  0.9953703704  0.6074074074  14.814814814  0.2183788723  0.2159738541  400           0.0160129595 
1.0000000000  1.0000000000  0.9652777778  0.9444444444  0.9803240741  0.9814814815  0.9976851852  0.9953703704  0.5898148148  16.666666666  0.1858990437  0.2159738541  450           0.0163926077 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2164, in main
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1476, in run
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 267, in in_project_roots
    return filename_to_in_scope_cache[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/typeshed/stubs/tabulate'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 545, in _is_int
    int(filename)
ValueError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1959, in handle_keyboard_interrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 607, in in_project_scope
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 280, in in_project_roots
    library_roots = _get_library_roots()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 261, in _get_library_roots
    return _get_roots(library_roots_cache, 'LIBRARY_ROOTS', set_library_roots, _get_default_library_roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 208, in _get_roots
    set_when_not_cached(roots)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 256, in set_library_roots
    roots = _set_roots(roots, _LIBRARY_ROOTS_CACHE)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 188, in _set_roots
    new_roots.append(_normpath(root))
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_utils.py", line 27, in _normpath
    return pydevd_file_utils.get_abs_path_real_path_and_base_from_file(filename)[0]
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 568, in get_abs_path_real_path_and_base_from_file
    if not is_real_file(f):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 552, in is_real_file
    return not _is_int(filename) and not filename.startswith("<ipython-input")
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 545, in _is_int
    int(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 626863) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 590, in cwru_domain
    Ax, Ay, numA = CWRU(self.dir, domain='A', balance=2).get_files()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 484, in get_files
    data1, lab1 = self.data_load(path1, j, label=int(k))
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 583, in data_load
    x = x[range(int(x.shape[0] / 2))]
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2280092593  0.2592592593  0.1967592593  0.2175925926  0.2083333333  0.2175925926  0.2083333333  0.1574074074  0.1925925926  0.0000000000  1.5011451244  0.1991591454  0             0.4694874287 
0.7129629630  0.6851851852  0.6307870370  0.6250000000  0.6319444444  0.5879629630  0.6550925926  0.6111111111  0.6379629630  1.8518518519  1.2122522700  0.2037658691  50            0.0160599136 
0.8275462963  0.8055555556  0.7395833333  0.7268518519  0.7581018519  0.7824074074  0.8078703704  0.8194444444  0.6537037037  3.7037037037  0.8115555620  0.2039470673  100           0.0161509562 
0.8831018519  0.8564814815  0.8078703704  0.8101851852  0.8553240741  0.8472222222  0.8819444444  0.8750000000  0.6907407407  5.5555555556  0.6402378583  0.2039470673  150           0.0164976883 
0.9305555556  0.9259259259  0.8310185185  0.8379629630  0.8831018519  0.8842592593  0.8958333333  0.9027777778  0.7111111111  7.4074074074  0.5439255422  0.2039470673  200           0.0160713196 
0.9629629630  0.9583333333  0.8981481481  0.8888888889  0.9004629630  0.9120370370  0.9178240741  0.9120370370  0.6694444444  9.2592592593  0.4308932269  0.2041282654  250           0.0160384035 
0.9791666667  0.9675925926  0.9444444444  0.9120370370  0.9178240741  0.9351851852  0.9502314815  0.9166666667  0.6953703704  11.111111111  0.3470736110  0.2041859627  300           0.0159730434 
0.9826388889  0.9814814815  0.9282407407  0.9074074074  0.9143518519  0.9259259259  0.9375000000  0.9212962963  0.7259259259  12.962962963  0.2871467406  0.2041859627  350           0.0187700939 
0.9861111111  0.9768518519  0.9884259259  0.9583333333  0.9710648148  0.9722222222  0.9930555556  0.9675925926  0.6555555556  14.814814814  0.2321935031  0.2047872543  400           0.0168249130 
0.9930555556  0.9814814815  0.9849537037  0.9537037037  0.9733796296  0.9814814815  0.9872685185  0.9814814815  0.6675925926  16.666666666  0.1938246965  0.2047872543  450           0.0157490587 
0.9953703704  0.9907407407  0.9918981481  0.9629629630  0.9756944444  0.9814814815  0.9918981481  0.9861111111  0.6675925926  18.518518518  0.1563325369  0.2047872543  500           0.0160771036 
0.9953703704  0.9861111111  0.9895833333  0.9583333333  0.9814814815  0.9861111111  0.9953703704  0.9861111111  0.6638888889  20.370370370  0.1384695359  0.2047872543  550           0.0161134434 
0.9965277778  0.9907407407  0.9976851852  0.9629629630  0.9884259259  0.9861111111  0.9953703704  0.9814814815  0.6703703704  22.222222222  0.1215775789  0.2047872543  600           0.0159046745 
0.9988425926  0.9907407407  0.9953703704  0.9675925926  0.9907407407  0.9907407407  0.9988425926  0.9814814815  0.6388888889  24.074074074  0.1024655385  0.2047872543  650           0.0157480478 
0.9976851852  0.9907407407  0.9965277778  0.9629629630  0.9803240741  0.9722222222  0.9976851852  0.9814814815  0.6620370370  25.925925925  0.0856260573  0.2047872543  700           0.0157839298 
0.9988425926  0.9953703704  0.9976851852  0.9814814815  0.9965277778  0.9814814815  0.9988425926  0.9814814815  0.6148148148  27.777777777  0.0778407598  0.2047872543  750           0.0156461048 
0.9965277778  0.9953703704  0.9965277778  0.9768518519  0.9942129630  0.9814814815  0.9965277778  0.9907407407  0.5842592593  29.629629629  0.0714961733  0.2159738541  800           0.0161464882 
0.9988425926  0.9953703704  0.9988425926  0.9722222222  0.9965277778  0.9861111111  0.9976851852  0.9907407407  0.6453703704  31.481481481  0.0679402290  0.2159738541  850           0.0159771776 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  0.9976851852  0.9861111111  0.9976851852  0.9861111111  0.6555555556  33.333333333  0.0591846816  0.2159738541  900           0.0161759186 
0.9988425926  0.9953703704  0.9988425926  0.9861111111  1.0000000000  0.9907407407  0.9988425926  0.9907407407  0.6314814815  35.185185185  0.0534677409  0.2162179947  950           0.0158019018 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 896, in __init__
    index_queue = multiprocessing_context.Queue()  # type: ignore
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 102, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 48, in __init__
    self._sem = ctx.BoundedSemaphore(maxsize)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 87, in BoundedSemaphore
    return BoundedSemaphore(value, ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 145, in __init__
    SemLock.__init__(self, SEMAPHORE, value, value, ctx=ctx)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 59, in __init__
    unlink_now)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Process Process-1553:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2245370370  0.2592592593  0.2025462963  0.2037037037  0.2129629630  0.2314814815  0.2291666667  0.1620370370  0.2064814815  0.0000000000  1.5011451244  0.1991591454  0             0.3530926704 
0.6423611111  0.5833333333  0.5949074074  0.5787037037  0.5821759259  0.5787037037  0.5949074074  0.5648148148  0.5796296296  1.8518518519  1.3301164126  0.2082047462  50            0.0171646357 
0.7256944444  0.6759259259  0.6863425926  0.6712962963  0.6597222222  0.6851851852  0.7199074074  0.6759259259  0.6250000000  3.7037037037  1.0646942115  0.2102766037  100           0.0159008408 
0.7800925926  0.7453703704  0.7118055556  0.6851851852  0.7384259259  0.7500000000  0.7569444444  0.7731481481  0.6555555556  5.5555555556  0.8366185582  0.2102766037  150           0.0159123230 
0.8414351852  0.7824074074  0.7777777778  0.7638888889  0.7986111111  0.8194444444  0.8449074074  0.8333333333  0.6592592593  7.4074074074  0.7304954469  0.2102766037  200           0.0159814835 
0.8773148148  0.8379629630  0.8043981481  0.8009259259  0.8425925926  0.8425925926  0.8680555556  0.8750000000  0.6657407407  9.2592592593  0.6542536414  0.2102766037  250           0.0160561323 
0.9085648148  0.9027777778  0.8263888889  0.8240740741  0.8750000000  0.8888888889  0.8969907407  0.9074074074  0.7055555556  11.111111111  0.5890086043  0.2102766037  300           0.0160365248 
0.9131944444  0.9027777778  0.8182870370  0.8101851852  0.8750000000  0.8888888889  0.8981481481  0.9027777778  0.7277777778  12.962962963  0.5453235221  0.2102766037  350           0.0161700392 
0.9502314815  0.9259259259  0.8784722222  0.8796296296  0.8865740741  0.8981481481  0.9085648148  0.9027777778  0.7009259259  14.814814814  0.4839388794  0.2102766037  400           0.0158553791 
0.9583333333  0.9398148148  0.8622685185  0.8472222222  0.8923611111  0.8981481481  0.9062500000  0.9120370370  0.7240740741  16.666666666  0.4325634319  0.2102766037  450           0.0156399393 
0.9745370370  0.9768518519  0.9039351852  0.8888888889  0.9027777778  0.9212962963  0.9178240741  0.9212962963  0.7157407407  18.518518518  0.3787404478  0.2102766037  500           0.0155118656 
0.9745370370  0.9629629630  0.9293981481  0.8842592593  0.9155092593  0.9212962963  0.9421296296  0.9166666667  0.7120370370  20.370370370  0.3374157894  0.2102766037  550           0.0158843994 
0.9861111111  0.9861111111  0.9745370370  0.9444444444  0.9583333333  0.9537037037  0.9768518519  0.9675925926  0.6500000000  22.222222222  0.3081171298  0.2102766037  600           0.0161702442 
0.9837962963  0.9768518519  0.9375000000  0.8888888889  0.9247685185  0.9212962963  0.9456018519  0.9398148148  0.7175925926  24.074074074  0.2733067098  0.2102766037  650           0.0161440754 
0.9861111111  0.9722222222  0.9317129630  0.8935185185  0.9236111111  0.9212962963  0.9375000000  0.9351851852  0.7157407407  25.925925925  0.2336211103  0.2119297981  700           0.0159432840 
0.9907407407  0.9814814815  0.9872685185  0.9583333333  0.9756944444  0.9722222222  0.9884259259  0.9722222222  0.6259259259  27.777777777  0.2176605451  0.2157330513  750           0.0160003853 
0.9895833333  0.9861111111  0.9826388889  0.9537037037  0.9710648148  0.9722222222  0.9895833333  0.9814814815  0.6240740741  29.629629629  0.1990278378  0.2157330513  800           0.0161807156 
0.9918981481  0.9907407407  0.9814814815  0.9490740741  0.9675925926  0.9629629630  0.9837962963  0.9768518519  0.6638888889  31.481481481  0.1873450613  0.2157330513  850           0.0155293465 
0.9930555556  0.9861111111  0.9826388889  0.9490740741  0.9745370370  0.9675925926  0.9930555556  0.9768518519  0.6907407407  33.333333333  0.1678295794  0.2157330513  900           0.0163138485 
0.9953703704  0.9861111111  0.9826388889  0.9444444444  0.9768518519  0.9675925926  0.9907407407  0.9768518519  0.6824074074  35.185185185  0.1532491940  0.2157330513  950           0.0160632277 
0.9942129630  0.9861111111  0.9895833333  0.9537037037  0.9745370370  0.9675925926  0.9930555556  0.9722222222  0.7027777778  37.037037037  0.1487655829  0.2157330513  1000          0.0159310627 
0.9930555556  0.9907407407  0.9907407407  0.9583333333  0.9895833333  0.9768518519  0.9965277778  0.9722222222  0.6509259259  38.888888888  0.1315198627  0.2157330513  1050          0.0164300013 
0.9965277778  1.0000000000  0.9953703704  0.9629629630  0.9837962963  0.9907407407  0.9965277778  0.9814814815  0.6694444444  40.740740740  0.1244037513  0.2157330513  1100          0.0176154613 
0.9965277778  0.9953703704  0.9965277778  0.9583333333  0.9884259259  0.9814814815  0.9976851852  0.9814814815  0.6518518519  42.592592592  0.1156405839  0.2157330513  1150          0.0159966326 
Process Process-1841:
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 251, in _bootstrap
    util._run_after_forkers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 132, in _run_after_forkers
    func(obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/_atfork.py", line 10, in wrapper
    func()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 2.5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0.8
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 2.5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0.8
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: Transfer
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	d_steps_per_g: 10
	data_augmentation: True
	delta: 2
	gda: False
	lr: 2.5e-05
	lr_d: 1e-05
	lr_iter: 2001
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	t_lambda: 0.8
	weight_decay: 0.0008
	weight_decay_d: 0.0008
Load Data.
B->A
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         gap           loss          mem_gb        step          step_time    
0.2673611111  0.2916666667  0.2430555556  0.2407407407  0.2523148148  0.2500000000  0.2569444444  0.2638888889  0.2675925926  0.0000000000  0.0911358818  1.5011451244  0.1991610527  0             0.5191857815 
0.5162037037  0.4953703704  0.4699074074  0.4259259259  0.4907407407  0.5138888889  0.4988425926  0.5000000000  0.4805555556  1.8518518519  0.0673896400  1.3644805336  0.2037692070  50            0.1759505081 
0.6180555556  0.5370370370  0.6273148148  0.5972222222  0.6145833333  0.6342592593  0.6469907407  0.6388888889  0.5277777778  3.7037037037  0.0756969919  1.2627785921  0.2045526505  100           0.1748322058 
0.6412037037  0.6111111111  0.6793981481  0.6481481481  0.6412037037  0.6296296296  0.6631944444  0.6342592593  0.6074074074  5.5555555556  0.0899848389  1.1038059163  0.2045526505  150           0.1829869032 
0.6689814815  0.6481481481  0.6967592593  0.6944444444  0.6689814815  0.6712962963  0.7210648148  0.6851851852  0.6083333333  7.4074074074  0.1094396860  0.9131207275  0.2047319412  200           0.1768257284 
0.7106481481  0.6620370370  0.7314814815  0.7268518519  0.7187500000  0.7453703704  0.7858796296  0.7361111111  0.6027777778  9.2592592593  0.1190093075  0.8268566787  0.2047319412  250           0.1789280987 
0.7974537037  0.7916666667  0.7581018519  0.7407407407  0.7881944444  0.7824074074  0.8391203704  0.8333333333  0.6425925926  11.111111111  0.1180570111  0.7448389208  0.2047319412  300           0.1721129322 
0.7569444444  0.7638888889  0.7650462963  0.6990740741  0.7546296296  0.7546296296  0.8252314815  0.7824074074  0.5657407407  12.962962963  0.1520170759  0.7001864624  0.2047328949  350           0.1761753321 
0.7847222222  0.7824074074  0.7754629630  0.7685185185  0.7731481481  0.7731481481  0.8379629630  0.8240740741  0.5981481481  14.814814814  0.1309666091  0.6752284205  0.2047328949  400           0.1859823990 
0.8240740741  0.8148148148  0.8043981481  0.8055555556  0.8634259259  0.8425925926  0.8796296296  0.8703703704  0.6518518519  16.666666666  0.1033295721  0.6305203736  0.2136254311  450           0.1905753946 
0.8506944444  0.8379629630  0.7986111111  0.8055555556  0.8287037037  0.8287037037  0.8726851852  0.8703703704  0.6212962963  18.518518518  0.1197275462  0.5887949634  0.2136254311  500           0.1961474276 
0.8969907407  0.8796296296  0.8310185185  0.8240740741  0.8622685185  0.8611111111  0.9050925926  0.9027777778  0.6435185185  20.370370370  0.1147489835  0.5452888530  0.2136254311  550           0.1937020302 
0.9039351852  0.8842592593  0.8946759259  0.8842592593  0.9050925926  0.8935185185  0.9178240741  0.9120370370  0.7055555556  22.222222222  0.1133144970  0.5067591172  0.2136254311  600           0.1906242990 
0.9375000000  0.9166666667  0.8935185185  0.8703703704  0.9097222222  0.9027777778  0.9201388889  0.9166666667  0.6703703704  24.074074074  0.1076444556  0.4786976993  0.2136254311  650           0.1803222179 
0.9502314815  0.9398148148  0.9039351852  0.8796296296  0.9143518519  0.8935185185  0.9155092593  0.9212962963  0.6861111111  25.925925925  0.1096351527  0.4365161771  0.2136254311  700           0.1783482885 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 77, in _launch
    os.close(child_w)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2638888889  0.2094907407  0.1898148148  0.2280092593  0.2361111111  0.2222222222  0.1898148148  0.2046296296  0.0000000000  1.5125107765  0.1991591454  0             0.4691147804 
0.6712962963  0.6759259259  0.6053240741  0.6203703704  0.5787037037  0.6157407407  0.6666666667  0.6712962963  0.5407407407  1.8518518519  1.3354453921  0.2037658691  50            0.0159399748 
0.7245370370  0.7129629630  0.6585648148  0.6712962963  0.6631944444  0.6666666667  0.7662037037  0.7407407407  0.5416666667  3.7037037037  1.0628689861  0.2039470673  100           0.0158274412 
0.8067129630  0.7731481481  0.6504629630  0.6620370370  0.7025462963  0.7037037037  0.8321759259  0.8379629630  0.6722222222  5.5555555556  0.8340603530  0.2039470673  150           0.0159563160 
0.8425925926  0.8379629630  0.6921296296  0.7175925926  0.7453703704  0.7268518519  0.8807870370  0.8796296296  0.6500000000  7.4074074074  0.7204915738  0.2039470673  200           0.0159249163 
0.9039351852  0.8981481481  0.7418981481  0.7546296296  0.7962962963  0.7870370370  0.9212962963  0.9398148148  0.6777777778  9.2592592593  0.6488235795  0.2046079636  250           0.0162600279 
0.9282407407  0.9259259259  0.8020833333  0.7916666667  0.8483796296  0.8425925926  0.9490740741  0.9537037037  0.6722222222  11.111111111  0.5949766016  0.2046079636  300           0.0158583117 
0.9467592593  0.9490740741  0.7939814815  0.7685185185  0.8530092593  0.8518518519  0.9629629630  0.9675925926  0.6638888889  12.962962963  0.5247667098  0.2046079636  350           0.0159778166 
0.9733796296  0.9675925926  0.8564814815  0.8518518519  0.9131944444  0.9166666667  0.9872685185  0.9814814815  0.6527777778  14.814814814  0.4600287223  0.2046079636  400           0.0157102537 
0.9803240741  0.9675925926  0.8796296296  0.8842592593  0.9131944444  0.9166666667  0.9895833333  0.9861111111  0.6583333333  16.666666666  0.4164479065  0.2046079636  450           0.0160141611 
0.9895833333  0.9722222222  0.9120370370  0.9074074074  0.9490740741  0.9675925926  0.9930555556  0.9861111111  0.7000000000  18.518518518  0.3653682387  0.2046079636  500           0.0159168005 
0.9942129630  0.9814814815  0.9166666667  0.9166666667  0.9560185185  0.9675925926  0.9953703704  0.9907407407  0.7138888889  20.370370370  0.3168447548  0.2046079636  550           0.0161710978 
0.9965277778  0.9861111111  0.9375000000  0.9444444444  0.9675925926  0.9907407407  0.9942129630  0.9953703704  0.6916666667  22.222222222  0.2946069354  0.2046079636  600           0.0159606218 
1.0000000000  1.0000000000  0.9270833333  0.9027777778  0.9502314815  0.9629629630  0.9976851852  0.9953703704  0.7222222222  24.074074074  0.2621778598  0.2046079636  650           0.0159173822 
1.0000000000  1.0000000000  0.9583333333  0.9444444444  0.9710648148  0.9768518519  0.9976851852  0.9953703704  0.6777777778  25.925925925  0.2317176276  0.2051506042  700           0.0155715656 
1.0000000000  1.0000000000  0.9548611111  0.9583333333  0.9861111111  0.9861111111  0.9942129630  0.9953703704  0.5972222222  27.777777777  0.2057146481  0.2051506042  750           0.0161675692 
1.0000000000  1.0000000000  0.9629629630  0.9675925926  0.9918981481  0.9907407407  0.9976851852  0.9953703704  0.5944444444  29.629629629  0.1935527445  0.2051506042  800           0.0162734795 
1.0000000000  1.0000000000  0.9618055556  0.9444444444  0.9594907407  0.9675925926  1.0000000000  1.0000000000  0.6777777778  31.481481481  0.1731453814  0.2051506042  850           0.0159414005 
1.0000000000  1.0000000000  0.9710648148  0.9490740741  0.9826388889  0.9861111111  0.9976851852  0.9953703704  0.6388888889  33.333333333  0.1565781644  0.2051506042  900           0.0161714268 
1.0000000000  1.0000000000  0.9814814815  0.9629629630  0.9872685185  0.9953703704  0.9976851852  0.9953703704  0.6083333333  35.185185185  0.1416886571  0.2051506042  950           0.0161185312 
1.0000000000  1.0000000000  0.9837962963  0.9675925926  0.9884259259  0.9907407407  0.9976851852  0.9953703704  0.6000000000  37.037037037  0.1297414297  0.2051506042  1000          0.0158958769 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  0.9965277778  1.0000000000  0.9976851852  0.9953703704  0.5611111111  38.888888888  0.1215211557  0.2051506042  1050          0.0160186720 
1.0000000000  1.0000000000  0.9895833333  0.9722222222  0.9907407407  0.9953703704  1.0000000000  1.0000000000  0.5833333333  40.740740740  0.1160124326  0.2178497314  1100          0.0157084227 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 768187) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2233796296  0.2314814815  0.1921296296  0.1990740741  0.2094907407  0.2407407407  0.2048611111  0.1851851852  0.2074074074  0.0000000000  1.4866926670  0.1991591454  0             0.3351378441 
0.6516203704  0.6388888889  0.6145833333  0.6342592593  0.5833333333  0.5972222222  0.5925925926  0.5833333333  0.5638888889  1.8518518519  1.3319502378  0.2037658691  50            0.0158194447 
0.7476851852  0.7314814815  0.7129629630  0.7314814815  0.6956018519  0.7037037037  0.7418981481  0.6851851852  0.6972222222  3.7037037037  1.0479421484  0.2039470673  100           0.0164057541 
0.7789351852  0.7870370370  0.7094907407  0.7037037037  0.7476851852  0.7314814815  0.7488425926  0.7407407407  0.7083333333  5.5555555556  0.8061224318  0.2041282654  150           0.0159341288 
0.8078703704  0.8101851852  0.7719907407  0.7453703704  0.7893518519  0.7731481481  0.8333333333  0.7777777778  0.7222222222  7.4074074074  0.6954885924  0.2043094635  200           0.0160036564 
0.8321759259  0.8379629630  0.7951388889  0.7638888889  0.8159722222  0.7916666667  0.8564814815  0.7962962963  0.7500000000  9.2592592593  0.6190046990  0.2047295570  250           0.0157252169 
0.8587962963  0.8703703704  0.8125000000  0.7777777778  0.8402777778  0.8055555556  0.8854166667  0.8194444444  0.7305555556  11.111111111  0.5886065638  0.2047295570  300           0.0159039927 
0.8831018519  0.8842592593  0.8043981481  0.7824074074  0.8530092593  0.8101851852  0.8888888889  0.8333333333  0.6916666667  12.962962963  0.5316301864  0.2047295570  350           0.0157919979 
0.9062500000  0.8888888889  0.8275462963  0.8009259259  0.8634259259  0.8101851852  0.9236111111  0.8888888889  0.7055555556  14.814814814  0.4808982724  0.2047891617  400           0.0156837845 
0.9293981481  0.9212962963  0.8391203704  0.8101851852  0.8738425926  0.8379629630  0.9293981481  0.8935185185  0.7194444444  16.666666666  0.4498671365  0.2047891617  450           0.0158408213 
0.9456018519  0.9259259259  0.8518518519  0.8287037037  0.8784722222  0.8333333333  0.9409722222  0.9027777778  0.7194444444  18.518518518  0.4142739654  0.2047891617  500           0.0160580873 
0.9733796296  0.9537037037  0.8541666667  0.8194444444  0.8784722222  0.8472222222  0.9421296296  0.9120370370  0.7138888889  20.370370370  0.3699912751  0.2047891617  550           0.0162100172 
0.9756944444  0.9444444444  0.9131944444  0.8750000000  0.8946759259  0.8518518519  0.9513888889  0.9305555556  0.6805555556  22.222222222  0.3541972059  0.2047891617  600           0.0159195089 
0.9837962963  0.9675925926  0.8993055556  0.8611111111  0.8993055556  0.8611111111  0.9456018519  0.9259259259  0.7083333333  24.074074074  0.3194371161  0.2047891617  650           0.0161143112 
0.9872685185  0.9675925926  0.9363425926  0.9074074074  0.9131944444  0.8888888889  0.9641203704  0.9351851852  0.7027777778  25.925925925  0.3009226462  0.2048373222  700           0.0187698460 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    fd = df.detach()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 493, in Client
    answer_challenge(c, authkey)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 737, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 790532) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[8.29934060e-01]
 [1.69974128e-01]
 [9.18115800e-05]]
[[4.47689752e-01]
 [3.74894956e-04]
 [5.51935353e-01]]
[[0.8533309 ]
 [0.03502751]
 [0.11164159]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
[[0.74160125]
 [0.24952403]
 [0.00887473]]
[[0.00563463]
 [0.13475929]
 [0.85960608]]
[[0.17340551]
 [0.50270176]
 [0.32389273]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2303240741  0.2361111111  0.2164351852  0.2083333333  0.2280092593  0.2361111111  0.2210648148  0.1898148148  0.2185185185  0.0000000000  1.4866926670  0.1991591454  0             0.4302563667 
0.4293981481  0.4259259259  0.3611111111  0.3518518519  0.3645833333  0.3750000000  0.3738425926  0.3750000000  0.3685185185  1.8518518519  1.4010459065  0.2039461136  50            0.0159171867 
0.6377314815  0.6157407407  0.5972222222  0.6296296296  0.5706018519  0.5925925926  0.6192129630  0.6342592593  0.5944444444  3.7037037037  1.3051053143  0.2047872543  100           0.0160449123 
0.6481481481  0.6435185185  0.6400462963  0.6342592593  0.6168981481  0.6296296296  0.6689814815  0.6296296296  0.6157407407  5.5555555556  1.1869453621  0.2047872543  150           0.0162784147 
0.6979166667  0.6944444444  0.6608796296  0.6759259259  0.6574074074  0.6481481481  0.6863425926  0.6435185185  0.6222222222  7.4074074074  1.0390656149  0.2047872543  200           0.0158115005 
0.7418981481  0.7546296296  0.6851851852  0.6898148148  0.6932870370  0.6990740741  0.6967592593  0.6574074074  0.6324074074  9.2592592593  0.9238557398  0.2047872543  250           0.0159591055 
0.7696759259  0.7685185185  0.7118055556  0.6944444444  0.7199074074  0.7175925926  0.7361111111  0.7083333333  0.6694444444  11.111111111  0.8456626117  0.2047872543  300           0.0182785320 
0.7800925926  0.7962962963  0.7523148148  0.7407407407  0.7592592593  0.7546296296  0.7986111111  0.7500000000  0.7083333333  12.962962963  0.7845041537  0.2047872543  350           0.0162235069 
0.8009259259  0.8101851852  0.7673611111  0.7500000000  0.7673611111  0.7500000000  0.8240740741  0.7870370370  0.7055555556  14.814814814  0.7228257596  0.2047872543  400           0.0163674974 
0.8032407407  0.8009259259  0.7696759259  0.7546296296  0.7766203704  0.7685185185  0.8402777778  0.7916666667  0.7000000000  16.666666666  0.7012388134  0.2047872543  450           0.0162283325 
0.8067129630  0.8287037037  0.7766203704  0.7546296296  0.7916666667  0.7638888889  0.8530092593  0.7962962963  0.7055555556  18.518518518  0.6666267002  0.2047872543  500           0.0163625908 
0.8402777778  0.8472222222  0.7962962963  0.7731481481  0.8171296296  0.7870370370  0.8460648148  0.8101851852  0.7222222222  20.370370370  0.6201467717  0.2047872543  550           0.0181957436 
0.8495370370  0.8379629630  0.7800925926  0.7546296296  0.8182870370  0.7685185185  0.8645833333  0.7916666667  0.7333333333  22.222222222  0.6133742511  0.2047872543  600           0.0159624958 
0.8576388889  0.8750000000  0.7870370370  0.7685185185  0.8310185185  0.8009259259  0.8773148148  0.8240740741  0.7166666667  24.074074074  0.5844930685  0.2047872543  650           0.0160000753 
0.8692129630  0.8703703704  0.8032407407  0.7731481481  0.8333333333  0.8055555556  0.8842592593  0.8101851852  0.7527777778  25.925925925  0.5723172295  0.2047872543  700           0.0159092283 
0.8807870370  0.8796296296  0.8101851852  0.7731481481  0.8368055556  0.8194444444  0.8865740741  0.8148148148  0.7222222222  27.777777777  0.5455453086  0.2047872543  750           0.0161004496 
0.8842592593  0.8935185185  0.8043981481  0.7685185185  0.8402777778  0.8194444444  0.8969907407  0.8425925926  0.7027777778  29.629629629  0.5233407813  0.2106251717  800           0.0160393810 
0.8946759259  0.9074074074  0.8090277778  0.7777777778  0.8587962963  0.8148148148  0.8969907407  0.8425925926  0.7111111111  31.481481481  0.5186506695  0.2106251717  850           0.0164344645 
0.9074074074  0.8981481481  0.8298611111  0.8055555556  0.8692129630  0.8148148148  0.9050925926  0.8657407407  0.7361111111  33.333333333  0.4940029687  0.2106251717  900           0.0160472536 
0.9074074074  0.9120370370  0.8217592593  0.7962962963  0.8657407407  0.8148148148  0.9085648148  0.8796296296  0.6888888889  35.185185185  0.4816221392  0.2106251717  950           0.0157982445 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 591, in cwru_domain
    Ax, Ay, numA = AugCWRU(self.dir, domain='A', balance=2, alpha=1.).get_files(5.3)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 659, in get_files
    RG = np.random.default_rng(seed)
  File "_generator.pyx", line 4360, in numpy.random._generator.default_rng
  File "_pcg64.pyx", line 109, in numpy.random._pcg64.PCG64.__init__
  File "bit_generator.pyx", line 526, in numpy.random.bit_generator.BitGenerator.__init__
  File "bit_generator.pyx", line 308, in numpy.random.bit_generator.SeedSequence.__init__
TypeError: SeedSequence expects int or sequence of ints for entropy not 5.3
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 195, in <module>
    train_x, train_y, tr_num = dataset.cwru_domain()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/datasets.py", line 591, in cwru_domain
    Ax, Ay, numA = AugCWRU(self.dir, domain='A', balance=2, alpha=1.).get_files(5.3)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/bearings_datasets.py", line 659, in get_files
    RG = np.random.default_rng(seed)
  File "_generator.pyx", line 4360, in numpy.random._generator.default_rng
  File "_pcg64.pyx", line 109, in numpy.random._pcg64.PCG64.__init__
  File "bit_generator.pyx", line 526, in numpy.random.bit_generator.BitGenerator.__init__
  File "bit_generator.pyx", line 308, in numpy.random.bit_generator.SeedSequence.__init__
TypeError: SeedSequence expects int or sequence of ints for entropy not 5.3
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 821292) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
[[0.55410848]
 [0.19037682]
 [0.25551471]]
[[0.48607197]
 [0.3752198 ]
 [0.13870822]]
[[0.33901664]
 [0.08137366]
 [0.5796097 ]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2314814815  0.2314814815  0.2233796296  0.1990740741  0.2546296296  0.2500000000  0.2372685185  0.1712962963  0.2138888889  0.0000000000  1.4942857027  0.1991591454  0             0.4629559517 
0.4039351852  0.4212962963  0.4085648148  0.3935185185  0.3715277778  0.4120370370  0.3472222222  0.3379629630  0.3712962963  1.8518518519  1.3893310642  0.2039470673  50            0.0158968067 
0.6782407407  0.6944444444  0.6550925926  0.6296296296  0.6481481481  0.6712962963  0.6134259259  0.6250000000  0.5583333333  3.7037037037  1.2874902153  0.2041282654  100           0.0157083702 
0.7083333333  0.7222222222  0.6840277778  0.6666666667  0.6712962963  0.7037037037  0.6921296296  0.6805555556  0.6379629630  5.5555555556  1.1504654765  0.2043671608  150           0.0160699463 
0.7488425926  0.7407407407  0.7222222222  0.6944444444  0.7106481481  0.7407407407  0.7013888889  0.6805555556  0.6518518519  7.4074074074  0.9842345500  0.2043671608  200           0.0162407732 
0.7870370370  0.7685185185  0.7743055556  0.7500000000  0.7673611111  0.8194444444  0.7291666667  0.7500000000  0.6879629630  9.2592592593  0.8486597073  0.2043690681  250           0.0160496902 
0.8495370370  0.8657407407  0.8356481481  0.8101851852  0.8263888889  0.8750000000  0.7928240741  0.8425925926  0.7555555556  11.111111111  0.7382550824  0.2043690681  300           0.0158826828 
0.8738425926  0.8935185185  0.8518518519  0.8564814815  0.8703703704  0.8935185185  0.8576388889  0.8888888889  0.7416666667  12.962962963  0.6640780234  0.2043690681  350           0.0161016273 
0.8993055556  0.9027777778  0.8773148148  0.8796296296  0.8738425926  0.8935185185  0.8877314815  0.9074074074  0.7527777778  14.814814814  0.5911193013  0.2043690681  400           0.0158015490 
0.8900462963  0.8703703704  0.8715277778  0.8750000000  0.8657407407  0.8842592593  0.8865740741  0.9120370370  0.7472222222  16.666666666  0.5466634756  0.2046079636  450           0.0158941078 
0.9108796296  0.9120370370  0.8923611111  0.9166666667  0.8993055556  0.9027777778  0.9062500000  0.9305555556  0.7583333333  18.518518518  0.5076115572  0.2046079636  500           0.0156737757 
0.9097222222  0.9166666667  0.8865740741  0.8981481481  0.8969907407  0.8981481481  0.8958333333  0.9166666667  0.7861111111  20.370370370  0.4588180298  0.2046079636  550           0.0157691193 
0.9293981481  0.9351851852  0.8993055556  0.9166666667  0.9039351852  0.9259259259  0.9224537037  0.9490740741  0.7638888889  22.222222222  0.4339150816  0.2046079636  600           0.0159796572 
0.9259259259  0.9212962963  0.8923611111  0.9027777778  0.9166666667  0.9166666667  0.9178240741  0.9537037037  0.7611111111  24.074074074  0.4065858561  0.2046079636  650           0.0159256124 
0.9293981481  0.9351851852  0.8969907407  0.9120370370  0.9236111111  0.9444444444  0.9305555556  0.9583333333  0.7666666667  25.925925925  0.3792566562  0.2046079636  700           0.0158540106 
0.9409722222  0.9444444444  0.9039351852  0.9120370370  0.9328703704  0.9490740741  0.9386574074  0.9675925926  0.7611111111  27.777777777  0.3562131447  0.2046079636  750           0.0160417652 
0.9375000000  0.9444444444  0.9178240741  0.9120370370  0.9340277778  0.9583333333  0.9456018519  0.9675925926  0.7611111111  29.629629629  0.3419325918  0.2046079636  800           0.0160966206 
0.9525462963  0.9537037037  0.9074074074  0.9259259259  0.9444444444  0.9583333333  0.9456018519  0.9675925926  0.7583333333  31.481481481  0.3318679917  0.2046079636  850           0.0157521820 
0.9548611111  0.9583333333  0.9317129630  0.9259259259  0.9583333333  0.9722222222  0.9513888889  0.9722222222  0.7583333333  33.333333333  0.3156054655  0.2046079636  900           0.0159027624 
0.9675925926  0.9629629630  0.9131944444  0.9166666667  0.9560185185  0.9675925926  0.9421296296  0.9675925926  0.7388888889  35.185185185  0.2886792648  0.2047295570  950           0.0161707020 
0.9675925926  0.9629629630  0.9502314815  0.9351851852  0.9629629630  0.9675925926  0.9513888889  0.9722222222  0.7638888889  37.037037037  0.2760446912  0.2047295570  1000          0.0159300661 
0.9756944444  0.9722222222  0.9432870370  0.9351851852  0.9629629630  0.9675925926  0.9513888889  0.9722222222  0.7416666667  38.888888888  0.2669377112  0.2150521278  1050          0.0162682295 
0.9791666667  0.9722222222  0.9293981481  0.9351851852  0.9594907407  0.9675925926  0.9479166667  0.9722222222  0.7222222222  40.740740740  0.2480488896  0.2150521278  1100          0.0160051727 
0.9780092593  0.9629629630  0.9467592593  0.9490740741  0.9710648148  0.9629629630  0.9513888889  0.9722222222  0.7305555556  42.592592592  0.2389949897  0.2150521278  1150          0.0160712671 
0.9849537037  0.9768518519  0.9560185185  0.9398148148  0.9710648148  0.9768518519  0.9571759259  0.9768518519  0.7416666667  44.444444444  0.2316491216  0.2150521278  1200          0.0158890963 
0.9849537037  0.9768518519  0.9664351852  0.9537037037  0.9745370370  0.9768518519  0.9594907407  0.9814814815  0.7305555556  46.296296296  0.2183819175  0.2150521278  1250          0.0160442257 
0.9895833333  0.9861111111  0.9687500000  0.9583333333  0.9745370370  0.9768518519  0.9629629630  0.9814814815  0.7222222222  48.148148148  0.2071935025  0.2150521278  1300          0.0158471727 
0.9872685185  0.9814814815  0.9664351852  0.9537037037  0.9745370370  0.9768518519  0.9560185185  0.9814814815  0.7083333333  50.000000000  0.1899249437  0.2150521278  1350          0.0160614967 
0.9826388889  0.9722222222  0.9699074074  0.9537037037  0.9745370370  0.9768518519  0.9594907407  0.9814814815  0.6888888889  51.851851851  0.1944902423  0.2150521278  1400          0.0159427452 
0.9895833333  0.9861111111  0.9722222222  0.9583333333  0.9780092593  0.9768518519  0.9722222222  0.9861111111  0.7222222222  53.703703703  0.1922193173  0.2150521278  1450          0.0159875774 
0.9918981481  0.9907407407  0.9756944444  0.9583333333  0.9814814815  0.9768518519  0.9756944444  0.9861111111  0.7055555556  55.555555555  0.1787047698  0.2150521278  1500          0.0161386347 
0.9895833333  0.9861111111  0.9756944444  0.9583333333  0.9745370370  0.9768518519  0.9722222222  0.9861111111  0.7000000000  57.407407407  0.1733088405  0.2150521278  1550          0.0158482504 
0.9942129630  0.9953703704  0.9791666667  0.9583333333  0.9780092593  0.9768518519  0.9699074074  0.9814814815  0.6944444444  59.259259259  0.1650728491  0.2150521278  1600          0.0156822205 
0.9965277778  1.0000000000  0.9791666667  0.9583333333  0.9814814815  0.9768518519  0.9756944444  0.9861111111  0.7000000000  61.111111111  0.1561818372  0.2150521278  1650          0.0170056152 
0.9965277778  1.0000000000  0.9872685185  0.9675925926  0.9814814815  0.9768518519  0.9756944444  0.9861111111  0.7055555556  62.962962963  0.1578725226  0.2150521278  1700          0.0160217524 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 1e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2291666667  0.2314814815  0.2037037037  0.1990740741  0.2500000000  0.2731481481  0.2384259259  0.1944444444  0.2185185185  0.0000000000  1.5111917257  0.1991591454  0             0.5905075073 
0.4097222222  0.3750000000  0.3807870370  0.3750000000  0.3888888889  0.4259259259  0.3437500000  0.3333333333  0.3074074074  1.8518518519  1.3723123050  0.2138485909  50            0.0160104752 
0.7048611111  0.6759259259  0.6817129630  0.6944444444  0.6921296296  0.7453703704  0.5798611111  0.5879629630  0.4722222222  3.7037037037  1.2481380463  0.2138485909  100           0.0161840820 
0.7743055556  0.7500000000  0.7673611111  0.7500000000  0.7824074074  0.8009259259  0.7037037037  0.7083333333  0.5898148148  5.5555555556  1.0874089360  0.2138485909  150           0.0160057878 
0.7835648148  0.7685185185  0.8078703704  0.7962962963  0.7881944444  0.8194444444  0.7349537037  0.7222222222  0.5916666667  7.4074074074  0.9031662858  0.2138485909  200           0.0161341953 
0.8252314815  0.8101851852  0.8842592593  0.8518518519  0.8449074074  0.8703703704  0.7893518519  0.7962962963  0.6370370370  9.2592592593  0.7563197863  0.2138485909  250           0.0162059593 
0.8495370370  0.8240740741  0.9317129630  0.9120370370  0.8819444444  0.8888888889  0.8449074074  0.8379629630  0.7101851852  11.111111111  0.6284346056  0.2138485909  300           0.0157168531 
0.8854166667  0.8611111111  0.9560185185  0.9259259259  0.9201388889  0.9305555556  0.9224537037  0.8935185185  0.7333333333  12.962962963  0.5445028520  0.2138485909  350           0.0158947468 
0.8912037037  0.8657407407  0.9594907407  0.9259259259  0.9328703704  0.9351851852  0.9317129630  0.8981481481  0.7518518519  14.814814814  0.4609991020  0.2138485909  400           0.0164022160 
0.8831018519  0.8564814815  0.9560185185  0.9259259259  0.9363425926  0.9490740741  0.9421296296  0.9259259259  0.7657407407  16.666666666  0.4239463484  0.2138485909  450           0.0162360907 
0.8958333333  0.8750000000  0.9571759259  0.9212962963  0.9583333333  0.9583333333  0.9606481481  0.9351851852  0.7907407407  18.518518518  0.3791132087  0.2138485909  500           0.0159579706 
0.9050925926  0.8796296296  0.9664351852  0.9398148148  0.9490740741  0.9537037037  0.9513888889  0.9305555556  0.7944444444  20.370370370  0.3374897343  0.2138485909  550           0.0159017944 
0.9039351852  0.8842592593  0.9618055556  0.9305555556  0.9502314815  0.9490740741  0.9780092593  0.9490740741  0.7833333333  22.222222222  0.3034945425  0.2138485909  600           0.0161976957 
0.9120370370  0.8796296296  0.9687500000  0.9444444444  0.9571759259  0.9629629630  0.9733796296  0.9398148148  0.7972222222  24.074074074  0.2786006686  0.2138485909  650           0.0160788012 
0.9062500000  0.8888888889  0.9594907407  0.9259259259  0.9456018519  0.9537037037  0.9814814815  0.9629629630  0.7750000000  25.925925925  0.2619175014  0.2138485909  700           0.0160577679 
0.9155092593  0.8935185185  0.9652777778  0.9305555556  0.9537037037  0.9629629630  0.9837962963  0.9537037037  0.7805555556  27.777777777  0.2449035436  0.2138485909  750           0.0159194136 
0.9189814815  0.8935185185  0.9652777778  0.9305555556  0.9479166667  0.9583333333  0.9826388889  0.9583333333  0.7611111111  29.629629629  0.2267332622  0.2138485909  800           0.0160019827 
0.9317129630  0.8981481481  0.9745370370  0.9490740741  0.9687500000  0.9722222222  0.9884259259  0.9629629630  0.7833333333  31.481481481  0.2173679411  0.2138485909  850           0.0157493019 
0.9305555556  0.9027777778  0.9768518519  0.9537037037  0.9733796296  0.9814814815  0.9918981481  0.9768518519  0.7944444444  33.333333333  0.1991474354  0.2138485909  900           0.0158125067 
0.9375000000  0.9027777778  0.9768518519  0.9537037037  0.9699074074  0.9814814815  0.9872685185  0.9675925926  0.7861111111  35.185185185  0.1908926286  0.2138485909  950           0.0158912182 
0.9386574074  0.8981481481  0.9814814815  0.9629629630  0.9733796296  0.9814814815  0.9895833333  0.9722222222  0.7888888889  37.037037037  0.1694770949  0.2161536217  1000          0.0162642860 
0.9525462963  0.9120370370  0.9814814815  0.9629629630  0.9768518519  0.9814814815  0.9918981481  0.9768518519  0.7722222222  38.888888888  0.1641171025  0.2161536217  1050          0.0163953686 
0.9490740741  0.9120370370  0.9814814815  0.9629629630  0.9768518519  0.9814814815  0.9918981481  0.9768518519  0.7583333333  40.740740740  0.1547451989  0.2161536217  1100          0.0162488317 
0.9606481481  0.9212962963  0.9837962963  0.9675925926  0.9803240741  0.9814814815  0.9918981481  0.9768518519  0.7861111111  42.592592592  0.1383761500  0.2161536217  1150          0.0156488800 
0.9699074074  0.9259259259  0.9837962963  0.9675925926  0.9803240741  0.9814814815  0.9918981481  0.9768518519  0.7722222222  44.444444444  0.1329079702  0.2161536217  1200          0.0157004404 
0.9745370370  0.9351851852  0.9837962963  0.9675925926  0.9837962963  0.9814814815  0.9953703704  0.9768518519  0.7722222222  46.296296296  0.1248748775  0.2161536217  1250          0.0158926344 
0.9791666667  0.9444444444  0.9942129630  0.9814814815  0.9872685185  0.9814814815  0.9976851852  0.9814814815  0.7861111111  48.148148148  0.1177277923  0.2161536217  1300          0.0157945061 
0.9861111111  0.9583333333  0.9942129630  0.9814814815  0.9895833333  0.9861111111  0.9976851852  0.9814814815  0.7777777778  50.000000000  0.1087721530  0.2161536217  1350          0.0161295700 
0.9791666667  0.9583333333  0.9872685185  0.9675925926  0.9837962963  0.9814814815  0.9942129630  0.9814814815  0.7388888889  51.851851851  0.1130511028  0.2161536217  1400          0.0164314795 
0.9884259259  0.9629629630  0.9895833333  0.9722222222  0.9965277778  0.9861111111  0.9976851852  0.9814814815  0.7722222222  53.703703703  0.0981756112  0.2161536217  1450          0.0158893490 
0.9895833333  0.9722222222  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.7611111111  55.555555555  0.0961899804  0.2161536217  1500          0.0162794209 
0.9930555556  0.9861111111  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.7777777778  57.407407407  0.0943601013  0.2161536217  1550          0.0167019844 
0.9965277778  1.0000000000  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.7861111111  59.259259259  0.0911551651  0.2161536217  1600          0.0176836109 
0.9965277778  0.9861111111  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.7916666667  61.111111111  0.0795656264  0.2161536217  1650          0.0157465887 
0.9953703704  0.9907407407  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8083333333  62.962962963  0.0800680045  0.2161536217  1700          0.0162565327 
0.9953703704  0.9907407407  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9976851852  0.9814814815  0.7638888889  64.814814814  0.0681266308  0.2161536217  1750          0.0161397886 
0.9965277778  1.0000000000  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.7972222222  66.666666666  0.0664068484  0.2161536217  1800          0.0163252878 
0.9965277778  1.0000000000  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.7861111111  68.518518518  0.0630103536  0.2161536217  1850          0.0161893892 
0.9965277778  1.0000000000  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8000000000  70.370370370  0.0561361324  0.2161536217  1900          0.0159317350 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.7888888889  72.222222222  0.0556514863  0.2161536217  1950          0.0163689852 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7833333333  74.074074074  0.0545545492  0.2161536217  2000          0.0160545063 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.7750000000  75.925925925  0.0490167764  0.2161536217  2050          0.0162371874 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7972222222  77.777777777  0.0469815962  0.2161536217  2100          0.0159312010 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7750000000  79.629629629  0.0443538555  0.2161536217  2150          0.0163905668 
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 170, in _start_thread
    debug('... done self._thread.start()')
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 48, in debug
    def debug(msg, *args):
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 56, in terminate
    os.kill(self.pid, signal.SIGTERM)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 871562) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 315, in _exit_function
    p._popen.terminate()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 56, in terminate
    os.kill(self.pid, signal.SIGTERM)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 872116) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 269, in <module>
    algorithm.to(device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.76 GiB total capacity; 109.50 KiB already allocated; 19.94 MiB free; 2.00 MiB reserved in total by PyTorch)
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2280092593  0.2592592593  0.1967592593  0.2175925926  0.2083333333  0.2175925926  0.2083333333  0.1574074074  0.1925925926  0.0000000000  1.5011451244  0.1991591454  0             0.3039834499 
0.7129629630  0.6851851852  0.6307870370  0.6250000000  0.6319444444  0.5879629630  0.6550925926  0.6111111111  0.6379629630  1.8518518519  1.2122522700  0.2039470673  50            0.0158356810 
0.8275462963  0.8055555556  0.7395833333  0.7268518519  0.7581018519  0.7824074074  0.8078703704  0.8194444444  0.6537037037  3.7037037037  0.8115555620  0.2039470673  100           0.0157899857 
0.8831018519  0.8564814815  0.8078703704  0.8101851852  0.8553240741  0.8472222222  0.8819444444  0.8750000000  0.6907407407  5.5555555556  0.6402378583  0.2039470673  150           0.0159990644 
0.9305555556  0.9259259259  0.8310185185  0.8379629630  0.8831018519  0.8842592593  0.8958333333  0.9027777778  0.7111111111  7.4074074074  0.5439255422  0.2100834846  200           0.0159012413 
0.9629629630  0.9583333333  0.8981481481  0.8888888889  0.9004629630  0.9120370370  0.9178240741  0.9120370370  0.6694444444  9.2592592593  0.4308932269  0.2100834846  250           0.0158721352 
0.9791666667  0.9675925926  0.9444444444  0.9120370370  0.9178240741  0.9351851852  0.9502314815  0.9166666667  0.6953703704  11.111111111  0.3470736110  0.2100834846  300           0.0159486103 
0.9826388889  0.9814814815  0.9282407407  0.9074074074  0.9143518519  0.9259259259  0.9375000000  0.9212962963  0.7259259259  12.962962963  0.2871467406  0.2100834846  350           0.0168378592 
0.9861111111  0.9768518519  0.9884259259  0.9583333333  0.9710648148  0.9722222222  0.9930555556  0.9675925926  0.6555555556  14.814814814  0.2321935031  0.2100834846  400           0.0161554527 
0.9930555556  0.9814814815  0.9849537037  0.9537037037  0.9733796296  0.9814814815  0.9872685185  0.9814814815  0.6675925926  16.666666666  0.1938246965  0.2100834846  450           0.0158522415 
0.9953703704  0.9907407407  0.9918981481  0.9629629630  0.9756944444  0.9814814815  0.9918981481  0.9861111111  0.6675925926  18.518518518  0.1563325369  0.2100834846  500           0.0160472345 
0.9953703704  0.9861111111  0.9895833333  0.9583333333  0.9814814815  0.9861111111  0.9953703704  0.9861111111  0.6638888889  20.370370370  0.1384695359  0.2100834846  550           0.0158103752 
0.9965277778  0.9907407407  0.9976851852  0.9629629630  0.9884259259  0.9861111111  0.9953703704  0.9814814815  0.6703703704  22.222222222  0.1215775789  0.2136673927  600           0.0159340906 
0.9988425926  0.9907407407  0.9953703704  0.9675925926  0.9907407407  0.9907407407  0.9988425926  0.9814814815  0.6388888889  24.074074074  0.1024655385  0.2136673927  650           0.0160802221 
0.9976851852  0.9907407407  0.9965277778  0.9629629630  0.9803240741  0.9722222222  0.9976851852  0.9814814815  0.6620370370  25.925925925  0.0856260573  0.2136673927  700           0.0159092808 
0.9988425926  0.9953703704  0.9976851852  0.9814814815  0.9965277778  0.9814814815  0.9988425926  0.9814814815  0.6148148148  27.777777777  0.0778407598  0.2136673927  750           0.0163914585 
0.9965277778  0.9953703704  0.9965277778  0.9768518519  0.9942129630  0.9814814815  0.9965277778  0.9907407407  0.5842592593  29.629629629  0.0714961733  0.2136673927  800           0.0164022160 
0.9988425926  0.9953703704  0.9988425926  0.9722222222  0.9965277778  0.9861111111  0.9976851852  0.9907407407  0.6453703704  31.481481481  0.0679402290  0.2136673927  850           0.0162316704 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  0.9976851852  0.9861111111  0.9976851852  0.9861111111  0.6555555556  33.333333333  0.0591846816  0.2155137062  900           0.0200953579 
0.9988425926  0.9953703704  0.9988425926  0.9861111111  1.0000000000  0.9907407407  0.9988425926  0.9907407407  0.6314814815  35.185185185  0.0534677409  0.2155137062  950           0.0162108040 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  1.0000000000  0.9907407407  0.9988425926  0.9861111111  0.6453703704  37.037037037  0.0481544301  0.2155137062  1000          0.0177798080 
1.0000000000  0.9953703704  0.9988425926  0.9722222222  0.9988425926  0.9907407407  0.9988425926  0.9861111111  0.6370370370  38.888888888  0.0437170505  0.2155137062  1050          0.0159048367 
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 119, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)   # ARM在predict处不同，输出也不同
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 128, in predict
    return self.network(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/normalization.py", line 171, in forward
    input, self.normalized_shape, self.weight, self.bias, self.eps)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2205, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Given normalized_shape=[1998], expected input with shape [*, 1998], but got input of size[128, 16, 510]
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2256944444  0.2361111111  0.1875000000  0.1805555556  0.1979166667  0.1620370370  0.2083333333  0.1574074074  0.1833333333  0.0000000000  1.5116630793  0.1991591454  0             0.3592329025 
0.6712962963  0.6064814815  0.6145833333  0.6388888889  0.6168981481  0.6018518519  0.6446759259  0.6018518519  0.6231481481  1.8518518519  1.2266832530  0.2039470673  50            0.0158657742 
0.8125000000  0.7638888889  0.7627314815  0.7638888889  0.7789351852  0.7314814815  0.8171296296  0.8425925926  0.6694444444  3.7037037037  0.8208354831  0.2041282654  100           0.0161062956 
0.9004629630  0.8564814815  0.8217592593  0.8240740741  0.8680555556  0.8564814815  0.8750000000  0.8935185185  0.7037037037  5.5555555556  0.6489834464  0.2046675682  150           0.0159303951 
0.9375000000  0.9444444444  0.8634259259  0.8657407407  0.8888888889  0.8888888889  0.8969907407  0.9166666667  0.6916666667  7.4074074074  0.5332207000  0.2046675682  200           0.0160993958 
0.9745370370  0.9814814815  0.9224537037  0.8981481481  0.9004629630  0.9212962963  0.9108796296  0.9212962963  0.6805555556  9.2592592593  0.4269290650  0.2046675682  250           0.0159078646 
0.9872685185  0.9629629630  0.9502314815  0.9444444444  0.9212962963  0.9305555556  0.9351851852  0.9305555556  0.7037037037  11.111111111  0.3466826367  0.2046675682  300           0.0156436920 
0.9837962963  0.9768518519  0.9386574074  0.9120370370  0.9212962963  0.9212962963  0.9224537037  0.9259259259  0.7296296296  12.962962963  0.2850623915  0.2046675682  350           0.0189953279 
0.9907407407  0.9814814815  0.9837962963  0.9583333333  0.9664351852  0.9537037037  0.9814814815  0.9722222222  0.7000000000  14.814814814  0.2345050114  0.2157926559  400           0.0179357386 
0.9930555556  0.9814814815  0.9895833333  0.9675925926  0.9780092593  0.9629629630  0.9872685185  0.9768518519  0.6731481481  16.666666666  0.1912594375  0.2157926559  450           0.0173726654 
0.9988425926  0.9953703704  0.9861111111  0.9537037037  0.9525462963  0.9398148148  0.9756944444  0.9583333333  0.7203703704  18.518518518  0.1583668698  0.2157926559  500           0.0160034132 
0.9942129630  0.9953703704  0.9930555556  0.9583333333  0.9745370370  0.9537037037  0.9907407407  0.9722222222  0.7074074074  20.370370370  0.1390233253  0.2157926559  550           0.0157633018 
0.9965277778  0.9907407407  0.9988425926  0.9861111111  0.9826388889  0.9629629630  0.9953703704  0.9861111111  0.6888888889  22.222222222  0.1202250002  0.2157926559  600           0.0160889864 
0.9953703704  0.9907407407  0.9976851852  0.9861111111  0.9803240741  0.9444444444  0.9965277778  0.9861111111  0.6888888889  24.074074074  0.1067742865  0.2157926559  650           0.0157580280 
0.9988425926  0.9907407407  0.9965277778  0.9907407407  0.9826388889  0.9537037037  0.9942129630  0.9722222222  0.7009259259  25.925925925  0.0868989921  0.2157926559  700           0.0161827278 
0.9988425926  0.9861111111  1.0000000000  0.9953703704  0.9976851852  0.9907407407  0.9976851852  0.9861111111  0.6148148148  27.777777777  0.0794530629  0.2157926559  750           0.0170273542 
0.9976851852  0.9907407407  0.9988425926  0.9814814815  0.9965277778  0.9768518519  0.9988425926  0.9861111111  0.6037037037  29.629629629  0.0742070664  0.2157926559  800           0.0186805487 
0.9988425926  0.9907407407  0.9976851852  0.9814814815  0.9930555556  0.9583333333  0.9976851852  0.9861111111  0.6925925926  31.481481481  0.0683915403  0.2157926559  850           0.0165805674 
1.0000000000  0.9907407407  1.0000000000  0.9953703704  0.9918981481  0.9675925926  1.0000000000  0.9861111111  0.6805555556  33.333333333  0.0572960570  0.2157926559  900           0.0159606171 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2152777778  0.2685185185  0.1863425926  0.2222222222  0.2141203704  0.2037037037  0.2129629630  0.1620370370  0.2018518519  0.0000000000  1.5116630793  0.1991591454  0             0.3684992790 
0.6145833333  0.5833333333  0.5682870370  0.6018518519  0.5983796296  0.5555555556  0.5972222222  0.5925925926  0.5592592593  1.8518518519  1.3419328141  0.2037658691  50            0.0157231522 
0.6956018519  0.6203703704  0.6759259259  0.7037037037  0.6608796296  0.6157407407  0.6921296296  0.6712962963  0.6240740741  3.7037037037  1.0732678020  0.2039461136  100           0.0159682274 
0.7523148148  0.6990740741  0.7013888889  0.6851851852  0.7314814815  0.7500000000  0.7500000000  0.7361111111  0.6833333333  5.5555555556  0.8411766851  0.2039470673  150           0.0160048485 
0.8275462963  0.7546296296  0.7800925926  0.7685185185  0.8020833333  0.7731481481  0.8368055556  0.8703703704  0.6898148148  7.4074074074  0.7279913616  0.2041273117  200           0.0159439135 
0.8796296296  0.8472222222  0.8043981481  0.7916666667  0.8541666667  0.8240740741  0.8703703704  0.8935185185  0.7055555556  9.2592592593  0.6514930439  0.2045469284  250           0.0160902596 
0.9085648148  0.8842592593  0.8333333333  0.8425925926  0.8842592593  0.8796296296  0.8854166667  0.9166666667  0.7157407407  11.111111111  0.5883557653  0.2045469284  300           0.0161228085 
0.9270833333  0.8935185185  0.8194444444  0.8194444444  0.8773148148  0.8842592593  0.8888888889  0.9074074074  0.7500000000  12.962962963  0.5409740853  0.2045469284  350           0.0159993076 
0.9537037037  0.9351851852  0.8668981481  0.8518518519  0.8946759259  0.9027777778  0.8993055556  0.9212962963  0.7203703704  14.814814814  0.4858905077  0.2045469284  400           0.0161302423 
0.9652777778  0.9398148148  0.8981481481  0.8888888889  0.8969907407  0.8981481481  0.9143518519  0.9259259259  0.7166666667  16.666666666  0.4337421811  0.2045469284  450           0.0159580135 
0.9675925926  0.9490740741  0.9050925926  0.8981481481  0.9027777778  0.9212962963  0.9120370370  0.9259259259  0.7407407407  18.518518518  0.3800077355  0.2045469284  500           0.0159211445 
0.9733796296  0.9537037037  0.9421296296  0.9074074074  0.9178240741  0.9212962963  0.9305555556  0.9166666667  0.7268518519  20.370370370  0.3431509313  0.2045469284  550           0.0158725834 
0.9803240741  0.9629629630  0.9733796296  0.9537037037  0.9456018519  0.9305555556  0.9675925926  0.9537037037  0.6777777778  22.222222222  0.3126476139  0.2045469284  600           0.0175167847 
0.9780092593  0.9629629630  0.9409722222  0.9166666667  0.9247685185  0.9305555556  0.9317129630  0.9305555556  0.7453703704  24.074074074  0.2828063664  0.2045469284  650           0.0169080400 
0.9791666667  0.9583333333  0.9548611111  0.9074074074  0.9351851852  0.9305555556  0.9502314815  0.9351851852  0.7444444444  25.925925925  0.2392513290  0.2045469284  700           0.0166968918 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2500000000  0.2512562814  0.2171717172  0.2676767677  0.2462121212  0.2562814070  0.2601010101  0.1919191919  0.2195367573  0.0000000000  1.5287518501  0.1991591454  0             0.3199405670 
0.6338383838  0.6231155779  0.5946969697  0.6212121212  0.5921717172  0.5577889447  0.5883838384  0.6060606061  0.6042296073  2.0202020202  1.3338509941  0.2038230896  50            0.0161973333 
0.6641414141  0.6633165829  0.6477272727  0.6313131313  0.6035353535  0.5979899497  0.6641414141  0.6818181818  0.5830815710  4.0404040404  1.0525640392  0.2042427063  100           0.0161287069 
0.7613636364  0.7889447236  0.7424242424  0.7121212121  0.7474747475  0.7185929648  0.8042929293  0.8080808081  0.6757301108  6.0606060606  0.8375642443  0.2042427063  150           0.0160748482 
0.7992424242  0.8241206030  0.7752525253  0.7575757576  0.7904040404  0.7889447236  0.8396464646  0.8737373737  0.6666666667  8.0808080808  0.7255840087  0.2042427063  200           0.0161677837 
0.8510101010  0.8693467337  0.8030303030  0.7878787879  0.8156565657  0.8291457286  0.8636363636  0.8989898990  0.6827794562  10.101010101  0.6636614060  0.2044687271  250           0.0162970448 
0.8914141414  0.9145728643  0.8156565657  0.8181818182  0.8573232323  0.8693467337  0.8863636364  0.9090909091  0.7009063444  12.121212121  0.6020853329  0.2044687271  300           0.0162133360 
0.9116161616  0.9246231156  0.8194444444  0.8232323232  0.8699494949  0.9195979899  0.8926767677  0.9242424242  0.7311178248  14.141414141  0.5427365559  0.2044687271  350           0.0163117933 
0.9368686869  0.9497487437  0.8358585859  0.8787878788  0.8813131313  0.9195979899  0.8977272727  0.9292929293  0.7452165156  16.161616161  0.4819560212  0.2044687271  400           0.0163545799 
0.9520202020  0.9597989950  0.9141414141  0.9090909091  0.8964646465  0.9246231156  0.9040404040  0.9393939394  0.7170191339  18.181818181  0.4403308386  0.2044687271  450           0.0159879875 
0.9633838384  0.9497487437  0.8977272727  0.9040404040  0.8989898990  0.9296482412  0.9065656566  0.9393939394  0.7653575025  20.202020202  0.3997052109  0.2044687271  500           0.0158142519 
0.9760101010  0.9547738693  0.9381313131  0.9191919192  0.9078282828  0.9246231156  0.9217171717  0.9494949495  0.7291037261  22.222222222  0.3584184361  0.2044687271  550           0.0160226297 
0.9848484848  0.9648241206  0.9520202020  0.9292929293  0.9204545455  0.9195979899  0.9179292929  0.9494949495  0.7109768379  24.242424242  0.3208041528  0.2044687271  600           0.0161817265 
0.9823232323  0.9748743719  0.9318181818  0.9242424242  0.9141414141  0.9346733668  0.9128787879  0.9444444444  0.7462235650  26.262626262  0.2845039880  0.2044687271  650           0.0160930777 
0.9861111111  0.9748743719  0.9646464646  0.9393939394  0.9393939394  0.9195979899  0.9393939394  0.9494949495  0.7230614300  28.282828282  0.2509553474  0.2044687271  700           0.0156612396 
0.9924242424  0.9798994975  0.9823232323  0.9545454545  0.9595959596  0.9497487437  0.9595959596  0.9646464646  0.6827794562  30.303030303  0.2364155963  0.2044687271  750           0.0160500526 
0.9911616162  0.9899497487  0.9924242424  0.9696969697  0.9671717172  0.9597989950  0.9734848485  0.9848484848  0.6757301108  32.323232323  0.2131251577  0.2044687271  800           0.0159242773 
0.9936868687  0.9798994975  0.9848484848  0.9747474747  0.9684343434  0.9648241206  0.9684343434  0.9696969697  0.7351460222  34.343434343  0.1949267679  0.2052035332  850           0.0159335375 
0.9898989899  0.9849246231  0.9861111111  0.9696969697  0.9722222222  0.9648241206  0.9722222222  0.9696969697  0.7291037261  36.363636363  0.1779603267  0.2052035332  900           0.0163604069 
0.9936868687  0.9849246231  0.9936868687  0.9848484848  0.9835858586  0.9648241206  0.9797979798  0.9898989899  0.6737160121  38.383838383  0.1603714789  0.2139353752  950           0.0161104488 
0.9949494949  0.9849246231  0.9936868687  0.9848484848  0.9911616162  0.9698492462  0.9861111111  0.9898989899  0.6777442095  40.404040404  0.1491328983  0.2139353752  1000          0.0160435867 
0.9949494949  0.9849246231  0.9949494949  0.9898989899  0.9861111111  0.9648241206  0.9823232323  0.9848484848  0.6686807654  42.424242424  0.1337383018  0.2139353752  1050          0.0157813931 
0.9962121212  0.9899497487  0.9987373737  0.9949494949  0.9911616162  0.9698492462  0.9886363636  0.9898989899  0.6706948640  44.444444444  0.1286094597  0.2139353752  1100          0.0161437988 
0.9962121212  0.9899497487  0.9987373737  1.0000000000  0.9936868687  0.9698492462  0.9911616162  0.9898989899  0.6586102719  46.464646464  0.1093886805  0.2139353752  1150          0.0175621843 
0.9962121212  0.9899497487  0.9974747475  1.0000000000  0.9974747475  0.9748743719  0.9936868687  0.9848484848  0.6304128902  48.484848484  0.1048121211  0.2139353752  1200          0.0167233944 
0.9974747475  0.9899497487  0.9987373737  1.0000000000  0.9962121212  0.9798994975  0.9898989899  0.9898989899  0.6797583082  50.505050505  0.1008039603  0.2139353752  1250          0.0172230005 
0.9974747475  0.9849246231  1.0000000000  1.0000000000  0.9974747475  0.9798994975  0.9936868687  0.9898989899  0.6636455186  52.525252525  0.0917367434  0.2139353752  1300          0.0161593676 
0.9974747475  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9849246231  0.9962121212  0.9949494949  0.6394763343  54.545454545  0.0820752481  0.2139353752  1350          0.0159841061 
0.9962121212  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9899497487  0.9962121212  0.9949494949  0.6304128902  56.565656565  0.0760686252  0.2139353752  1400          0.0162567472 
0.9974747475  0.9899497487  1.0000000000  1.0000000000  0.9974747475  0.9798994975  0.9949494949  0.9949494949  0.6596173212  58.585858585  0.0785362548  0.2139353752  1450          0.0158593416 
0.9974747475  0.9849246231  0.9987373737  0.9848484848  0.9936868687  0.9698492462  0.9911616162  0.9848484848  0.7129909366  60.606060606  0.0706896040  0.2139353752  1500          0.0161154079 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9798994975  0.9962121212  0.9898989899  0.6596173212  62.626262626  0.0694800849  0.2139353752  1550          0.0161748409 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9698492462  0.9962121212  0.9949494949  0.6646525680  64.646464646  0.0632183318  0.2139353752  1600          0.0161708784 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9748743719  0.9974747475  0.9898989899  0.6696878147  66.666666666  0.0560008076  0.2139353752  1650          0.0159459972 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9849246231  0.9987373737  0.9949494949  0.6505538771  68.686868686  0.0534255365  0.2139353752  1700          0.0162922144 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9798994975  0.9974747475  0.9898989899  0.6596173212  70.707070707  0.0533307225  0.2139353752  1750          0.0170911884 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9798994975  0.9987373737  0.9949494949  0.6535750252  72.727272727  0.0471968694  0.2139353752  1800          0.0163036919 
1.0000000000  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9798994975  0.9974747475  1.0000000000  0.6485397784  74.747474747  0.0469212632  0.2139353752  1850          0.0162633991 
0.9987373737  0.9899497487  1.0000000000  1.0000000000  0.9987373737  0.9748743719  0.9974747475  0.9898989899  0.6676737160  76.767676767  0.0440156824  0.2170667648  1900          0.0162455368 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2106481481  0.2361111111  0.2337962963  0.2175925926  0.2314814815  0.2222222222  0.2245370370  0.1990740741  0.2142857143  0.0000000000  1.5219694376  0.1991591454  0             0.5294442177 
0.6678240741  0.6620370370  0.5844907407  0.5925925926  0.5659722222  0.6111111111  0.6689814815  0.6712962963  0.5142857143  1.8518518519  1.3363602209  0.2037658691  50            0.0160157871 
0.7291666667  0.7222222222  0.6458333333  0.6805555556  0.6435185185  0.6620370370  0.7754629630  0.7453703704  0.5250000000  3.7037037037  1.0591065836  0.2041282654  100           0.0161511326 
0.8113425926  0.7962962963  0.6469907407  0.6759259259  0.6944444444  0.6944444444  0.8090277778  0.8055555556  0.6035714286  5.5555555556  0.8329322946  0.2043094635  150           0.0160041380 
0.8368055556  0.8333333333  0.6886574074  0.7037037037  0.7395833333  0.7222222222  0.8726851852  0.8842592593  0.6250000000  7.4074074074  0.7209709752  0.2043094635  200           0.0159134340 
0.8912037037  0.8796296296  0.7511574074  0.7592592593  0.7812500000  0.7916666667  0.9166666667  0.9305555556  0.6571428571  9.2592592593  0.6524955463  0.2043094635  250           0.0161985493 
0.9189814815  0.9212962963  0.7916666667  0.7777777778  0.8437500000  0.8472222222  0.9351851852  0.9398148148  0.6428571429  11.111111111  0.5983019912  0.2043094635  300           0.0162333584 
0.9398148148  0.9490740741  0.7951388889  0.7638888889  0.8506944444  0.8472222222  0.9594907407  0.9675925926  0.6392857143  12.962962963  0.5312225109  0.2043094635  350           0.0159876966 
0.9733796296  0.9537037037  0.8599537037  0.8518518519  0.9189814815  0.9212962963  0.9895833333  0.9722222222  0.6285714286  14.814814814  0.4652930588  0.2043094635  400           0.0162412167 
0.9826388889  0.9722222222  0.8784722222  0.8750000000  0.9155092593  0.9074074074  0.9872685185  0.9675925926  0.6178571429  16.666666666  0.4192417359  0.2043094635  450           0.0161595678 
0.9895833333  0.9722222222  0.8969907407  0.9120370370  0.9456018519  0.9675925926  0.9930555556  0.9861111111  0.6642857143  18.518518518  0.3698391825  0.2083859444  500           0.0161536407 
0.9942129630  0.9814814815  0.9108796296  0.9120370370  0.9467592593  0.9629629630  0.9953703704  0.9907407407  0.6571428571  20.370370370  0.3202534431  0.2083859444  550           0.0160127068 
0.9965277778  0.9861111111  0.9305555556  0.9444444444  0.9722222222  0.9861111111  0.9976851852  0.9953703704  0.6464285714  22.222222222  0.2972302186  0.2083859444  600           0.0192053366 
1.0000000000  1.0000000000  0.9293981481  0.9074074074  0.9502314815  0.9490740741  0.9976851852  0.9953703704  0.6821428571  24.074074074  0.2629870024  0.2083859444  650           0.0185541821 
0.9976851852  0.9953703704  0.9525462963  0.9259259259  0.9710648148  0.9768518519  0.9976851852  0.9953703704  0.6178571429  25.925925925  0.2333856606  0.2083859444  700           0.0192154503 
1.0000000000  1.0000000000  0.9444444444  0.9583333333  0.9849537037  0.9907407407  0.9907407407  0.9953703704  0.5571428571  27.777777777  0.2082205704  0.2083859444  750           0.0192653322 
1.0000000000  1.0000000000  0.9513888889  0.9722222222  0.9872685185  0.9953703704  0.9976851852  0.9953703704  0.5571428571  29.629629629  0.1953482512  0.2083859444  800           0.0168158102 
1.0000000000  1.0000000000  0.9490740741  0.9120370370  0.9629629630  0.9675925926  1.0000000000  1.0000000000  0.6464285714  31.481481481  0.1749476534  0.2085690498  850           0.0187099218 
1.0000000000  1.0000000000  0.9675925926  0.9490740741  0.9826388889  0.9861111111  0.9976851852  0.9953703704  0.5821428571  33.333333333  0.1589687306  0.2085690498  900           0.0171966267 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  0.9872685185  0.9953703704  0.9976851852  0.9953703704  0.5750000000  35.185185185  0.1427907158  0.2085690498  950           0.0169329786 
1.0000000000  1.0000000000  0.9872685185  0.9814814815  0.9907407407  0.9953703704  0.9976851852  0.9953703704  0.5714285714  37.037037037  0.1301543117  0.2142100334  1000          0.0165427637 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  0.9965277778  1.0000000000  0.9976851852  0.9953703704  0.5214285714  38.888888888  0.1215835486  0.2142100334  1050          0.0163157892 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2106481481  0.2361111111  0.2337962963  0.2175925926  0.2314814815  0.2222222222  0.2245370370  0.1990740741  0.2357142857  0.0000000000  1.5219694376  0.1991591454  0             0.3363196850 
0.6678240741  0.6620370370  0.5844907407  0.5925925926  0.5659722222  0.6111111111  0.6689814815  0.6712962963  0.5464285714  1.8518518519  1.3363602209  0.2039470673  50            0.0158816481 
0.7291666667  0.7222222222  0.6458333333  0.6805555556  0.6435185185  0.6620370370  0.7754629630  0.7453703704  0.5392857143  3.7037037037  1.0591065836  0.2043094635  100           0.0160013580 
0.8113425926  0.7962962963  0.6469907407  0.6759259259  0.6944444444  0.6944444444  0.8090277778  0.8055555556  0.6035714286  5.5555555556  0.8329322946  0.2043094635  150           0.0160454130 
0.8368055556  0.8333333333  0.6886574074  0.7037037037  0.7395833333  0.7222222222  0.8726851852  0.8842592593  0.6250000000  7.4074074074  0.7209709752  0.2043094635  200           0.0160119915 
0.8912037037  0.8796296296  0.7511574074  0.7592592593  0.7812500000  0.7916666667  0.9166666667  0.9305555556  0.6535714286  9.2592592593  0.6524955463  0.2045483589  250           0.0159436703 
0.9189814815  0.9212962963  0.7916666667  0.7777777778  0.8437500000  0.8472222222  0.9351851852  0.9398148148  0.6500000000  11.111111111  0.5983019912  0.2045483589  300           0.0160209465 
0.9398148148  0.9490740741  0.7951388889  0.7638888889  0.8506944444  0.8472222222  0.9594907407  0.9675925926  0.6428571429  12.962962963  0.5312225109  0.2045483589  350           0.0162692022 
0.9733796296  0.9537037037  0.8599537037  0.8518518519  0.9189814815  0.9212962963  0.9895833333  0.9722222222  0.6142857143  14.814814814  0.4652930588  0.2045483589  400           0.0163525629 
0.9826388889  0.9722222222  0.8784722222  0.8750000000  0.9155092593  0.9074074074  0.9872685185  0.9675925926  0.6214285714  16.666666666  0.4192417359  0.2045483589  450           0.0160001087 
0.9895833333  0.9722222222  0.8969907407  0.9120370370  0.9456018519  0.9675925926  0.9930555556  0.9861111111  0.6464285714  18.518518518  0.3698391825  0.2045483589  500           0.0169438982 
0.9942129630  0.9814814815  0.9108796296  0.9120370370  0.9467592593  0.9629629630  0.9953703704  0.9907407407  0.6464285714  20.370370370  0.3202534431  0.2045483589  550           0.0160986042 
0.9965277778  0.9861111111  0.9305555556  0.9444444444  0.9722222222  0.9861111111  0.9976851852  0.9953703704  0.6321428571  22.222222222  0.2972302186  0.2046694756  600           0.0177976084 
1.0000000000  1.0000000000  0.9293981481  0.9074074074  0.9502314815  0.9490740741  0.9976851852  0.9953703704  0.6750000000  24.074074074  0.2629870024  0.2046694756  650           0.0179266977 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1110765) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2094907407  0.2222222222  0.2083333333  0.1851851852  0.2407407407  0.2500000000  0.2303240741  0.1898148148  0.2285714286  0.0000000000  1.5201679468  0.1991591454  0             0.5113878250 
0.7280092593  0.6990740741  0.6898148148  0.6944444444  0.7060185185  0.7175925926  0.5983796296  0.5601851852  0.4928571429  1.8518518519  1.2750184631  0.2037658691  50            0.0161117649 
0.8368055556  0.8333333333  0.8854166667  0.8750000000  0.8414351852  0.8425925926  0.8090277778  0.8009259259  0.6500000000  3.7037037037  0.9006504703  0.2039470673  100           0.0177266550 
0.8657407407  0.8287037037  0.9363425926  0.9212962963  0.8784722222  0.8888888889  0.8449074074  0.8287037037  0.7285714286  5.5555555556  0.5818000001  0.2045478821  150           0.0165316486 
0.9027777778  0.8750000000  0.9629629630  0.9398148148  0.9375000000  0.9444444444  0.9363425926  0.9212962963  0.9035714286  7.4074074074  0.4258484888  0.2045478821  200           0.0159586477 
0.8981481481  0.8657407407  0.9618055556  0.9305555556  0.9537037037  0.9629629630  0.9756944444  0.9444444444  0.9250000000  9.2592592593  0.3351637816  0.2045478821  250           0.0161824512 
0.9236111111  0.8888888889  0.9687500000  0.9444444444  0.9606481481  0.9629629630  0.9780092593  0.9490740741  0.9321428571  11.111111111  0.2706395426  0.2045478821  300           0.0160921907 
0.9282407407  0.8981481481  0.9791666667  0.9583333333  0.9641203704  0.9629629630  0.9837962963  0.9537037037  0.9464285714  12.962962963  0.2273030970  0.2045478821  350           0.0159199381 
0.9375000000  0.9027777778  0.9768518519  0.9537037037  0.9733796296  0.9814814815  0.9918981481  0.9768518519  0.9071428571  14.814814814  0.1859725727  0.2045478821  400           0.0160989952 
0.9456018519  0.9120370370  0.9791666667  0.9583333333  0.9722222222  0.9722222222  0.9895833333  0.9722222222  0.8785714286  16.666666666  0.1669393064  0.2045478821  450           0.0159679699 
0.9664351852  0.9259259259  0.9884259259  0.9768518519  0.9884259259  0.9907407407  0.9988425926  0.9907407407  0.9000000000  18.518518518  0.1468457845  0.2045478821  500           0.0162272167 
0.9745370370  0.9351851852  0.9895833333  0.9722222222  0.9942129630  0.9953703704  0.9976851852  0.9814814815  0.8785714286  20.370370370  0.1188608065  0.2045478821  550           0.0160437775 
0.9895833333  0.9722222222  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8821428571  22.222222222  0.0997644378  0.2045478821  600           0.0157133770 
0.9895833333  0.9861111111  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8821428571  24.074074074  0.0866033682  0.2045478821  650           0.0157801628 
0.9976851852  0.9814814815  0.9942129630  0.9814814815  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8607142857  25.925925925  0.0795627611  0.2045478821  700           0.0164240265 
1.0000000000  1.0000000000  0.9953703704  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8750000000  27.777777777  0.0681389432  0.2157330513  750           0.0159976101 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.8571428571  29.629629629  0.0556678378  0.2157330513  800           0.0165697336 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8750000000  31.481481481  0.0532231183  0.2157330513  850           0.0163320398 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8464285714  33.333333333  0.0504374889  0.2157330513  900           0.0165269566 
0.9965277778  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8785714286  35.185185185  0.0427470294  0.2157330513  950           0.0160666800 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1160381) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2094907407  0.2222222222  0.2083333333  0.1851851852  0.2407407407  0.2500000000  0.2303240741  0.1898148148  0.2214285714  0.0000000000  1.5201679468  0.1991591454  0             0.4728541374 
0.7280092593  0.6990740741  0.6898148148  0.6944444444  0.7060185185  0.7175925926  0.5983796296  0.5601851852  0.4178571429  1.8518518519  1.2750184631  0.2037658691  50            0.0158698368 
0.8368055556  0.8333333333  0.8854166667  0.8750000000  0.8414351852  0.8425925926  0.8090277778  0.8009259259  0.4285714286  3.7037037037  0.9006504703  0.2039470673  100           0.0161762047 
0.8657407407  0.8287037037  0.9363425926  0.9212962963  0.8784722222  0.8888888889  0.8449074074  0.8287037037  0.3857142857  5.5555555556  0.5818000001  0.2041282654  150           0.0159378767 
0.9027777778  0.8750000000  0.9629629630  0.9398148148  0.9375000000  0.9444444444  0.9363425926  0.9212962963  0.3214285714  7.4074074074  0.4258484888  0.2041282654  200           0.0158835983 
0.8981481481  0.8657407407  0.9618055556  0.9305555556  0.9537037037  0.9629629630  0.9756944444  0.9444444444  0.2928571429  9.2592592593  0.3351637816  0.2045502663  250           0.0160512018 
0.9236111111  0.8888888889  0.9687500000  0.9444444444  0.9606481481  0.9629629630  0.9780092593  0.9490740741  0.3035714286  11.111111111  0.2706395426  0.2045502663  300           0.0159406757 
0.9282407407  0.8981481481  0.9791666667  0.9583333333  0.9641203704  0.9629629630  0.9837962963  0.9537037037  0.3000000000  12.962962963  0.2273030970  0.2045502663  350           0.0162418413 
0.9375000000  0.9027777778  0.9768518519  0.9537037037  0.9733796296  0.9814814815  0.9918981481  0.9768518519  0.2964285714  14.814814814  0.1859725727  0.2045502663  400           0.0159426308 
0.9456018519  0.9120370370  0.9791666667  0.9583333333  0.9722222222  0.9722222222  0.9895833333  0.9722222222  0.2964285714  16.666666666  0.1669393064  0.2045502663  450           0.0163512516 
0.9664351852  0.9259259259  0.9884259259  0.9768518519  0.9884259259  0.9907407407  0.9988425926  0.9907407407  0.3142857143  18.518518518  0.1468457845  0.2045502663  500           0.0160786390 
0.9745370370  0.9351851852  0.9895833333  0.9722222222  0.9942129630  0.9953703704  0.9976851852  0.9814814815  0.3142857143  20.370370370  0.1188608065  0.2047090530  550           0.0161430264 
0.9895833333  0.9722222222  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.3250000000  22.222222222  0.0997644378  0.2047090530  600           0.0159166050 
0.9895833333  0.9861111111  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.3392857143  24.074074074  0.0866033682  0.2047090530  650           0.0161573601 
0.9976851852  0.9814814815  0.9942129630  0.9814814815  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.3392857143  25.925925925  0.0795627611  0.2102785110  700           0.0160732794 
1.0000000000  1.0000000000  0.9953703704  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.3535714286  27.777777777  0.0681389432  0.2102785110  750           0.0158780622 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.3500000000  29.629629629  0.0556678378  0.2102785110  800           0.0162893057 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1185225) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
[[0.39546199]
 [0.59301806]
 [0.01151995]]
[[0.00103976]
 [0.2521556 ]
 [0.74680464]]
[[0.15865173]
 [0.1778992 ]
 [0.66344906]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2106481481  0.2361111111  0.2337962963  0.2175925926  0.2314814815  0.2222222222  0.2245370370  0.1990740741  0.2142857143  0.0000000000  1.5219694376  0.1991591454  0             0.3222281933 
0.6678240741  0.6620370370  0.5844907407  0.5925925926  0.5659722222  0.6111111111  0.6689814815  0.6712962963  0.4464285714  1.8518518519  1.3363602209  0.2039470673  50            0.0158299923 
0.7291666667  0.7222222222  0.6458333333  0.6805555556  0.6435185185  0.6620370370  0.7754629630  0.7453703704  0.4857142857  3.7037037037  1.0591065836  0.2041282654  100           0.0162233448 
0.8113425926  0.7962962963  0.6469907407  0.6759259259  0.6944444444  0.6944444444  0.8090277778  0.8055555556  0.5178571429  5.5555555556  0.8329322946  0.2041282654  150           0.0164201641 
0.8368055556  0.8333333333  0.6886574074  0.7037037037  0.7395833333  0.7222222222  0.8726851852  0.8842592593  0.4750000000  7.4074074074  0.7209709752  0.2041282654  200           0.0163838291 
0.8912037037  0.8796296296  0.7511574074  0.7592592593  0.7812500000  0.7916666667  0.9166666667  0.9305555556  0.4678571429  9.2592592593  0.6524955463  0.2049126625  250           0.0159342766 
0.9189814815  0.9212962963  0.7916666667  0.7777777778  0.8437500000  0.8472222222  0.9351851852  0.9398148148  0.4642857143  11.111111111  0.5983019912  0.2049126625  300           0.0159797144 
0.9398148148  0.9490740741  0.7951388889  0.7638888889  0.8506944444  0.8472222222  0.9594907407  0.9675925926  0.5285714286  12.962962963  0.5312225109  0.2119488716  350           0.0161866760 
0.9733796296  0.9537037037  0.8599537037  0.8518518519  0.9189814815  0.9212962963  0.9895833333  0.9722222222  0.5142857143  14.814814814  0.4652930588  0.2123708725  400           0.0160671616 
0.9826388889  0.9722222222  0.8784722222  0.8750000000  0.9155092593  0.9074074074  0.9872685185  0.9675925926  0.5357142857  16.666666666  0.4192417359  0.2123708725  450           0.0159536314 
0.9895833333  0.9722222222  0.8969907407  0.9120370370  0.9456018519  0.9675925926  0.9930555556  0.9861111111  0.5642857143  18.518518518  0.3698391825  0.2123708725  500           0.0163325882 
0.9942129630  0.9814814815  0.9108796296  0.9120370370  0.9467592593  0.9629629630  0.9953703704  0.9907407407  0.5821428571  20.370370370  0.3202534431  0.2123708725  550           0.0157767344 
0.9965277778  0.9861111111  0.9305555556  0.9444444444  0.9722222222  0.9861111111  0.9976851852  0.9953703704  0.5928571429  22.222222222  0.2972302186  0.2123708725  600           0.0159016228 
1.0000000000  1.0000000000  0.9293981481  0.9074074074  0.9502314815  0.9490740741  0.9976851852  0.9953703704  0.6285714286  24.074074074  0.2629870024  0.2123708725  650           0.0160409164 
0.9976851852  0.9953703704  0.9525462963  0.9259259259  0.9710648148  0.9768518519  0.9976851852  0.9953703704  0.6285714286  25.925925925  0.2333856606  0.2123708725  700           0.0161691999 
1.0000000000  1.0000000000  0.9444444444  0.9583333333  0.9849537037  0.9907407407  0.9907407407  0.9953703704  0.5892857143  27.777777777  0.2082205704  0.2123708725  750           0.0162732506 
1.0000000000  1.0000000000  0.9513888889  0.9722222222  0.9872685185  0.9953703704  0.9976851852  0.9953703704  0.5964285714  29.629629629  0.1953482512  0.2123708725  800           0.0161078215 
1.0000000000  1.0000000000  0.9490740741  0.9120370370  0.9629629630  0.9675925926  1.0000000000  1.0000000000  0.6392857143  31.481481481  0.1749476534  0.2123708725  850           0.0158302975 
1.0000000000  1.0000000000  0.9675925926  0.9490740741  0.9826388889  0.9861111111  0.9976851852  0.9953703704  0.6250000000  33.333333333  0.1589687306  0.2123708725  900           0.0160164452 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  0.9872685185  0.9953703704  0.9976851852  0.9953703704  0.6321428571  35.185185185  0.1427907158  0.2123708725  950           0.0159093857 
1.0000000000  1.0000000000  0.9872685185  0.9814814815  0.9907407407  0.9953703704  0.9976851852  0.9953703704  0.6535714286  37.037037037  0.1301543117  0.2123708725  1000          0.0160941839 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  0.9965277778  1.0000000000  0.9976851852  0.9953703704  0.6357142857  38.888888888  0.1215835486  0.2123708725  1050          0.0159701300 
1.0000000000  1.0000000000  0.9895833333  0.9861111111  0.9907407407  0.9953703704  0.9976851852  0.9953703704  0.6321428571  40.740740740  0.1172386135  0.2123708725  1100          0.0159268236 
1.0000000000  1.0000000000  0.9930555556  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.6250000000  42.592592592  0.1054304035  0.2123708725  1150          0.0161377382 
1.0000000000  1.0000000000  0.9872685185  0.9953703704  0.9942129630  0.9953703704  1.0000000000  1.0000000000  0.6428571429  44.444444444  0.0974872829  0.2123708725  1200          0.0160507584 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.6250000000  46.296296296  0.0891350706  0.2123708725  1250          0.0158559799 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.6250000000  48.148148148  0.0868311324  0.2123708725  1300          0.0163645983 
1.0000000000  1.0000000000  0.9988425926  0.9907407407  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.6178571429  50.000000000  0.0749181093  0.2123708725  1350          0.0163073683 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.6142857143  51.851851851  0.0679926509  0.2142686844  1400          0.0165521479 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6321428571  53.703703703  0.0678487013  0.2142686844  1450          0.0173919439 
1.0000000000  1.0000000000  0.9988425926  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6250000000  55.555555555  0.0605924517  0.2142686844  1500          0.0162325287 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6250000000  57.407407407  0.0580661825  0.2142686844  1550          0.0169732141 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  59.259259259  0.0580384907  0.2142686844  1600          0.0159540033 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  61.111111111  0.0541701548  0.2142686844  1650          0.0162096834 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6214285714  62.962962963  0.0525026174  0.2142686844  1700          0.0161276007 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6214285714  64.814814814  0.0445393467  0.2142686844  1750          0.0159266233 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6178571429  66.666666666  0.0396936854  0.2142686844  1800          0.0161694384 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6142857143  68.518518518  0.0402619030  0.2178988457  1850          0.0161539698 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6250000000  70.370370370  0.0411552637  0.2178988457  1900          0.0162095499 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  72.222222222  0.0364780239  0.2178988457  1950          0.0158749104 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6214285714  74.074074074  0.0376022232  0.2178988457  2000          0.0163105297 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6214285714  75.925925925  0.0322594271  0.2178988457  2050          0.0161059380 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  77.777777777  0.0291494660  0.2178988457  2100          0.0161529207 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6178571429  79.629629629  0.0347225092  0.2178988457  2150          0.0162508106 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  81.481481481  0.0283846815  0.2179055214  2200          0.0164297819 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  83.333333333  0.0234018959  0.2179055214  2250          0.0157707739 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6178571429  85.185185185  0.0258969520  0.2179055214  2300          0.0177231121 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  87.037037037  0.0251612421  0.2179055214  2350          0.0163487339 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6214285714  88.888888888  0.0221444547  0.2179055214  2400          0.0158039618 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6250000000  90.740740740  0.0222766608  0.2179055214  2450          0.0159798861 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.6285714286  92.592592592  0.0227454504  0.2191443443  2500          0.0159255600 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
[[0.15880448]
 [0.04564997]
 [0.79554555]]
[[0.16060191]
 [0.05056221]
 [0.78883588]]
[[0.46179954]
 [0.51068225]
 [0.02751821]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2129629630  0.2175925926  0.2222222222  0.2314814815  0.2372685185  0.2175925926  0.2245370370  0.1898148148  0.2178571429  0.0000000000  1.5016152859  0.1991591454  0             0.3203194141 
0.6875000000  0.6898148148  0.6215277778  0.6250000000  0.5937500000  0.5694444444  0.6076388889  0.6111111111  0.4535714286  1.8518518519  1.3272890973  0.2039470673  50            0.0160746765 
0.7905092593  0.8101851852  0.7118055556  0.6944444444  0.6631944444  0.6666666667  0.6898148148  0.6296296296  0.5142857143  3.7037037037  1.0523080695  0.2041282654  100           0.0160908699 
0.7951388889  0.7916666667  0.6666666667  0.6388888889  0.6689814815  0.6435185185  0.6678240741  0.6203703704  0.5642857143  5.5555555556  0.8220650554  0.2043094635  150           0.0165350580 
0.8356481481  0.8379629630  0.7592592593  0.7546296296  0.7164351852  0.6898148148  0.7476851852  0.6898148148  0.5178571429  7.4074074074  0.7206089771  0.2043094635  200           0.0164052439 
0.8541666667  0.8750000000  0.8356481481  0.7962962963  0.7789351852  0.7453703704  0.7962962963  0.7453703704  0.5178571429  9.2592592593  0.6466828835  0.2043690681  250           0.0161824369 
0.8761574074  0.8981481481  0.8738425926  0.8379629630  0.8148148148  0.7685185185  0.8622685185  0.8148148148  0.4857142857  11.111111111  0.5945125043  0.2048468590  300           0.0159591389 
0.9201388889  0.9305555556  0.8668981481  0.8240740741  0.8379629630  0.8009259259  0.8703703704  0.8518518519  0.5607142857  12.962962963  0.5384343421  0.2048468590  350           0.0158309460 
0.9305555556  0.9305555556  0.9004629630  0.8703703704  0.8981481481  0.8379629630  0.9606481481  0.9490740741  0.4821428571  14.814814814  0.4763693255  0.2048468590  400           0.0158771038 
0.9421296296  0.9398148148  0.9178240741  0.8842592593  0.9363425926  0.9212962963  0.9652777778  0.9583333333  0.5178571429  16.666666666  0.4255627263  0.2048468590  450           0.0158994961 
0.9664351852  0.9537037037  0.9189814815  0.8935185185  0.9479166667  0.9305555556  0.9606481481  0.9629629630  0.5785714286  18.518518518  0.3893227816  0.2162127495  500           0.0168133974 
0.9826388889  0.9722222222  0.9259259259  0.8935185185  0.9583333333  0.9305555556  0.9675925926  0.9629629630  0.5750000000  20.370370370  0.3390650678  0.2162127495  550           0.0158610487 
0.9837962963  0.9814814815  0.9363425926  0.9074074074  0.9606481481  0.9351851852  0.9791666667  0.9722222222  0.6107142857  22.222222222  0.3127009287  0.2162127495  600           0.0163776398 
0.9930555556  0.9861111111  0.9409722222  0.9027777778  0.9745370370  0.9629629630  0.9837962963  0.9675925926  0.5892857143  24.074074074  0.2781088975  0.2162127495  650           0.0163292599 
0.9861111111  0.9861111111  0.9432870370  0.9212962963  0.9756944444  0.9722222222  0.9814814815  0.9768518519  0.6178571429  25.925925925  0.2531520066  0.2162127495  700           0.0160301781 
0.9965277778  0.9861111111  0.9502314815  0.9074074074  0.9780092593  0.9768518519  0.9745370370  0.9629629630  0.5928571429  27.777777777  0.2282899079  0.2162127495  750           0.0164643145 
0.9965277778  0.9861111111  0.9560185185  0.9398148148  0.9803240741  0.9814814815  0.9791666667  0.9722222222  0.5857142857  29.629629629  0.2111858785  0.2162127495  800           0.0161401272 
0.9918981481  0.9907407407  0.9594907407  0.9537037037  0.9884259259  0.9907407407  0.9988425926  0.9907407407  0.6464285714  31.481481481  0.1932053599  0.2162127495  850           0.0162422276 
0.9976851852  0.9953703704  0.9664351852  0.9537037037  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.6392857143  33.333333333  0.1798430987  0.2162127495  900           0.0167404461 
0.9976851852  0.9953703704  0.9675925926  0.9490740741  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.6357142857  35.185185185  0.1629760157  0.2162127495  950           0.0164717388 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2013888889  0.2314814815  0.2199074074  0.2314814815  0.2291666667  0.2222222222  0.2453703704  0.1898148148  0.2142857143  0.0000000000  1.5096950531  0.1991591454  0             0.3237409592 
0.6296296296  0.5879629630  0.5810185185  0.5555555556  0.5879629630  0.5740740741  0.6087962963  0.5601851852  0.4750000000  1.8518518519  1.3306987619  0.2037658691  50            0.0163559151 
0.7430555556  0.7083333333  0.6944444444  0.6759259259  0.6840277778  0.6944444444  0.7268518519  0.6805555556  0.4142857143  3.7037037037  1.0666033065  0.2039470673  100           0.0158631992 
0.7916666667  0.7361111111  0.7083333333  0.6759259259  0.7418981481  0.7314814815  0.7546296296  0.7777777778  0.4714285714  5.5555555556  0.8376869488  0.2039470673  150           0.0158629084 
0.8414351852  0.7824074074  0.7777777778  0.7685185185  0.7939814815  0.8101851852  0.8414351852  0.8333333333  0.4214285714  7.4074074074  0.7303843582  0.2039470673  200           0.0158835840 
0.8750000000  0.8472222222  0.8055555556  0.8009259259  0.8414351852  0.8518518519  0.8599537037  0.8611111111  0.4035714286  9.2592592593  0.6557493293  0.2043690681  250           0.0161432791 
0.9016203704  0.9027777778  0.8310185185  0.8194444444  0.8796296296  0.8935185185  0.8946759259  0.8981481481  0.4892857143  11.111111111  0.5917219818  0.2043690681  300           0.0156661034 
0.9143518519  0.9120370370  0.8229166667  0.8287037037  0.8750000000  0.8981481481  0.8981481481  0.9027777778  0.5428571429  12.962962963  0.5480561501  0.2043690681  350           0.0158934307 
0.9502314815  0.9398148148  0.8692129630  0.8750000000  0.8900462963  0.8935185185  0.9050925926  0.9027777778  0.5000000000  14.814814814  0.4846414959  0.2043690681  400           0.0161003304 
0.9548611111  0.9629629630  0.8715277778  0.8657407407  0.8923611111  0.8981481481  0.9039351852  0.9074074074  0.5392857143  16.666666666  0.4346833420  0.2157959938  450           0.0159926605 
0.9699074074  0.9907407407  0.9050925926  0.8842592593  0.9050925926  0.9166666667  0.9143518519  0.9120370370  0.5785714286  18.518518518  0.3809064931  0.2157959938  500           0.0158704901 
0.9768518519  0.9768518519  0.9340277778  0.8935185185  0.9178240741  0.9212962963  0.9340277778  0.9166666667  0.5928571429  20.370370370  0.3414252067  0.2157959938  550           0.0161025906 
0.9849537037  0.9861111111  0.9733796296  0.9259259259  0.9479166667  0.9444444444  0.9733796296  0.9583333333  0.5392857143  22.222222222  0.3108099943  0.2157959938  600           0.0159521198 
0.9803240741  0.9722222222  0.9328703704  0.8935185185  0.9224537037  0.9259259259  0.9363425926  0.9305555556  0.6107142857  24.074074074  0.2762147161  0.2157959938  650           0.0158301926 
0.9849537037  0.9768518519  0.9282407407  0.8981481481  0.9247685185  0.9259259259  0.9340277778  0.9305555556  0.6214285714  25.925925925  0.2358804193  0.2157959938  700           0.0161519766 
0.9918981481  0.9814814815  0.9837962963  0.9629629630  0.9745370370  0.9722222222  0.9895833333  0.9722222222  0.5428571429  27.777777777  0.2207824656  0.2157959938  750           0.0162220430 
0.9895833333  0.9907407407  0.9791666667  0.9537037037  0.9756944444  0.9722222222  0.9918981481  0.9768518519  0.5535714286  29.629629629  0.2019695240  0.2157959938  800           0.0173004103 
0.9907407407  0.9907407407  0.9803240741  0.9490740741  0.9641203704  0.9629629630  0.9861111111  0.9722222222  0.5750000000  31.481481481  0.1888228324  0.2157959938  850           0.0158110762 
0.9930555556  0.9907407407  0.9837962963  0.9537037037  0.9733796296  0.9722222222  0.9907407407  0.9768518519  0.6178571429  33.333333333  0.1690319717  0.2157959938  900           0.0161686754 
0.9953703704  0.9861111111  0.9861111111  0.9490740741  0.9710648148  0.9675925926  0.9918981481  0.9768518519  0.6071428571  35.185185185  0.1530464712  0.2157959938  950           0.0162907887 
0.9942129630  0.9861111111  0.9884259259  0.9537037037  0.9733796296  0.9675925926  0.9907407407  0.9768518519  0.6392857143  37.037037037  0.1482780176  0.2157959938  1000          0.0162149715 
0.9918981481  0.9907407407  0.9895833333  0.9583333333  0.9849537037  0.9768518519  0.9965277778  0.9768518519  0.6035714286  38.888888888  0.1323201902  0.2157959938  1050          0.0162750626 
0.9965277778  0.9953703704  0.9965277778  0.9583333333  0.9861111111  0.9768518519  0.9965277778  0.9814814815  0.5964285714  40.740740740  0.1242590755  0.2157959938  1100          0.0160278893 
0.9965277778  0.9907407407  0.9953703704  0.9583333333  0.9872685185  0.9768518519  0.9976851852  0.9814814815  0.5857142857  42.592592592  0.1168019253  0.2157959938  1150          0.0161467218 
0.9965277778  0.9907407407  0.9953703704  0.9537037037  0.9814814815  0.9768518519  0.9965277778  0.9814814815  0.6071428571  44.444444444  0.1067391486  0.2157959938  1200          0.0164194393 
0.9976851852  0.9953703704  0.9976851852  0.9722222222  0.9918981481  0.9861111111  0.9976851852  0.9907407407  0.5750000000  46.296296296  0.1007796571  0.2157959938  1250          0.0160344887 
0.9976851852  0.9907407407  0.9953703704  0.9629629630  0.9930555556  0.9861111111  0.9976851852  0.9814814815  0.6000000000  48.148148148  0.0914730601  0.2157959938  1300          0.0162138319 
0.9988425926  1.0000000000  0.9988425926  0.9722222222  0.9861111111  0.9768518519  0.9976851852  0.9861111111  0.6000000000  50.000000000  0.0828128723  0.2157959938  1350          0.0158737946 
0.9988425926  0.9953703704  0.9976851852  0.9768518519  0.9953703704  0.9861111111  0.9976851852  0.9907407407  0.5714285714  51.851851851  0.0806449899  0.2157959938  1400          0.0165367937 
0.9976851852  1.0000000000  0.9976851852  0.9583333333  0.9965277778  0.9861111111  0.9976851852  0.9861111111  0.6214285714  53.703703703  0.0805171586  0.2157959938  1450          0.0181144047 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  0.9976851852  0.9861111111  0.9988425926  0.9907407407  0.5642857143  55.555555555  0.0709161503  0.2161531448  1500          0.0157593346 
0.9976851852  1.0000000000  0.9988425926  0.9814814815  0.9907407407  0.9768518519  0.9976851852  0.9861111111  0.5892857143  57.407407407  0.0673316773  0.2161531448  1550          0.0159795618 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  0.9965277778  0.9861111111  0.9988425926  0.9907407407  0.5892857143  59.259259259  0.0645083170  0.2161531448  1600          0.0158549881 
0.9988425926  0.9953703704  0.9976851852  0.9768518519  0.9988425926  0.9814814815  0.9988425926  0.9907407407  0.5642857143  61.111111111  0.0567997444  0.2161531448  1650          0.0159883833 
0.9988425926  1.0000000000  0.9988425926  0.9814814815  0.9988425926  0.9861111111  1.0000000000  0.9907407407  0.5392857143  62.962962963  0.0563597713  0.2161531448  1700          0.0163110781 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  0.9988425926  0.9861111111  0.9976851852  0.9907407407  0.5750000000  64.814814814  0.0511415445  0.2161531448  1750          0.0162927341 
0.9988425926  1.0000000000  0.9988425926  0.9814814815  0.9976851852  0.9861111111  0.9988425926  0.9907407407  0.5678571429  66.666666666  0.0478037701  0.2161531448  1800          0.0154251146 
0.9988425926  0.9953703704  0.9988425926  0.9768518519  1.0000000000  0.9907407407  1.0000000000  0.9907407407  0.5821428571  68.518518518  0.0503150415  0.2161531448  1850          0.0158829212 
0.9988425926  1.0000000000  1.0000000000  0.9814814815  1.0000000000  0.9861111111  1.0000000000  0.9907407407  0.5642857143  70.370370370  0.0469801619  0.2161531448  1900          0.0191239262 
0.9988425926  1.0000000000  1.0000000000  0.9768518519  0.9988425926  0.9861111111  1.0000000000  0.9907407407  0.5785714286  72.222222222  0.0403830821  0.2161531448  1950          0.0183087492 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2442129630  0.2500000000  0.1851851852  0.1712962963  0.2280092593  0.2546296296  0.2175925926  0.1620370370  0.2101851852  0.0000000000  1.5111917257  0.1991591454  0             0.3411593437 
0.7233796296  0.6898148148  0.6678240741  0.6666666667  0.6747685185  0.7407407407  0.5868055556  0.5648148148  0.4629629630  1.8518518519  1.2772752237  0.2039470673  50            0.0159852600 
0.8344907407  0.8148148148  0.8946759259  0.8657407407  0.8391203704  0.8518518519  0.8171296296  0.7962962963  0.6509259259  3.7037037037  0.9057636654  0.2041282654  100           0.0159323359 
0.8761574074  0.8287037037  0.9293981481  0.9074074074  0.8761574074  0.8842592593  0.8564814815  0.8240740741  0.6861111111  5.5555555556  0.5834006447  0.2119479179  150           0.0157489300 
0.9039351852  0.8703703704  0.9629629630  0.9398148148  0.9398148148  0.9490740741  0.9375000000  0.9166666667  0.8472222222  7.4074074074  0.4252650630  0.2119479179  200           0.0160042429 
0.8969907407  0.8703703704  0.9618055556  0.9305555556  0.9571759259  0.9629629630  0.9756944444  0.9444444444  0.8750000000  9.2592592593  0.3321569097  0.2119479179  250           0.0157544518 
0.9201388889  0.8888888889  0.9664351852  0.9398148148  0.9618055556  0.9583333333  0.9733796296  0.9398148148  0.8638888889  11.111111111  0.2688577539  0.2119479179  300           0.0155897379 
0.9282407407  0.8981481481  0.9791666667  0.9583333333  0.9652777778  0.9722222222  0.9837962963  0.9537037037  0.8833333333  12.962962963  0.2260115486  0.2119479179  350           0.0160950470 
0.9398148148  0.9074074074  0.9768518519  0.9537037037  0.9733796296  0.9814814815  0.9918981481  0.9768518519  0.8694444444  14.814814814  0.1860932054  0.2119479179  400           0.0160954905 
0.9513888889  0.9166666667  0.9791666667  0.9583333333  0.9756944444  0.9722222222  0.9895833333  0.9722222222  0.8305555556  16.666666666  0.1670684457  0.2119479179  450           0.0160123777 
0.9664351852  0.9259259259  0.9907407407  0.9814814815  0.9884259259  0.9907407407  0.9988425926  0.9907407407  0.8666666667  18.518518518  0.1476743171  0.2119479179  500           0.0159977627 
0.9780092593  0.9351851852  0.9895833333  0.9722222222  0.9907407407  0.9953703704  0.9976851852  0.9814814815  0.8305555556  20.370370370  0.1193262626  0.2119479179  550           0.0172122240 
0.9895833333  0.9722222222  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8611111111  22.222222222  0.0998312618  0.2119479179  600           0.0160158062 
0.9895833333  0.9861111111  0.9895833333  0.9722222222  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8361111111  24.074074074  0.0869902108  0.2119479179  650           0.0161958599 
0.9976851852  0.9814814815  0.9942129630  0.9814814815  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.8250000000  25.925925925  0.0801529243  0.2119479179  700           0.0161142111 
1.0000000000  1.0000000000  0.9953703704  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8333333333  27.777777777  0.0685534320  0.2119479179  750           0.0172551870 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2094907407  0.2222222222  0.2083333333  0.1851851852  0.2407407407  0.2500000000  0.2303240741  0.1898148148  0.2250000000  0.0000000000  1.5201679468  0.1991591454  0             0.3331944942 
0.7280092593  0.6990740741  0.6898148148  0.6944444444  0.7060185185  0.7175925926  0.5983796296  0.5601851852  0.4607142857  1.8518518519  1.2750184631  0.2037658691  50            0.0163069296 
0.8368055556  0.8333333333  0.8854166667  0.8750000000  0.8414351852  0.8425925926  0.8090277778  0.8009259259  0.4785714286  3.7037037037  0.9006504703  0.2041282654  100           0.0162469625 
0.8657407407  0.8287037037  0.9363425926  0.9212962963  0.8784722222  0.8888888889  0.8449074074  0.8287037037  0.4107142857  5.5555555556  0.5818000001  0.2139081955  150           0.0161427355 
0.9027777778  0.8750000000  0.9629629630  0.9398148148  0.9375000000  0.9444444444  0.9363425926  0.9212962963  0.3500000000  7.4074074074  0.4258484888  0.2139081955  200           0.0162026978 
0.8981481481  0.8657407407  0.9618055556  0.9305555556  0.9537037037  0.9629629630  0.9756944444  0.9444444444  0.3285714286  9.2592592593  0.3351637816  0.2139081955  250           0.0158986759 
0.9236111111  0.8888888889  0.9687500000  0.9444444444  0.9606481481  0.9629629630  0.9780092593  0.9490740741  0.3500000000  11.111111111  0.2706395426  0.2139081955  300           0.0158154774 
0.9282407407  0.8981481481  0.9791666667  0.9583333333  0.9641203704  0.9629629630  0.9837962963  0.9537037037  0.3535714286  12.962962963  0.2273030970  0.2139081955  350           0.0160484695 
0.9375000000  0.9027777778  0.9768518519  0.9537037037  0.9733796296  0.9814814815  0.9918981481  0.9768518519  0.3392857143  14.814814814  0.1859725727  0.2139081955  400           0.0164758968 
0.9456018519  0.9120370370  0.9791666667  0.9583333333  0.9722222222  0.9722222222  0.9895833333  0.9722222222  0.3321428571  16.666666666  0.1669393064  0.2139081955  450           0.0162031841 
0.9664351852  0.9259259259  0.9884259259  0.9768518519  0.9884259259  0.9907407407  0.9988425926  0.9907407407  0.3642857143  18.518518518  0.1468457845  0.2139081955  500           0.0161362314 
0.9745370370  0.9351851852  0.9895833333  0.9722222222  0.9942129630  0.9953703704  0.9976851852  0.9814814815  0.3535714286  20.370370370  0.1188608065  0.2139081955  550           0.0161847639 
0.9895833333  0.9722222222  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.3642857143  22.222222222  0.0997644378  0.2139081955  600           0.0159477806 
Process Process-1072:
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 251, in _bootstrap
    util._run_after_forkers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 132, in _run_after_forkers
    func(obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 69, in _after_fork
    self._notempty = threading.Condition(threading.Lock())
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
[[0.49196732]
 [0.18577301]
 [0.32225966]]
[[0.53288864]
 [0.03034978]
 [0.43676158]]
[[0.78773115]
 [0.1413385 ]
 [0.07093035]]
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2094907407  0.2222222222  0.2083333333  0.1851851852  0.2407407407  0.2500000000  0.2303240741  0.1898148148  0.1385714286  0.0000000000  1.5201679468  0.1991591454  0             0.3304922581 
0.7280092593  0.6990740741  0.6898148148  0.6944444444  0.7060185185  0.7175925926  0.5983796296  0.5601851852  0.5485714286  1.8518518519  1.2750184631  0.2039470673  50            0.0162599659 
0.8368055556  0.8333333333  0.8854166667  0.8750000000  0.8414351852  0.8425925926  0.8090277778  0.8009259259  0.6471428571  3.7037037037  0.9006504703  0.2041583061  100           0.0160848379 
0.8657407407  0.8287037037  0.9363425926  0.9212962963  0.8784722222  0.8888888889  0.8449074074  0.8287037037  0.6371428571  5.5555555556  0.5818000001  0.2043395042  150           0.0159314013 
0.9027777778  0.8750000000  0.9629629630  0.9398148148  0.9375000000  0.9444444444  0.9363425926  0.9212962963  0.6642857143  7.4074074074  0.4258484888  0.2043395042  200           0.0160609007 
0.8981481481  0.8657407407  0.9618055556  0.9305555556  0.9537037037  0.9629629630  0.9756944444  0.9444444444  0.6228571429  9.2592592593  0.3351637816  0.2045207024  250           0.0161158848 
0.9236111111  0.8888888889  0.9687500000  0.9444444444  0.9606481481  0.9629629630  0.9780092593  0.9490740741  0.6457142857  11.111111111  0.2706395426  0.2045207024  300           0.0161081886 
0.9282407407  0.8981481481  0.9791666667  0.9583333333  0.9641203704  0.9629629630  0.9837962963  0.9537037037  0.6314285714  12.962962963  0.2273030970  0.2045207024  350           0.0163599920 
0.9375000000  0.9027777778  0.9768518519  0.9537037037  0.9733796296  0.9814814815  0.9918981481  0.9768518519  0.6028571429  14.814814814  0.1859725727  0.2106571198  400           0.0160210657 
0.9456018519  0.9120370370  0.9791666667  0.9583333333  0.9722222222  0.9722222222  0.9895833333  0.9722222222  0.5771428571  16.666666666  0.1669393064  0.2106571198  450           0.0161209345 
0.9664351852  0.9259259259  0.9884259259  0.9768518519  0.9884259259  0.9907407407  0.9988425926  0.9907407407  0.6057142857  18.518518518  0.1468457845  0.2106571198  500           0.0159907055 
0.9745370370  0.9351851852  0.9895833333  0.9722222222  0.9942129630  0.9953703704  0.9976851852  0.9814814815  0.5757142857  20.370370370  0.1188608065  0.2106571198  550           0.0158271408 
0.9895833333  0.9722222222  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.5900000000  22.222222222  0.0997644378  0.2106571198  600           0.0161243534 
0.9895833333  0.9861111111  0.9918981481  0.9768518519  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.5971428571  24.074074074  0.0866033682  0.2106571198  650           0.0160808802 
0.9976851852  0.9814814815  0.9942129630  0.9814814815  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.5642857143  25.925925925  0.0795627611  0.2106571198  700           0.0162610769 
1.0000000000  1.0000000000  0.9953703704  0.9907407407  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5685714286  27.777777777  0.0681389432  0.2106571198  750           0.0160901880 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  0.9988425926  0.9907407407  0.5657142857  29.629629629  0.0556678378  0.2106571198  800           0.0161618280 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5842857143  31.481481481  0.0532231183  0.2106571198  850           0.0159960032 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5442857143  33.333333333  0.0504374889  0.2106571198  900           0.0159899426 
0.9965277778  1.0000000000  1.0000000000  1.0000000000  0.9976851852  0.9953703704  0.9988425926  0.9907407407  0.5857142857  35.185185185  0.0427470294  0.2106571198  950           0.0161039543 
1.0000000000  1.0000000000  0.9976851852  0.9953703704  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5471428571  37.037037037  0.0374473914  0.2106571198  1000          0.0162441206 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5757142857  38.888888888  0.0327381815  0.2106571198  1050          0.0161134958 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5814285714  40.740740740  0.0321843278  0.2106571198  1100          0.0161133623 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5785714286  42.592592592  0.0261042653  0.2106571198  1150          0.0156866312 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5585714286  44.444444444  0.0237037513  0.2106571198  1200          0.0159181738 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5685714286  46.296296296  0.0222392921  0.2106571198  1250          0.0163410997 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5685714286  48.148148148  0.0219874871  0.2106571198  1300          0.0161988354 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5771428571  50.000000000  0.0181117583  0.2106571198  1350          0.0159068727 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5414285714  51.851851851  0.0216140350  0.2106571198  1400          0.0158830929 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5785714286  53.703703703  0.0162519147  0.2106571198  1450          0.0161442089 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5600000000  55.555555555  0.0151744839  0.2106571198  1500          0.0163018847 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5700000000  57.407407407  0.0148393342  0.2159442902  1550          0.0161492252 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5700000000  59.259259259  0.0154175336  0.2159442902  1600          0.0161396408 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5857142857  61.111111111  0.0129670729  0.2159442902  1650          0.0159473276 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5814285714  62.962962963  0.0135532246  0.2159442902  1700          0.0161058664 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5528571429  64.814814814  0.0100775164  0.2159442902  1750          0.0162325048 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5728571429  66.666666666  0.0099850891  0.2159442902  1800          0.0158985710 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5471428571  68.518518518  0.0086348364  0.2159442902  1850          0.0158786535 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5671428571  70.370370370  0.0077815589  0.2159442902  1900          0.0161192703 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5642857143  72.222222222  0.0083604810  0.2159442902  1950          0.0160259867 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5471428571  74.074074074  0.0075990816  0.2159442902  2000          0.0162414122 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5614285714  75.925925925  0.0067593853  0.2159442902  2050          0.0158971930 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5671428571  77.777777777  0.0062404482  0.2159442902  2100          0.0162165976 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5600000000  79.629629629  0.0064572253  0.2159442902  2150          0.0160183477 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5414285714  81.481481481  0.0076357478  0.2159442902  2200          0.0163146973 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5528571429  83.333333333  0.0057027985  0.2159442902  2250          0.0159666729 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5700000000  85.185185185  0.0045299447  0.2159442902  2300          0.0159526014 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5571428571  87.037037037  0.0058966252  0.2159442902  2350          0.0161478949 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5542857143  88.888888888  0.0048875766  0.2159442902  2400          0.0162621307 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5800000000  90.740740740  0.0040850943  0.2159442902  2450          0.0164707327 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5700000000  92.592592592  0.0041475042  0.2159442902  2500          0.0164319611 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: ERM
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 2.5e-05
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2013888889  0.2314814815  0.2199074074  0.2314814815  0.2291666667  0.2222222222  0.2453703704  0.1898148148  0.1328571429  0.0000000000  1.5096950531  0.1991591454  0             0.3310902119 
0.6296296296  0.5879629630  0.5810185185  0.5555555556  0.5879629630  0.5740740741  0.6087962963  0.5601851852  0.5642857143  1.8518518519  1.3306987619  0.2039761543  50            0.0158416653 
0.7430555556  0.7083333333  0.6944444444  0.6759259259  0.6840277778  0.6944444444  0.7268518519  0.6805555556  0.6171428571  3.7037037037  1.0666033065  0.2044982910  100           0.0161915493 
0.7916666667  0.7361111111  0.7083333333  0.6759259259  0.7418981481  0.7314814815  0.7546296296  0.7777777778  0.6457142857  5.5555555556  0.8376869488  0.2044982910  150           0.0162358475 
0.8414351852  0.7824074074  0.7777777778  0.7685185185  0.7939814815  0.8101851852  0.8414351852  0.8333333333  0.6657142857  7.4074074074  0.7303843582  0.2044982910  200           0.0161340332 
0.8750000000  0.8472222222  0.8055555556  0.8009259259  0.8414351852  0.8518518519  0.8599537037  0.8611111111  0.6871428571  9.2592592593  0.6557493293  0.2044982910  250           0.0160627127 
0.9016203704  0.9027777778  0.8310185185  0.8194444444  0.8796296296  0.8935185185  0.8946759259  0.8981481481  0.6971428571  11.111111111  0.5917219818  0.2044982910  300           0.0163262510 
0.9143518519  0.9120370370  0.8229166667  0.8287037037  0.8750000000  0.8981481481  0.8981481481  0.9027777778  0.7485714286  12.962962963  0.5480561501  0.2044982910  350           0.0160005951 
0.9502314815  0.9398148148  0.8692129630  0.8750000000  0.8900462963  0.8935185185  0.9050925926  0.9027777778  0.7100000000  14.814814814  0.4846414959  0.2044982910  400           0.0159328890 
0.9548611111  0.9629629630  0.8715277778  0.8657407407  0.8923611111  0.8981481481  0.9039351852  0.9074074074  0.7328571429  16.666666666  0.4346833420  0.2044982910  450           0.0161748457 
0.9699074074  0.9907407407  0.9050925926  0.8842592593  0.9050925926  0.9166666667  0.9143518519  0.9120370370  0.7142857143  18.518518518  0.3809064931  0.2044982910  500           0.0162802410 
0.9768518519  0.9768518519  0.9340277778  0.8935185185  0.9178240741  0.9212962963  0.9340277778  0.9166666667  0.7142857143  20.370370370  0.3414252067  0.2044982910  550           0.0158250523 
0.9849537037  0.9861111111  0.9733796296  0.9259259259  0.9479166667  0.9444444444  0.9733796296  0.9583333333  0.6657142857  22.222222222  0.3108099943  0.2044982910  600           0.0159344912 
0.9803240741  0.9722222222  0.9328703704  0.8935185185  0.9224537037  0.9259259259  0.9363425926  0.9305555556  0.7285714286  24.074074074  0.2762147161  0.2044982910  650           0.0163268328 
0.9849537037  0.9768518519  0.9282407407  0.8981481481  0.9247685185  0.9259259259  0.9340277778  0.9305555556  0.7342857143  25.925925925  0.2358804193  0.2044982910  700           0.0160153008 
0.9918981481  0.9814814815  0.9837962963  0.9629629630  0.9745370370  0.9722222222  0.9895833333  0.9722222222  0.5928571429  27.777777777  0.2207824656  0.2044982910  750           0.0160647011 
0.9895833333  0.9907407407  0.9791666667  0.9537037037  0.9756944444  0.9722222222  0.9918981481  0.9768518519  0.6142857143  29.629629629  0.2019695240  0.2044982910  800           0.0164484024 
0.9907407407  0.9907407407  0.9803240741  0.9490740741  0.9641203704  0.9629629630  0.9861111111  0.9722222222  0.6700000000  31.481481481  0.1888228324  0.2189636230  850           0.0159394979 
0.9930555556  0.9907407407  0.9837962963  0.9537037037  0.9733796296  0.9722222222  0.9907407407  0.9768518519  0.6928571429  33.333333333  0.1690319717  0.2189636230  900           0.0176120758 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 52, in info
    def info(msg, *args):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1483741) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1834061135  0.1826086957  0.1877729258  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1832460733  0.0000000000  4.8551445007  0.3691520691  0             0.5127067566 
0.3973799127  0.3565217391  0.4082969432  0.4434782609  0.3449781659  0.3304347826  0.3755458515  0.4521739130  0.3455497382  3.4934497817  4.1625274324  0.9714274406  50            0.0627036524 
0.6113537118  0.5739130435  0.5633187773  0.6086956522  0.5829694323  0.4956521739  0.5283842795  0.5217391304  0.5113438045  6.9868995633  3.8827885962  0.9714541435  100           0.0634915733 
0.8056768559  0.7739130435  0.7663755459  0.8521739130  0.7685589520  0.7304347826  0.7489082969  0.6869565217  0.5986038394  10.480349345  3.4645503187  0.9716391563  150           0.0614578676 
0.8318777293  0.8521739130  0.8013100437  0.8347826087  0.8165938865  0.8000000000  0.7903930131  0.7826086957  0.5846422339  13.973799126  2.8368399239  1.2888331413  200           0.0608935595 
0.8602620087  0.8608695652  0.8493449782  0.8608695652  0.8602620087  0.8521739130  0.8362445415  0.8347826087  0.5619546248  17.467248908  2.2499712086  1.2888331413  250           0.0606943655 
0.8864628821  0.9130434783  0.8842794760  0.9217391304  0.8820960699  0.8869565217  0.8624454148  0.8869565217  0.5567190227  20.960698690  1.7774553347  1.2888331413  300           0.0613543749 
0.9017467249  0.9478260870  0.8886462882  0.9217391304  0.8973799127  0.9130434783  0.8951965066  0.9217391304  0.5235602094  24.454148471  1.4712651992  1.2888331413  350           0.0636431742 
0.8908296943  0.9304347826  0.8973799127  0.9217391304  0.8951965066  0.9304347826  0.8930131004  0.9304347826  0.5165794066  27.947598253  1.2244314945  1.2888331413  400           0.0640228987 
0.9323144105  0.9565217391  0.9082969432  0.9391304348  0.9017467249  0.9217391304  0.9213973799  0.9478260870  0.4938917976  31.441048034  1.0110037613  1.2888331413  450           0.0626794147 
0.9868995633  0.9913043478  0.9694323144  0.9652173913  0.9519650655  0.9478260870  0.9759825328  0.9826086957  0.4973821990  34.934497816  0.8952961683  1.2888331413  500           0.0609911394 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 896, in __init__
    index_queue = multiprocessing_context.Queue()  # type: ignore
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 102, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 42, in __init__
    self._rlock = ctx.Lock()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 67, in Lock
    return Lock(ctx=self.get_context())
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 59, in __init__
    unlink_now)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1921397380  0.2000000000  0.1921397380  0.2000000000  0.1834061135  0.1913043478  0.1877729258  0.1826086957  0.1884816754  0.0000000000  4.8551445007  0.3691520691  0             0.3699765205 
0.6135371179  0.5565217391  0.5698689956  0.6260869565  0.5829694323  0.5130434783  0.5633187773  0.5913043478  0.5235602094  3.4934497817  4.0401078796  0.9714274406  50            0.0601369429 
0.8100436681  0.7652173913  0.7860262009  0.8173913043  0.7663755459  0.7391304348  0.7729257642  0.7217391304  0.5305410122  6.9868995633  3.3449241686  0.9714274406  100           0.0606122160 
0.8755458515  0.8869565217  0.8799126638  0.9130434783  0.8668122271  0.8782608696  0.8558951965  0.8782608696  0.5759162304  10.480349345  2.2804322481  0.9714274406  150           0.0600002289 
0.8820960699  0.9217391304  0.8864628821  0.9043478261  0.8842794760  0.9130434783  0.8755458515  0.9217391304  0.5445026178  13.973799126  1.5243028617  0.9716463089  200           0.0603426838 
0.9170305677  0.9391304348  0.8995633188  0.9130434783  0.9061135371  0.9130434783  0.9061135371  0.9478260870  0.4659685864  17.467248908  1.1170927906  0.9716463089  250           0.0635882568 
0.9890829694  0.9913043478  0.9737991266  0.9652173913  0.9606986900  0.9565217391  0.9781659389  0.9565217391  0.4799301920  20.960698690  0.8182669401  0.9716463089  300           0.0629830456 
0.9890829694  0.9826086957  0.9344978166  0.9565217391  0.9323144105  0.9478260870  0.9606986900  0.9565217391  0.4659685864  24.454148471  0.6102085626  0.9716463089  350           0.0617189026 
0.9934497817  0.9913043478  0.9934497817  0.9826086957  0.9890829694  0.9739130435  0.9912663755  1.0000000000  0.5026178010  27.947598253  0.4563550299  0.9716463089  400           0.0599584532 
0.9912663755  0.9913043478  1.0000000000  1.0000000000  1.0000000000  0.9913043478  0.9912663755  1.0000000000  0.5218150087  31.441048034  0.3515830761  0.9716463089  450           0.0609465313 
0.9956331878  0.9913043478  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9956331878  1.0000000000  0.5357766143  34.934497816  0.2866929942  0.9716463089  500           0.0613859415 
1.0000000000  0.9913043478  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9934497817  0.9826086957  0.5113438045  38.427947598  0.2307712783  0.9716463089  550           0.0606859541 
1.0000000000  0.9913043478  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9956331878  1.0000000000  0.5200698080  41.921397379  0.1801401916  0.9716463089  600           0.0605438423 
1.0000000000  0.9913043478  0.9978165939  1.0000000000  1.0000000000  1.0000000000  0.9934497817  1.0000000000  0.5410122164  45.414847161  0.1543922640  0.9716463089  650           0.0626721764 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 25914) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1834061135  0.1826086957  0.1855895197  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1832460733  0.0000000000  4.8551445007  0.3691520691  0             0.5359489918 
0.2947598253  0.2782608696  0.3165938865  0.3478260870  0.2947598253  0.2695652174  0.3013100437  0.3391304348  0.3438045375  3.4934497817  4.3059331989  0.9714274406  50            0.0608294344 
0.4323144105  0.3478260870  0.3864628821  0.4086956522  0.4082969432  0.3652173913  0.3886462882  0.4608695652  0.4101221640  6.9868995633  4.1031940889  0.9716463089  100           0.0599718714 
0.4956331878  0.4434782609  0.4497816594  0.4608695652  0.4388646288  0.4434782609  0.4388646288  0.5304347826  0.4415357766  10.480349345  3.9940144300  0.9716463089  150           0.0631574535 
0.6004366812  0.5739130435  0.5502183406  0.6000000000  0.5262008734  0.5130434783  0.5371179039  0.5478260870  0.5270506108  13.973799126  3.8916456509  0.9716463089  200           0.0614376545 
0.6790393013  0.6434782609  0.5982532751  0.6521739130  0.6157205240  0.6000000000  0.5895196507  0.5652173913  0.5654450262  17.467248908  3.7145402431  0.9716463089  250           0.0627164841 
0.8013100437  0.7565217391  0.7030567686  0.8000000000  0.6812227074  0.6695652174  0.6877729258  0.6434782609  0.6055846422  20.960698690  3.5261900139  0.9716463089  300           0.0623524857 
0.8165938865  0.7478260870  0.7314410480  0.8086956522  0.7292576419  0.7130434783  0.7074235808  0.6869565217  0.6090750436  24.454148471  3.3000853348  0.9716463089  350           0.0623021126 
0.7882096070  0.7913043478  0.7707423581  0.8000000000  0.7903930131  0.7304347826  0.7641921397  0.7478260870  0.5584642234  27.947598253  3.0036771297  0.9716463089  400           0.0617837667 
0.8100436681  0.7826086957  0.7794759825  0.8260869565  0.7903930131  0.7478260870  0.7991266376  0.7565217391  0.5497382199  31.441048034  2.7350845432  0.9716463089  450           0.0624154949 
0.8427947598  0.8000000000  0.8144104803  0.8608695652  0.8122270742  0.7739130435  0.8187772926  0.8173913043  0.5514834206  34.934497816  2.4498829460  0.9716463089  500           0.0614977646 
0.8558951965  0.8434782609  0.8275109170  0.8608695652  0.8406113537  0.8260869565  0.8296943231  0.8434782609  0.5619546248  38.427947598  2.1931638622  0.9716463089  550           0.0611752367 
0.8471615721  0.8521739130  0.8362445415  0.8521739130  0.8493449782  0.8347826087  0.8384279476  0.8434782609  0.5706806283  41.921397379  1.9761877012  0.9716463089  600           0.0602017927 
0.8449781659  0.8434782609  0.8318777293  0.8608695652  0.8471615721  0.8434782609  0.8275109170  0.8086956522  0.5549738220  45.414847161  1.8357408547  0.9716463089  650           0.0606808090 
0.8755458515  0.8956521739  0.8733624454  0.9043478261  0.8711790393  0.8782608696  0.8646288210  0.8782608696  0.5602094241  48.908296943  1.7148303866  0.9719805717  700           0.0600868559 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1834061135  0.1826086957  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1884816754  0.0000000000  4.5351276398  0.1006202698  0             0.3768017292 
0.2838427948  0.3565217391  0.3078602620  0.3217391304  0.3013100437  0.3217391304  0.3318777293  0.2695652174  0.3141361257  3.4934497817  4.2681289959  0.2653427124  50            0.0575407362 
0.4148471616  0.4347826087  0.3711790393  0.3652173913  0.3820960699  0.4086956522  0.3973799127  0.3478260870  0.3560209424  6.9868995633  4.1111977148  0.2653427124  100           0.0581007147 
0.5131004367  0.5043478261  0.4039301310  0.3652173913  0.4213973799  0.4347826087  0.4475982533  0.3913043478  0.3752181501  10.480349345  4.0058743000  0.2653803825  150           0.0584999228 
0.5960698690  0.5739130435  0.4825327511  0.4521739130  0.5065502183  0.5043478261  0.4934497817  0.4086956522  0.4363001745  13.973799126  3.9024999428  0.2653803825  200           0.0586428213 
0.6703056769  0.6347826087  0.5436681223  0.4782608696  0.5764192140  0.5652173913  0.5611353712  0.5130434783  0.5078534031  17.467248908  3.7328780127  0.2653803825  250           0.0590397835 
0.7205240175  0.7043478261  0.6200873362  0.6000000000  0.6593886463  0.6782608696  0.6135371179  0.5652173913  0.5706806283  20.960698690  3.5102603292  0.2654380798  300           0.0588392735 
0.7685589520  0.7304347826  0.6703056769  0.6173913043  0.6921397380  0.6956521739  0.6615720524  0.6347826087  0.5898778360  24.454148471  3.2963986015  0.2654380798  350           0.0593613863 
0.7707423581  0.7565217391  0.7205240175  0.7304347826  0.7314410480  0.7739130435  0.7096069869  0.6956521739  0.6178010471  27.947598253  3.0350913334  0.2654380798  400           0.0589151335 
0.7969432314  0.7913043478  0.7489082969  0.7652173913  0.7663755459  0.7826086957  0.7576419214  0.7652173913  0.6300174520  31.441048034  2.8293615055  0.2654595375  450           0.0584362841 
0.8144104803  0.8000000000  0.7794759825  0.7739130435  0.7707423581  0.8086956522  0.7685589520  0.7826086957  0.6387434555  34.934497816  2.6004455662  0.2654595375  500           0.0585892820 
0.8340611354  0.8173913043  0.7903930131  0.8000000000  0.7882096070  0.8347826087  0.8034934498  0.7913043478  0.6492146597  38.427947598  2.4023239613  0.2654595375  550           0.0585959864 
0.8318777293  0.8260869565  0.8144104803  0.8086956522  0.7947598253  0.8521739130  0.7947598253  0.8347826087  0.6352530541  41.921397379  2.2243593526  0.2654595375  600           0.0589393616 
0.8340611354  0.8086956522  0.8209606987  0.8173913043  0.7991266376  0.8521739130  0.7991266376  0.8521739130  0.6178010471  45.414847161  2.0852916002  0.2654595375  650           0.0589243126 
0.8537117904  0.8956521739  0.8384279476  0.8347826087  0.8275109170  0.8608695652  0.8209606987  0.8608695652  0.6422338569  48.908296943  1.9918823910  0.2654595375  700           0.0585334539 
0.8624454148  0.8956521739  0.8471615721  0.8695652174  0.8340611354  0.8521739130  0.8318777293  0.8521739130  0.6492146597  52.401746724  1.8696801853  0.2654595375  750           0.0581853199 
0.8689956332  0.9043478261  0.8515283843  0.8695652174  0.8362445415  0.8695652174  0.8362445415  0.8695652174  0.6404886562  55.895196506  1.7692548585  0.2654595375  800           0.0582647753 
0.8842794760  0.9043478261  0.8689956332  0.8782608696  0.8406113537  0.8782608696  0.8406113537  0.8695652174  0.6143106457  59.388646288  1.6752620482  0.2654595375  850           0.0585209608 
0.8755458515  0.9130434783  0.8558951965  0.8869565217  0.8427947598  0.8869565217  0.8406113537  0.8695652174  0.6125654450  62.882096069  1.5712570763  0.2654595375  900           0.0589241934 
0.8864628821  0.9130434783  0.8624454148  0.8869565217  0.8471615721  0.8869565217  0.8471615721  0.8695652174  0.6212914485  66.375545851  1.4919118857  0.2654595375  950           0.0585408545 
0.8930131004  0.9217391304  0.8755458515  0.8695652174  0.8515283843  0.8869565217  0.8493449782  0.8695652174  0.5951134380  69.868995633  1.4222656059  0.2654595375  1000          0.0585254288 
0.8951965066  0.9304347826  0.8777292576  0.8695652174  0.8537117904  0.8869565217  0.8493449782  0.8695652174  0.5968586387  73.362445414  1.3821137404  0.2654595375  1050          0.0585574722 
0.8951965066  0.9217391304  0.8777292576  0.8869565217  0.8602620087  0.8956521739  0.8646288210  0.8956521739  0.6125654450  76.855895196  1.4044687843  0.2654595375  1100          0.0578154087 
0.8930131004  0.9217391304  0.8820960699  0.8521739130  0.8537117904  0.8869565217  0.8471615721  0.8695652174  0.5759162304  80.349344978  1.4061354518  0.2667212486  1150          0.0597421217 
0.8930131004  0.9217391304  0.8733624454  0.8782608696  0.8558951965  0.8869565217  0.8537117904  0.8695652174  0.6143106457  83.842794759  1.4115172696  0.2667212486  1200          0.0582192039 
0.8951965066  0.9217391304  0.8755458515  0.8869565217  0.8580786026  0.8782608696  0.8668122271  0.8782608696  0.6108202443  87.336244541  1.3372294950  0.2667212486  1250          0.0584826469 
0.8995633188  0.9130434783  0.8864628821  0.8782608696  0.8668122271  0.8782608696  0.8820960699  0.8782608696  0.6038394415  90.829694323  1.3666927886  0.2667212486  1300          0.0584421635 
0.8951965066  0.9130434783  0.8799126638  0.8869565217  0.8646288210  0.8782608696  0.8646288210  0.8782608696  0.5986038394  94.323144104  1.3732406235  0.2667212486  1350          0.0583024454 
0.8930131004  0.9217391304  0.8733624454  0.8869565217  0.8558951965  0.8869565217  0.8537117904  0.8695652174  0.6125654450  97.816593886  1.3612159228  0.2667212486  1400          0.0588345909 
0.8951965066  0.9130434783  0.8777292576  0.8782608696  0.8558951965  0.8869565217  0.8602620087  0.8782608696  0.6020942408  101.31004366  1.4088544989  0.2667212486  1450          0.0586540747 
0.8908296943  0.9304347826  0.8755458515  0.8608695652  0.8493449782  0.8869565217  0.8427947598  0.8695652174  0.5916230366  104.80349344  1.4140249062  0.2667212486  1500          0.0590571737 
0.8951965066  0.9217391304  0.8820960699  0.8869565217  0.8624454148  0.8695652174  0.8624454148  0.8782608696  0.6055846422  108.29694323  1.4121758306  0.2667212486  1550          0.0596981001 
0.8930131004  0.9391304348  0.8733624454  0.8608695652  0.8471615721  0.8869565217  0.8406113537  0.8695652174  0.5933682373  111.79039301  1.4231520820  0.2667212486  1600          0.0585436296 
0.8951965066  0.9217391304  0.8755458515  0.8869565217  0.8580786026  0.8782608696  0.8602620087  0.8782608696  0.6178010471  115.28384279  1.3971782708  0.2667212486  1650          0.0589877892 
0.8930131004  0.9217391304  0.8733624454  0.8782608696  0.8558951965  0.8869565217  0.8537117904  0.8695652174  0.6108202443  118.77729257  1.3936477327  0.2667212486  1700          0.0589282990 
0.8930131004  0.9217391304  0.8733624454  0.8695652174  0.8537117904  0.8869565217  0.8537117904  0.8695652174  0.6038394415  122.27074235  1.3854647064  0.2667212486  1750          0.0589480543 
0.8951965066  0.9217391304  0.8799126638  0.8869565217  0.8624454148  0.8608695652  0.8580786026  0.8695652174  0.6195462478  125.76419213  1.4055266333  0.2667212486  1800          0.0600718212 
0.8930131004  0.9130434783  0.8799126638  0.8782608696  0.8537117904  0.8869565217  0.8668122271  0.8782608696  0.5951134380  129.25764192  1.3728927660  0.2667212486  1850          0.0584747791 
0.8908296943  0.9217391304  0.8711790393  0.8695652174  0.8515283843  0.8869565217  0.8515283843  0.8695652174  0.6055846422  132.75109170  1.3749680686  0.2667212486  1900          0.0577658129 
0.8930131004  0.9217391304  0.8711790393  0.8695652174  0.8537117904  0.8869565217  0.8493449782  0.8695652174  0.6038394415  136.24454148  1.3878999913  0.2667212486  1950          0.0582241631 
0.8930131004  0.9217391304  0.8689956332  0.8695652174  0.8515283843  0.8869565217  0.8493449782  0.8695652174  0.6090750436  139.73799126  1.3683697724  0.2667212486  2000          0.0583322668 
0.8930131004  0.9217391304  0.8799126638  0.8782608696  0.8602620087  0.8608695652  0.8624454148  0.8608695652  0.6195462478  143.23144104  1.3850635743  0.2667212486  2050          0.0591430473 
0.8908296943  0.9304347826  0.8755458515  0.8695652174  0.8493449782  0.8869565217  0.8493449782  0.8695652174  0.6003490401  146.72489082  1.4066158056  0.2667212486  2100          0.0575390577 
0.8930131004  0.9217391304  0.8755458515  0.8869565217  0.8580786026  0.8782608696  0.8602620087  0.8695652174  0.6108202443  150.21834061  1.3647413993  0.2667212486  2150          0.0588140392 
0.8951965066  0.9217391304  0.8777292576  0.8869565217  0.8624454148  0.8782608696  0.8668122271  0.8782608696  0.6020942408  153.71179039  1.4273307395  0.2667212486  2200          0.0584363985 
0.8951965066  0.9217391304  0.8777292576  0.8782608696  0.8558951965  0.8869565217  0.8624454148  0.8782608696  0.6003490401  157.20524017  1.3988183069  0.2667212486  2250          0.0587444258 
0.8886462882  0.9217391304  0.8755458515  0.8695652174  0.8537117904  0.8869565217  0.8537117904  0.8695652174  0.6020942408  160.69868995  1.4061520982  0.2667212486  2300          0.0578187561 
0.8930131004  0.9130434783  0.8799126638  0.8869565217  0.8537117904  0.8782608696  0.8646288210  0.8782608696  0.5951134380  164.19213973  1.4039395261  0.2667212486  2350          0.0588300753 
0.8930131004  0.9217391304  0.8755458515  0.8869565217  0.8602620087  0.8782608696  0.8602620087  0.8695652174  0.6125654450  167.68558951  1.3758743525  0.2667212486  2400          0.0585317135 
0.8951965066  0.9217391304  0.8864628821  0.8869565217  0.8668122271  0.8608695652  0.8711790393  0.8695652174  0.6073298429  171.17903930  1.3816220665  0.3474483490  2450          0.0598154020 
0.8908296943  0.9217391304  0.8733624454  0.8869565217  0.8580786026  0.8782608696  0.8558951965  0.8695652174  0.6265270506  174.67248908  1.3820412898  0.3474483490  2500          0.0579340363 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  4.6340842247  0.1362590790  0             0.4240477085 
0.2816593886  0.3304347826  0.3122270742  0.3130434783  0.3013100437  0.3130434783  0.3362445415  0.3043478261  0.3176265271  3.4934497817  4.3327617073  0.3009815216  50            0.0705910730 
0.3973799127  0.4086956522  0.3733624454  0.3565217391  0.3842794760  0.4086956522  0.3864628821  0.3478260870  0.3647469459  6.9868995633  4.1786145687  0.3009815216  100           0.0690093279 
0.4912663755  0.5043478261  0.4170305677  0.4086956522  0.4192139738  0.4434782609  0.4475982533  0.4000000000  0.3874345550  10.480349345  4.0780254221  0.3009815216  150           0.0718375778 
0.5938864629  0.5652173913  0.4737991266  0.4347826087  0.4716157205  0.5130434783  0.4934497817  0.4434782609  0.4485165794  13.973799126  3.9789833546  0.3010191917  200           0.0744141817 
0.6462882096  0.5913043478  0.5196506550  0.4695652174  0.5174672489  0.5478260870  0.5218340611  0.4956521739  0.4799301920  17.467248908  3.8413747692  0.3010191917  250           0.0770772076 
0.7074235808  0.6521739130  0.6048034934  0.5304347826  0.6397379913  0.6173913043  0.5982532751  0.5913043478  0.5567190227  20.960698690  3.6956781673  0.3010191917  300           0.0761876631 
0.7379912664  0.7217391304  0.6637554585  0.5739130435  0.6659388646  0.6434782609  0.6441048035  0.5826086957  0.5671902269  24.454148471  3.4995609283  0.3010191917  350           0.0743798780 
0.7620087336  0.7391304348  0.6986899563  0.6869565217  0.7270742358  0.7043478261  0.7008733624  0.6869565217  0.6143106457  27.947598253  3.2681834364  0.3010191917  400           0.0775952482 
0.7794759825  0.7826086957  0.7248908297  0.7043478261  0.7445414847  0.7391304348  0.7292576419  0.7478260870  0.6143106457  31.441048034  3.0791218567  0.3010191917  450           0.0767518711 
0.8078602620  0.7739130435  0.7576419214  0.7478260870  0.7598253275  0.7826086957  0.7467248908  0.7391304348  0.6212914485  34.934497816  2.8215675879  0.3010392189  500           0.0796674633 
0.8187772926  0.8173913043  0.7947598253  0.7913043478  0.7816593886  0.8347826087  0.7903930131  0.7826086957  0.6492146597  38.427947598  2.6365396976  0.3010392189  550           0.0712474918 
0.8275109170  0.8347826087  0.8100436681  0.8086956522  0.7903930131  0.8347826087  0.7838427948  0.8260869565  0.6265270506  41.921397379  2.4723578119  0.3010768890  600           0.0704879189 
0.8384279476  0.8173913043  0.8144104803  0.8173913043  0.8056768559  0.8521739130  0.7860262009  0.8260869565  0.6178010471  45.414847161  2.3356847477  0.3010768890  650           0.0706475925 
0.8515283843  0.8782608696  0.8253275109  0.8434782609  0.8122270742  0.8608695652  0.8187772926  0.8608695652  0.6352530541  48.908296943  2.2395052552  0.3010768890  700           0.0685566473 
0.8580786026  0.8695652174  0.8318777293  0.8434782609  0.8275109170  0.8347826087  0.8296943231  0.8608695652  0.6719022688  52.401746724  2.1280568552  0.3010768890  750           0.0718186760 
0.8580786026  0.9043478261  0.8427947598  0.8608695652  0.8275109170  0.8695652174  0.8275109170  0.8695652174  0.6387434555  55.895196506  2.0469794416  0.3010768890  800           0.0717532778 
0.8602620087  0.8782608696  0.8493449782  0.8608695652  0.8384279476  0.8521739130  0.8275109170  0.8695652174  0.6317626527  59.388646288  1.9624778438  0.3010768890  850           0.0712209845 
0.8689956332  0.9043478261  0.8558951965  0.8695652174  0.8362445415  0.8869565217  0.8384279476  0.8695652174  0.6230366492  62.882096069  1.8628204989  0.3010768890  900           0.0777783680 
0.8689956332  0.9217391304  0.8537117904  0.8782608696  0.8362445415  0.8782608696  0.8406113537  0.8695652174  0.6369982548  66.375545851  1.7982142401  0.3010768890  950           0.0740456629 
0.8799126638  0.9043478261  0.8558951965  0.8869565217  0.8449781659  0.8608695652  0.8427947598  0.8695652174  0.6195462478  69.868995633  1.7553489900  0.3010768890  1000          0.0733857441 
0.8799126638  0.9043478261  0.8515283843  0.8869565217  0.8493449782  0.8695652174  0.8449781659  0.8695652174  0.6195462478  73.362445414  1.7179065132  0.3039984703  1050          0.0728987694 
0.8777292576  0.9043478261  0.8602620087  0.8782608696  0.8406113537  0.8782608696  0.8384279476  0.8695652174  0.6178010471  76.855895196  1.7435250258  0.3039984703  1100          0.0741449308 
0.8689956332  0.9043478261  0.8624454148  0.8782608696  0.8471615721  0.8782608696  0.8406113537  0.8695652174  0.5986038394  80.349344978  1.7407698250  0.3039984703  1150          0.0756717873 
0.8820960699  0.9043478261  0.8602620087  0.8869565217  0.8471615721  0.8521739130  0.8449781659  0.8695652174  0.6125654450  83.842794759  1.7503354716  0.3831868172  1200          0.0749947929 
0.8777292576  0.9130434783  0.8580786026  0.8695652174  0.8471615721  0.8869565217  0.8340611354  0.8695652174  0.5898778360  87.336244541  1.6731965399  0.3831868172  1250          0.0722176313 
0.8799126638  0.9043478261  0.8580786026  0.8782608696  0.8471615721  0.8782608696  0.8406113537  0.8695652174  0.6108202443  90.829694323  1.7027989364  0.3831868172  1300          0.0690305805 
0.8842794760  0.8956521739  0.8668122271  0.8869565217  0.8471615721  0.8695652174  0.8493449782  0.8695652174  0.6038394415  94.323144104  1.6793350363  0.3831868172  1350          0.0704428768 
0.8711790393  0.9043478261  0.8689956332  0.8695652174  0.8493449782  0.8782608696  0.8406113537  0.8695652174  0.5951134380  97.816593886  1.7211990428  0.3831868172  1400          0.0698457146 
0.8777292576  0.9130434783  0.8602620087  0.8695652174  0.8471615721  0.8782608696  0.8340611354  0.8695652174  0.5933682373  101.31004366  1.7302577639  0.3831868172  1450          0.0704331493 
0.8799126638  0.9043478261  0.8537117904  0.8869565217  0.8471615721  0.8695652174  0.8449781659  0.8695652174  0.6108202443  104.80349344  1.7072180557  0.3831868172  1500          0.0700806808 
0.8820960699  0.9130434783  0.8537117904  0.8782608696  0.8471615721  0.8521739130  0.8449781659  0.8695652174  0.6439790576  108.29694323  1.7419503713  0.3831868172  1550          0.0702171516 
0.8733624454  0.9130434783  0.8602620087  0.8695652174  0.8471615721  0.8869565217  0.8384279476  0.8695652174  0.5898778360  111.79039301  1.7626724243  0.3831868172  1600          0.0694372129 
0.8777292576  0.9130434783  0.8580786026  0.8869565217  0.8384279476  0.8782608696  0.8449781659  0.8695652174  0.6230366492  115.28384279  1.7404952335  0.3831868172  1650          0.0727717352 
0.8799126638  0.9130434783  0.8580786026  0.8869565217  0.8427947598  0.8521739130  0.8471615721  0.8695652174  0.6247818499  118.77729257  1.7438310909  0.3831868172  1700          0.0747881556 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2261, in update
    meta_train_loss_main += 10*penalty
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             21.036304950 
0.2641921397  0.3130434783  0.2729257642  0.3304347826  0.2751091703  0.3652173913  0.3034934498  0.2086956522  0.2862129145  3.4934497817  4.7533910370  0.3009815216  50            0.0712575102 
0.3165938865  0.3391304348  0.2947598253  0.3478260870  0.3209606987  0.3130434783  0.3384279476  0.2782608696  0.3438045375  6.9868995633  4.4690368557  0.3010392189  100           0.0708292770 
0.3340611354  0.3391304348  0.3296943231  0.3652173913  0.3449781659  0.3391304348  0.3558951965  0.3304347826  0.3420593368  10.480349345  4.3376425743  0.3010392189  150           0.0699934769 
0.3842794760  0.3565217391  0.3471615721  0.4347826087  0.3668122271  0.3826086957  0.3799126638  0.3565217391  0.3577661431  13.973799126  4.2711931515  0.3011345863  200           0.0695875359 
0.4039301310  0.4000000000  0.3668122271  0.4173913043  0.3799126638  0.3913043478  0.3820960699  0.3478260870  0.3630017452  17.467248908  4.2035705948  0.3011345863  250           0.0719551229 
0.4475982533  0.4347826087  0.3908296943  0.4521739130  0.4104803493  0.4173913043  0.4017467249  0.3739130435  0.3839441536  20.960698690  4.1727181053  0.3011345863  300           0.0723628855 
0.4388646288  0.4521739130  0.4126637555  0.4608695652  0.4257641921  0.4347826087  0.3995633188  0.4086956522  0.3787085515  24.454148471  4.1371190834  0.3011345863  350           0.0803363419 
0.4585152838  0.4695652174  0.4279475983  0.4695652174  0.4366812227  0.4260869565  0.4126637555  0.4434782609  0.3891797557  27.947598253  4.1057382584  0.3831448555  400           0.0783806372 
0.5065502183  0.5130434783  0.4519650655  0.4869565217  0.4628820961  0.5043478261  0.4410480349  0.4695652174  0.4083769634  31.441048034  4.0885362053  0.3831448555  450           0.0731337023 
0.5000000000  0.5565217391  0.4606986900  0.4956521739  0.4606986900  0.5043478261  0.4454148472  0.4695652174  0.4083769634  34.934497816  4.0256537533  0.3831448555  500           0.0692843723 
0.5196506550  0.5391304348  0.4606986900  0.4956521739  0.4628820961  0.5217391304  0.4519650655  0.4347826087  0.4188481675  38.427947598  3.9857873106  0.3831448555  550           0.0723662567 
0.5917030568  0.5913043478  0.4890829694  0.5043478261  0.4737991266  0.5478260870  0.4759825328  0.4521739130  0.4869109948  41.921397379  3.9384283972  0.3831448555  600           0.0720114374 
0.6834061135  0.7130434783  0.5786026201  0.5913043478  0.5633187773  0.6000000000  0.5545851528  0.4956521739  0.5776614311  45.414847161  3.8670033026  0.3831448555  650           0.0715598822 
0.7467248908  0.7565217391  0.6288209607  0.6086956522  0.6113537118  0.6695652174  0.6004366812  0.5478260870  0.6265270506  48.908296943  3.7461091137  0.3831448555  700           0.0705940437 
0.7729257642  0.8173913043  0.6768558952  0.6782608696  0.7052401747  0.7565217391  0.6965065502  0.6347826087  0.6788830716  52.401746724  3.5923248911  0.3831448555  750           0.0710977983 
0.7707423581  0.8434782609  0.7248908297  0.7217391304  0.7401746725  0.8173913043  0.7139737991  0.7043478261  0.6509598604  55.895196506  3.4619094610  0.3831448555  800           0.0707322407 
0.7925764192  0.8434782609  0.7707423581  0.7652173913  0.7729257642  0.8782608696  0.7554585153  0.8000000000  0.6457242583  59.388646288  3.3190271759  0.3831448555  850           0.0688782263 
0.8144104803  0.8608695652  0.7925764192  0.8086956522  0.7903930131  0.8782608696  0.7925764192  0.7739130435  0.6527050611  62.882096069  3.1245159292  0.3831448555  900           0.0702487564 
0.8275109170  0.8869565217  0.8122270742  0.8173913043  0.8034934498  0.8869565217  0.8144104803  0.8000000000  0.6771378709  66.375545851  3.0283365202  0.3831448555  950           0.0705766535 
0.8187772926  0.8695652174  0.8144104803  0.8260869565  0.8013100437  0.8956521739  0.8034934498  0.7826086957  0.6579406632  69.868995633  2.9253917503  0.3831448555  1000          0.0709009552 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
RuntimeError: DataLoader worker (pid 186898) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2641921397  0.3043478261  0.2663755459  0.2782608696  0.2554585153  0.2347826087  0.2598253275  0.2956521739  0.2722513089  0.0000000000  5.1459832191  0.1362590790  0             0.6572961807 
0.7925764192  0.8695652174  0.8318777293  0.8434782609  0.7903930131  0.8608695652  0.7729257642  0.7652173913  0.5567190227  3.4934497817  4.1584921265  0.3009815216  50            0.0699996424 
0.8493449782  0.8956521739  0.8668122271  0.8782608696  0.8340611354  0.8782608696  0.8187772926  0.8260869565  0.5951134380  6.9868995633  3.1719111300  0.3830871582  100           0.0706687117 
0.8668122271  0.8869565217  0.8820960699  0.8695652174  0.8537117904  0.9217391304  0.8362445415  0.8260869565  0.5567190227  10.480349345  2.8324091005  0.3830871582  150           0.0711878490 
0.9454148472  0.9478260870  0.9344978166  0.9130434783  0.9104803493  0.9304347826  0.9344978166  0.8608695652  0.5706806283  13.973799126  2.3898404646  0.3830871582  200           0.0698675632 
0.9475982533  0.9391304348  0.9628820961  0.9478260870  0.9454148472  0.9391304348  0.9323144105  0.8956521739  0.5287958115  17.467248908  1.9481436086  0.3830871582  250           0.0706368494 
0.9388646288  0.9478260870  0.9497816594  0.9304347826  0.9366812227  0.9478260870  0.9606986900  0.8782608696  0.5061082024  20.960698690  1.6575193739  0.3830871582  300           0.0699975395 
0.9672489083  0.9652173913  0.9759825328  0.9565217391  0.9541484716  0.9652173913  0.9650655022  0.8782608696  0.5549738220  24.454148471  1.4240161538  0.3830871582  350           0.0702938414 
0.9781659389  0.9739130435  0.9868995633  0.9565217391  0.9737991266  0.9652173913  0.9737991266  0.9130434783  0.5497382199  27.947598253  1.2664313865  0.3830871582  400           0.0700678253 
0.9803493450  0.9826086957  0.9934497817  0.9739130435  0.9803493450  0.9739130435  0.9694323144  0.9304347826  0.4991273997  31.441048034  1.1147457206  0.3830871582  450           0.0690812922 
0.9781659389  0.9565217391  0.9825327511  0.9391304348  0.9847161572  0.9652173913  0.9934497817  0.9391304348  0.5532286213  34.934497816  1.0276695991  0.3830871582  500           0.0710032892 
0.9912663755  0.9826086957  0.9956331878  0.9739130435  0.9912663755  0.9913043478  0.9847161572  0.9565217391  0.5043630017  38.427947598  0.9883829832  0.3830871582  550           0.0710421658 
0.9912663755  0.9913043478  0.9956331878  0.9739130435  0.9934497817  0.9913043478  0.9912663755  0.9391304348  0.5061082024  41.921397379  0.8606729269  0.3830871582  600           0.0710374641 
0.9825327511  0.9739130435  0.9890829694  0.9652173913  0.9934497817  0.9739130435  0.9956331878  0.9391304348  0.5253054101  45.414847161  0.7857835293  0.3830871582  650           0.0700822544 
0.9912663755  0.9652173913  0.9956331878  0.9565217391  1.0000000000  0.9913043478  0.9978165939  0.9565217391  0.5165794066  48.908296943  0.7746437514  0.3830871582  700           0.0702604771 
0.9978165939  0.9913043478  0.9978165939  0.9826086957  1.0000000000  0.9913043478  0.9978165939  0.9652173913  0.4956369983  52.401746724  0.7253947729  0.3830871582  750           0.0699497938 
0.9934497817  0.9565217391  0.9978165939  0.9652173913  0.9934497817  0.9826086957  0.9956331878  0.9391304348  0.5322862129  55.895196506  0.6096539468  0.3830871582  800           0.0724512148 
0.9934497817  1.0000000000  1.0000000000  0.9739130435  1.0000000000  0.9913043478  1.0000000000  0.9826086957  0.4781849913  59.388646288  0.5919538081  0.3830871582  850           0.0726298714 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1877729258  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.3861842155 
0.3951965066  0.4086956522  0.3842794760  0.4695652174  0.4454148472  0.4434782609  0.4235807860  0.4086956522  0.3577661431  3.4934497817  4.4002872658  0.3009815216  50            0.0698471165 
0.5218340611  0.5304347826  0.4606986900  0.4608695652  0.4694323144  0.4869565217  0.4126637555  0.4347826087  0.3664921466  6.9868995633  4.1581006050  0.3009815216  100           0.0727222157 
0.6506550218  0.6521739130  0.5698689956  0.5565217391  0.5545851528  0.6347826087  0.5436681223  0.5565217391  0.5514834206  10.480349345  3.9496361446  0.3011198044  150           0.0704511929 
0.7947598253  0.8695652174  0.7729257642  0.7913043478  0.7794759825  0.8521739130  0.7510917031  0.7739130435  0.6178010471  13.973799126  3.5889116430  0.3011198044  200           0.0759261131 
0.8209606987  0.8521739130  0.7838427948  0.8347826087  0.7860262009  0.8608695652  0.7707423581  0.8000000000  0.5968586387  17.467248908  3.1027389908  0.3011198044  250           0.0719710827 
0.8515283843  0.8869565217  0.8427947598  0.8347826087  0.8078602620  0.8869565217  0.8275109170  0.8608695652  0.6753926702  20.960698690  2.7470012188  0.3011198044  300           0.0724591541 
0.8471615721  0.9130434783  0.8340611354  0.8434782609  0.8122270742  0.8956521739  0.8187772926  0.8608695652  0.6352530541  24.454148471  2.5595723104  0.3011384010  350           0.0735968781 
0.8646288210  0.9130434783  0.8427947598  0.8608695652  0.8122270742  0.8956521739  0.8209606987  0.8521739130  0.5951134380  27.947598253  2.4146158028  0.3011384010  400           0.0722160959 
0.8668122271  0.8869565217  0.8427947598  0.8608695652  0.8253275109  0.9043478261  0.8318777293  0.8521739130  0.5846422339  31.441048034  2.2779195428  0.3011384010  450           0.0712733030 
0.8842794760  0.8956521739  0.8646288210  0.8782608696  0.8209606987  0.9043478261  0.8384279476  0.8782608696  0.5794066318  34.934497816  2.1869705844  0.3011384010  500           0.0728249598 
0.9061135371  0.8956521739  0.8864628821  0.8869565217  0.8493449782  0.9217391304  0.8689956332  0.8956521739  0.5881326353  38.427947598  2.0371748090  0.3011384010  550           0.0799876451 
0.9388646288  0.9130434783  0.9213973799  0.8956521739  0.8908296943  0.9391304348  0.8995633188  0.8695652174  0.5375218150  41.921397379  2.0011442852  0.3011384010  600           0.0699409533 
0.9257641921  0.9043478261  0.9213973799  0.9043478261  0.8777292576  0.9217391304  0.8842794760  0.8695652174  0.5392670157  45.414847161  1.8718489933  0.3011384010  650           0.0706564713 
0.9388646288  0.9130434783  0.9148471616  0.8956521739  0.8842794760  0.9304347826  0.8733624454  0.8956521739  0.5375218150  48.908296943  1.9187925959  0.3011384010  700           0.0706309843 
0.9585152838  0.9391304348  0.9366812227  0.9130434783  0.9213973799  0.9652173913  0.9323144105  0.9130434783  0.5794066318  52.401746724  1.7646142769  0.3011384010  750           0.0694642496 
0.9650655022  0.9391304348  0.9432314410  0.9217391304  0.9148471616  0.9565217391  0.9301310044  0.9130434783  0.5340314136  55.895196506  1.6450851965  0.3011384010  800           0.0701189566 
0.9716157205  0.9565217391  0.9672489083  0.9391304348  0.9563318777  0.9739130435  0.9410480349  0.9217391304  0.5497382199  59.388646288  1.5776437283  0.3011384010  850           0.0696949959 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 300, in <module>
    for x, y in next(train_minibatches_iterator)]
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/fast_data_loader.py", line 46, in __iter__
    yield next(self._infinite_iterator)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1010, in _try_get_data
    fs = [tempfile.NamedTemporaryFile() for i in range(fds_limit_margin)]
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1010, in <listcomp>
    fs = [tempfile.NamedTemporaryFile() for i in range(fds_limit_margin)]
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tempfile.py", line 551, in NamedTemporaryFile
    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/tempfile.py", line 262, in _mkstemp_inner
    fd = _os.open(file, flags, 0o600)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.3807804585 
0.3187772926  0.3304347826  0.3187772926  0.3478260870  0.3340611354  0.3739130435  0.3602620087  0.3130434783  0.3368237347  3.4934497817  4.5477384758  0.3010191917  50            0.0715771103 
0.4213973799  0.3913043478  0.3864628821  0.4695652174  0.4017467249  0.4086956522  0.3777292576  0.3478260870  0.3769633508  6.9868995633  4.2725732327  0.3010191917  100           0.0706718493 
0.4868995633  0.5043478261  0.4388646288  0.4956521739  0.4432314410  0.4521739130  0.4235807860  0.4173913043  0.3821989529  10.480349345  4.1599752140  0.3010191917  150           0.0714518976 
0.5807860262  0.5913043478  0.4890829694  0.5043478261  0.4781659389  0.5304347826  0.4759825328  0.4695652174  0.4520069808  13.973799126  4.0885945272  0.3010191917  200           0.0687290573 
0.6375545852  0.6000000000  0.5021834061  0.5565217391  0.5152838428  0.5652173913  0.4978165939  0.5043478261  0.5218150087  17.467248908  3.9520867586  0.3010191917  250           0.0701908588 
0.7882096070  0.8000000000  0.6921397380  0.7043478261  0.7074235808  0.7565217391  0.6812227074  0.6521739130  0.6230366492  20.960698690  3.7827686882  0.3010406494  300           0.0705858564 
0.7882096070  0.8521739130  0.7663755459  0.8000000000  0.7816593886  0.8260869565  0.7576419214  0.7739130435  0.6457242583  24.454148471  3.4590615892  0.3010406494  350           0.0704998732 
0.8253275109  0.8869565217  0.8165938865  0.8347826087  0.7925764192  0.8695652174  0.8100436681  0.8086956522  0.6404886562  27.947598253  3.1149792147  0.3010997772  400           0.0693531132 
0.8253275109  0.9043478261  0.8100436681  0.8260869565  0.7991266376  0.8695652174  0.8100436681  0.8173913043  0.6369982548  31.441048034  2.8754112387  0.3010997772  450           0.0702415943 
0.8318777293  0.8956521739  0.8209606987  0.8260869565  0.7969432314  0.8869565217  0.8122270742  0.7913043478  0.6020942408  34.934497816  2.7032721138  0.3010997772  500           0.0716154432 
0.8275109170  0.9130434783  0.8275109170  0.8260869565  0.8100436681  0.8956521739  0.8165938865  0.8608695652  0.6666666667  38.427947598  2.5365962267  0.3010997772  550           0.0709432459 
0.8449781659  0.8956521739  0.8340611354  0.8434782609  0.8078602620  0.8869565217  0.8144104803  0.8347826087  0.6195462478  41.921397379  2.4987996101  0.3010997772  600           0.0715967798 
0.8515283843  0.8956521739  0.8406113537  0.8521739130  0.8078602620  0.8956521739  0.8209606987  0.8521739130  0.6020942408  45.414847161  2.4068393898  0.3010997772  650           0.0705114985 
0.8537117904  0.9043478261  0.8427947598  0.8608695652  0.8165938865  0.8956521739  0.8296943231  0.8608695652  0.6108202443  48.908296943  2.4502781796  0.3010997772  700           0.0713026953 
0.8406113537  0.8869565217  0.8427947598  0.8608695652  0.8187772926  0.8869565217  0.8340611354  0.8695652174  0.6666666667  52.401746724  2.3267018032  0.3010997772  750           0.0736997700 
0.8493449782  0.9043478261  0.8449781659  0.8782608696  0.8209606987  0.8956521739  0.8318777293  0.8782608696  0.6108202443  55.895196506  2.2494636917  0.3010997772  800           0.0718668842 
0.8580786026  0.8956521739  0.8515283843  0.8695652174  0.8231441048  0.8956521739  0.8362445415  0.8869565217  0.5968586387  59.388646288  2.2127527022  0.3010997772  850           0.0710580826 
0.8580786026  0.8869565217  0.8558951965  0.8782608696  0.8275109170  0.8956521739  0.8449781659  0.8782608696  0.6073298429  62.882096069  2.0803836966  0.3010997772  900           0.0714293718 
0.8602620087  0.9043478261  0.8558951965  0.8782608696  0.8253275109  0.9043478261  0.8406113537  0.8695652174  0.6178010471  66.375545851  2.1059559703  0.3010997772  950           0.0748063803 
0.8777292576  0.8956521739  0.8624454148  0.8782608696  0.8340611354  0.9043478261  0.8515283843  0.8869565217  0.5951134380  69.868995633  2.0553385520  0.3010997772  1000          0.0800344610 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 137, in updatecache
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/codecs.py", line 318, in decode
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 269452) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1984, in handle_keyboard_interrupt
    traceback.print_exception(type(value), value, tb, limit=limit)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 104, in print_exception
    type(value), value, tb, limit=limit).format(chain=chain):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 509, in __init__
    capture_locals=capture_locals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 364, in extract
    f.line
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 286, in line
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 137, in updatecache
    lines = fp.readlines()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 270254) is killed by signal: Terminated. 
We've got an error while stopping in post-mortem: <class 'RuntimeError'>

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.3836288452 
0.3187772926  0.3304347826  0.3187772926  0.3478260870  0.3340611354  0.3739130435  0.3602620087  0.3130434783  0.3368237347  3.4934497817  4.5477384758  0.3009815216  50            0.0741093063 
0.4213973799  0.3913043478  0.3864628821  0.4695652174  0.4017467249  0.4086956522  0.3777292576  0.3478260870  0.3769633508  6.9868995633  4.2725732327  0.3011007309  100           0.0730665827 
0.4868995633  0.5043478261  0.4388646288  0.4956521739  0.4432314410  0.4521739130  0.4235807860  0.4173913043  0.3821989529  10.480349345  4.1599752140  0.3011007309  150           0.0718250322 
0.5807860262  0.5913043478  0.4890829694  0.5043478261  0.4781659389  0.5304347826  0.4759825328  0.4695652174  0.4520069808  13.973799126  4.0885945272  0.3011007309  200           0.0718535757 
0.6375545852  0.6000000000  0.5021834061  0.5565217391  0.5152838428  0.5652173913  0.4978165939  0.5043478261  0.5218150087  17.467248908  3.9520867586  0.3011007309  250           0.0710445309 
0.7882096070  0.8000000000  0.6921397380  0.7043478261  0.7074235808  0.7565217391  0.6812227074  0.6521739130  0.6230366492  20.960698690  3.7827686882  0.3011007309  300           0.0709144163 
0.7882096070  0.8521739130  0.7663755459  0.8000000000  0.7816593886  0.8260869565  0.7576419214  0.7739130435  0.6457242583  24.454148471  3.4590615892  0.3011007309  350           0.0697958374 
0.8253275109  0.8869565217  0.8165938865  0.8347826087  0.7925764192  0.8695652174  0.8100436681  0.8086956522  0.6404886562  27.947598253  3.1149792147  0.3011007309  400           0.0706442213 
0.8253275109  0.9043478261  0.8100436681  0.8260869565  0.7991266376  0.8695652174  0.8100436681  0.8173913043  0.6369982548  31.441048034  2.8754112387  0.3011007309  450           0.0692238951 
0.8318777293  0.8956521739  0.8209606987  0.8260869565  0.7969432314  0.8869565217  0.8122270742  0.7913043478  0.6020942408  34.934497816  2.7032721138  0.3011345863  500           0.0725075722 
0.8275109170  0.9130434783  0.8275109170  0.8260869565  0.8100436681  0.8956521739  0.8165938865  0.8608695652  0.6666666667  38.427947598  2.5365962267  0.3011345863  550           0.0697431564 
0.8296943231  0.9043478261  0.8275109170  0.8260869565  0.8056768559  0.8956521739  0.8144104803  0.8173913043  0.6387434555  41.921397379  2.5351716661  0.3011345863  600           0.0683161974 
0.8275109170  0.9043478261  0.8231441048  0.8347826087  0.8078602620  0.8956521739  0.8056768559  0.8173913043  0.6160558464  45.414847161  2.5178581619  0.3011345863  650           0.0735760117 
0.8318777293  0.9217391304  0.8253275109  0.8260869565  0.8100436681  0.8956521739  0.8187772926  0.8521739130  0.6631762653  48.908296943  2.6148447657  0.3011345863  700           0.0736737490 
0.8209606987  0.8956521739  0.8275109170  0.8347826087  0.8078602620  0.8869565217  0.8187772926  0.8434782609  0.6666666667  52.401746724  2.5668939686  0.3011345863  750           0.0728049755 
0.8275109170  0.9043478261  0.8275109170  0.8260869565  0.8100436681  0.8956521739  0.8078602620  0.8260869565  0.6300174520  55.895196506  2.5343373060  0.3011345863  800           0.0716434669 
0.8296943231  0.9043478261  0.8275109170  0.8260869565  0.8122270742  0.9043478261  0.8122270742  0.8347826087  0.6300174520  59.388646288  2.5420684862  0.3011345863  850           0.0736202526 
0.8275109170  0.9130434783  0.8253275109  0.8347826087  0.8100436681  0.8956521739  0.8144104803  0.8608695652  0.6509598604  62.882096069  2.4801477528  0.3011345863  900           0.0711410141 
0.8296943231  0.9130434783  0.8296943231  0.8347826087  0.8100436681  0.8956521739  0.8209606987  0.8521739130  0.6684118674  66.375545851  2.5250781918  0.3011345863  950           0.0705034828 
0.8275109170  0.9130434783  0.8275109170  0.8347826087  0.8100436681  0.8956521739  0.8165938865  0.8521739130  0.6666666667  69.868995633  2.5233087015  0.3011345863  1000          0.0725234842 
0.8253275109  0.9130434783  0.8296943231  0.8260869565  0.8122270742  0.8956521739  0.8165938865  0.8521739130  0.6631762653  73.362445414  2.5208978605  0.3011345863  1050          0.0707266998 
0.8296943231  0.9043478261  0.8296943231  0.8260869565  0.8122270742  0.8956521739  0.8187772926  0.8434782609  0.6439790576  76.855895196  2.5418597746  0.3011345863  1100          0.0699658823 
0.8318777293  0.9043478261  0.8275109170  0.8260869565  0.8100436681  0.9043478261  0.8100436681  0.8260869565  0.6212914485  80.349344978  2.5332161188  0.3011345863  1150          0.0723721790 
0.8275109170  0.9130434783  0.8296943231  0.8347826087  0.8100436681  0.8869565217  0.8165938865  0.8521739130  0.6631762653  83.842794759  2.5337488604  0.3011345863  1200          0.0717727852 
0.8318777293  0.9043478261  0.8231441048  0.8434782609  0.8013100437  0.8869565217  0.8034934498  0.8086956522  0.5968586387  87.336244541  2.4774414730  0.3831076622  1250          0.0742731380 
0.8275109170  0.9043478261  0.8253275109  0.8260869565  0.8122270742  0.9043478261  0.8144104803  0.8434782609  0.6544502618  90.829694323  2.4862652206  0.3831076622  1300          0.0701325226 
0.8253275109  0.9130434783  0.8296943231  0.8347826087  0.8122270742  0.8956521739  0.8144104803  0.8434782609  0.6492146597  94.323144104  2.4620511961  0.3831076622  1350          0.0740067005 
0.8275109170  0.9043478261  0.8275109170  0.8260869565  0.8100436681  0.8869565217  0.8078602620  0.8173913043  0.6160558464  97.816593886  2.5396694803  0.3831076622  1400          0.0732298040 
0.8318777293  0.9043478261  0.8231441048  0.8434782609  0.8013100437  0.8869565217  0.8056768559  0.8173913043  0.6038394415  101.31004366  2.5295931721  0.3831076622  1450          0.0715663624 
0.8253275109  0.9130434783  0.8296943231  0.8347826087  0.8122270742  0.8956521739  0.8144104803  0.8434782609  0.6561954625  104.80349344  2.5208955717  0.3831076622  1500          0.0722865820 
0.8296943231  0.9130434783  0.8296943231  0.8434782609  0.8100436681  0.8869565217  0.8231441048  0.8521739130  0.6858638743  108.29694323  2.5430082655  0.3831076622  1550          0.0718487358 
0.8318777293  0.8956521739  0.8275109170  0.8434782609  0.8013100437  0.8869565217  0.8056768559  0.8173913043  0.5986038394  111.79039301  2.5465370226  0.3831076622  1600          0.0724744892 
0.8318777293  0.9130434783  0.8318777293  0.8434782609  0.8122270742  0.8956521739  0.8231441048  0.8608695652  0.6596858639  115.28384279  2.5353879929  0.3831076622  1650          0.0721271515 
0.8253275109  0.9130434783  0.8318777293  0.8434782609  0.8100436681  0.8869565217  0.8209606987  0.8521739130  0.6701570681  118.77729257  2.4994287300  0.3831076622  1700          0.0731977844 
0.8253275109  0.9043478261  0.8318777293  0.8347826087  0.8100436681  0.9043478261  0.8187772926  0.8521739130  0.6579406632  122.27074235  2.5716239405  0.3831076622  1750          0.0718087959 
0.8275109170  0.9130434783  0.8318777293  0.8521739130  0.8100436681  0.8782608696  0.8209606987  0.8521739130  0.6841186736  125.76419213  2.5296463346  0.3831076622  1800          0.0760450649 
0.8231441048  0.9130434783  0.8318777293  0.8347826087  0.8100436681  0.8869565217  0.8209606987  0.8434782609  0.6771378709  129.25764192  2.5003876448  0.3831076622  1850          0.0731262064 
0.8296943231  0.9043478261  0.8275109170  0.8347826087  0.8122270742  0.8956521739  0.8165938865  0.8521739130  0.6509598604  132.75109170  2.5057206869  0.3831076622  1900          0.0699987793 
0.8318777293  0.8956521739  0.8231441048  0.8521739130  0.7991266376  0.8869565217  0.8100436681  0.8173913043  0.5986038394  136.24454148  2.4730231380  0.3831076622  1950          0.0724265671 
0.8275109170  0.9043478261  0.8296943231  0.8260869565  0.8122270742  0.8956521739  0.8165938865  0.8521739130  0.6387434555  139.73799126  2.5310927773  0.3831076622  2000          0.0722088146 
0.8340611354  0.9130434783  0.8340611354  0.8347826087  0.8122270742  0.8956521739  0.8253275109  0.8608695652  0.6596858639  143.23144104  2.5215957785  0.3831076622  2050          0.0722968292 
0.8296943231  0.9043478261  0.8275109170  0.8347826087  0.8100436681  0.8956521739  0.8187772926  0.8521739130  0.6579406632  146.72489082  2.5447056627  0.3831076622  2100          0.0712097740 
0.8275109170  0.9043478261  0.8275109170  0.8347826087  0.8122270742  0.8956521739  0.8165938865  0.8521739130  0.6387434555  150.21834061  2.4904425287  0.3831076622  2150          0.0711192179 
0.8253275109  0.9043478261  0.8340611354  0.8521739130  0.8122270742  0.8869565217  0.8209606987  0.8521739130  0.6823734729  153.71179039  2.5262670946  0.3831076622  2200          0.0710533905 
0.8275109170  0.9043478261  0.8340611354  0.8434782609  0.8122270742  0.8956521739  0.8253275109  0.8521739130  0.6771378709  157.20524017  2.5035908699  0.3831076622  2250          0.0718023586 
0.8318777293  0.9043478261  0.8318777293  0.8260869565  0.8122270742  0.8869565217  0.8165938865  0.8434782609  0.6369982548  160.69868995  2.5381063557  0.3831076622  2300          0.0764483881 
0.8253275109  0.9043478261  0.8384279476  0.8347826087  0.8122270742  0.8869565217  0.8209606987  0.8521739130  0.6527050611  164.19213973  2.5483074427  0.3831076622  2350          0.0729112959 
0.8296943231  0.9043478261  0.8340611354  0.8347826087  0.8122270742  0.8956521739  0.8209606987  0.8521739130  0.6561954625  167.68558951  2.4881772900  0.3831076622  2400          0.0726202583 
0.8275109170  0.9043478261  0.8318777293  0.8434782609  0.8100436681  0.8956521739  0.8231441048  0.8521739130  0.6649214660  171.17903930  2.4994363165  0.3831076622  2450          0.0737151670 
0.8384279476  0.9130434783  0.8318777293  0.8347826087  0.8122270742  0.8869565217  0.8209606987  0.8434782609  0.6457242583  174.67248908  2.5192920589  0.3831076622  2500          0.0730429363 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 358, in <module>
    save_checkpoint('model.pkl')
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.3959190845 
0.2794759825  0.2782608696  0.2816593886  0.3391304348  0.3013100437  0.3478260870  0.3144104803  0.2521739130  0.2966841187  3.4934497817  4.7039884186  0.3009815216  50            0.0753329420 
0.3362445415  0.3565217391  0.3187772926  0.3304347826  0.3362445415  0.3130434783  0.3668122271  0.2956521739  0.3490401396  6.9868995633  4.4163650036  0.3009815216  100           0.0718415213 
0.3777292576  0.3826086957  0.3427947598  0.4000000000  0.3668122271  0.3826086957  0.3799126638  0.3478260870  0.3438045375  10.480349345  4.2880810356  0.3831300735  150           0.0728997850 
0.4104803493  0.4086956522  0.3711790393  0.4521739130  0.3995633188  0.4173913043  0.3864628821  0.3478260870  0.3595113438  13.973799126  4.2269095516  0.3831300735  200           0.0720884848 
0.4410480349  0.4260869565  0.3777292576  0.4608695652  0.3930131004  0.4086956522  0.3951965066  0.3739130435  0.3734729494  17.467248908  4.1608498859  0.3831300735  250           0.0797842264 
0.5087336245  0.4782608696  0.4279475983  0.4608695652  0.4366812227  0.4869565217  0.4213973799  0.4000000000  0.4013961606  20.960698690  4.1301043701  0.3831300735  300           0.0699286175 
0.4781659389  0.5043478261  0.4366812227  0.4869565217  0.4432314410  0.4695652174  0.4279475983  0.4260869565  0.3961605585  24.454148471  4.0865405750  0.3831300735  350           0.0735773516 
0.5262008734  0.5304347826  0.4606986900  0.4956521739  0.4628820961  0.5043478261  0.4432314410  0.4869565217  0.4188481675  27.947598253  4.0419948435  0.3831300735  400           0.0734592009 
0.5720524017  0.5565217391  0.4890829694  0.4869565217  0.4825327511  0.5217391304  0.4737991266  0.4521739130  0.4589877836  31.441048034  4.0042966461  0.3831300735  450           0.0725993252 
0.5676855895  0.5826086957  0.4956331878  0.4956521739  0.4803493450  0.5391304348  0.4737991266  0.4608695652  0.4502617801  34.934497816  3.8970978928  0.3831300735  500           0.0762773180 
0.6506550218  0.6782608696  0.5414847162  0.5478260870  0.5262008734  0.6173913043  0.5240174672  0.4956521739  0.5759162304  38.427947598  3.7796406317  0.3831300735  550           0.0722471762 
0.7620087336  0.8086956522  0.6768558952  0.6608695652  0.6659388646  0.7217391304  0.6484716157  0.5826086957  0.6369982548  41.921397379  3.6435073280  0.3831300735  600           0.0828520966 
0.8034934498  0.8347826087  0.7576419214  0.7652173913  0.7620087336  0.8173913043  0.7379912664  0.7913043478  0.6230366492  45.414847161  3.4645883274  0.3831300735  650           0.0765969706 
0.8122270742  0.8521739130  0.7838427948  0.8000000000  0.7838427948  0.8434782609  0.7663755459  0.7739130435  0.6369982548  48.908296943  3.2837886333  0.3831300735  700           0.0763041782 
0.8296943231  0.8782608696  0.8122270742  0.8173913043  0.8034934498  0.8695652174  0.8078602620  0.8260869565  0.6928446771  52.401746724  3.1031896639  0.3831300735  750           0.0701722097 
0.8144104803  0.8695652174  0.8013100437  0.8086956522  0.7969432314  0.8782608696  0.7947598253  0.7913043478  0.6317626527  55.895196506  2.9702901077  0.3831300735  800           0.0713201284 
0.8165938865  0.8782608696  0.8122270742  0.8173913043  0.7947598253  0.8869565217  0.7947598253  0.7739130435  0.6247818499  59.388646288  2.8527553558  0.3831300735  850           0.0698064137 
0.8340611354  0.8956521739  0.8253275109  0.8173913043  0.7991266376  0.8782608696  0.8056768559  0.8086956522  0.6387434555  62.882096069  2.7013068247  0.3831300735  900           0.0794187021 
0.8296943231  0.9043478261  0.8253275109  0.8173913043  0.8100436681  0.8956521739  0.8100436681  0.8260869565  0.6614310646  66.375545851  2.6645520782  0.3831300735  950           0.0709541559 
0.8275109170  0.9043478261  0.8296943231  0.8260869565  0.8122270742  0.8869565217  0.8122270742  0.8347826087  0.6596858639  69.868995633  2.6028499031  0.3831300735  1000          0.0694202995 
0.8275109170  0.8782608696  0.8296943231  0.8347826087  0.8144104803  0.8782608696  0.8165938865  0.8521739130  0.6649214660  73.362445414  2.5683458662  0.3831300735  1050          0.0692827368 
0.8384279476  0.9130434783  0.8340611354  0.8347826087  0.8078602620  0.8869565217  0.8253275109  0.8173913043  0.6352530541  76.855895196  2.5361600876  0.3831300735  1100          0.0708656311 
0.8340611354  0.8956521739  0.8340611354  0.8260869565  0.8078602620  0.8869565217  0.8231441048  0.8347826087  0.6352530541  80.349344978  2.4813313818  0.3831300735  1150          0.0711850214 
0.8296943231  0.8869565217  0.8427947598  0.8347826087  0.8144104803  0.8782608696  0.8209606987  0.8608695652  0.6614310646  83.842794759  2.4482536602  0.3831300735  1200          0.0706315708 
0.8471615721  0.8956521739  0.8318777293  0.8608695652  0.8122270742  0.8956521739  0.8187772926  0.8521739130  0.5986038394  87.336244541  2.3628219891  0.3831300735  1250          0.0698985100 
0.8515283843  0.8956521739  0.8384279476  0.8521739130  0.8144104803  0.8956521739  0.8231441048  0.8434782609  0.6125654450  90.829694323  2.3230766439  0.3831300735  1300          0.0704468346 
0.8384279476  0.8956521739  0.8427947598  0.8434782609  0.8122270742  0.8782608696  0.8231441048  0.8695652174  0.6300174520  94.323144104  2.2691037130  0.3831300735  1350          0.0723573923 
0.8602620087  0.8956521739  0.8406113537  0.8608695652  0.8165938865  0.8956521739  0.8209606987  0.8434782609  0.5916230366  97.816593886  2.3238219810  0.3831300735  1400          0.0777775955 
0.8537117904  0.9043478261  0.8471615721  0.8695652174  0.8209606987  0.9130434783  0.8253275109  0.8260869565  0.5706806283  101.31004366  2.2875192571  0.3831300735  1450          0.0710735989 
0.8493449782  0.8869565217  0.8493449782  0.8608695652  0.8165938865  0.8782608696  0.8340611354  0.8782608696  0.6369982548  104.80349344  2.2582722998  0.3831300735  1500          0.0707957983 
0.8493449782  0.9043478261  0.8515283843  0.8695652174  0.8209606987  0.8869565217  0.8384279476  0.8782608696  0.6422338569  108.29694323  2.2653963470  0.3831300735  1550          0.0725833797 
0.8558951965  0.9043478261  0.8537117904  0.8695652174  0.8231441048  0.9130434783  0.8296943231  0.8434782609  0.5741710297  111.79039301  2.2192399096  0.3831300735  1600          0.0732329988 
0.8624454148  0.8956521739  0.8537117904  0.8695652174  0.8209606987  0.8956521739  0.8427947598  0.8782608696  0.6369982548  115.28384279  2.1750541759  0.3831300735  1650          0.0751025963 
0.8537117904  0.9043478261  0.8537117904  0.8608695652  0.8187772926  0.8869565217  0.8384279476  0.8782608696  0.6282722513  118.77729257  2.1370041394  0.3831300735  1700          0.0849110603 
0.8646288210  0.8782608696  0.8602620087  0.8695652174  0.8296943231  0.9043478261  0.8449781659  0.8608695652  0.6038394415  122.27074235  2.1867640519  0.3831300735  1750          0.0719415045 
0.8624454148  0.8782608696  0.8471615721  0.8608695652  0.8209606987  0.9043478261  0.8449781659  0.8869565217  0.6212914485  125.76419213  2.1118996692  0.3831300735  1800          0.0725376320 
0.8602620087  0.8869565217  0.8558951965  0.8608695652  0.8275109170  0.8956521739  0.8493449782  0.8782608696  0.6282722513  129.25764192  2.0665149331  0.3831300735  1850          0.0796656466 
0.8668122271  0.8869565217  0.8602620087  0.8869565217  0.8275109170  0.8869565217  0.8427947598  0.8782608696  0.5986038394  132.75109170  2.0656815171  0.3831300735  1900          0.0707700682 
0.8580786026  0.9130434783  0.8580786026  0.8695652174  0.8318777293  0.9130434783  0.8340611354  0.8521739130  0.5706806283  136.24454148  2.0062062192  0.3831300735  1950          0.0803622818 
0.8689956332  0.9043478261  0.8689956332  0.8782608696  0.8362445415  0.9130434783  0.8406113537  0.8782608696  0.5689354276  139.73799126  2.0311572433  0.3831300735  2000          0.0777903223 
0.8646288210  0.9130434783  0.8646288210  0.8782608696  0.8362445415  0.9130434783  0.8362445415  0.8782608696  0.5968586387  143.23144104  1.9905903339  0.3831300735  2050          0.0752285051 
0.8864628821  0.9043478261  0.8908296943  0.8869565217  0.8493449782  0.9043478261  0.8515283843  0.8782608696  0.5689354276  146.72489082  1.9927811313  0.3831300735  2100          0.0738133717 
0.8864628821  0.8956521739  0.8930131004  0.8869565217  0.8493449782  0.9043478261  0.8515283843  0.8782608696  0.5567190227  150.21834061  1.9361035538  0.3831300735  2150          0.0739237309 
0.8951965066  0.8869565217  0.8864628821  0.8782608696  0.8537117904  0.9043478261  0.8711790393  0.8956521739  0.6143106457  153.71179039  1.9715772009  0.3831300735  2200          0.0759176493 
0.8930131004  0.9217391304  0.8886462882  0.8869565217  0.8471615721  0.9130434783  0.8558951965  0.8869565217  0.5881326353  157.20524017  1.8977373862  0.3831300735  2250          0.0742405558 
0.8930131004  0.9043478261  0.8951965066  0.8869565217  0.8558951965  0.9130434783  0.8624454148  0.8869565217  0.5724258290  160.69868995  1.9243682075  0.3831300735  2300          0.0733053064 
0.8930131004  0.9043478261  0.8908296943  0.8869565217  0.8471615721  0.9043478261  0.8580786026  0.8869565217  0.5776614311  164.19213973  1.9310255051  0.3831300735  2350          0.0763898420 
0.8973799127  0.9043478261  0.8973799127  0.8869565217  0.8537117904  0.9130434783  0.8580786026  0.8695652174  0.5671902269  167.68558951  1.8510623431  0.3831300735  2400          0.0764818478 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2255, in update
    loss_main = self.ce_loss(pred_a, y_subset_a)  # 对训练数据，计算ce_loss eq.1
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2247, in update
    for i in meta_train_idx:
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2272, in update
    meta_train_loss_main += 10*penalty   # 100 for coral
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1826086957  0.1877729258  0.1913043478  0.1834061135  0.1826086957  0.1867364747  0.0000000000  6.4312663078  0.1124811172  0             0.4052627087 
0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1832460733  3.4934497817  34.533833322  0.2772035599  50            0.0660090065 
0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1832460733  6.9868995633  107.39974929  0.2772035599  100           0.0653828001 
0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1832460733  10.480349345  116.28946380  0.2772035599  150           0.0653666830 
0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1834061135  0.1826086957  0.1832460733  13.973799126  115.75443618  0.2772035599  200           0.0668372917 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2276, in update
    meta_train_loss_main.backward(retain_graph=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1952266693  0.1124811172  0             0.3715240955 
0.2816593886  0.2869565217  0.2467248908  0.2260869565  0.2314410480  0.2347826087  0.2314410480  0.2260869565  0.2268760908  3.4934497817  4.8061595631  0.2772035599  50            0.0677644396 
0.3799126638  0.3913043478  0.3187772926  0.3130434783  0.3340611354  0.3217391304  0.3013100437  0.2521739130  0.2897033159  6.9868995633  4.4345209885  0.2772035599  100           0.0666431808 
0.3864628821  0.3478260870  0.3427947598  0.3217391304  0.3493449782  0.3478260870  0.3275109170  0.3043478261  0.3141361257  10.480349345  4.4844650364  0.2772789001  150           0.0663177013 
0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2722513089  13.973799126  9.3863512325  0.3593668938  200           0.0660584784 
0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2722513089  17.467248908  20.595477371  0.3593668938  250           0.0655981112 
0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2722513089  20.960698690  21.628564910  0.3593668938  300           0.0663529730 
0.4126637555  0.3652173913  0.3493449782  0.2956521739  0.3362445415  0.3043478261  0.3165938865  0.2782608696  0.2862129145  24.454148471  24.188317451  0.3593668938  350           0.0659652090 
0.5043668122  0.5043478261  0.4825327511  0.4347826087  0.4694323144  0.4695652174  0.4759825328  0.4521739130  0.3490401396  27.947598253  37.804091682  0.3593668938  400           0.0663885880 
0.4956331878  0.4869565217  0.4847161572  0.4260869565  0.4563318777  0.4000000000  0.4388646288  0.4086956522  0.3560209424  31.441048034  43.349610748  0.3593668938  450           0.0679961395 
0.5218340611  0.4956521739  0.5131004367  0.4434782609  0.4912663755  0.4782608696  0.4847161572  0.4347826087  0.3821989529  34.934497816  42.430345077  0.3593668938  500           0.0659365082 
0.5327510917  0.5130434783  0.5174672489  0.4695652174  0.5021834061  0.4782608696  0.4956331878  0.4347826087  0.3891797557  38.427947598  45.322404937  0.3593668938  550           0.0654821396 
0.5327510917  0.5130434783  0.5218340611  0.4521739130  0.5021834061  0.5130434783  0.4956331878  0.4347826087  0.3944153578  41.921397379  45.361175689  0.3593668938  600           0.0679800177 
0.5502183406  0.5130434783  0.5371179039  0.4695652174  0.5305676856  0.5391304348  0.5283842795  0.4521739130  0.4520069808  45.414847161  44.819658126  0.3593668938  650           0.0662400103 
0.5458515284  0.5043478261  0.5283842795  0.4521739130  0.5021834061  0.4956521739  0.5065502183  0.4347826087  0.4223385689  48.908296943  44.677803115  0.3593668938  700           0.0674638367 
0.5327510917  0.5217391304  0.5152838428  0.4695652174  0.5087336245  0.5043478261  0.5065502183  0.4347826087  0.3804537522  52.401746724  44.376077194  0.3593668938  750           0.0651339197 
0.5393013100  0.5130434783  0.5240174672  0.4956521739  0.5087336245  0.5043478261  0.5087336245  0.4434782609  0.4031413613  55.895196506  47.322024307  0.3593668938  800           0.0654647636 
0.5393013100  0.5043478261  0.5327510917  0.4869565217  0.5262008734  0.5217391304  0.5240174672  0.4695652174  0.4397905759  59.388646288  44.701351089  0.3593668938  850           0.0658974600 
0.5283842795  0.5043478261  0.5174672489  0.4782608696  0.5218340611  0.5217391304  0.5218340611  0.4695652174  0.3856893543  62.882096069  46.827750167  0.3593668938  900           0.0679747963 
Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7f1363ace950>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/_weakrefset.py", line 38, in _remove
    def _remove(item, selfref=ref(self)):
KeyboardInterrupt: 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 448147) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1952266693  0.1124811172  0             0.3936429024 
0.4737991266  0.4956521739  0.3995633188  0.3478260870  0.4082969432  0.4434782609  0.3951965066  0.3565217391  0.3804537522  3.4934497817  4.4232477951  0.2772035599  50            0.0655380297 
0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2722513089  6.9868995633  6.9461982822  0.2772612572  100           0.0644238853 
0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2729257642  0.2695652174  0.2722513089  10.480349345  18.190723037  0.2772612572  150           0.0642276621 
0.5000000000  0.4869565217  0.4585152838  0.4000000000  0.4519650655  0.4434782609  0.4388646288  0.4260869565  0.3455497382  13.973799126  23.022530479  0.2792515755  200           0.0648007393 
0.5480349345  0.4869565217  0.5131004367  0.4608695652  0.5174672489  0.5304347826  0.5283842795  0.4782608696  0.4345549738  17.467248908  43.974252014  0.2793092728  250           0.0652792072 
0.6462882096  0.5826086957  0.5589519651  0.4695652174  0.5742358079  0.5043478261  0.5938864629  0.5130434783  0.3734729494  20.960698690  41.841015548  0.2793092728  300           0.0670877886 
0.7663755459  0.7043478261  0.6877729258  0.6260869565  0.6746724891  0.6782608696  0.6921397380  0.6434782609  0.4502617801  24.454148471  46.190580978  0.2793092728  350           0.0677858496 
0.7445414847  0.7130434783  0.7205240175  0.7043478261  0.6921397380  0.7304347826  0.7270742358  0.6869565217  0.4834205934  27.947598253  54.520801696  0.2793092728  400           0.0650499153 
0.7991266376  0.7391304348  0.7205240175  0.6521739130  0.6943231441  0.6956521739  0.7030567686  0.6782608696  0.4310645724  31.441048034  58.103533172  0.2793092728  450           0.0673966551 
0.7620087336  0.7391304348  0.7401746725  0.6434782609  0.7074235808  0.7217391304  0.7183406114  0.6782608696  0.4415357766  34.934497816  62.113971633  0.2793092728  500           0.0687791014 
0.7816593886  0.7391304348  0.7620087336  0.6782608696  0.7248908297  0.7217391304  0.7336244541  0.6347826087  0.4205933682  38.427947598  69.373021316  0.2793092728  550           0.0691585922 
0.7816593886  0.7391304348  0.7751091703  0.6956521739  0.7467248908  0.7130434783  0.7467248908  0.6695652174  0.3926701571  41.921397379  72.414684295  0.2793092728  600           0.0694438219 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2272, in update
    meta_train_loss_main += 1*penalty   # 100 for coral
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1877729258  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  4.6390085220  0.1124811172  0             9.9211435318 
0.4017467249  0.3739130435  0.3515283843  0.3391304348  0.4170305677  0.4173913043  0.4148471616  0.3739130435  0.3490401396  3.4934497817  4.1750829697  0.2772035599  50            0.0656526232 
0.5458515284  0.5391304348  0.4650655022  0.4434782609  0.4737991266  0.4869565217  0.4628820961  0.3913043478  0.4223385689  6.9868995633  3.9333728075  0.2772035599  100           0.0653242445 
0.7576419214  0.6869565217  0.6462882096  0.5826086957  0.6659388646  0.6521739130  0.6331877729  0.5913043478  0.5898778360  10.480349345  3.7037589598  0.2772035599  150           0.0645438910 
0.7991266376  0.8086956522  0.7336244541  0.7043478261  0.7423580786  0.7565217391  0.7248908297  0.7565217391  0.6195462478  13.973799126  3.6173858261  0.2772412300  200           0.0647682190 
0.8449781659  0.8260869565  0.7969432314  0.8260869565  0.7925764192  0.8347826087  0.7903930131  0.8086956522  0.6143106457  17.467248908  3.9581479359  0.2793831825  250           0.0652392149 
0.8580786026  0.8956521739  0.8362445415  0.8521739130  0.8231441048  0.8521739130  0.8318777293  0.8521739130  0.6387434555  20.960698690  4.3171767998  0.2793831825  300           0.0645293903 
0.8755458515  0.8956521739  0.8427947598  0.8521739130  0.8384279476  0.8869565217  0.8340611354  0.8695652174  0.6125654450  24.454148471  4.6658413315  0.2793831825  350           0.0651496267 
0.8646288210  0.8869565217  0.8755458515  0.8782608696  0.8427947598  0.8782608696  0.8406113537  0.8608695652  0.6020942408  27.947598253  4.8319782162  0.2793831825  400           0.0675136375 
0.9126637555  0.9304347826  0.8995633188  0.8434782609  0.8711790393  0.9130434783  0.8668122271  0.8695652174  0.5706806283  31.441048034  4.7220829296  0.2793831825  450           0.0656706762 
0.9257641921  0.9304347826  0.9061135371  0.8608695652  0.8864628821  0.8956521739  0.8864628821  0.8956521739  0.5794066318  34.934497816  4.6636991501  0.2793831825  500           0.0662037516 
0.9454148472  0.9217391304  0.9279475983  0.8956521739  0.9104803493  0.9130434783  0.9213973799  0.8956521739  0.5741710297  38.427947598  4.6870882225  0.2793831825  550           0.0659103012 
0.9519650655  0.9304347826  0.9585152838  0.9217391304  0.9410480349  0.9130434783  0.9563318777  0.9043478261  0.5427574171  41.921397379  4.5716030407  0.3593091965  600           0.0662150335 
0.9497816594  0.9304347826  0.9519650655  0.9130434783  0.9192139738  0.8956521739  0.9454148472  0.9043478261  0.5410122164  45.414847161  4.5512843800  0.3593091965  650           0.0656439734 
0.9694323144  0.9391304348  0.9454148472  0.8608695652  0.9323144105  0.9217391304  0.9366812227  0.9043478261  0.5497382199  48.908296943  4.5866651535  0.3593091965  700           0.0679133797 
0.9803493450  0.9478260870  0.9737991266  0.9130434783  0.9650655022  0.9391304348  0.9694323144  0.9304347826  0.5654450262  52.401746724  4.5965314150  0.3593091965  750           0.0657240105 
0.9825327511  0.9652173913  0.9847161572  0.9130434783  0.9737991266  0.9391304348  0.9650655022  0.9304347826  0.5253054101  55.895196506  4.5951198196  0.3593091965  800           0.0664158154 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 494635) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/logging/__init__.py", line 1954, in shutdown

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2252, in update
    feat_a = self.featurizer(x_subset_a)  # 提取特征
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2252, in update
    feat_a = self.featurizer(x_subset_a)  # 提取特征
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2252, in update
    feat_a = self.featurizer(x_subset_a)  # 提取特征
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1877729258  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  4.5774908066  0.1362590790  0             0.4442057610 
0.4061135371  0.3826086957  0.3602620087  0.3478260870  0.4148471616  0.4260869565  0.4104803493  0.3565217391  0.3455497382  3.4934497817  4.1735537672  0.3009815216  50            0.0732152414 
0.5524017467  0.5217391304  0.4759825328  0.4347826087  0.4803493450  0.5043478261  0.4672489083  0.4000000000  0.4310645724  6.9868995633  3.9131456280  0.3009815216  100           0.0748249578 
0.7685589520  0.6956521739  0.6353711790  0.5826086957  0.6768558952  0.6608695652  0.6397379913  0.5913043478  0.5828970332  10.480349345  3.5141521883  0.3009815216  150           0.0741335726 
0.7882096070  0.7826086957  0.7314410480  0.7043478261  0.7445414847  0.7565217391  0.7183406114  0.7565217391  0.6212914485  13.973799126  2.9284327936  0.3009815216  200           0.0728539610 
0.8340611354  0.8347826087  0.7925764192  0.8000000000  0.7860262009  0.8086956522  0.7882096070  0.8173913043  0.6055846422  17.467248908  2.4506813097  0.3009815216  250           0.0733413601 
0.8558951965  0.8956521739  0.8406113537  0.8521739130  0.8165938865  0.8434782609  0.8231441048  0.8521739130  0.6422338569  20.960698690  2.0165901661  0.3009815216  300           0.0766695738 
0.8668122271  0.8956521739  0.8427947598  0.8608695652  0.8340611354  0.8782608696  0.8275109170  0.8608695652  0.6335078534  24.454148471  1.7615490007  0.3011007309  350           0.0729218483 
0.8602620087  0.8869565217  0.8668122271  0.8782608696  0.8318777293  0.8782608696  0.8406113537  0.8695652174  0.6038394415  27.947598253  1.5200469780  0.3011007309  400           0.0731043482 
0.8908296943  0.9217391304  0.8777292576  0.8521739130  0.8580786026  0.9043478261  0.8471615721  0.8695652174  0.5602094241  31.441048034  1.3634596133  0.3012366295  450           0.0719023561 
0.9192139738  0.9217391304  0.9082969432  0.8782608696  0.8886462882  0.8956521739  0.8930131004  0.8956521739  0.5514834206  34.934497816  1.1842953360  0.3012366295  500           0.0723975182 
0.9344978166  0.9217391304  0.9213973799  0.8956521739  0.9104803493  0.9130434783  0.9170305677  0.8956521739  0.5689354276  38.427947598  1.0497158051  0.3012366295  550           0.0734091711 
0.9497816594  0.9565217391  0.9563318777  0.9130434783  0.9410480349  0.9391304348  0.9475982533  0.9043478261  0.5357766143  41.921397379  0.9398645592  0.3012366295  600           0.0753138399 
0.9585152838  0.9217391304  0.9519650655  0.9217391304  0.9279475983  0.9130434783  0.9366812227  0.9043478261  0.5322862129  45.414847161  0.8720805371  0.3012366295  650           0.0767400932 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 317, in _exit_function
    for p in active_children():
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 523891) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1877729258  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  4.6081075668  0.1124811172  0             0.3906612396 
0.4082969432  0.3826086957  0.3580786026  0.3478260870  0.4126637555  0.4173913043  0.4082969432  0.3565217391  0.3507853403  3.4934497817  4.1738847780  0.2772035599  50            0.0658923006 
0.5502183406  0.5478260870  0.4759825328  0.4434782609  0.4868995633  0.5043478261  0.4650655022  0.4000000000  0.4328097731  6.9868995633  3.9214051104  0.2772035599  100           0.0654080200 
0.7532751092  0.6956521739  0.6397379913  0.5739130435  0.6659388646  0.6608695652  0.6375545852  0.5826086957  0.5811518325  10.480349345  3.6037190723  0.2772626877  150           0.0652047968 
0.7947598253  0.7826086957  0.7314410480  0.7043478261  0.7379912664  0.7478260870  0.7183406114  0.7565217391  0.6160558464  13.973799126  3.2766273546  0.2772626877  200           0.0664025927 
0.8406113537  0.8260869565  0.7991266376  0.8173913043  0.7882096070  0.8260869565  0.7903930131  0.8086956522  0.6125654450  17.467248908  3.2329838467  0.2772626877  250           0.0664848995 
0.8558951965  0.8956521739  0.8362445415  0.8521739130  0.8187772926  0.8434782609  0.8340611354  0.8434782609  0.6422338569  20.960698690  3.2538705397  0.2772626877  300           0.0663022041 
0.8646288210  0.8956521739  0.8406113537  0.8608695652  0.8318777293  0.8869565217  0.8340611354  0.8608695652  0.6195462478  24.454148471  3.3901999569  0.2772626877  350           0.0668494511 
0.8624454148  0.8956521739  0.8755458515  0.8695652174  0.8406113537  0.8782608696  0.8384279476  0.8608695652  0.6003490401  27.947598253  3.4562596989  0.2772626877  400           0.0655897903 
0.9039301310  0.9391304348  0.8973799127  0.8434782609  0.8646288210  0.9043478261  0.8602620087  0.8695652174  0.5759162304  31.441048034  3.4265645456  0.2772626877  450           0.0664075375 
0.9279475983  0.9217391304  0.9039301310  0.8695652174  0.8908296943  0.8956521739  0.8930131004  0.8956521739  0.5654450262  34.934497816  3.3375875473  0.2772626877  500           0.0660352325 
0.9475982533  0.9217391304  0.9279475983  0.8956521739  0.9082969432  0.9130434783  0.9213973799  0.8956521739  0.5724258290  38.427947598  3.2999750328  0.3593091965  550           0.0676689863 
0.9541484716  0.9391304348  0.9628820961  0.9130434783  0.9432314410  0.9217391304  0.9541484716  0.9043478261  0.5462478185  41.921397379  3.2024194193  0.3593091965  600           0.0659548235 
0.9585152838  0.9304347826  0.9541484716  0.9043478261  0.9279475983  0.8956521739  0.9432314410  0.9043478261  0.5305410122  45.414847161  3.1740421629  0.3593091965  650           0.0664087009 
0.9716157205  0.9391304348  0.9519650655  0.8695652174  0.9410480349  0.9391304348  0.9388646288  0.8956521739  0.5427574171  48.908296943  3.1648389912  0.3593091965  700           0.0661920881 
0.9759825328  0.9652173913  0.9803493450  0.9130434783  0.9650655022  0.9217391304  0.9759825328  0.9304347826  0.5689354276  52.401746724  3.1413687897  0.3593091965  750           0.0644824409 
0.9825327511  0.9739130435  0.9847161572  0.9304347826  0.9803493450  0.9304347826  0.9672489083  0.9217391304  0.5305410122  55.895196506  3.1323666096  0.3593091965  800           0.0666544962 
0.9847161572  0.9739130435  0.9847161572  0.8956521739  0.9737991266  0.9391304348  0.9672489083  0.9304347826  0.5357766143  59.388646288  3.1364402580  0.3593091965  850           0.0650795650 
0.9803493450  0.9565217391  0.9912663755  0.9391304348  0.9912663755  0.9391304348  0.9847161572  0.9217391304  0.5445026178  62.882096069  3.0865147638  0.3593091965  900           0.0653730583 
0.9868995633  0.9739130435  0.9890829694  0.9391304348  0.9868995633  0.9478260870  0.9803493450  0.9391304348  0.5497382199  66.375545851  3.0500835991  0.3593091965  950           0.0650075626 
0.9890829694  0.9739130435  0.9912663755  0.9478260870  0.9934497817  0.9478260870  0.9759825328  0.9217391304  0.5392670157  69.868995633  3.0064960241  0.3593091965  1000          0.0656543446 
0.9890829694  0.9739130435  0.9912663755  0.9478260870  0.9912663755  0.9478260870  0.9825327511  0.9304347826  0.5357766143  73.362445414  3.0020415020  0.3593091965  1050          0.0653832436 
0.9890829694  0.9739130435  0.9934497817  0.9391304348  0.9912663755  0.9391304348  0.9781659389  0.9217391304  0.5479930192  76.855895196  3.0120322371  0.3593091965  1100          0.0650908756 
0.9890829694  0.9739130435  1.0000000000  0.9739130435  0.9934497817  0.9478260870  0.9868995633  0.9304347826  0.5270506108  80.349344978  2.9749191713  0.3593091965  1150          0.0656105423 
0.9890829694  0.9478260870  0.9978165939  0.9565217391  0.9978165939  0.9652173913  0.9912663755  0.9391304348  0.5602094241  83.842794759  2.9585262537  0.3593091965  1200          0.0663426876 
0.9934497817  0.9739130435  1.0000000000  0.9652173913  0.9912663755  0.9478260870  0.9781659389  0.9478260870  0.5287958115  87.336244541  2.9423200941  0.3593091965  1250          0.0658133507 
0.9912663755  0.9739130435  1.0000000000  0.9739130435  0.9956331878  0.9652173913  0.9912663755  0.9217391304  0.5445026178  90.829694323  2.9417634583  0.3593091965  1300          0.0660619688 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
KeyboardInterrupt
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 582685) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2.5e-05
	lr_omega: 0.0005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1877729258  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  4.6699094772  0.1124811172  0             0.3740863800 
0.4126637555  0.3826086957  0.3537117904  0.3391304348  0.4148471616  0.4173913043  0.4213973799  0.3478260870  0.3525305410  3.4934497817  4.1776672602  0.2772035599  50            0.0653814077 
0.5414847162  0.5217391304  0.4606986900  0.4434782609  0.4650655022  0.4869565217  0.4606986900  0.3913043478  0.4031413613  6.9868995633  3.9477983570  0.2772035599  100           0.0659942007 
0.7445414847  0.6956521739  0.6331877729  0.5565217391  0.6615720524  0.6521739130  0.6222707424  0.5826086957  0.5828970332  10.480349345  3.8083799744  0.2772250175  150           0.0657719946 
0.8013100437  0.8086956522  0.7358078603  0.7043478261  0.7467248908  0.7652173913  0.7292576419  0.7565217391  0.6230366492  13.973799126  3.9633176565  0.2772412300  200           0.0645716095 
0.8449781659  0.8434782609  0.7991266376  0.8260869565  0.7969432314  0.8347826087  0.7925764192  0.8086956522  0.6265270506  17.467248908  4.6543482399  0.2772789001  250           0.0667519569 
0.8602620087  0.8956521739  0.8384279476  0.8434782609  0.8296943231  0.8608695652  0.8384279476  0.8521739130  0.6317626527  20.960698690  5.2524881935  0.2772789001  300           0.0664273596 
0.8755458515  0.9043478261  0.8406113537  0.8521739130  0.8384279476  0.8782608696  0.8362445415  0.8695652174  0.6178010471  24.454148471  5.6928831673  0.2772789001  350           0.0667311192 
0.8668122271  0.8869565217  0.8733624454  0.8782608696  0.8449781659  0.8782608696  0.8449781659  0.8608695652  0.5968586387  27.947598253  5.8924061394  0.2772789001  400           0.0660725164 
0.9170305677  0.9304347826  0.8973799127  0.8434782609  0.8755458515  0.9130434783  0.8711790393  0.8782608696  0.5759162304  31.441048034  5.7010507298  0.3593091965  450           0.0665035725 
0.9192139738  0.9304347826  0.9061135371  0.8608695652  0.8799126638  0.8956521739  0.8820960699  0.8956521739  0.5881326353  34.934497816  5.7047026348  0.3593091965  500           0.0638479042 
0.9432314410  0.9217391304  0.9301310044  0.8956521739  0.9126637555  0.9130434783  0.9235807860  0.8956521739  0.5776614311  38.427947598  5.7975888538  0.3593091965  550           0.0649324989 
0.9541484716  0.9304347826  0.9475982533  0.9217391304  0.9410480349  0.9043478261  0.9497816594  0.8956521739  0.5479930192  41.921397379  5.6448087120  0.3593091965  600           0.0664979982 
0.9497816594  0.9304347826  0.9410480349  0.9130434783  0.9104803493  0.8956521739  0.9388646288  0.8956521739  0.5462478185  45.414847161  5.6533185768  0.3593091965  650           0.0656681967 
0.9650655022  0.9478260870  0.9410480349  0.8608695652  0.9235807860  0.9304347826  0.9279475983  0.9043478261  0.5549738220  48.908296943  5.7231393623  0.3593091965  700           0.0665068531 
0.9781659389  0.9391304348  0.9716157205  0.9130434783  0.9606986900  0.9217391304  0.9672489083  0.9304347826  0.5636998255  52.401746724  5.7838400078  0.3593091965  750           0.0664226437 
0.9803493450  0.9739130435  0.9825327511  0.8956521739  0.9650655022  0.9391304348  0.9628820961  0.9391304348  0.5218150087  55.895196506  5.8309590435  0.3593091965  800           0.0657327080 
0.9847161572  0.9652173913  0.9825327511  0.9043478261  0.9694323144  0.9391304348  0.9737991266  0.9304347826  0.5410122164  59.388646288  5.9050809002  0.3593091965  850           0.0655365419 
0.9825327511  0.9652173913  0.9912663755  0.9478260870  0.9847161572  0.9391304348  0.9847161572  0.9217391304  0.5287958115  62.882096069  5.8944084358  0.3593091965  900           0.0648911572 
0.9868995633  0.9652173913  0.9868995633  0.9217391304  0.9781659389  0.9391304348  0.9781659389  0.9217391304  0.5636998255  66.375545851  5.8235961342  0.3593091965  950           0.0650719500 
0.9890829694  0.9739130435  0.9890829694  0.9217391304  0.9890829694  0.9304347826  0.9781659389  0.9304347826  0.5375218150  69.868995633  5.6887515640  0.3593091965  1000          0.0653576136 
0.9890829694  0.9739130435  0.9912663755  0.9391304348  0.9890829694  0.9478260870  0.9825327511  0.9217391304  0.5410122164  73.362445414  5.7752042198  0.3593091965  1050          0.0654129553 
0.9890829694  0.9565217391  0.9890829694  0.9391304348  0.9847161572  0.9391304348  0.9781659389  0.9130434783  0.5549738220  76.855895196  5.8547895432  0.3593091965  1100          0.0654580927 
0.9912663755  0.9739130435  0.9956331878  0.9478260870  0.9912663755  0.9478260870  0.9825327511  0.9478260870  0.5183246073  80.349344978  5.7796034336  0.3593091965  1150          0.0650515556 
0.9868995633  0.9478260870  0.9956331878  0.9565217391  0.9956331878  0.9652173913  0.9890829694  0.9043478261  0.5567190227  83.842794759  5.8126564884  0.3593091965  1200          0.0659497881 
0.9912663755  0.9826086957  0.9956331878  0.9391304348  0.9912663755  0.9565217391  0.9803493450  0.9478260870  0.5165794066  87.336244541  5.8046057796  0.3593091965  1250          0.0657341909 
0.9912663755  0.9739130435  0.9978165939  0.9652173913  0.9934497817  0.9478260870  0.9890829694  0.9391304348  0.5357766143  90.829694323  5.7696280575  0.3593091965  1300          0.0660588884 
0.9912663755  0.9739130435  0.9956331878  0.9478260870  0.9912663755  0.9478260870  0.9890829694  0.9304347826  0.5584642234  94.323144104  5.7018006897  0.3593091965  1350          0.0659868145 
0.9912663755  0.9652173913  1.0000000000  0.9565217391  0.9978165939  0.9478260870  0.9890829694  0.9217391304  0.5462478185  97.816593886  5.6966394711  0.3593091965  1400          0.0659709024 
0.9956331878  0.9739130435  0.9956331878  0.9391304348  0.9825327511  0.9565217391  0.9803493450  0.9478260870  0.5165794066  101.31004366  5.7727995491  0.3593091965  1450          0.0658505726 
0.9956331878  0.9826086957  1.0000000000  0.9826086957  0.9956331878  0.9565217391  0.9912663755  0.9478260870  0.5445026178  104.80349344  5.6429092598  0.3593091965  1500          0.0650460339 
0.9978165939  0.9913043478  1.0000000000  0.9739130435  0.9956331878  0.9652173913  0.9912663755  0.9478260870  0.5375218150  108.29694323  5.8221077728  0.3593468666  1550          0.0669610119 
0.9978165939  1.0000000000  1.0000000000  0.9739130435  0.9934497817  0.9652173913  0.9890829694  0.9478260870  0.4938917976  111.79039301  5.8150263119  0.3593468666  1600          0.0653752899 
0.9956331878  0.9913043478  1.0000000000  0.9652173913  0.9934497817  0.9652173913  0.9956331878  0.9478260870  0.5532286213  115.28384279  5.7685130215  0.3593468666  1650          0.0670156336 
0.9956331878  0.9739130435  1.0000000000  0.9739130435  1.0000000000  0.9652173913  0.9956331878  0.9565217391  0.5497382199  118.77729257  5.6916835403  0.3593468666  1700          0.0678375196 
0.9934497817  0.9652173913  1.0000000000  0.9739130435  1.0000000000  0.9739130435  0.9934497817  0.9652173913  0.5636998255  122.27074235  5.6171790123  0.3593468666  1750          0.0776981449 
0.9978165939  0.9826086957  1.0000000000  0.9652173913  1.0000000000  0.9652173913  0.9978165939  0.9565217391  0.5427574171  125.76419213  5.7492271519  0.3593468666  1800          0.0751474714 
0.9978165939  0.9739130435  1.0000000000  0.9739130435  1.0000000000  0.9652173913  0.9978165939  0.9565217391  0.5514834206  129.25764192  5.8156297493  0.3593468666  1850          0.0676387024 
0.9978165939  0.9913043478  1.0000000000  0.9739130435  1.0000000000  0.9652173913  1.0000000000  0.9565217391  0.5445026178  132.75109170  5.8291094208  0.3593468666  1900          0.0709881401 
1.0000000000  1.0000000000  1.0000000000  0.9652173913  0.9934497817  0.9652173913  0.9912663755  0.9565217391  0.5043630017  136.24454148  5.7722020912  0.3593468666  1950          0.0817814636 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 5e-05
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.4447207451 
0.2838427948  0.2869565217  0.2838427948  0.3304347826  0.2969432314  0.3565217391  0.3253275109  0.2347826087  0.2914485166  3.4934497817  4.7053698158  0.3009815216  50            0.0777136517 
0.3340611354  0.3478260870  0.3231441048  0.3565217391  0.3384279476  0.3391304348  0.3689956332  0.3130434783  0.3420593368  6.9868995633  4.4278572369  0.3009815216  100           0.0808743000 
0.3973799127  0.4000000000  0.3558951965  0.4086956522  0.3558951965  0.4086956522  0.3973799127  0.3478260870  0.3734729494  10.480349345  4.3196597672  0.3010568619  150           0.0745553398 
0.4497816594  0.4608695652  0.3777292576  0.4173913043  0.4213973799  0.4608695652  0.4170305677  0.3826086957  0.3874345550  13.973799126  4.2810993481  0.3010568619  200           0.0768194246 
0.5000000000  0.5043478261  0.4279475983  0.4521739130  0.4301310044  0.4608695652  0.4432314410  0.3913043478  0.4013961606  17.467248908  4.2121488190  0.3010568619  250           0.0751518583 
0.5720524017  0.5652173913  0.4628820961  0.4782608696  0.4650655022  0.4869565217  0.4847161572  0.4347826087  0.4101221640  20.960698690  4.1956702614  0.3010568619  300           0.0767274714 
0.5851528384  0.5826086957  0.5000000000  0.4869565217  0.5000000000  0.5217391304  0.4606986900  0.4434782609  0.4258289703  24.454148471  4.1681665373  0.3010568619  350           0.0752001238 
0.6048034934  0.6260869565  0.5152838428  0.5217391304  0.5305676856  0.5130434783  0.4737991266  0.4956521739  0.4345549738  27.947598253  4.1057918310  0.3010568619  400           0.0774003077 
0.6550218341  0.6260869565  0.5480349345  0.6000000000  0.5480349345  0.5478260870  0.5218340611  0.4956521739  0.5113438045  31.441048034  4.0750762749  0.3010568619  450           0.0754199648 
0.6288209607  0.6000000000  0.5196506550  0.5739130435  0.5371179039  0.5565217391  0.5065502183  0.4782608696  0.4712041885  34.934497816  3.9536493587  0.3010568619  500           0.0756044102 
0.7314410480  0.6956521739  0.6222707424  0.6086956522  0.6375545852  0.6608695652  0.5938864629  0.5565217391  0.5759162304  38.427947598  3.8388701296  0.3010568619  550           0.0777950811 
0.7947598253  0.8000000000  0.7183406114  0.7217391304  0.7379912664  0.7565217391  0.6812227074  0.6695652174  0.5863874346  41.921397379  3.7512631226  0.3010568619  600           0.0763355350 
0.7882096070  0.7826086957  0.7401746725  0.7304347826  0.7358078603  0.7826086957  0.6943231441  0.7043478261  0.5636998255  45.414847161  3.5982607603  0.3010568619  650           0.0810099506 
0.8122270742  0.8173913043  0.7489082969  0.8000000000  0.7620087336  0.8173913043  0.7270742358  0.7304347826  0.6282722513  48.908296943  3.4863505220  0.3010568619  700           0.0773827171 
0.8231441048  0.8434782609  0.7903930131  0.8086956522  0.7882096070  0.8521739130  0.7663755459  0.7913043478  0.6631762653  52.401746724  3.3022352409  0.3010568619  750           0.0757850981 
0.8187772926  0.8695652174  0.7860262009  0.8173913043  0.7903930131  0.8869565217  0.7641921397  0.7739130435  0.6335078534  55.895196506  3.2297544813  0.3010568619  800           0.0730867529 
0.8187772926  0.8608695652  0.7991266376  0.8260869565  0.7903930131  0.8956521739  0.7860262009  0.7826086957  0.6265270506  59.388646288  3.1201817083  0.3010568619  850           0.0727041531 
0.8384279476  0.8956521739  0.8187772926  0.8347826087  0.8034934498  0.8956521739  0.7947598253  0.8000000000  0.6439790576  62.882096069  3.0016014719  0.3010568619  900           0.0730696726 
0.8471615721  0.8869565217  0.8318777293  0.8434782609  0.8078602620  0.8869565217  0.8187772926  0.8086956522  0.6474694590  66.375545851  2.9819966221  0.3010568619  950           0.0742277527 
0.8362445415  0.8782608696  0.8296943231  0.8434782609  0.8078602620  0.8869565217  0.8209606987  0.8173913043  0.6544502618  69.868995633  2.9196387053  0.3831291199  1000          0.0730970621 
0.8384279476  0.8869565217  0.8253275109  0.8521739130  0.8078602620  0.8782608696  0.8275109170  0.8434782609  0.6666666667  73.362445414  2.8825470066  0.3831291199  1050          0.0733642197 
0.8471615721  0.8956521739  0.8340611354  0.8521739130  0.8100436681  0.8956521739  0.8209606987  0.8434782609  0.6335078534  76.855895196  2.8640852165  0.3831291199  1100          0.0783603001 
0.8384279476  0.8869565217  0.8340611354  0.8434782609  0.8100436681  0.8956521739  0.8187772926  0.8260869565  0.6352530541  80.349344978  2.7901298952  0.3831291199  1150          0.0790009260 
0.8384279476  0.8869565217  0.8406113537  0.8521739130  0.8100436681  0.8782608696  0.8340611354  0.8521739130  0.6614310646  83.842794759  2.7574471283  0.3831815720  1200          0.0750743628 
0.8580786026  0.8956521739  0.8427947598  0.8695652174  0.8056768559  0.8956521739  0.8100436681  0.8434782609  0.5968586387  87.336244541  2.6687847853  0.3831815720  1250          0.0746285582 
0.8515283843  0.8869565217  0.8471615721  0.8695652174  0.8078602620  0.8869565217  0.8231441048  0.8260869565  0.6020942408  90.829694323  2.6340094805  0.3831815720  1300          0.0738385820 
0.8471615721  0.8869565217  0.8362445415  0.8521739130  0.8122270742  0.8956521739  0.8253275109  0.8608695652  0.6369982548  94.323144104  2.5867068720  0.3831815720  1350          0.0733870125 
0.8537117904  0.8695652174  0.8493449782  0.8695652174  0.8144104803  0.8956521739  0.8144104803  0.8608695652  0.5968586387  97.816593886  2.6601504374  0.3831815720  1400          0.0729909515 
0.8580786026  0.9043478261  0.8493449782  0.8782608696  0.8100436681  0.8956521739  0.8078602620  0.8173913043  0.5759162304  101.31004366  2.5904052353  0.3831815720  1450          0.0734838057 
0.8624454148  0.8869565217  0.8537117904  0.8608695652  0.8144104803  0.8956521739  0.8384279476  0.8608695652  0.6439790576  104.80349344  2.5711305928  0.3831815720  1500          0.0729225492 
0.8580786026  0.9043478261  0.8558951965  0.8695652174  0.8209606987  0.8956521739  0.8406113537  0.8695652174  0.6422338569  108.29694323  2.5515796471  0.3831815720  1550          0.0724045467 
0.8646288210  0.8956521739  0.8493449782  0.8869565217  0.8187772926  0.8956521739  0.8165938865  0.8434782609  0.5811518325  111.79039301  2.5237899780  0.3831815720  1600          0.0738533974 
0.8668122271  0.8956521739  0.8558951965  0.8695652174  0.8187772926  0.9043478261  0.8406113537  0.8608695652  0.6387434555  115.28384279  2.4839724207  0.3831815720  1650          0.0715032196 
0.8580786026  0.8956521739  0.8580786026  0.8695652174  0.8187772926  0.8956521739  0.8384279476  0.8608695652  0.6317626527  118.77729257  2.4213039398  0.3831815720  1700          0.0735890150 
0.8711790393  0.8869565217  0.8646288210  0.8695652174  0.8296943231  0.9043478261  0.8406113537  0.8695652174  0.6195462478  122.27074235  2.4839979172  0.3831815720  1750          0.0759281445 
0.8602620087  0.8782608696  0.8537117904  0.8782608696  0.8231441048  0.8956521739  0.8471615721  0.8608695652  0.6404886562  125.76419213  2.4089681339  0.3831815720  1800          0.0750379705 
0.8711790393  0.9043478261  0.8602620087  0.8695652174  0.8253275109  0.9043478261  0.8427947598  0.8608695652  0.6369982548  129.25764192  2.3559352970  0.3831815720  1850          0.0741955137 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2287, in update
    meta_train_loss_dg.backward(create_graph=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 1.25e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.3921458721 
0.2838427948  0.3217391304  0.3100436681  0.3043478261  0.3056768559  0.3304347826  0.3144104803  0.2260869565  0.2949389180  3.4934497817  4.6980748653  0.3009815216  50            0.0753490496 
0.3122270742  0.3217391304  0.3209606987  0.3391304348  0.3231441048  0.3391304348  0.3471615721  0.2521739130  0.3472949389  6.9868995633  4.3926719284  0.3009815216  100           0.0734571218 
0.3602620087  0.3478260870  0.3384279476  0.3739130435  0.3296943231  0.3304347826  0.3471615721  0.2521739130  0.3525305410  10.480349345  4.2621957302  0.3009815216  150           0.0727278805 
0.4061135371  0.3826086957  0.3515283843  0.3565217391  0.3711790393  0.3478260870  0.3646288210  0.3304347826  0.3560209424  13.973799126  4.2016286755  0.3009815216  200           0.0734542656 
0.4410480349  0.4521739130  0.3777292576  0.3826086957  0.3886462882  0.4434782609  0.3799126638  0.3304347826  0.3734729494  17.467248908  4.1534558010  0.3009815216  250           0.0731546068 
0.4716157205  0.5043478261  0.3995633188  0.4347826087  0.4170305677  0.4434782609  0.3951965066  0.3304347826  0.3979057592  20.960698690  4.1254935169  0.3009815216  300           0.0731335926 
0.4759825328  0.5043478261  0.4432314410  0.4434782609  0.4344978166  0.4086956522  0.4082969432  0.3826086957  0.4171029668  24.454148471  4.0858182144  0.3009815216  350           0.0708663654 
0.5174672489  0.5478260870  0.4890829694  0.4869565217  0.4672489083  0.4521739130  0.4366812227  0.4347826087  0.4310645724  27.947598253  4.0448768044  0.3010568619  400           0.0729885626 
0.6200873362  0.6347826087  0.5502183406  0.5391304348  0.5393013100  0.6000000000  0.5152838428  0.4695652174  0.5130890052  31.441048034  4.0066562128  0.3010568619  450           0.0738136482 
0.6288209607  0.6608695652  0.5458515284  0.5130434783  0.5174672489  0.5652173913  0.5131004367  0.4869565217  0.4834205934  34.934497816  3.8861011410  0.3010568619  500           0.0725636339 
0.6943231441  0.7391304348  0.5917030568  0.5913043478  0.5938864629  0.6260869565  0.5611353712  0.5304347826  0.5776614311  38.427947598  3.7421837187  0.3010568619  550           0.0734681797 
0.7641921397  0.8173913043  0.7030567686  0.6695652174  0.7161572052  0.7304347826  0.6812227074  0.6347826087  0.6335078534  41.921397379  3.5914547825  0.3010568619  600           0.0748725224 
0.7860262009  0.7739130435  0.7445414847  0.7478260870  0.7685589520  0.8434782609  0.7248908297  0.7043478261  0.5951134380  45.414847161  3.4105448103  0.3010945320  650           0.0723545551 
0.8056768559  0.8434782609  0.7794759825  0.7826086957  0.7838427948  0.8347826087  0.7663755459  0.7304347826  0.6230366492  48.908296943  3.2568557644  0.3831248283  700           0.0728915215 
0.8209606987  0.8695652174  0.8100436681  0.8347826087  0.8013100437  0.8608695652  0.8056768559  0.7913043478  0.6806282723  52.401746724  3.1191134119  0.3831248283  750           0.0736817932 
0.8231441048  0.8782608696  0.8034934498  0.8260869565  0.7903930131  0.8695652174  0.7947598253  0.7826086957  0.6457242583  55.895196506  2.9941436768  0.3831248283  800           0.0732336712 
0.8187772926  0.8695652174  0.8078602620  0.8086956522  0.7925764192  0.8782608696  0.7903930131  0.7739130435  0.6317626527  59.388646288  2.8795003653  0.3831248283  850           0.0730904102 
0.8275109170  0.8956521739  0.8165938865  0.8260869565  0.7991266376  0.8782608696  0.8034934498  0.8000000000  0.6474694590  62.882096069  2.7425313139  0.3831248283  900           0.0713686800 
0.8296943231  0.8956521739  0.8253275109  0.8434782609  0.8122270742  0.8782608696  0.8231441048  0.8260869565  0.6788830716  66.375545851  2.6947797441  0.3832840919  950           0.0729369211 
0.8209606987  0.9043478261  0.8296943231  0.8260869565  0.8100436681  0.8869565217  0.8100436681  0.8173913043  0.6596858639  69.868995633  2.6205668402  0.3832840919  1000          0.0763969326 
0.8231441048  0.8956521739  0.8362445415  0.8434782609  0.8100436681  0.8869565217  0.8253275109  0.8434782609  0.6771378709  73.362445414  2.5874905539  0.3832840919  1050          0.0731959200 
0.8427947598  0.9043478261  0.8384279476  0.8347826087  0.8034934498  0.8782608696  0.8231441048  0.8260869565  0.6457242583  76.855895196  2.5624352312  0.3832840919  1100          0.0744118214 
0.8384279476  0.8956521739  0.8340611354  0.8347826087  0.8056768559  0.8782608696  0.8209606987  0.8347826087  0.6404886562  80.349344978  2.5084077215  0.3832840919  1150          0.0746407509 
0.8275109170  0.8869565217  0.8362445415  0.8521739130  0.8122270742  0.8782608696  0.8340611354  0.8608695652  0.6701570681  83.842794759  2.4774248886  0.3832840919  1200          0.0728795576 
0.8471615721  0.9043478261  0.8406113537  0.8434782609  0.8100436681  0.9043478261  0.8253275109  0.8521739130  0.6125654450  87.336244541  2.3966951990  0.3832840919  1250          0.0731941891 
0.8471615721  0.9043478261  0.8471615721  0.8434782609  0.8100436681  0.8956521739  0.8253275109  0.8434782609  0.6230366492  90.829694323  2.3515842438  0.3832840919  1300          0.0732096004 
0.8406113537  0.9043478261  0.8449781659  0.8521739130  0.8100436681  0.8782608696  0.8253275109  0.8521739130  0.6509598604  94.323144104  2.3042871714  0.3832840919  1350          0.0728537273 
0.8537117904  0.8956521739  0.8515283843  0.8608695652  0.8100436681  0.8956521739  0.8275109170  0.8521739130  0.6073298429  97.816593886  2.3627383256  0.3832840919  1400          0.0726881599 
0.8558951965  0.9043478261  0.8471615721  0.8695652174  0.8209606987  0.9043478261  0.8231441048  0.8260869565  0.5863874346  101.31004366  2.3315087700  0.3832840919  1450          0.0721429253 
0.8493449782  0.9043478261  0.8471615721  0.8521739130  0.8100436681  0.8695652174  0.8340611354  0.8608695652  0.6614310646  104.80349344  2.3024818778  0.3832840919  1500          0.0718483019 
0.8493449782  0.9130434783  0.8493449782  0.8521739130  0.8100436681  0.8782608696  0.8318777293  0.8608695652  0.6544502618  108.29694323  2.3055694628  0.3832840919  1550          0.0716058922 
0.8580786026  0.9043478261  0.8493449782  0.8782608696  0.8231441048  0.9043478261  0.8253275109  0.8521739130  0.5968586387  111.79039301  2.2374355507  0.3832840919  1600          0.0752168798 
0.8558951965  0.9043478261  0.8537117904  0.8521739130  0.8122270742  0.8782608696  0.8427947598  0.8608695652  0.6509598604  115.28384279  2.2303701305  0.3832840919  1650          0.0752029848 
0.8493449782  0.9130434783  0.8493449782  0.8521739130  0.8144104803  0.8869565217  0.8427947598  0.8695652174  0.6509598604  118.77729257  2.1765292525  0.3832840919  1700          0.0751057243 
0.8558951965  0.8782608696  0.8537117904  0.8521739130  0.8253275109  0.8782608696  0.8449781659  0.8521739130  0.6352530541  122.27074235  2.2324967551  0.3832840919  1750          0.0752377939 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1855895197  0.1913043478  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1902268761  0.0000000000  5.1459832191  0.1362590790  0             0.3913550377 
0.2969432314  0.3565217391  0.3165938865  0.3565217391  0.3187772926  0.3391304348  0.3449781659  0.2521739130  0.3246073298  3.4934497817  4.5872481632  0.3009815216  50            0.0721083641 
0.3537117904  0.3478260870  0.3165938865  0.3217391304  0.3493449782  0.3565217391  0.3406113537  0.2869565217  0.3612565445  6.9868995633  4.2829893780  0.3009815216  100           0.0738471937 
0.4301310044  0.4173913043  0.3908296943  0.4000000000  0.3930131004  0.3826086957  0.3864628821  0.3652173913  0.3560209424  10.480349345  4.1736388111  0.3009815216  150           0.0732847452 
0.4781659389  0.5043478261  0.4388646288  0.4869565217  0.4388646288  0.4782608696  0.4235807860  0.3565217391  0.3996509599  13.973799126  4.1247611713  0.3009815216  200           0.0723228788 
0.5283842795  0.5391304348  0.4737991266  0.4869565217  0.4650655022  0.5217391304  0.4388646288  0.4347826087  0.4328097731  17.467248908  4.0597821093  0.3009815216  250           0.0730026007 
0.6659388646  0.6956521739  0.5742358079  0.6000000000  0.5917030568  0.5913043478  0.5589519651  0.5043478261  0.5305410122  20.960698690  3.9799897575  0.3010191917  300           0.0726975918 
0.7161572052  0.7391304348  0.6441048035  0.6086956522  0.6615720524  0.7043478261  0.6244541485  0.6260869565  0.6020942408  24.454148471  3.8148227167  0.3010191917  350           0.0730698919 
0.7816593886  0.7913043478  0.7423580786  0.7130434783  0.7554585153  0.8000000000  0.7205240175  0.7304347826  0.6404886562  27.947598253  3.5535334492  0.3010191917  400           0.0712155485 
0.7969432314  0.8260869565  0.7860262009  0.8086956522  0.7903930131  0.8608695652  0.7838427948  0.8000000000  0.6247818499  31.441048034  3.3063757658  0.3010768890  450           0.0761998224 
0.8034934498  0.8608695652  0.7903930131  0.8347826087  0.7947598253  0.8608695652  0.7751091703  0.7652173913  0.6212914485  34.934497816  3.0597121096  0.3010768890  500           0.0739868879 
0.8122270742  0.8869565217  0.8100436681  0.8260869565  0.8056768559  0.8782608696  0.8056768559  0.8260869565  0.6858638743  38.427947598  2.8626702547  0.3010768890  550           0.0724538088 
0.8231441048  0.8695652174  0.8187772926  0.8347826087  0.7969432314  0.8782608696  0.7947598253  0.7913043478  0.6300174520  41.921397379  2.7709941101  0.3010768890  600           0.0747171164 
0.8362445415  0.8782608696  0.8275109170  0.8434782609  0.8013100437  0.8782608696  0.8078602620  0.8260869565  0.6125654450  45.414847161  2.6391534042  0.3010768890  650           0.0728915977 
0.8427947598  0.9043478261  0.8340611354  0.8347826087  0.8078602620  0.8869565217  0.8209606987  0.8347826087  0.6422338569  48.908296943  2.6409218550  0.3010768890  700           0.0732685661 
0.8275109170  0.8956521739  0.8275109170  0.8521739130  0.8078602620  0.8869565217  0.8296943231  0.8608695652  0.6806282723  52.401746724  2.5417897177  0.3010768890  750           0.0720302868 
0.8406113537  0.9130434783  0.8384279476  0.8347826087  0.8144104803  0.8782608696  0.8296943231  0.8608695652  0.6282722513  55.895196506  2.4447335219  0.3010768890  800           0.0763366890 
0.8384279476  0.9043478261  0.8515283843  0.8434782609  0.8187772926  0.9043478261  0.8318777293  0.8521739130  0.6300174520  59.388646288  2.3860962701  0.3010768890  850           0.0736728477 
0.8449781659  0.8956521739  0.8515283843  0.8521739130  0.8144104803  0.9043478261  0.8362445415  0.8608695652  0.6457242583  62.882096069  2.2741510868  0.3010768890  900           0.0734437609 
0.8427947598  0.9043478261  0.8537117904  0.8521739130  0.8144104803  0.8956521739  0.8384279476  0.8434782609  0.6474694590  66.375545851  2.2755449438  0.3010768890  950           0.0751435471 
0.8406113537  0.8956521739  0.8493449782  0.8521739130  0.8144104803  0.8869565217  0.8340611354  0.8782608696  0.6457242583  69.868995633  2.2228932595  0.3010768890  1000          0.0763079214 
0.8515283843  0.8869565217  0.8515283843  0.8608695652  0.8144104803  0.8956521739  0.8449781659  0.8695652174  0.6474694590  73.362445414  2.1927683282  0.3833017349  1050          0.0724922562 
0.8602620087  0.9043478261  0.8602620087  0.8695652174  0.8296943231  0.9043478261  0.8318777293  0.8608695652  0.6160558464  76.855895196  2.1833188891  0.3833017349  1100          0.0728115606 
0.8646288210  0.9043478261  0.8580786026  0.8782608696  0.8296943231  0.9043478261  0.8318777293  0.8695652174  0.6055846422  80.349344978  2.1263762450  0.3833017349  1150          0.0740814829 
0.8580786026  0.8956521739  0.8624454148  0.8695652174  0.8231441048  0.8956521739  0.8471615721  0.8869565217  0.6352530541  83.842794759  2.0866021347  0.3833017349  1200          0.0719451809 
0.8668122271  0.8956521739  0.8624454148  0.8869565217  0.8362445415  0.9130434783  0.8340611354  0.8695652174  0.5846422339  87.336244541  2.0365488863  0.3833017349  1250          0.0727746964 
0.8668122271  0.9043478261  0.8733624454  0.8869565217  0.8406113537  0.9130434783  0.8427947598  0.8782608696  0.6003490401  90.829694323  1.9924519587  0.3833017349  1300          0.0733432245 
0.8820960699  0.9043478261  0.8777292576  0.8956521739  0.8384279476  0.9043478261  0.8602620087  0.8869565217  0.6108202443  94.323144104  1.9251842737  0.3833017349  1350          0.0734626532 
0.8842794760  0.9043478261  0.8908296943  0.8869565217  0.8427947598  0.9130434783  0.8580786026  0.8782608696  0.5759162304  97.816593886  1.9879707742  0.3833017349  1400          0.0729316425 
0.8624454148  0.9130434783  0.8733624454  0.8869565217  0.8362445415  0.9130434783  0.8362445415  0.8434782609  0.5567190227  101.31004366  1.9779094696  0.3833017349  1450          0.0724911499 
0.8995633188  0.8869565217  0.8842794760  0.8869565217  0.8493449782  0.9217391304  0.8755458515  0.8869565217  0.6108202443  104.80349344  1.9310775065  0.3833017349  1500          0.0725082874 
0.8930131004  0.9043478261  0.8864628821  0.8956521739  0.8427947598  0.8956521739  0.8602620087  0.8869565217  0.6108202443  108.29694323  1.9443277454  0.3833017349  1550          0.0720734024 
0.8755458515  0.9217391304  0.8864628821  0.8956521739  0.8471615721  0.9130434783  0.8449781659  0.8695652174  0.5584642234  111.79039301  1.8703662276  0.3833017349  1600          0.0731072330 
0.9061135371  0.9130434783  0.8995633188  0.8869565217  0.8602620087  0.9043478261  0.8755458515  0.8869565217  0.6038394415  115.28384279  1.8385533810  0.3833017349  1650          0.0722393131 
0.9082969432  0.8956521739  0.9061135371  0.8956521739  0.8799126638  0.9391304348  0.8930131004  0.8956521739  0.6073298429  118.77729257  1.8102484512  0.3833017349  1700          0.0720868158 
0.9257641921  0.8956521739  0.9279475983  0.8956521739  0.8908296943  0.9391304348  0.9061135371  0.9130434783  0.5828970332  122.27074235  1.8378238869  0.3833017349  1750          0.0724750233 
0.9410480349  0.9043478261  0.9279475983  0.9043478261  0.8951965066  0.9478260870  0.9235807860  0.9130434783  0.5916230366  125.76419213  1.7843490529  0.3833017349  1800          0.0740286493 
0.9257641921  0.9043478261  0.9279475983  0.9043478261  0.8930131004  0.9478260870  0.9082969432  0.9130434783  0.5933682373  129.25764192  1.7326093817  0.3833017349  1850          0.0721004534 
0.9323144105  0.9304347826  0.9344978166  0.9043478261  0.8930131004  0.9391304348  0.9082969432  0.9043478261  0.5602094241  132.75109170  1.7448232031  0.3833017349  1900          0.0751926565 
0.8995633188  0.9130434783  0.9104803493  0.8956521739  0.8646288210  0.9130434783  0.8646288210  0.8869565217  0.5619546248  136.24454148  1.6787258410  0.3833017349  1950          0.0746879005 
0.9366812227  0.9304347826  0.9388646288  0.8956521739  0.8908296943  0.9391304348  0.9039301310  0.9130434783  0.5392670157  139.73799126  1.6923117304  0.3833017349  2000          0.0769283342 
0.9257641921  0.9217391304  0.9344978166  0.8956521739  0.8908296943  0.9478260870  0.8995633188  0.9130434783  0.5654450262  143.23144104  1.6530854630  0.3833017349  2050          0.0751036263 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 176, in accuracy
    p = network.predict(x)   # ARM在predict处不同
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2343, in predict
    return self.phi(self.featurizer(x))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 285, in forward
    x = self.layer2(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/normalization.py", line 171, in forward
    input, self.normalized_shape, self.weight, self.bias, self.eps)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2205, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1984, in handle_keyboard_interrupt
    traceback.print_exception(type(value), value, tb, limit=limit)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 104, in print_exception
    type(value), value, tb, limit=limit).format(chain=chain):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 509, in __init__
    capture_locals=capture_locals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 364, in extract
    f.line
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 286, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 137, in updatecache
    lines = fp.readlines()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/codecs.py", line 318, in decode
    def decode(self, input, final=False):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 741628) is killed by signal: Terminated. 
We've got an error while stopping in post-mortem: <class 'RuntimeError'>

Exception ignored in: <module 'threading' from '/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py'>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/threading.py", line 1279, in _shutdown
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
RuntimeError: DataLoader worker (pid 741669) is killed by signal: Terminated. 
Exception ignored in: <bound method _ConnectionBase.__del__ of <multiprocessing.connection.Connection object at 0x7fc26c363eb8>>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 130, in __del__
    def __del__(self):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
RuntimeError: DataLoader worker (pid 740986) is killed by signal: Terminated. 
Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fc26c6be3c8>>
Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7fc3af261ae8>
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/weakref.py", line 109, in remove
    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 63, in handler
    def handler(signum, frame):
RuntimeError: DataLoader worker (pid 740707) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.1855895197  0.1826086957  0.1834061135  0.1826086957  0.1877729258  0.1913043478  0.1834061135  0.1913043478  0.1884816754  0.0000000000  4.5351276398  0.1006202698  0             0.3875255585 
0.3973799127  0.3826086957  0.3558951965  0.3391304348  0.3777292576  0.4000000000  0.3951965066  0.2956521739  0.3769633508  3.4934497817  4.1827299309  0.2653427124  50            0.0605704784 
0.5349344978  0.5130434783  0.4585152838  0.4347826087  0.4759825328  0.4869565217  0.4475982533  0.4260869565  0.4013961606  6.9868995633  3.9693263912  0.2653427124  100           0.0604499626 
0.6572052402  0.6086956522  0.5720524017  0.5217391304  0.5611353712  0.5652173913  0.5524017467  0.4956521739  0.5165794066  10.480349345  3.6970466042  0.2653427124  150           0.0600390100 
0.7576419214  0.7739130435  0.6986899563  0.7043478261  0.7205240175  0.7043478261  0.6834061135  0.6956521739  0.6282722513  13.973799126  3.2577550840  0.2653427124  200           0.0602131891 
0.8056768559  0.8000000000  0.7467248908  0.7478260870  0.7532751092  0.7913043478  0.7510917031  0.7478260870  0.6300174520  17.467248908  2.8380361414  0.2653427124  250           0.0609576130 
0.8406113537  0.8521739130  0.8013100437  0.7913043478  0.7882096070  0.8347826087  0.8013100437  0.8086956522  0.6509598604  20.960698690  2.3924079084  0.2653427124  300           0.0608702421 
0.8362445415  0.8869565217  0.8209606987  0.8000000000  0.8100436681  0.8608695652  0.8100436681  0.8173913043  0.6317626527  24.454148471  2.1123699594  0.2653427124  350           0.0601443434 
0.8471615721  0.8695652174  0.8471615721  0.8434782609  0.8296943231  0.8782608696  0.8275109170  0.8608695652  0.6178010471  27.947598253  1.8490096188  0.2653427124  400           0.0615724707 
0.8711790393  0.9130434783  0.8580786026  0.8608695652  0.8449781659  0.8782608696  0.8406113537  0.8521739130  0.6247818499  31.441048034  1.6808114243  0.2653427124  450           0.0600272608 
0.8689956332  0.9217391304  0.8602620087  0.8695652174  0.8406113537  0.8869565217  0.8427947598  0.8695652174  0.6073298429  34.934497816  1.5037976027  0.2653427124  500           0.0608077335 
0.9213973799  0.9130434783  0.8951965066  0.8869565217  0.8799126638  0.8956521739  0.8842794760  0.8782608696  0.5898778360  38.427947598  1.3448884487  0.2653427124  550           0.0603270960 
0.9344978166  0.9130434783  0.9213973799  0.9043478261  0.9061135371  0.9130434783  0.9213973799  0.8956521739  0.5410122164  41.921397379  1.2253863645  0.2654619217  600           0.0604624033 
0.9257641921  0.9217391304  0.9235807860  0.8869565217  0.8973799127  0.8869565217  0.9017467249  0.8782608696  0.5375218150  45.414847161  1.1392167997  0.2654619217  650           0.0596744823 
0.9519650655  0.9217391304  0.9344978166  0.8695652174  0.9039301310  0.9130434783  0.9170305677  0.9130434783  0.5410122164  48.908296943  1.0567745841  0.2654995918  700           0.0597252512 
0.9519650655  0.9304347826  0.9344978166  0.8695652174  0.9104803493  0.9130434783  0.9235807860  0.9130434783  0.5619546248  52.401746724  0.9474051523  0.2654995918  750           0.0604362249 
0.9672489083  0.9478260870  0.9541484716  0.8695652174  0.9104803493  0.9304347826  0.9213973799  0.9130434783  0.5183246073  55.895196506  0.8530294758  0.2655372620  800           0.0602412128 
0.9585152838  0.9478260870  0.9694323144  0.8869565217  0.9519650655  0.9304347826  0.9563318777  0.9304347826  0.5357766143  59.388646288  0.7810237813  0.2655372620  850           0.0606907892 
0.9716157205  0.9565217391  0.9694323144  0.8956521739  0.9606986900  0.9478260870  0.9541484716  0.9391304348  0.5270506108  62.882096069  0.7235182637  0.2655372620  900           0.0606864309 
0.9737991266  0.9478260870  0.9737991266  0.9043478261  0.9563318777  0.9478260870  0.9650655022  0.9304347826  0.5497382199  66.375545851  0.6487760401  0.2655372620  950           0.0600033617 
0.9759825328  0.9652173913  0.9716157205  0.8869565217  0.9585152838  0.9304347826  0.9519650655  0.9130434783  0.5235602094  69.868995633  0.5951387262  0.2655372620  1000          0.0597078133 
0.9759825328  0.9565217391  0.9847161572  0.9391304348  0.9781659389  0.9391304348  0.9672489083  0.9391304348  0.5148342059  73.362445414  0.5484696019  0.2655372620  1050          0.0602705383 
0.9825327511  0.9565217391  0.9825327511  0.9391304348  0.9803493450  0.9478260870  0.9781659389  0.9304347826  0.5392670157  76.855895196  0.5414608717  0.2655372620  1100          0.0608919001 
0.9825327511  0.9739130435  0.9868995633  0.9391304348  0.9912663755  0.9565217391  0.9650655022  0.9217391304  0.4921465969  80.349344978  0.4859098125  0.2655372620  1150          0.0620174074 
0.9825327511  0.9565217391  0.9956331878  0.9565217391  0.9912663755  0.9391304348  0.9803493450  0.9217391304  0.5287958115  83.842794759  0.4412456977  0.2655372620  1200          0.0634489441 
0.9890829694  0.9652173913  0.9868995633  0.9391304348  0.9847161572  0.9478260870  0.9737991266  0.9217391304  0.5357766143  87.336244541  0.3727946505  0.2655372620  1250          0.0619723511 
0.9847161572  0.9565217391  0.9956331878  0.9478260870  0.9934497817  0.9391304348  0.9803493450  0.9304347826  0.5427574171  90.829694323  0.3678219828  0.2678818703  1300          0.0627280664 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.2552552553  0.2500000000  0.2552552553  0.2738095238  0.2582582583  0.2619047619  0.2522522523  0.2500000000  0.2613908873  0.0000000000  4.9990310669  0.1362590790  0             0.3812470436 
0.4564564565  0.4285714286  0.4204204204  0.4880952381  0.4024024024  0.4047619048  0.4654654655  0.3571428571  0.3477218225  4.8048048048  4.2861262703  0.3009815216  50            0.0691050577 
0.5975975976  0.5357142857  0.5135135135  0.6071428571  0.5255255255  0.5119047619  0.5495495495  0.4404761905  0.3980815348  9.6096096096  3.7897765303  0.3009815216  100           0.0742167950 
0.6936936937  0.6666666667  0.6546546547  0.6666666667  0.6276276276  0.6190476190  0.6696696697  0.5714285714  0.5371702638  14.414414414  3.5679350948  0.3009815216  150           0.0744900846 
0.7327327327  0.7380952381  0.6936936937  0.6547619048  0.6996996997  0.6071428571  0.7297297297  0.6190476190  0.5707434053  19.219219219  3.4074185133  0.3010210991  200           0.0713094139 
0.7807807808  0.7142857143  0.7087087087  0.6904761905  0.7447447447  0.6666666667  0.7297297297  0.6071428571  0.6043165468  24.024024024  3.2121727943  0.3010210991  250           0.0701287079 
0.8168168168  0.7619047619  0.7567567568  0.7738095238  0.7657657658  0.7261904762  0.8018018018  0.6904761905  0.6258992806  28.828828828  2.9919787121  0.3010210991  300           0.0698597908 
0.7927927928  0.7619047619  0.7057057057  0.7976190476  0.7387387387  0.7738095238  0.7387387387  0.7023809524  0.6474820144  33.633633633  2.7475556850  0.3010606766  350           0.0703227615 
0.8918918919  0.8333333333  0.8468468468  0.8452380952  0.8198198198  0.7738095238  0.8708708709  0.7500000000  0.6738609113  38.438438438  2.6040190172  0.3010606766  400           0.0699451733 
0.8948948949  0.8452380952  0.8708708709  0.8809523810  0.8558558559  0.8571428571  0.8798798799  0.7738095238  0.7050359712  43.243243243  2.4420980215  0.3010606766  450           0.0714878368 
0.9369369369  0.9285714286  0.8978978979  0.9285714286  0.8948948949  0.8809523810  0.9009009009  0.8095238095  0.7026378897  48.048048048  2.2653348160  0.3010606766  500           0.0699990225 
0.9729729730  0.9761904762  0.9189189189  0.9166666667  0.9129129129  0.8928571429  0.9249249249  0.8690476190  0.7194244604  52.852852852  2.1454074740  0.3010606766  550           0.0697089863 
0.9789789790  0.9761904762  0.9399399399  0.9285714286  0.9189189189  0.9166666667  0.9399399399  0.9047619048  0.7074340528  57.657657657  2.1182680058  0.3010606766  600           0.0710324049 
0.9789789790  0.9761904762  0.9339339339  0.8928571429  0.9099099099  0.9166666667  0.9489489489  0.9285714286  0.7697841727  62.462462462  2.0791365075  0.3010606766  650           0.0710652685 
0.9759759760  0.9880952381  0.9609609610  0.9166666667  0.9339339339  0.9404761905  0.9519519520  0.9285714286  0.7194244604  67.267267267  1.9633927250  0.3010606766  700           0.0704406214 
0.9849849850  1.0000000000  0.9849849850  0.9761904762  0.9609609610  0.9404761905  0.9639639640  0.9404761905  0.7050359712  72.072072072  1.9240494680  0.3831186295  750           0.0719428730 
0.9789789790  0.9880952381  0.9579579580  0.9285714286  0.9399399399  0.9404761905  0.9549549550  0.9523809524  0.7505995204  76.876876876  1.8024332857  0.3831186295  800           0.0711000395 
0.9879879880  1.0000000000  0.9909909910  0.9880952381  0.9669669670  0.9404761905  0.9699699700  0.9404761905  0.7074340528  81.681681681  1.7953168559  0.3831186295  850           0.0700319242 
0.9819819820  1.0000000000  0.9909909910  1.0000000000  0.9699699700  0.9404761905  0.9669669670  0.9523809524  0.7266187050  86.486486486  1.7091727185  0.3831186295  900           0.0705363035 
0.9849849850  1.0000000000  0.9849849850  1.0000000000  0.9669669670  0.9404761905  0.9699699700  0.9642857143  0.7458033573  91.291291291  1.6795274973  0.3831186295  950           0.0708457565 
0.9939939940  1.0000000000  0.9879879880  0.9880952381  0.9729729730  0.9642857143  0.9789789790  0.9642857143  0.7649880096  96.096096096  1.5825513935  0.3831186295  1000          0.0713504601 
0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.9699699700  0.9761904762  0.9849849850  0.9761904762  0.7721822542  100.90090090  1.5629968238  0.3831186295  1050          0.0709942818 
0.9879879880  1.0000000000  0.9969969970  1.0000000000  0.9789789790  0.9523809524  0.9849849850  0.9761904762  0.7577937650  105.70570570  1.5041685009  0.3831186295  1100          0.0714212656 
0.9849849850  1.0000000000  0.9969969970  1.0000000000  0.9849849850  0.9880952381  0.9849849850  0.9642857143  0.7649880096  110.51051051  1.4499629688  0.3831186295  1150          0.0711605549 
0.9849849850  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9761904762  0.9849849850  0.9642857143  0.7601918465  115.31531531  1.3812960815  0.3831186295  1200          0.0704828405 
0.9819819820  0.9880952381  1.0000000000  1.0000000000  0.9789789790  0.9642857143  0.9879879880  0.9761904762  0.7601918465  120.12012012  1.2796151447  0.3831186295  1250          0.0706527519 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9879879880  0.9880952381  0.8009592326  124.92492492  1.2092263079  0.3831186295  1300          0.0749958611 
0.9879879880  1.0000000000  1.0000000000  1.0000000000  0.9819819820  0.9880952381  0.9849849850  0.9880952381  0.7673860911  129.72972972  1.1919849586  0.3831186295  1350          0.0738314342 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.8033573141  134.53453453  1.1582116592  0.3831186295  1400          0.0734369469 
0.9879879880  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9880952381  0.9879879880  0.9880952381  0.7817745803  139.33933933  1.0920458579  0.3831186295  1450          0.0711187935 
0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.8153477218  144.14414414  1.0573388481  0.3831186295  1500          0.0707019329 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9849849850  1.0000000000  0.8057553957  148.94894894  1.0009340250  0.3831186295  1550          0.0716302252 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9879879880  1.0000000000  0.8009592326  153.75375375  1.0213162315  0.3831186295  1600          0.0700686598 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.7985611511  158.55855855  1.0215988040  0.3831186295  1650          0.0696094513 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9879879880  0.9880952381  0.7937649880  163.36336336  0.9930536354  0.3831186295  1700          0.0688848639 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.8057553957  168.16816816  0.9446002054  0.3831186295  1750          0.0702818108 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.8033573141  172.97297297  0.9486990917  0.3831186295  1800          0.0712455750 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.8033573141  177.77777777  0.9036546290  0.3831186295  1850          0.0702411556 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9909909910  1.0000000000  0.8009592326  182.58258258  0.9065760708  0.3831186295  1900          0.0701586723 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9909909910  1.0000000000  0.8009592326  187.38738738  0.9028874123  0.3831186295  1950          0.0710901499 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9909909910  0.9880952381  0.7841726619  192.19219219  0.8488551915  0.3831186295  2000          0.0702934456 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9909909910  1.0000000000  0.8057553957  196.99699699  0.8713899100  0.3831186295  2050          0.0709913683 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9909909910  1.0000000000  0.7937649880  201.80180180  0.8056227350  0.3831186295  2100          0.0795104694 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9909909910  1.0000000000  0.8009592326  206.60660660  0.8491347110  0.3831186295  2150          0.0752872086 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "_pydevd_frame_eval/pydevd_frame_evaluator_common.pyx", line 157, in _pydevd_frame_eval.pydevd_frame_evaluator_common.get_func_code_info
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_bundle/pydev_log.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 557, in get_abs_path_real_path_and_base_from_file
    return NORM_PATHS_AND_BASE_CONTAINER[f]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_bundle/pydev_log.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 230, in _NormPaths
    return NORM_PATHS_CONTAINER[filename]
KeyError: '/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_bundle/pydev_log.py'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "_pydevd_frame_eval/pydevd_frame_evaluator_common.pyx", line 159, in _pydevd_frame_eval.pydevd_frame_evaluator_common.get_func_code_info
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 571, in get_abs_path_real_path_and_base_from_file
    abs_path, real_path = _NormPaths(f)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 238, in _NormPaths
    real_path = _NormPath(filename, rPath)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd_file_utils.py", line 246, in _NormPath
    r = normpath(filename)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 395, in realpath
    path, ok = _joinrealpath(filename[:0], filename, {})
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 429, in _joinrealpath
    if not islink(newpath):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/posixpath.py", line 171, in islink
    st = os.lstat(path)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 838142) is killed by signal: Terminated. 
We've got an error while stopping in post-mortem: <class 'RuntimeError'>

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3363363363  0.3690476190  0.3363363363  0.3333333333  0.3423423423  0.3809523810  0.3573573574  0.2976190476  0.3189448441  0.0000000000  3.4921488762  0.1006202698  0             0.3580369949 
0.6096096096  0.5833333333  0.5915915916  0.5357142857  0.5615615616  0.6309523810  0.6186186186  0.5476190476  0.5203836930  4.8048048048  3.2305666685  0.2653427124  50            0.0584942436 
0.7957957958  0.7261904762  0.7267267267  0.6547619048  0.7297297297  0.7738095238  0.7267267267  0.7857142857  0.6163069544  9.6096096096  2.9044243383  0.2653427124  100           0.0593020964 
0.8138138138  0.7619047619  0.7327327327  0.6428571429  0.7177177177  0.7738095238  0.7267267267  0.7857142857  0.6522781775  14.414414414  2.4538694477  0.2653427124  150           0.0582672787 
0.9189189189  0.8333333333  0.8168168168  0.7619047619  0.8408408408  0.8333333333  0.8348348348  0.8333333333  0.6594724221  19.219219219  1.9664782476  0.2653427124  200           0.0588647747 
0.9639639640  0.9285714286  0.9009009009  0.8571428571  0.9309309309  0.8809523810  0.9159159159  0.9166666667  0.6618705036  24.024024024  1.5762529302  0.2653427124  250           0.0586380768 
0.9819819820  0.9523809524  0.9579579580  0.8809523810  0.9729729730  0.9285714286  0.9519519520  0.9404761905  0.6834532374  28.828828828  1.3052298427  0.2653427124  300           0.0593370199 
0.9909909910  0.9761904762  0.9729729730  0.9285714286  0.9759759760  0.9523809524  0.9609609610  0.9642857143  0.7026378897  33.633633633  1.0390251255  0.2653427124  350           0.0591043758 
0.9909909910  0.9761904762  0.9849849850  0.9523809524  0.9849849850  0.9642857143  0.9699699700  0.9642857143  0.7098321343  38.438438438  0.8442849505  0.2653427124  400           0.0576231861 
0.9909909910  0.9761904762  0.9969969970  0.9761904762  0.9909909910  0.9642857143  0.9789789790  0.9642857143  0.7458033573  43.243243243  0.6483614230  0.2653427124  450           0.0595255613 
0.9939939940  0.9880952381  0.9969969970  0.9761904762  0.9939939940  0.9761904762  0.9879879880  0.9761904762  0.7745803357  48.048048048  0.5335812962  0.2653427124  500           0.0602842379 
0.9939939940  0.9880952381  1.0000000000  0.9880952381  0.9939939940  0.9761904762  0.9909909910  0.9761904762  0.7721822542  52.852852852  0.4316027391  0.2653427124  550           0.0580787134 
0.9969969970  0.9880952381  1.0000000000  0.9880952381  0.9909909910  0.9880952381  0.9909909910  0.9761904762  0.7865707434  57.657657657  0.3547880846  0.2653427124  600           0.0582646942 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9939939940  0.9880952381  0.9939939940  0.9880952381  0.7937649880  62.462462462  0.2852633420  0.2653698921  650           0.0582772064 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9939939940  1.0000000000  0.9939939940  0.9761904762  0.7937649880  67.267267267  0.2426302323  0.2653698921  700           0.0574714613 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.7985611511  72.072072072  0.2114357705  0.2653822899  750           0.0587356091 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.7913669065  76.876876876  0.1990673766  0.2653822899  800           0.0586515856 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.7937649880  81.681681681  0.1516671330  0.2653822899  850           0.0592030478 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8081534772  86.486486486  0.1336634484  0.2653822899  900           0.0581914854 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8177458034  91.291291291  0.1231909113  0.2653822899  950           0.0585225868 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8153477218  96.096096096  0.1126356668  0.2653822899  1000          0.0589162636 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8105515588  100.90090090  0.0967655905  0.2653822899  1050          0.0588321018 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8033573141  105.70570570  0.0830331784  0.2653822899  1100          0.0584848166 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8057553957  110.51051051  0.0780759257  0.2653822899  1150          0.0624443245 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8129496403  115.31531531  0.0646283415  0.2653822899  1200          0.0592045450 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  120.12012012  0.0619929586  0.2653822899  1250          0.0590642929 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  124.92492492  0.0603436346  0.2653822899  1300          0.0587155485 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  129.72972972  0.0554797608  0.2654218674  1350          0.0589344883 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  134.53453453  0.0534144746  0.2654218674  1400          0.0589679480 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8129496403  139.33933933  0.0476827367  0.2654218674  1450          0.0597370386 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  144.14414414  0.0446811549  0.2654218674  1500          0.0604517269 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 898687) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 2e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3273273273  0.3571428571  0.3333333333  0.2976190476  0.3303303303  0.3690476190  0.3723723724  0.2976190476  0.3093525180  0.0000000000  4.1691751480  0.1362590790  0             32.681613922 
0.5045045045  0.4523809524  0.4204204204  0.4166666667  0.4324324324  0.5000000000  0.4294294294  0.4642857143  0.4220623501  4.8048048048  3.6603795910  0.3010253906  50            0.0710449696 
0.5645645646  0.5357142857  0.4624624625  0.4880952381  0.4834834835  0.4761904762  0.4504504505  0.5119047619  0.4268585132  9.6096096096  3.3433549595  0.3010253906  100           0.0708245754 
0.6396396396  0.5595238095  0.5825825826  0.6071428571  0.6186186186  0.6785714286  0.5585585586  0.5952380952  0.5035971223  14.414414414  3.2305081177  0.3010253906  150           0.0710580206 
0.8138138138  0.7619047619  0.7237237237  0.7380952381  0.7867867868  0.7857142857  0.6936936937  0.7976190476  0.6618705036  19.219219219  3.0947804689  0.3010253906  200           0.0699074841 
0.8588588589  0.7857142857  0.7867867868  0.7380952381  0.8078078078  0.8214285714  0.7177177177  0.8095238095  0.6474820144  24.024024024  2.9008278084  0.3010253906  250           0.0701422787 
0.8018018018  0.7380952381  0.7597597598  0.7142857143  0.7477477477  0.8095238095  0.6846846847  0.7261904762  0.5755395683  28.828828828  2.6571209097  0.3010482788  300           0.0727898026 
0.9009009009  0.8452380952  0.8498498498  0.9047619048  0.8588588589  0.8809523810  0.8198198198  0.8214285714  0.6498800959  33.633633633  2.4470107031  0.3010482788  350           0.0752007771 
0.8948948949  0.7976190476  0.8828828829  0.8809523810  0.8648648649  0.9047619048  0.8048048048  0.8095238095  0.6067146283  38.438438438  2.2636396265  0.3010482788  400           0.0810590649 
0.9339339339  0.9047619048  0.9339339339  0.9166666667  0.9219219219  0.9523809524  0.9279279279  0.9166666667  0.6642685851  43.243243243  2.1508885765  0.3010482788  450           0.0719317293 
0.9519519520  0.9404761905  0.9519519520  0.9523809524  0.9339339339  0.9285714286  0.9489489489  0.9285714286  0.6786570743  48.048048048  2.0317704415  0.3010482788  500           0.0728427601 
0.9669669670  0.9404761905  0.9549549550  0.9523809524  0.9459459459  0.9285714286  0.9609609610  0.9166666667  0.7074340528  52.852852852  2.0122371888  0.3010482788  550           0.0749560213 
0.9609609610  0.9642857143  0.9369369369  0.9285714286  0.9369369369  0.9166666667  0.9549549550  0.9523809524  0.7290167866  57.657657657  1.9210447288  0.3010482788  600           0.0740149879 
0.9729729730  0.9761904762  0.9699699700  0.9761904762  0.9459459459  0.9523809524  0.9609609610  0.9642857143  0.6906474820  62.462462462  1.8246401262  0.3010482788  650           0.0735457945 
0.9969969970  1.0000000000  0.9729729730  0.9642857143  0.9759759760  0.9404761905  0.9639639640  0.9880952381  0.6906474820  67.267267267  1.7544877768  0.3010482788  700           0.0731048584 
0.9939939940  0.9880952381  0.9669669670  0.9761904762  0.9579579580  0.9523809524  0.9729729730  0.9880952381  0.7410071942  72.072072072  1.7264652061  0.3010482788  750           0.0717301130 
0.9789789790  0.9880952381  0.9939939940  1.0000000000  0.9669669670  0.9523809524  0.9759759760  0.9642857143  0.6858513189  76.876876876  1.6766301107  0.3010482788  800           0.0796280813 
1.0000000000  1.0000000000  0.9849849850  0.9880952381  0.9699699700  0.9642857143  0.9759759760  0.9880952381  0.7218225420  81.681681681  1.5803231382  0.3010482788  850           0.0731159830 
1.0000000000  0.9880952381  0.9849849850  0.9880952381  0.9609609610  0.9642857143  0.9789789790  0.9880952381  0.7290167866  86.486486486  1.5186508799  0.3010482788  900           0.0764582396 
0.9849849850  1.0000000000  0.9939939940  0.9880952381  0.9759759760  0.9761904762  0.9759759760  0.9642857143  0.7146282974  91.291291291  1.5173865867  0.3010482788  950           0.0758577061 
0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.9699699700  0.9642857143  0.9789789790  0.9642857143  0.7577937650  96.096096096  1.4157104850  0.3010482788  1000          0.0728429365 
0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.9699699700  0.9642857143  0.9789789790  0.9642857143  0.7529976019  100.90090090  1.3140375710  0.3010482788  1050          0.0706133890 
0.9879879880  1.0000000000  1.0000000000  1.0000000000  0.9759759760  0.9642857143  0.9819819820  0.9761904762  0.7553956835  105.70570570  1.2387204254  0.3039946556  1100          0.0705889130 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9819819820  0.9761904762  0.7673860911  110.51051051  1.1704908812  0.3039946556  1150          0.0717255974 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9789789790  0.9642857143  0.9849849850  0.9642857143  0.7434052758  115.31531531  1.1280173779  0.3039946556  1200          0.0739036560 
0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.9819819820  0.9761904762  0.9819819820  0.9761904762  0.7673860911  120.12012012  1.0551979434  0.3039946556  1250          0.0707237148 
0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.9789789790  0.9761904762  0.9819819820  0.9761904762  0.7625899281  124.92492492  1.0527500296  0.3039946556  1300          0.0705969429 
0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.9789789790  0.9761904762  0.9819819820  0.9761904762  0.7865707434  129.72972972  1.0124651337  0.3039946556  1350          0.0706439114 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9849849850  1.0000000000  0.7673860911  134.53453453  0.9651005459  0.3039946556  1400          0.0707447481 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9761904762  0.9849849850  1.0000000000  0.7649880096  139.33933933  0.9193993008  0.3039946556  1450          0.0714947462 
0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.9759759760  0.9880952381  0.9849849850  0.9761904762  0.7889688249  144.14414414  0.9070028484  0.3039946556  1500          0.0715251827 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9761904762  0.9849849850  1.0000000000  0.7841726619  148.94894894  0.8559397471  0.3039946556  1550          0.0712712574 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9761904762  0.9849849850  1.0000000000  0.7793764988  153.75375375  0.8690715277  0.3039946556  1600          0.0710502100 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9849849850  1.0000000000  0.7841726619  158.55855855  0.8689223468  0.3039946556  1650          0.0705524302 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9761904762  0.9849849850  1.0000000000  0.7721822542  163.36336336  0.8178929913  0.3039946556  1700          0.0717276812 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9761904762  0.9879879880  1.0000000000  0.7745803357  168.16816816  0.8042319095  0.3039946556  1750          0.0717296982 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9849849850  1.0000000000  0.7913669065  172.97297297  0.7615747118  0.3039946556  1800          0.0717478609 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9879879880  1.0000000000  0.7745803357  177.77777777  0.7577397490  0.3039946556  1850          0.0697091579 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9761904762  0.9879879880  1.0000000000  0.7889688249  182.58258258  0.7340666032  0.3039946556  1900          0.0694002438 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.7937649880  187.38738738  0.7467365336  0.3039946556  1950          0.0737434959 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9879879880  1.0000000000  0.7961630695  192.19219219  0.7373940885  0.3039946556  2000          0.0722749424 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9879879880  1.0000000000  0.7985611511  196.99699699  0.7127379441  0.3039946556  2050          0.0738593340 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9909909910  1.0000000000  0.7937649880  201.80180180  0.6936899757  0.3039946556  2100          0.0755613422 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.7937649880  206.60660660  0.6772580677  0.3039946556  2150          0.0721043396 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9909909910  1.0000000000  0.7817745803  211.41141141  0.6735678887  0.3039946556  2200          0.0750336599 
Process Process-3361:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 251, in _bootstrap
    util._run_after_forkers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 132, in _run_after_forkers
    func(obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 70, in _after_fork
    self._buffer = collections.deque()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
RuntimeError: DataLoader worker (pid 940768) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2245, in update
    feat_a = self.featurizer(x_subset_a)  # 提取特征
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 263, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 260, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
Python 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.16.1 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.16.1

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
We've got an error while stopping in post-mortem: <class 'RuntimeError'>

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3273273273  0.3452380952  0.3453453453  0.2976190476  0.3393393393  0.3809523810  0.3663663664  0.2976190476  0.3141486811  0.0000000000  4.1691751480  0.1362590790  0             0.3714001179 
0.5585585586  0.5595238095  0.5435435435  0.5833333333  0.6006006006  0.5595238095  0.5525525526  0.5119047619  0.5179856115  4.8048048048  3.4465367222  0.3009815216  50            0.0692501020 
0.8198198198  0.7500000000  0.7597597598  0.7619047619  0.7567567568  0.7380952381  0.7387387387  0.7738095238  0.6594724221  9.6096096096  3.1036493635  0.3009815216  100           0.0699606895 
0.8468468468  0.7857142857  0.7807807808  0.8095238095  0.7927927928  0.8452380952  0.7597597598  0.7738095238  0.6978417266  14.414414414  2.6700954723  0.3010077477  150           0.0692440319 
0.9459459459  0.8571428571  0.9189189189  0.8690476190  0.9339339339  0.9047619048  0.9069069069  0.8809523810  0.6450839329  19.219219219  2.2164985037  0.3010077477  200           0.0691809130 
0.9459459459  0.9285714286  0.9189189189  0.9166666667  0.9189189189  0.9404761905  0.9459459459  0.9404761905  0.6690647482  24.024024024  1.9897999597  0.3010077477  250           0.0702279568 
0.9609609610  0.9166666667  0.9639639640  0.9523809524  0.9609609610  0.9523809524  0.9609609610  0.9404761905  0.6378896882  28.828828828  1.8790452003  0.3010077477  300           0.0677084446 
0.9849849850  0.9880952381  0.9759759760  0.9404761905  0.9549549550  0.9523809524  0.9579579580  0.9880952381  0.7577937650  33.633633633  1.7464350224  0.3010077477  350           0.0690996790 
0.9939939940  0.9880952381  0.9939939940  0.9880952381  0.9789789790  0.9761904762  0.9669669670  0.9642857143  0.7002398082  38.438438438  1.5622580028  0.3010077477  400           0.0696277094 
0.9819819820  0.9880952381  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9759759760  0.9880952381  0.7218225420  43.243243243  1.4059067416  0.3010077477  450           0.0687589502 
0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.9849849850  0.9880952381  0.9789789790  0.9761904762  0.7745803357  48.048048048  1.2195420170  0.3010077477  500           0.0749776173 
0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.9789789790  0.9880952381  0.9819819820  0.9761904762  0.7817745803  52.852852852  1.1600080550  0.3010077477  550           0.0722629261 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9849849850  0.9880952381  0.7721822542  57.657657657  1.0328184891  0.3010087013  600           0.0706835222 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9761904762  0.9849849850  1.0000000000  0.7673860911  62.462462462  0.9393255830  0.3010087013  650           0.0698287916 
0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.9819819820  0.9761904762  0.7913669065  67.267267267  0.8744890440  0.3010087013  700           0.0686177588 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9879879880  1.0000000000  0.7985611511  72.072072072  0.8328259575  0.3010087013  750           0.0695244503 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9879879880  1.0000000000  0.7769784173  76.876876876  0.8208126652  0.3010087013  800           0.0702506065 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9909909910  1.0000000000  0.8033573141  81.681681681  0.7459381759  0.3010087013  850           0.0702225542 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9880952381  0.9909909910  1.0000000000  0.8009592326  86.486486486  0.7034655780  0.3010087013  900           0.0689159107 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9849849850  0.9880952381  0.9909909910  1.0000000000  0.7889688249  91.291291291  0.7322770858  0.3010087013  950           0.0711385822 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.8153477218  96.096096096  0.6839206511  0.3010087013  1000          0.0749586916 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9909909910  1.0000000000  0.8153477218  100.90090090  0.6508246917  0.3010087013  1050          0.0735400915 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8033573141  105.70570570  0.6003302521  0.3010087013  1100          0.0712559319 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8297362110  110.51051051  0.5840520114  0.3831143379  1150          0.0776546478 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.8177458034  115.31531531  0.5762964201  0.3831143379  1200          0.0715843058 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8201438849  120.12012012  0.5408309394  0.3831143379  1250          0.0699561596 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8105515588  124.92492492  0.5487986284  0.3831143379  1300          0.0727910566 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8081534772  129.72972972  0.5444092369  0.3831143379  1350          0.0708742380 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8177458034  134.53453453  0.5184372568  0.3831143379  1400          0.0694512224 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8129496403  139.33933933  0.4993008792  0.3831143379  1450          0.0752517271 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  144.14414414  0.4927296770  0.3831143379  1500          0.0715814066 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8249400480  148.94894894  0.4648740262  0.3831143379  1550          0.0698318624 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8177458034  153.75375375  0.4692067158  0.3831143379  1600          0.0718341637 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8201438849  158.55855855  0.4866594434  0.3831143379  1650          0.0735038376 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8177458034  163.36336336  0.4561275399  0.3831143379  1700          0.0722527122 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.8153477218  168.16816816  0.4522093856  0.3831143379  1750          0.0728181553 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8105515588  172.97297297  0.4160290271  0.3831143379  1800          0.0737140226 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  177.77777777  0.4127950966  0.3831143379  1850          0.0710446405 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  182.58258258  0.4076599288  0.3831143379  1900          0.0731874943 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  187.38738738  0.4137580043  0.3831143379  1950          0.0714662409 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  192.19219219  0.4060379571  0.3831143379  2000          0.0699867201 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  196.99699699  0.4049234915  0.3831143379  2050          0.0711897230 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  201.80180180  0.3828464365  0.3831143379  2100          0.0705447006 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  206.60660660  0.3676526743  0.3831143379  2150          0.0711925650 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  211.41141141  0.3772488469  0.3831143379  2200          0.0726724863 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  216.21621621  0.3722112370  0.3831143379  2250          0.0741217709 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 5e-05
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3423423423  0.3333333333  0.3483483483  0.3452380952  0.3483483483  0.3809523810  0.3573573574  0.3333333333  0.3237410072  0.0000000000  3.4921488762  0.1006202698  0             0.3566794395 
0.7807807808  0.7500000000  0.7267267267  0.7023809524  0.6936936937  0.7380952381  0.6756756757  0.7142857143  0.6450839329  4.8048048048  3.0070328808  0.2653822899  50            0.0564993048 
0.9429429429  0.9047619048  0.8798798799  0.8214285714  0.9159159159  0.8452380952  0.8948948949  0.8571428571  0.6666666667  9.6096096096  2.0441871548  0.2654218674  100           0.0585264969 
0.9849849850  0.9642857143  0.9639639640  0.9047619048  0.9639639640  0.9404761905  0.9519519520  0.9404761905  0.7074340528  14.414414414  1.2552096224  0.2654218674  150           0.0577915573 
0.9969969970  0.9880952381  0.9969969970  0.9761904762  0.9879879880  0.9761904762  0.9759759760  0.9880952381  0.7362110312  19.219219219  0.7520537364  0.2654218674  200           0.0584385633 
0.9939939940  0.9880952381  1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9879879880  0.9880952381  0.7745803357  24.024024024  0.4505660599  0.2654218674  250           0.0573361826 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  0.9880952381  0.7841726619  28.828828828  0.2878997576  0.2654218674  300           0.0578891706 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.7961630695  33.633633633  0.1847189148  0.2654218674  350           0.0583473015 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8009592326  38.438438438  0.1435150175  0.2654218674  400           0.0581694365 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.7985611511  43.243243243  0.0951125567  0.2654218674  450           0.0584469175 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8249400480  48.048048048  0.0776061222  0.2654218674  500           0.0592714453 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8201438849  52.852852852  0.0650199831  0.2654218674  550           0.0583823586 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8249400480  57.657657657  0.0585843179  0.2654218674  600           0.0634144831 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  62.462462462  0.0431013520  0.2654218674  650           0.0595302534 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  67.267267267  0.0369557550  0.3474879265  700           0.0623823452 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  72.072072072  0.0341545150  0.3474879265  750           0.0618379116 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  76.876876876  0.0312534545  0.3474879265  800           0.0619624043 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  81.681681681  0.0202912377  0.3474879265  850           0.0610476875 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  86.486486486  0.0211400222  0.3474879265  900           0.0604447937 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  91.291291291  0.0188657624  0.3474879265  950           0.0594104958 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  96.096096096  0.0204988732  0.3474879265  1000          0.0588983202 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  100.90090090  0.0156088630  0.3474879265  1050          0.0576060104 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  105.70570570  0.0152955465  0.3474879265  1100          0.0658187008 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  110.51051051  0.0128112326  0.3474879265  1150          0.0614230442 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  115.31531531  0.0095504775  0.3474879265  1200          0.0617064667 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  120.12012012  0.0089210156  0.3474879265  1250          0.0582670450 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  124.92492492  0.0091100154  0.3474879265  1300          0.0582000303 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 54, in _cleanup
    for p in list(_children):
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
Traceback (most recent call last):
KeyboardInterrupt
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Process Process-2017:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 251, in _bootstrap
    util._run_after_forkers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 132, in _run_after_forkers
    func(obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/_atfork.py", line 10, in wrapper
    func()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3363363363  0.3214285714  0.3363363363  0.3333333333  0.3453453453  0.3809523810  0.3513513514  0.3095238095  0.3117505995  0.0000000000  4.1691751480  0.1362590790  0             0.3809275627 
0.7627627628  0.6785714286  0.7237237237  0.7619047619  0.7027027027  0.7142857143  0.7177177177  0.7380952381  0.6570743405  4.8048048048  3.2839341259  0.3010210991  50            0.0685029888 
0.9159159159  0.8571428571  0.8528528529  0.7976190476  0.8978978979  0.8690476190  0.8348348348  0.8095238095  0.6594724221  9.6096096096  2.5807648230  0.3010606766  100           0.0698945045 
0.9549549550  0.9285714286  0.9519519520  0.9523809524  0.9309309309  0.9523809524  0.9519519520  0.8928571429  0.6906474820  14.414414414  1.9958175421  0.3010606766  150           0.0700409842 
0.9789789790  0.9880952381  1.0000000000  0.9880952381  0.9759759760  0.9642857143  0.9699699700  0.9642857143  0.7026378897  19.219219219  1.7324245858  0.3010606766  200           0.0698327971 
0.9909909910  1.0000000000  0.9969969970  0.9880952381  0.9819819820  0.9642857143  0.9759759760  0.9880952381  0.7577937650  24.024024024  1.4373813152  0.3010606766  250           0.0704568815 
0.9879879880  1.0000000000  0.9969969970  1.0000000000  0.9759759760  0.9761904762  0.9789789790  0.9642857143  0.7482014388  28.828828828  1.1785397518  0.3010606766  300           0.0711307049 
0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.9879879880  0.9880952381  0.9849849850  0.9880952381  0.7889688249  33.633633633  0.9999413776  0.3011002541  350           0.0703079653 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9849849850  0.9880952381  0.9939939940  1.0000000000  0.8177458034  38.438438438  0.8475340343  0.3011002541  400           0.0694736576 
0.9969969970  0.9880952381  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9879879880  0.9880952381  0.7721822542  43.243243243  0.7668225563  0.3011002541  450           0.0705415344 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.9969969970  1.0000000000  0.7913669065  48.048048048  0.6867687428  0.3011002541  500           0.0702195549 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.8153477218  52.852852852  0.6834018707  0.3011002541  550           0.0702956009 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  1.0000000000  0.8033573141  57.657657657  0.6204713082  0.3011002541  600           0.0704150677 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.8201438849  62.462462462  0.5648245960  0.3011002541  650           0.0701373148 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8105515588  67.267267267  0.5399548823  0.3011002541  700           0.0701934719 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8249400480  72.072072072  0.5200025713  0.3011002541  750           0.0697079468 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8201438849  76.876876876  0.5122470641  0.3011002541  800           0.0693787861 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8369304556  81.681681681  0.4512804824  0.3011002541  850           0.0711956692 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8273381295  86.486486486  0.4421906406  0.3011002541  900           0.0702060795 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8249400480  91.291291291  0.4524114609  0.3025765419  950           0.0705585527 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  96.096096096  0.4227277517  0.3025765419  1000          0.0698499060 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  100.90090090  0.4018379641  0.3025765419  1050          0.0691785145 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  105.70570570  0.3775233096  0.3025765419  1100          0.0701500130 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  110.51051051  0.3625123087  0.3025765419  1150          0.0719664431 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  115.31531531  0.3643690324  0.3025765419  1200          0.0706768417 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  120.12012012  0.3390604761  0.3025765419  1250          0.0730371189 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  124.92492492  0.3393623528  0.3025765419  1300          0.0711217737 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  129.72972972  0.3362743381  0.3025765419  1350          0.0733304501 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  134.53453453  0.3140573531  0.3025765419  1400          0.0721001768 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  139.33933933  0.3051062316  0.3025765419  1450          0.0734100056 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  144.14414414  0.3062582099  0.3025765419  1500          0.0716659737 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  148.94894894  0.2870496938  0.3025765419  1550          0.0711436319 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  153.75375375  0.2776716805  0.3025765419  1600          0.0717288780 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 300, in <module>
    for x, y in next(train_minibatches_iterator)]
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/fast_data_loader.py", line 46, in __iter__
    yield next(self._infinite_iterator)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 996, in _try_get_data
    self._mark_worker_as_unavailable(worker_id)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1252, in _mark_worker_as_unavailable
    assert self._workers_done_event.is_set() == shutdown
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 339, in is_set
    with self._cond:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 230, in __enter__
    return self._lock.__enter__()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3663663664  0.3809523810  0.3663663664  0.3571428571  0.3723723724  0.3809523810  0.3843843844  0.3928571429  0.3645083933  0.0000000000  4.1691751480  0.1362590790  0             0.3791818619 
0.8318318318  0.8571428571  0.7867867868  0.7857142857  0.7837837838  0.8095238095  0.8168168168  0.8690476190  0.7721822542  4.8048048048  2.7271537542  0.3009815216  50            0.0698711872 
0.9459459459  0.9642857143  0.9939939940  0.9880952381  0.9579579580  0.9761904762  0.9669669670  0.9404761905  0.7314148681  9.6096096096  1.8295705128  0.3009815216  100           0.0694566965 
0.9849849850  1.0000000000  0.9969969970  1.0000000000  0.9699699700  1.0000000000  0.9789789790  0.9761904762  0.7697841727  14.414414414  1.0599432361  0.3009815216  150           0.0695696831 
0.9879879880  1.0000000000  0.9939939940  1.0000000000  0.9819819820  1.0000000000  0.9909909910  0.9880952381  0.7985611511  19.219219219  0.7969184756  0.3009815216  200           0.0708596230 
0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.9849849850  1.0000000000  0.9969969970  1.0000000000  0.8105515588  24.024024024  0.6221577644  0.3009815216  250           0.0685769367 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8393285372  28.828828828  0.5585305560  0.3010087013  300           0.0698511600 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8393285372  33.633633633  0.4749856043  0.3010087013  350           0.0690082550 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.7769784173  38.438438438  0.3850373217  0.3010401726  400           0.0699809599 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  43.243243243  0.3518450779  0.3010482788  450           0.0699818087 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7769784173  48.048048048  0.3325044823  0.3010482788  500           0.0710523510 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7985611511  52.852852852  0.2930658710  0.3010482788  550           0.0705401516 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  57.657657657  0.2635090172  0.3010482788  600           0.0738204384 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  62.462462462  0.2233482309  0.3010482788  650           0.0788475561 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7314148681  67.267267267  0.2352813622  0.3010482788  700           0.0749240732 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  72.072072072  0.2070733584  0.3010482788  750           0.0735689783 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  76.876876876  0.1994281736  0.3010482788  800           0.0701666021 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  81.681681681  0.1827604070  0.3010482788  850           0.0689773655 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8129496403  86.486486486  0.1822651437  0.3010482788  900           0.0698076344 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  91.291291291  0.1717225276  0.3010482788  950           0.0704361820 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  96.096096096  0.1566555956  0.3010482788  1000          0.0707475710 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8393285372  100.90090090  0.1585121809  0.3831529617  1050          0.0704468679 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  105.70570570  0.1294615169  0.3831529617  1100          0.0707551861 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  110.51051051  0.1322575165  0.3831529617  1150          0.0733155441 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.00025
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3423423423  0.3690476190  0.3483483483  0.3452380952  0.3513513514  0.3809523810  0.3573573574  0.3690476190  0.3453237410  0.0000000000  4.1691751480  0.1362590790  0             0.3707835674 
0.8618618619  0.8809523810  0.8258258258  0.8452380952  0.8258258258  0.8452380952  0.8408408408  0.8571428571  0.6690647482  4.8048048048  2.9363549137  0.3009815216  50            0.0699618292 
0.9849849850  0.9761904762  0.9729729730  0.9404761905  0.9759759760  0.9285714286  0.9729729730  0.9523809524  0.7098321343  9.6096096096  1.9990593791  0.3009815216  100           0.0710790253 
0.9789789790  1.0000000000  0.9969969970  1.0000000000  0.9699699700  0.9880952381  0.9849849850  0.9761904762  0.7697841727  14.414414414  1.4418642998  0.3009815216  150           0.0716908693 
0.9819819820  1.0000000000  0.9909909910  1.0000000000  0.9789789790  1.0000000000  0.9819819820  0.9761904762  0.7985611511  19.219219219  1.0358907068  0.3009815216  200           0.0704568100 
0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.8273381295  24.024024024  0.8126255083  0.3009815216  250           0.0700627279 
0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.8177458034  28.828828828  0.7161678159  0.3009815216  300           0.0698315287 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.8345323741  33.633633633  0.6400956976  0.3010210991  350           0.0698565292 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.7793764988  38.438438438  0.5334466934  0.3010210991  400           0.0700694227 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.7889688249  43.243243243  0.4961981332  0.3010210991  450           0.0703132820 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.7913669065  48.048048048  0.4323091006  0.3010606766  500           0.0706516027 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  52.852852852  0.4291091779  0.3010606766  550           0.0720093966 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  57.657657657  0.3932036787  0.3010606766  600           0.0691833687 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  62.462462462  0.3490888676  0.3010606766  650           0.0692918682 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  67.267267267  0.3457362494  0.3010606766  700           0.0707638884 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8297362110  72.072072072  0.3148139879  0.3010606766  750           0.0711157703 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  76.876876876  0.3087602714  0.3010606766  800           0.0700766706 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  81.681681681  0.2815265483  0.3010606766  850           0.0782838488 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 17, in __init__
    util._flush_std_streams()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 401, in _flush_std_streams
    sys.stderr.flush()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 224, in flush
    self.file.flush()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4504504505  0.4642857143  0.4264264264  0.4761904762  0.3993993994  0.5238095238  0.4504504505  0.4642857143  0.4172661871  0.0000000000  3.4921488762  0.1006202698  0             0.3657009602 
0.9909909910  1.0000000000  0.9939939940  0.9880952381  0.9969969970  0.9880952381  0.9789789790  0.9761904762  0.7601918465  4.8048048048  1.2545544520  0.2653427124  50            0.0570732260 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8657074341  9.6096096096  0.0965055919  0.2653427124  100           0.0587097406 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  14.414414414  0.0292798307  0.2653427124  150           0.0580608797 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  19.219219219  0.0114652273  0.2653427124  200           0.0576260567 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  24.024024024  0.0060895695  0.2653427124  250           0.0585345030 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  28.828828828  0.0047632658  0.2653822899  300           0.0585658741 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  33.633633633  0.0034723533  0.2653822899  350           0.0583850479 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  38.438438438  0.0029562550  0.2673482895  400           0.0596009064 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  43.243243243  0.0018840953  0.2673482895  450           0.0573827553 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  48.048048048  0.0015674701  0.2673482895  500           0.0585745287 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  52.852852852  0.0013198026  0.2673482895  550           0.0586152220 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  57.657657657  0.0013473405  0.2673482895  600           0.0602121449 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 17, in __init__
    util._flush_std_streams()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 397, in _flush_std_streams
    sys.stdout.flush()
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 223, in flush
    self.stdout.flush()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
RuntimeError: DataLoader worker (pid 1215020) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4504504505  0.4642857143  0.4264264264  0.4761904762  0.3993993994  0.5238095238  0.4504504505  0.4642857143  0.4172661871  0.0000000000  3.4921488762  0.1006202698  0             0.5033063889 
0.6546546547  0.6666666667  0.6306306306  0.6309523810  0.6636636637  0.6547619048  0.6186186186  0.5714285714  0.5635491607  0.9609609610  2.8385457754  0.1811370850  10            0.0590654135 
0.9339339339  0.9047619048  0.8798798799  0.8809523810  0.8948948949  0.8928571429  0.8648648649  0.8333333333  0.6498800959  1.9219219219  1.6543617964  0.1812162399  20            0.0560576916 
0.9879879880  0.9761904762  0.9249249249  0.9404761905  0.9279279279  0.9166666667  0.9639639640  0.8928571429  0.7553956835  2.8828828829  0.9752202928  0.1812162399  30            0.0580380440 
0.9849849850  1.0000000000  0.9909909910  0.9642857143  0.9699699700  0.9880952381  0.9639639640  0.9523809524  0.6930455635  3.8438438438  0.5520647079  0.1812434196  40            0.0575298071 
0.9909909910  1.0000000000  0.9969969970  0.9880952381  0.9789789790  1.0000000000  0.9879879880  0.9761904762  0.7889688249  4.8048048048  0.3472187892  0.1812653542  50            0.0582345247 
0.9939939940  1.0000000000  1.0000000000  0.9880952381  0.9879879880  1.0000000000  0.9879879880  0.9761904762  0.8057553957  5.7657657658  0.1768664196  0.1812653542  60            0.0581578732 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  0.9880952381  0.7721822542  6.7267267267  0.0868169703  0.1812653542  70            0.0578284740 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.8249400480  7.6876876877  0.0680745738  0.1812653542  80            0.0581838846 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.8153477218  8.6486486486  0.0773728877  0.1812653542  90            0.0598622322 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8824940048  9.6096096096  0.0982819734  0.1812653542  100           0.0583103418 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  10.570570570  0.0467427235  0.2632822990  110           0.0583544254 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  0.9880952381  0.8513189448  11.531531531  0.0642275026  0.2632822990  120           0.0586708784 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8201438849  12.492492492  0.0417473421  0.2653822899  130           0.0595592737 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  13.453453453  0.0215160406  0.2653822899  140           0.0594557047 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  14.414414414  0.0181674037  0.2653822899  150           0.0588123322 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  15.375375375  0.0188629547  0.2653822899  160           0.0577932358 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  16.336336336  0.0150988961  0.2653822899  170           0.0581156015 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  17.297297297  0.0109300389  0.2653822899  180           0.0565480471 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  18.258258258  0.0137525554  0.2653822899  190           0.0578169107 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  19.219219219  0.0123369309  0.2653822899  200           0.0605165720 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  20.180180180  0.0069717512  0.2653822899  210           0.0587336779 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  21.141141141  0.0052967514  0.2653822899  220           0.0592592955 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  22.102102102  0.0033454072  0.2653822899  230           0.0604372025 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  23.063063063  0.0052744410  0.2653822899  240           0.0577321768 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  24.024024024  0.0039285931  0.2653822899  250           0.0584422350 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  24.984984985  0.0035898007  0.2653822899  260           0.0594558001 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  25.945945945  0.0030574341  0.2653822899  270           0.0589561224 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  26.906906906  0.0040274263  0.2653822899  280           0.0577377081 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  27.867867867  0.0022193364  0.2653822899  290           0.0588644981 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  28.828828828  0.0052930346  0.2653822899  300           0.0607181311 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  29.789789789  0.0031635165  0.2653822899  310           0.0596773386 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  30.750750750  0.0035622468  0.2653822899  320           0.0593494654 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  31.711711711  0.0023863406  0.2653822899  330           0.0587252617 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  32.672672672  0.0017070806  0.2653822899  340           0.0582919121 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  33.633633633  0.0022410556  0.2653822899  350           0.0590354919 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  34.594594594  0.0010453854  0.2653822899  360           0.0576783657 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  35.555555555  0.0019957203  0.2653822899  370           0.0592942953 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  36.516516516  0.0014032998  0.2653822899  380           0.0590824127 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  37.477477477  0.0030355479  0.2653822899  390           0.0573347807 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  38.438438438  0.0016692017  0.2653822899  400           0.0578062773 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  39.399399399  0.0035229938  0.2653822899  410           0.0578990221 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  40.360360360  0.0050351492  0.2653822899  420           0.0577736616 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  41.321321321  0.0024126483  0.2653822899  430           0.0575754404 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  42.282282282  0.0018545538  0.2653822899  440           0.0642940521 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  43.243243243  0.0014775327  0.2653822899  450           0.0580765247 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  44.204204204  0.0022339725  0.2653822899  460           0.0593720198 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  45.165165165  0.0019914726  0.2653822899  470           0.0574822664 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  46.126126126  0.0022189293  0.2653822899  480           0.0563146353 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  47.087087087  0.0020872934  0.2653822899  490           0.0603044033 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  48.048048048  0.0029110247  0.2653822899  500           0.0567948580 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  49.009009009  0.0031502287  0.2653822899  510           0.0584595680 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  49.969969970  0.0018836019  0.2653822899  520           0.0582563877 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  50.930930930  0.0017701861  0.2653822899  530           0.0569683790 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  51.891891891  0.0016046784  0.2653822899  540           0.0571706772 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  52.852852852  0.0009981858  0.2653822899  550           0.0584077835 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  53.813813813  0.0008003710  0.2653822899  560           0.0593752623 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  54.774774774  0.0005950199  0.2653822899  570           0.0568788528 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  55.735735735  0.0006476985  0.2653822899  580           0.0572868347 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  56.696696696  0.0006565567  0.2653822899  590           0.0574570179 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  57.657657657  0.0015488527  0.2653822899  600           0.0566517115 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  58.618618618  0.0079213811  0.2653822899  610           0.0598519087 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  59.579579579  0.0022875879  0.2653822899  620           0.0578641415 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  60.540540540  0.0025703322  0.2653822899  630           0.0594548464 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  61.501501501  0.0022631015  0.2653822899  640           0.0575530291 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  62.462462462  0.0031454117  0.2653822899  650           0.0582246780 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  63.423423423  0.0014716976  0.2653822899  660           0.0586476803 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7314148681  64.384384384  0.0092592671  0.2653822899  670           0.0571834803 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  65.345345345  0.0019653924  0.2653822899  680           0.0647256136 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  66.306306306  0.0032395381  0.2653822899  690           0.0592115164 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  67.267267267  0.0009094421  0.2653822899  700           0.0585025549 
0.9729729730  0.9880952381  0.9639639640  0.9642857143  0.9639639640  0.9642857143  0.9789789790  0.9880952381  0.7793764988  68.228228228  0.0159497942  0.2653822899  710           0.0574004650 
1.0000000000  1.0000000000  1.0000000000  0.9642857143  0.9939939940  1.0000000000  0.9909909910  0.9642857143  0.7146282974  69.189189189  0.0454236392  0.2653822899  720           0.0561128855 
0.9969969970  1.0000000000  1.0000000000  0.9761904762  0.9909909910  0.9880952381  0.9849849850  0.9761904762  0.7050359712  70.150150150  0.0335725038  0.2653822899  730           0.0569586754 
0.9969969970  1.0000000000  0.9969969970  0.9880952381  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8537170264  71.111111111  0.0592211777  0.2653822899  740           0.0571150064 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8489208633  72.072072072  0.0216362788  0.2653822899  750           0.0586141825 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  73.033033033  0.0140796483  0.2653822899  760           0.0576347113 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  73.993993994  0.0049805068  0.2653822899  770           0.0573721409 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  74.954954955  0.0044086189  0.2653822899  780           0.0576353073 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  75.915915915  0.0024569520  0.2653822899  790           0.0578558922 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  76.876876876  0.0010700433  0.2653822899  800           0.0574918032 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  77.837837837  0.0014279837  0.2653822899  810           0.0568150759 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  78.798798798  0.0011604317  0.2653822899  820           0.0557593822 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  79.759759759  0.0031907537  0.2653822899  830           0.0572371721 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  80.720720720  0.0007091919  0.2653822899  840           0.0580610752 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  81.681681681  0.0007171583  0.2653822899  850           0.0561781883 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  82.642642642  0.0009792637  0.2653822899  860           0.0578186035 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  83.603603603  0.0012814269  0.2653822899  870           0.0566874504 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  84.564564564  0.0007197695  0.2653822899  880           0.0570241451 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  85.525525525  0.0006233148  0.2653822899  890           0.0565078259 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  86.486486486  0.0005644591  0.2653822899  900           0.0586296320 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  87.447447447  0.0004109625  0.2653822899  910           0.0584965229 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  88.408408408  0.0002821103  0.2653822899  920           0.0629507780 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  89.369369369  0.0003979054  0.2653822899  930           0.0584596634 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  90.330330330  0.0008750623  0.2653822899  940           0.0586245775 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  91.291291291  0.0007533610  0.2653822899  950           0.0580171108 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  92.252252252  0.0008690508  0.2653822899  960           0.0570053339 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  93.213213213  0.0004404966  0.2653822899  970           0.0572557688 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  94.174174174  0.0004690201  0.2653822899  980           0.0596444368 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  95.135135135  0.0003566739  0.2653822899  990           0.0585845232 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  96.096096096  0.0005186119  0.2653822899  1000          0.0573237181 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  97.057057057  0.0004240543  0.2653822899  1010          0.0598790646 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  98.018018018  0.0010960382  0.2653822899  1020          0.0604123354 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  98.978978979  0.0007382384  0.2653822899  1030          0.0573135853 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  99.939939939  0.0005640630  0.2653822899  1040          0.0577034473 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  100.90090090  0.0005240911  0.2653822899  1050          0.0586934566 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  101.86186186  0.0003577232  0.2653822899  1060          0.0585582495 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  102.82282282  0.0002527342  0.2653822899  1070          0.0581117392 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  103.78378378  0.0002611144  0.2653822899  1080          0.0541038036 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  104.74474474  0.0003273932  0.2653822899  1090          0.0568901062 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  105.70570570  0.0004306130  0.2653822899  1100          0.0582745075 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  106.66666666  0.0017944205  0.2653822899  1110          0.0580625534 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  107.62762762  0.0002927418  0.2653822899  1120          0.0562431812 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  108.58858858  0.0007171285  0.2653822899  1130          0.0573932886 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  109.54954954  0.0007593739  0.2653822899  1140          0.0593611479 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  110.51051051  0.0003342264  0.2653822899  1150          0.0570900917 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  111.47147147  0.0009598181  0.2653822899  1160          0.0572558403 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  112.43243243  0.0012891586  0.2653822899  1170          0.0631785870 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  113.39339339  0.0004684262  0.2653822899  1180          0.0583930254 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  114.35435435  0.0004467094  0.2653822899  1190          0.0624902248 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  115.31531531  0.0003382564  0.2653822899  1200          0.0609740019 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  116.27627627  0.0002114170  0.2653822899  1210          0.0631480455 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  117.23723723  0.0004176350  0.2653822899  1220          0.0595744610 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  118.19819819  0.0015478147  0.2653822899  1230          0.0600701094 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  119.15915915  0.0023823692  0.2653822899  1240          0.0599575043 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  120.12012012  0.0009282878  0.2653822899  1250          0.0579786062 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  121.08108108  0.0005123040  0.2653822899  1260          0.0587167025 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  122.04204204  0.0003740237  0.2653822899  1270          0.0588524580 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  123.00300300  0.0007023868  0.2653822899  1280          0.0596895933 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  123.96396396  0.0002179927  0.2653822899  1290          0.0581178665 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  124.92492492  0.0005883703  0.2653822899  1300          0.0573305845 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  125.88588588  0.0004317041  0.2653822899  1310          0.0574230909 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  126.84684684  0.0002158612  0.2653822899  1320          0.0568534851 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  127.80780780  0.0007803950  0.2653822899  1330          0.0584017515 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  128.76876876  0.0002547917  0.2653822899  1340          0.0580416203 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  129.72972972  0.0002634856  0.2653822899  1350          0.0565462351 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  130.69069069  0.0005227139  0.2653822899  1360          0.0569486380 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  131.65165165  0.0002068727  0.2653822899  1370          0.0600112200 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  132.61261261  0.0004501916  0.2653822899  1380          0.0601298094 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  133.57357357  0.0003167386  0.2653822899  1390          0.0588651180 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  134.53453453  0.0001957532  0.2653822899  1400          0.0588219166 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  135.49549549  0.0005239031  0.2653822899  1410          0.0581833601 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  136.45645645  0.0004003477  0.2653822899  1420          0.0592530251 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  137.41741741  0.0003276906  0.2653822899  1430          0.0580302954 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  138.37837837  0.0001628984  0.2653822899  1440          0.0568374395 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  139.33933933  0.0004034623  0.2653822899  1450          0.0587646246 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  140.30030030  0.0002134412  0.2653822899  1460          0.0591645241 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  141.26126126  0.0003042719  0.2653822899  1470          0.0571174145 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  142.22222222  0.0001820214  0.2653822899  1480          0.0598637104 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  143.18318318  0.0002049635  0.2653822899  1490          0.0559394836 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  144.14414414  0.0003038967  0.2653822899  1500          0.0583202124 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  145.10510510  0.0002075090  0.2653822899  1510          0.0584853888 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  146.06606606  0.0001941539  0.2653822899  1520          0.0579719543 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  147.02702702  0.0003937704  0.2653822899  1530          0.0607101202 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  147.98798798  0.0002465067  0.2653822899  1540          0.0589020729 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1233764) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1233865) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3573573574  0.3690476190  0.3543543544  0.3452380952  0.3633633634  0.3809523810  0.3693693694  0.3809523810  0.3621103118  0.0000000000  4.5507488251  0.1362590790  0             0.3740923405 
0.6096096096  0.5714285714  0.5645645646  0.5833333333  0.5855855856  0.5952380952  0.5825825826  0.5952380952  0.5251798561  0.9609609610  3.4261393070  0.3009815216  10            0.0711339951 
0.6156156156  0.5714285714  0.5975975976  0.5833333333  0.6156156156  0.6547619048  0.5915915916  0.6190476190  0.5275779376  1.9219219219  3.1475018263  0.3009815216  20            0.0680351257 
0.7057057057  0.7261904762  0.6846846847  0.7023809524  0.6816816817  0.7261904762  0.7117117117  0.7023809524  0.6474820144  2.8828828829  2.8621811867  0.3009815216  30            0.0728219032 
0.6876876877  0.6666666667  0.6846846847  0.6904761905  0.6756756757  0.6785714286  0.6846846847  0.6785714286  0.6306954436  3.8438438438  2.5605827093  0.3009815216  40            0.0716849327 
0.7447447447  0.7261904762  0.7297297297  0.7619047619  0.7267267267  0.7738095238  0.7327327327  0.7380952381  0.6594724221  4.8048048048  2.5083991766  0.3009815216  50            0.0695677757 
0.7777777778  0.8333333333  0.8108108108  0.8095238095  0.7657657658  0.7619047619  0.8138138138  0.8333333333  0.7649880096  5.7657657658  2.3839138031  0.3009815216  60            0.0698336363 
0.9129129129  0.8571428571  0.8378378378  0.8214285714  0.8408408408  0.8095238095  0.8828828829  0.8452380952  0.7865707434  6.7267267267  2.3806453943  0.3009815216  70            0.0752425671 
0.8468468468  0.9166666667  0.8378378378  0.8690476190  0.8288288288  0.8571428571  0.8408408408  0.9404761905  0.7673860911  7.6876876877  2.1363974452  0.3009815216  80            0.0713289738 
0.8438438438  0.9047619048  0.8528528529  0.9166666667  0.8348348348  0.8690476190  0.8468468468  0.9166666667  0.7194244604  8.6486486486  2.1492321491  0.3009815216  90            0.0705123663 
0.9669669670  0.9642857143  0.9369369369  0.9285714286  0.9159159159  0.9404761905  0.9549549550  0.9404761905  0.8513189448  9.6096096096  1.9214813828  0.3009815216  100           0.0702016115 
0.9729729730  0.9285714286  0.9489489489  0.9166666667  0.9309309309  0.9523809524  0.9579579580  0.9523809524  0.8297362110  10.570570570  1.6452738881  0.3009815216  110           0.0687505245 
0.9549549550  0.9523809524  0.9879879880  0.9880952381  0.9669669670  0.9642857143  0.9759759760  0.9880952381  0.7745803357  11.531531531  1.6899080515  0.3009815216  120           0.0696442604 
0.9429429429  0.9642857143  0.9819819820  0.9880952381  0.9549549550  0.9523809524  0.9549549550  0.9404761905  0.7146282974  12.492492492  1.4404498339  0.3009815216  130           0.0695088148 
0.9549549550  0.9642857143  0.9849849850  1.0000000000  0.9489489489  0.9523809524  0.9489489489  0.9523809524  0.7002398082  13.453453453  1.2433794618  0.3009815216  140           0.0699054956 
0.9729729730  1.0000000000  0.9879879880  1.0000000000  0.9729729730  0.9880952381  0.9819819820  0.9880952381  0.8009592326  14.414414414  1.1942362249  0.3009815216  150           0.0707381487 
0.9819819820  0.9880952381  0.9849849850  1.0000000000  0.9729729730  0.9880952381  0.9789789790  0.9880952381  0.7889688249  15.375375375  1.1196822286  0.3009815216  160           0.0697045326 
0.9849849850  1.0000000000  0.9849849850  0.9761904762  0.9729729730  1.0000000000  0.9879879880  0.9880952381  0.8561151079  16.336336336  1.0815256119  0.3009815216  170           0.0715675592 
0.9849849850  1.0000000000  0.9909909910  1.0000000000  0.9819819820  1.0000000000  0.9879879880  0.9880952381  0.8201438849  17.297297297  0.9685730398  0.3009815216  180           0.0699985504 
0.9849849850  1.0000000000  0.9909909910  0.9880952381  0.9699699700  1.0000000000  0.9879879880  1.0000000000  0.8465227818  18.258258258  0.9799587846  0.3009815216  190           0.0712962627 
0.9849849850  1.0000000000  0.9849849850  0.9404761905  0.9669669670  1.0000000000  0.9819819820  0.9880952381  0.7865707434  19.219219219  0.9878238738  0.3009815216  200           0.0694459677 
0.9819819820  1.0000000000  0.9939939940  0.9880952381  0.9849849850  1.0000000000  0.9759759760  0.9880952381  0.7721822542  20.180180180  0.9762387991  0.3009815216  210           0.0670523882 
0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.9759759760  1.0000000000  0.9849849850  1.0000000000  0.8513189448  21.141141141  0.9434235692  0.3009815216  220           0.0725160360 
0.9729729730  1.0000000000  1.0000000000  1.0000000000  0.9849849850  1.0000000000  0.9879879880  0.9761904762  0.8009592326  22.102102102  0.7439344704  0.3009815216  230           0.0709764242 
0.9969969970  1.0000000000  0.9939939940  1.0000000000  0.9909909910  1.0000000000  0.9909909910  0.9880952381  0.8249400480  23.063063063  0.7473595917  0.3009815216  240           0.0721553802 
1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.8369304556  24.024024024  0.7797266364  0.3009815216  250           0.0724630356 
1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9849849850  1.0000000000  0.9909909910  1.0000000000  0.8561151079  24.984984985  0.7747309804  0.3009815216  260           0.0769463301 
0.9819819820  1.0000000000  1.0000000000  1.0000000000  0.9879879880  1.0000000000  0.9879879880  0.9642857143  0.8033573141  25.945945945  0.7202388972  0.3009815216  270           0.0725956202 
0.9849849850  1.0000000000  1.0000000000  1.0000000000  0.9879879880  1.0000000000  0.9909909910  0.9761904762  0.8033573141  26.906906906  0.6875023186  0.3009815216  280           0.0704086065 
0.9939939940  1.0000000000  0.9909909910  0.9642857143  0.9819819820  1.0000000000  0.9969969970  1.0000000000  0.7985611511  27.867867867  0.6897794008  0.3009815216  290           0.0747407198 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.8273381295  28.828828828  0.6782708764  0.3009815216  300           0.0689133406 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9909909910  0.9880952381  0.8153477218  29.789789789  0.6259030163  0.3009815216  310           0.0760012388 
0.9909909910  1.0000000000  0.9909909910  0.9642857143  0.9819819820  1.0000000000  1.0000000000  1.0000000000  0.7505995204  30.750750750  0.6664405406  0.3009815216  320           0.0729313850 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.8369304556  31.711711711  0.5773043185  0.3009815216  330           0.0689466715 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9909909910  0.9880952381  0.8273381295  32.672672672  0.6365811825  0.3009815216  340           0.0729458094 
0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8057553957  33.633633633  0.5873327106  0.3009815216  350           0.0713214397 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.8417266187  34.594594594  0.5669027865  0.3009815216  360           0.0682850361 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  1.0000000000  0.9880952381  0.7793764988  35.555555555  0.5558205187  0.3009815216  370           0.0697195768 
1.0000000000  1.0000000000  0.9939939940  0.9761904762  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.7841726619  36.516516516  0.5018803000  0.3009815216  380           0.0729805231 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9939939940  0.9880952381  0.8057553957  37.477477477  0.4680601150  0.3009815216  390           0.0696602106 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.8417266187  38.438438438  0.4654721618  0.3009815216  400           0.0692528486 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7745803357  39.399399399  0.4727013588  0.3009815216  410           0.0712475061 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  40.360360360  0.4540455788  0.3009815216  420           0.0771513700 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.8249400480  41.321321321  0.4708061635  0.3009815216  430           0.0804064989 
0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7649880096  42.282282282  0.4064472228  0.3009815216  440           0.0800754547 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8393285372  43.243243243  0.4681708246  0.3009815216  450           0.0798505306 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.7985611511  44.204204204  0.4701032579  0.3009815216  460           0.0737688541 
1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.7889688249  45.165165165  0.4688433737  0.3009815216  470           0.0706784010 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.8441247002  46.126126126  0.4084177464  0.3009815216  480           0.0704159260 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7745803357  47.087087087  0.4461731374  0.3009815216  490           0.0721857071 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 379, in select
    for fd, event in fd_event_list:
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3813813814  0.4047619048  0.3753753754  0.3690476190  0.3663663664  0.4047619048  0.3813813814  0.3690476190  0.3741007194  0.0000000000  3.7876014709  0.1362590790  0             0.3654057980 
0.6156156156  0.5357142857  0.6276276276  0.6190476190  0.6066066066  0.6309523810  0.5825825826  0.5595238095  0.5971223022  0.9609609610  3.2100347519  0.2167758942  10            0.0712339640 
0.7297297297  0.7023809524  0.7087087087  0.6785714286  0.6966966967  0.7142857143  0.6906906907  0.6785714286  0.6354916067  1.9219219219  2.5021423101  0.2168154716  20            0.0683113098 
0.8048048048  0.8095238095  0.7867867868  0.8333333333  0.7777777778  0.8095238095  0.7927927928  0.7857142857  0.6402877698  2.8828828829  2.0239626765  0.2169094086  30            0.0682346106 
0.9789789790  0.9523809524  0.9639639640  0.9404761905  0.9459459459  0.9880952381  0.9429429429  0.9523809524  0.6762589928  3.8438438438  1.6426208496  0.2169365883  40            0.0714364529 
0.9729729730  0.9880952381  0.9819819820  1.0000000000  0.9699699700  0.9880952381  0.9699699700  0.9404761905  0.7266187050  4.8048048048  1.3973973989  0.2990641594  50            0.0695168734 
0.9789789790  1.0000000000  0.9969969970  1.0000000000  0.9789789790  0.9761904762  0.9699699700  0.9642857143  0.7122302158  5.7657657658  1.2662235498  0.2990641594  60            0.0700906515 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9759759760  0.9642857143  0.7170263789  6.7267267267  1.1079765320  0.2990641594  70            0.0718128443 
0.9789789790  0.9761904762  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9819819820  0.9761904762  0.7505995204  7.6876876877  0.9448431969  0.2990641594  80            0.0697400808 
0.9789789790  0.9880952381  1.0000000000  1.0000000000  0.9849849850  0.9761904762  0.9669669670  0.9642857143  0.7170263789  8.6486486486  0.8881347716  0.2990641594  90            0.0697192907 
0.9879879880  1.0000000000  0.9939939940  0.9880952381  0.9789789790  1.0000000000  0.9849849850  0.9880952381  0.8009592326  9.6096096096  0.7447792113  0.2990641594  100           0.0669939041 
0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.9849849850  0.9880952381  0.9849849850  0.9880952381  0.8441247002  10.570570570  0.7180210769  0.2990641594  110           0.0697948456 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  0.9642857143  0.7937649880  11.531531531  0.7243438005  0.2990818024  120           0.0702864170 
0.9909909910  1.0000000000  0.9909909910  1.0000000000  0.9969969970  0.9880952381  0.9909909910  0.9880952381  0.7865707434  12.492492492  0.6211710781  0.3010754585  130           0.0685808897 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
KeyboardInterrupt
Traceback (most recent call last):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 379, in select
    for fd, event in fd_event_list:
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1530382) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3813813814  0.4047619048  0.3753753754  0.3690476190  0.3663663664  0.4047619048  0.3813813814  0.3690476190  0.3741007194  0.0000000000  3.7876014709  0.1362590790  0             0.3759825230 
0.6156156156  0.5357142857  0.6276276276  0.6190476190  0.6066066066  0.6309523810  0.5825825826  0.5595238095  0.5971223022  0.9609609610  3.2100347519  0.2167758942  10            0.0762702227 
0.7297297297  0.7023809524  0.7087087087  0.6785714286  0.6966966967  0.7142857143  0.6906906907  0.6785714286  0.6354916067  1.9219219219  2.5021423101  0.2168154716  20            0.0701556444 
0.8048048048  0.8095238095  0.7867867868  0.8333333333  0.7777777778  0.8095238095  0.7927927928  0.7857142857  0.6402877698  2.8828828829  2.0239626765  0.2168946266  30            0.0711534262 
0.9789789790  0.9523809524  0.9639639640  0.9404761905  0.9459459459  0.9880952381  0.9429429429  0.9523809524  0.6762589928  3.8438438438  1.6426208496  0.2168946266  40            0.0699138165 
0.9729729730  0.9880952381  0.9819819820  1.0000000000  0.9699699700  0.9880952381  0.9699699700  0.9404761905  0.7266187050  4.8048048048  1.3973973989  0.3010606766  50            0.0741684437 
0.9789789790  1.0000000000  0.9969969970  1.0000000000  0.9789789790  0.9761904762  0.9699699700  0.9642857143  0.7122302158  5.7657657658  1.2662235498  0.3010606766  60            0.0731424332 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9879879880  0.9880952381  0.9759759760  0.9642857143  0.7170263789  6.7267267267  1.1079765320  0.3010606766  70            0.0697248936 
0.9789789790  0.9761904762  1.0000000000  1.0000000000  0.9819819820  0.9761904762  0.9819819820  0.9761904762  0.7505995204  7.6876876877  0.9448431969  0.3010606766  80            0.0802076578 
0.9789789790  0.9880952381  1.0000000000  1.0000000000  0.9849849850  0.9761904762  0.9669669670  0.9642857143  0.7170263789  8.6486486486  0.8881347716  0.3010606766  90            0.0727807045 
0.9879879880  1.0000000000  0.9939939940  0.9880952381  0.9789789790  1.0000000000  0.9849849850  0.9880952381  0.8009592326  9.6096096096  0.7447792113  0.3010606766  100           0.0760286808 
0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.9849849850  0.9880952381  0.9849849850  0.9880952381  0.8441247002  10.570570570  0.7180210769  0.3010606766  110           0.0703929186 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  0.9642857143  0.7937649880  11.531531531  0.7243438005  0.3010606766  120           0.0685771465 
0.9909909910  1.0000000000  0.9909909910  1.0000000000  0.9969969970  0.9880952381  0.9909909910  0.9880952381  0.7865707434  12.492492492  0.6211710781  0.3010606766  130           0.0758720875 
0.9849849850  0.9880952381  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9849849850  0.9761904762  0.7529976019  13.453453453  0.6464831710  0.3010606766  140           0.0727594376 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9879879880  1.0000000000  0.9939939940  1.0000000000  0.8345323741  14.414414414  0.6124601573  0.3010606766  150           0.0718513966 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9849849850  1.0000000000  0.9969969970  1.0000000000  0.8393285372  15.375375375  0.5440822244  0.3010606766  160           0.0705646038 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8345323741  16.336336336  0.4755040079  0.3014264107  170           0.0709991693 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9909909910  1.0000000000  0.8177458034  17.297297297  0.4569428384  0.3014264107  180           0.0721796513 
1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  1.0000000000  0.9909909910  1.0000000000  0.8441247002  18.258258258  0.4562720448  0.3014264107  190           0.0699170828 
1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.7937649880  19.219219219  0.4502814949  0.3014264107  200           0.0708323717 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.8033573141  20.180180180  0.4281932920  0.3014264107  210           0.0696280003 
1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.8153477218  21.141141141  0.4441852808  0.3014264107  220           0.0682752609 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9879879880  0.9880952381  0.8177458034  22.102102102  0.3497088313  0.3014264107  230           0.0697819471 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.7889688249  23.063063063  0.3558552533  0.3014264107  240           0.0701248407 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  24.024024024  0.3626658320  0.3014264107  250           0.0721988440 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  24.984984985  0.3177789539  0.3014264107  260           0.0702980995 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  1.0000000000  1.0000000000  0.8465227818  25.945945945  0.3328168690  0.3014264107  270           0.0687272549 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.8249400480  26.906906906  0.3317523196  0.3014264107  280           0.0710228205 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  27.867867867  0.3038305327  0.3014264107  290           0.0716072798 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  28.828828828  0.3175955117  0.3014264107  300           0.0695854187 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.8369304556  29.789789789  0.2984764710  0.3014264107  310           0.0728228807 
0.9939939940  1.0000000000  0.9969969970  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7362110312  30.750750750  0.3661136657  0.3014264107  320           0.0712552071 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8609112710  31.711711711  0.2924470335  0.3014264107  330           0.0703718662 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.8393285372  32.672672672  0.3133886531  0.3014264107  340           0.0701859236 
0.9939939940  1.0000000000  0.9969969970  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9761904762  0.7458033573  33.633633633  0.3075125456  0.3014264107  350           0.0686395645 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  34.594594594  0.2623903438  0.3014264107  360           0.0701252937 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  35.555555555  0.2494856298  0.3014264107  370           0.0690325260 
1.0000000000  1.0000000000  0.9939939940  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7673860911  36.516516516  0.2298736408  0.3014264107  380           0.0681254387 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.8225419664  37.477477477  0.2217534035  0.3014264107  390           0.0697155714 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  38.438438438  0.2138315514  0.3014264107  400           0.0725074291 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  39.399399399  0.2011975676  0.3014264107  410           0.0710977316 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  40.360360360  0.2163215384  0.3014264107  420           0.0702202559 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  41.321321321  0.2108550504  0.3014264107  430           0.0764146805 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7649880096  42.282282282  0.1832470119  0.3014264107  440           0.0699299574 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  43.243243243  0.2139745221  0.3014264107  450           0.0697480917 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  44.204204204  0.2231797069  0.3014264107  460           0.0706187248 
0.9969969970  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7673860911  45.165165165  0.2074701570  0.3014264107  470           0.0674754381 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  46.126126126  0.1645251229  0.3014264107  480           0.0700420618 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7889688249  47.087087087  0.2127428427  0.3014264107  490           0.0705203295 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  48.048048048  0.2378224343  0.3014264107  500           0.0687312365 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  49.009009009  0.2196087532  0.3014264107  510           0.0705684185 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7673860911  49.969969970  0.1863691874  0.3014264107  520           0.0715328693 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7649880096  50.930930930  0.1708654627  0.3014264107  530           0.0705745697 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  51.891891891  0.1958784878  0.3014264107  540           0.0682926893 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7505995204  52.852852852  0.2115959212  0.3014264107  550           0.0738747120 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8153477218  53.813813813  0.1835398011  0.3014264107  560           0.0704686165 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7649880096  54.774774774  0.1656050004  0.3014264107  570           0.0698981524 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  55.735735735  0.1344794057  0.3014264107  580           0.0683243990 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  56.696696696  0.2221384555  0.3014264107  590           0.0700002432 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  57.657657657  0.1667584896  0.3014264107  600           0.0693858624 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  58.618618618  0.1910471015  0.3014264107  610           0.0708645582 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  59.579579579  0.1519435920  0.3014264107  620           0.0699447393 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  60.540540540  0.1678934112  0.3014264107  630           0.0708903790 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  61.501501501  0.1691828430  0.3014264107  640           0.0710059166 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  62.462462462  0.1521919213  0.3014264107  650           0.0728703499 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  63.423423423  0.1664850913  0.3014264107  660           0.0710927963 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  64.384384384  0.1663589843  0.3014264107  670           0.0704272747 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  65.345345345  0.1562940739  0.3014264107  680           0.0711020470 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  66.306306306  0.1383594342  0.3014264107  690           0.0718435526 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  67.267267267  0.1658144318  0.3014264107  700           0.0695420980 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  68.228228228  0.1617264047  0.3014264107  710           0.0695977688 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7721822542  69.189189189  0.1153099529  0.3014264107  720           0.0695374489 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  70.150150150  0.1505651854  0.3014264107  730           0.0691526413 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  71.111111111  0.1433020622  0.3014264107  740           0.0699809313 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  72.072072072  0.1577634647  0.3014264107  750           0.0698108196 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  73.033033033  0.1440773495  0.3014264107  760           0.0693106651 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  73.993993994  0.1219002254  0.3014264107  770           0.0701718569 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  74.954954955  0.1240531221  0.3014264107  780           0.0693466425 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  75.915915915  0.1137226112  0.3014264107  790           0.0685937881 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  76.876876876  0.1223130502  0.3014264107  800           0.0699244499 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  77.837837837  0.1304777071  0.3014264107  810           0.0688848734 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7625899281  78.798798798  0.1304930441  0.3014264107  820           0.0719625950 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  79.759759759  0.1350219406  0.3014264107  830           0.0692412138 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  80.720720720  0.1096058331  0.3014264107  840           0.0700641394 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  81.681681681  0.1134945892  0.3014264107  850           0.0680664539 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7553956835  82.642642642  0.1334478170  0.3014264107  860           0.0697442770 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  83.603603603  0.1246926904  0.3014264107  870           0.0702080965 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  84.564564564  0.1363132901  0.3014264107  880           0.0698790073 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  85.525525525  0.1342590988  0.3014264107  890           0.0710889816 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  86.486486486  0.0994562164  0.3014264107  900           0.0713145971 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  87.447447447  0.1080683611  0.3014264107  910           0.0728837013 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  88.408408408  0.1135989189  0.3014264107  920           0.0701324940 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  89.369369369  0.1067436419  0.3014264107  930           0.0724018812 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  90.330330330  0.0816455513  0.3014264107  940           0.0728158712 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  91.291291291  0.1091167711  0.3014264107  950           0.0755460978 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  92.252252252  0.1238872379  0.3014264107  960           0.0719659328 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  93.213213213  0.1149837010  0.3014264107  970           0.0689251423 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7769784173  94.174174174  0.1292496353  0.3014264107  980           0.0720742464 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1663554) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3603603604  0.3095238095  0.3303303303  0.3452380952  0.3243243243  0.3809523810  0.3843843844  0.3333333333  0.3525179856  0.0000000000  29.457105636  0.1364407539  0             0.3770308495 
0.2672672673  0.2619047619  0.2612612613  0.2738095238  0.2582582583  0.2500000000  0.2612612613  0.2619047619  0.2517985612  0.9609609610  25.663141250  0.2169971466  10            0.0917165756 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1668550) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3663663664  0.3809523810  0.3663663664  0.3571428571  0.3723723724  0.3809523810  0.3843843844  0.3928571429  0.3645083933  0.0000000000  4.1691751480  0.1362590790  0             0.3996522427 
0.5705705706  0.5000000000  0.5405405405  0.5833333333  0.5435435435  0.6071428571  0.5375375375  0.5952380952  0.5035971223  0.9609609610  3.3498735905  0.2167801857  10            0.0726267815 
0.6966966967  0.6666666667  0.6846846847  0.7023809524  0.6726726727  0.6547619048  0.6786786787  0.6904761905  0.6642685851  1.9219219219  2.9874842167  0.2167801857  20            0.0728148937 
0.7207207207  0.7023809524  0.7117117117  0.7142857143  0.6996996997  0.7500000000  0.7147147147  0.7261904762  0.6450839329  2.8828828829  2.6491803408  0.2167801857  30            0.0813217163 
0.8288288288  0.8095238095  0.7807807808  0.7619047619  0.7477477477  0.8214285714  0.7657657658  0.8214285714  0.6954436451  3.8438438438  2.3034854889  0.2167801857  40            0.0800111294 
0.8228228228  0.8809523810  0.8018018018  0.8214285714  0.7837837838  0.8333333333  0.7987987988  0.8333333333  0.7146282974  4.8048048048  2.1609346509  0.2167801857  50            0.0695173264 
0.8438438438  0.9047619048  0.8228228228  0.8571428571  0.7957957958  0.8690476190  0.8318318318  0.8928571429  0.7266187050  5.7657657658  2.0905420542  0.2183313370  60            0.0717669010 
0.9789789790  0.9523809524  0.9459459459  0.9285714286  0.9429429429  1.0000000000  0.9489489489  0.9404761905  0.7577937650  6.7267267267  1.9839095354  0.2183313370  70            0.0746208191 
0.9609609610  0.9880952381  0.9759759760  1.0000000000  0.9489489489  0.9523809524  0.9609609610  0.9642857143  0.7266187050  7.6876876877  1.7151875377  0.2183313370  80            0.0707088470 
0.9609609610  0.9404761905  0.9909909910  0.9880952381  0.9549549550  0.9404761905  0.9519519520  0.9285714286  0.7146282974  8.6486486486  1.6410006881  0.2988815308  90            0.0755282640 
0.9819819820  0.9761904762  0.9849849850  0.9761904762  0.9609609610  1.0000000000  0.9789789790  0.9642857143  0.8153477218  9.6096096096  1.4429527760  0.2988815308  100           0.1062060833 
0.9879879880  0.9880952381  0.9669669670  0.9880952381  0.9489489489  0.9880952381  0.9699699700  0.9761904762  0.8441247002  10.570570570  1.2785310268  0.2988815308  110           0.0779846668 
0.9549549550  0.9404761905  0.9939939940  0.9761904762  0.9579579580  0.9642857143  0.9609609610  0.9642857143  0.7410071942  11.531531531  1.2904828787  0.2988815308  120           0.0872050524 
0.9549549550  0.9404761905  0.9849849850  0.9761904762  0.9579579580  0.9404761905  0.9549549550  0.9523809524  0.7218225420  12.492492492  1.0659728706  0.2988815308  130           0.0700902224 
0.9669669670  0.9761904762  1.0000000000  1.0000000000  0.9789789790  0.9642857143  0.9849849850  0.9761904762  0.7697841727  13.453453453  1.0319798946  0.2988815308  140           0.0777149916 
0.9759759760  0.9880952381  0.9849849850  1.0000000000  0.9669669670  0.9761904762  0.9879879880  1.0000000000  0.7817745803  14.414414414  1.0069133162  0.2988815308  150           0.0879049063 
0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.9729729730  1.0000000000  0.9909909910  1.0000000000  0.8321342926  15.375375375  0.9142256021  0.2988815308  160           0.0732411623 
0.9909909910  1.0000000000  0.9879879880  1.0000000000  0.9789789790  1.0000000000  0.9939939940  1.0000000000  0.8393285372  16.336336336  0.8739203513  0.2988815308  170           0.0930244207 
0.9879879880  1.0000000000  0.9969969970  1.0000000000  0.9819819820  0.9880952381  0.9879879880  0.9880952381  0.8153477218  17.297297297  0.7526595950  0.2988815308  180           0.0751479387 
0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.9819819820  1.0000000000  0.9939939940  1.0000000000  0.8033573141  18.258258258  0.7754632115  0.2988815308  190           0.0704197884 
0.9969969970  1.0000000000  0.9909909910  0.9880952381  0.9819819820  1.0000000000  0.9909909910  1.0000000000  0.7937649880  19.219219219  0.7199685276  0.2988815308  200           0.0710059404 
0.9879879880  1.0000000000  0.9939939940  0.9880952381  0.9879879880  1.0000000000  0.9879879880  0.9880952381  0.7529976019  20.180180180  0.7748503268  0.2988815308  210           0.0689925194 
1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9849849850  0.9880952381  0.9909909910  1.0000000000  0.8561151079  21.141141141  0.7616698623  0.2988815308  220           0.0693477869 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9879879880  1.0000000000  0.8465227818  22.102102102  0.6261387676  0.2988815308  230           0.0718811989 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.7769784173  23.063063063  0.6060076505  0.2988815308  240           0.0738268614 
0.9969969970  1.0000000000  0.9909909910  0.9880952381  0.9879879880  1.0000000000  0.9939939940  1.0000000000  0.7721822542  24.024024024  0.6654802799  0.2988815308  250           0.0724548340 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9909909910  1.0000000000  0.8537170264  24.984984985  0.6209604800  0.2988815308  260           0.0691790342 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.8177458034  25.945945945  0.5633886129  0.2988815308  270           0.0747038126 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9879879880  1.0000000000  0.9939939940  0.9642857143  0.8201438849  26.906906906  0.5416626006  0.2988815308  280           0.0745417356 
1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9879879880  1.0000000000  0.9969969970  1.0000000000  0.7769784173  27.867867867  0.5242991567  0.2988815308  290           0.0688914061 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.8033573141  28.828828828  0.5601733506  0.2988815308  300           0.0701959372 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9939939940  1.0000000000  0.8273381295  29.789789789  0.5246633172  0.2988815308  310           0.0684837818 
0.9969969970  1.0000000000  0.9939939940  1.0000000000  0.9909909910  1.0000000000  1.0000000000  0.9880952381  0.7458033573  30.750750750  0.5613691092  0.2988815308  320           0.0699950218 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.8321342926  31.711711711  0.4472785950  0.2989606857  330           0.0717325449 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.8321342926  32.672672672  0.5170543492  0.2989606857  340           0.0673909426 
1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7841726619  33.633633633  0.4936005950  0.2989606857  350           0.0702981949 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.8033573141  34.594594594  0.4221125841  0.2989606857  360           0.0736337423 
Process Process-2788:
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 104, in start
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 24, in poll
    def poll(self, flag=os.WNOHANG):
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 246, in _bootstrap
    util._close_stdin()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 384, in _close_stdin
    sys.stdin = open(fd, closefd=False)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/_bootlocale.py", line 23, in getpreferredencoding
    def getpreferredencoding(do_setlocale=True):
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4024024024  0.4047619048  0.3993993994  0.3928571429  0.3903903904  0.4285714286  0.4294294294  0.4047619048  0.3645083933  0.0000000000  3.3767423630  0.1124811172  0             0.3751068115 
0.6276276276  0.6666666667  0.6366366366  0.6904761905  0.6546546547  0.7023809524  0.6516516517  0.5952380952  0.5395683453  0.9609609610  2.9375675917  0.2772035599  10            0.0702136278 
0.8708708709  0.8095238095  0.8348348348  0.8333333333  0.8318318318  0.8571428571  0.8318318318  0.7976190476  0.6163069544  1.9219219219  3.6079352856  0.2772035599  20            0.0644220352 
0.9639639640  0.9880952381  0.9609609610  0.9404761905  0.9519519520  0.9642857143  0.9669669670  0.9642857143  0.6930455635  2.8828828829  3.7004127502  0.2772035599  30            0.0798237801 
0.9879879880  1.0000000000  0.9939939940  0.9880952381  0.9849849850  0.9880952381  0.9789789790  0.9761904762  0.6954436451  3.8438438438  2.8179028749  0.2772035599  40            0.0835656404 
0.9909909910  0.9880952381  0.9969969970  0.9880952381  0.9909909910  1.0000000000  0.9849849850  0.9642857143  0.7913669065  4.8048048048  2.7568251371  0.2772035599  50            0.0642882109 
0.9879879880  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9909909910  0.9761904762  0.7458033573  5.7657657658  2.6515820980  0.2772035599  60            0.0658970833 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9969969970  0.9880952381  0.8249400480  6.7267267267  2.5330177069  0.2772035599  70            0.0638180494 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  0.9939939940  0.9761904762  0.7817745803  7.6876876877  2.5321262121  0.2772035599  80            0.0655127287 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9909909910  0.9880952381  0.7985611511  8.6486486486  2.5625051737  0.2772035599  90            0.0649154425 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8369304556  9.6096096096  2.6634120703  0.2773089409  100           0.0675247669 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8129496403  10.570570570  2.7293447256  0.2773089409  110           0.0639765263 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8225419664  11.531531531  2.5607635975  0.2773089409  120           0.0637907267 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8081534772  12.492492492  2.5806509256  0.2773089409  130           0.0632143736 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8681055156  13.453453453  2.6719090700  0.2773089409  140           0.0618638992 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7913669065  14.414414414  2.7107406378  0.2773089409  150           0.0679560184 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  15.375375375  2.4859605551  0.2773089409  160           0.0627321482 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7865707434  16.336336336  2.5696827650  0.2773089409  170           0.0634335279 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  17.297297297  2.4850610256  0.2773089409  180           0.0645028353 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  18.258258258  2.6406853676  0.2773089409  190           0.0640616894 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8009592326  19.219219219  2.4913861990  0.2773089409  200           0.0641998053 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  20.180180180  2.5110122442  0.2773089409  210           0.0638806105 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  21.141141141  2.5222739935  0.2801971436  220           0.0646869898 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  22.102102102  2.6008724451  0.2801971436  230           0.0637755871 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  23.063063063  2.5252603769  0.2802276611  240           0.0676949978 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  24.024024024  2.6230669260  0.2802276611  250           0.0628734827 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  24.984984985  2.5375377655  0.2802276611  260           0.0656168938 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  25.945945945  2.5360597610  0.2802276611  270           0.0627158642 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  26.906906906  2.5462946653  0.2802276611  280           0.0648396254 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  27.867867867  2.4620305061  0.2802276611  290           0.0679165125 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  28.828828828  2.5584121943  0.2802276611  300           0.0677031755 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  29.789789789  2.5321614742  0.2802276611  310           0.0651124239 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  30.750750750  2.5842695951  0.2802276611  320           0.0630744219 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2310, in update
    theta_updated_new[k] = v - self.hparams['lr'] * grad_theta[k]
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0004
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4084084084  0.4166666667  0.4054054054  0.4047619048  0.3873873874  0.4166666667  0.4084084084  0.3809523810  0.3741007194  0.0000000000  3.3767423630  0.1124811172  0             0.3701758385 
0.6396396396  0.7023809524  0.6426426426  0.7261904762  0.6606606607  0.7261904762  0.6366366366  0.5952380952  0.5491606715  0.9609609610  2.9716331720  0.1929979324  10            0.0671969175 
0.8408408408  0.7619047619  0.7987987988  0.7976190476  0.8018018018  0.8452380952  0.7807807808  0.7500000000  0.6402877698  1.9219219219  3.2261207342  0.1930022240  20            0.0634090424 
0.9519519520  0.9642857143  0.9249249249  0.9166666667  0.9219219219  0.9523809524  0.9459459459  0.9523809524  0.6978417266  2.8828828829  4.0819198370  0.2751431465  30            0.0661455870 
0.9879879880  0.9880952381  0.9939939940  1.0000000000  0.9729729730  0.9761904762  0.9639639640  0.9642857143  0.6882494005  3.8438438438  3.5380309105  0.2751431465  40            0.0636427641 
0.9879879880  0.9880952381  0.9849849850  0.9761904762  0.9909909910  0.9880952381  0.9789789790  0.9642857143  0.7434052758  4.8048048048  2.8563418627  0.2751431465  50            0.0652227640 
0.9939939940  1.0000000000  1.0000000000  0.9880952381  0.9909909910  0.9880952381  0.9939939940  0.9523809524  0.7338129496  5.7657657658  2.8179199219  0.2751431465  60            0.0663859844 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9909909910  0.9880952381  0.9939939940  0.9642857143  0.7793764988  6.7267267267  2.7340066195  0.2751431465  70            0.0628971815 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9939939940  0.9761904762  0.7985611511  7.6876876877  2.7178317785  0.2772474289  80            0.0683597088 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  0.9880952381  0.8033573141  8.6486486486  2.6692653179  0.2772474289  90            0.0652622223 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.8009592326  9.6096096096  2.8194044828  0.2772474289  100           0.0651797056 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  10.570570570  2.7871747255  0.2772474289  110           0.0646836281 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  11.531531531  2.7090844393  0.2772474289  120           0.0653998613 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7985611511  12.492492492  2.7515547752  0.2772474289  130           0.0604207039 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8273381295  13.453453453  2.7411708593  0.2772474289  140           0.0664102793 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7889688249  14.414414414  2.8019080877  0.2772474289  150           0.0676099300 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  15.375375375  2.5968815327  0.2772474289  160           0.0648849010 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  16.336336336  2.6884774685  0.2772474289  170           0.0650487423 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  17.297297297  2.5400899649  0.2772474289  180           0.0661559582 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  18.258258258  2.7969792604  0.2772474289  190           0.0643109798 
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
Traceback (most recent call last):
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)

During handling of the above exception, another exception occurred:

KeyboardInterrupt
Traceback (most recent call last):

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1794492) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4744744745  0.4047619048  0.3993993994  0.3928571429  0.3993993994  0.4166666667  0.4444444444  0.3809523810  0.4100719424  0.0000000000  3.3767423630  0.1124811172  0             0.3673207760 
0.6066066066  0.6904761905  0.6126126126  0.6666666667  0.6096096096  0.6190476190  0.6126126126  0.5952380952  0.5851318945  0.9609609610  3.0765009880  0.2772078514  10            0.0675292969 
0.9519519520  0.9285714286  0.9399399399  0.9285714286  0.9249249249  0.9285714286  0.9339339339  0.9285714286  0.6714628297  1.9219219219  4.0674364805  0.2772078514  20            0.0615002871 
0.9879879880  1.0000000000  0.9819819820  0.9761904762  0.9639639640  0.9880952381  0.9699699700  0.9404761905  0.7242206235  2.8828828829  3.3744572639  0.2772078514  30            0.0650404692 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9819819820  1.0000000000  0.9759759760  0.9761904762  0.7362110312  3.8438438438  2.6635437965  0.2772078514  40            0.0617694139 
0.9939939940  1.0000000000  0.9969969970  0.9880952381  0.9729729730  1.0000000000  0.9939939940  0.9642857143  0.8153477218  4.8048048048  2.4556851864  0.2772078514  50            0.0630463123 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9909909910  0.9880952381  0.7889688249  5.7657657658  2.5123469591  0.2772078514  60            0.0638266087 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.8249400480  6.7267267267  2.4226014137  0.2772078514  70            0.0631999493 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9939939940  1.0000000000  0.8225419664  7.6876876877  2.5653443098  0.2772078514  80            0.0696640491 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.8057553957  8.6486486486  2.5828712940  0.2772078514  90            0.0632545233 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  1.0000000000  0.9880952381  0.7434052758  9.6096096096  2.6281367302  0.2772307396  100           0.0649249792 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8681055156  10.570570570  2.6943741322  0.2772307396  110           0.0659224033 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8249400480  11.531531531  2.5209914684  0.2772307396  120           0.0681143045 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8057553957  12.492492492  2.5483207941  0.2772307396  130           0.0649590492 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8537170264  13.453453453  2.6721225023  0.2772307396  140           0.0624500513 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7745803357  14.414414414  2.5782753944  0.2772307396  150           0.0613313675 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  15.375375375  2.4930061579  0.2772307396  160           0.0639730692 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  16.336336336  2.4572058916  0.2772307396  170           0.0738788366 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  17.297297297  2.5099909782  0.2772307396  180           0.0637336969 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  18.258258258  2.6459723711  0.2772307396  190           0.0642812014 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  19.219219219  2.3972676992  0.2772307396  200           0.0643267393 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  20.180180180  2.4101461649  0.2772307396  210           0.0635864258 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  21.141141141  2.5546662092  0.2772307396  220           0.0730390310 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  22.102102102  2.6334969997  0.2772307396  230           0.0641291142 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 940, in __init__
    self._reset(loader, first_iter=True)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 971, in _reset
    self._try_put_index()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1216, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 169, in _start_thread
    self._thread.start()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1828118) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
KeyboardInterrupt
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)

During handling of the above exception, another exception occurred:

  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
Traceback (most recent call last):
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 292, in _on_run
    r = self.sock.recv(1024)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
KeyboardInterrupt
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 296, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()

During handling of the above exception, another exception occurred:

AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 218, in run
    self._on_run()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1846, in _on_run
    return ReaderThread._on_run(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 328, in _on_run
    self.handle_except()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1849, in handle_except
    ReaderThread.handle_except(self)
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_comm.py", line 332, in handle_except
    self.global_debugger_holder.global_dbg.finish_debugging_session()
AttributeError: 'NoneType' object has no attribute 'finish_debugging_session'
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 379, in select
    for fd, event in fd_event_list:
Error in atexit._run_exitfuncs:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1829202) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3903903904  0.3928571429  0.4204204204  0.3928571429  0.3903903904  0.4047619048  0.3993993994  0.4166666667  0.4196642686  0.0000000000  3.4921488762  0.1006202698  0             0.3741042614 
0.6846846847  0.7619047619  0.7117117117  0.7619047619  0.6726726727  0.6547619048  0.6846846847  0.6666666667  0.6378896882  0.9609609610  2.7202381611  0.1812162399  10            0.0574610710 
0.9579579580  0.8928571429  0.8768768769  0.8452380952  0.8648648649  0.8095238095  0.8618618619  0.8571428571  0.6930455635  1.9219219219  1.3733841181  0.1812162399  20            0.0565108776 
0.9909909910  1.0000000000  0.9759759760  0.9761904762  0.9639639640  0.9880952381  0.9759759760  0.9761904762  0.7817745803  2.8828828829  0.7425490141  0.2632822990  30            0.0569928169 
0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.9789789790  0.9880952381  0.9849849850  1.0000000000  0.7889688249  3.8438438438  0.2706424311  0.2632822990  40            0.0570991278 
0.9909909910  1.0000000000  1.0000000000  0.9880952381  0.9939939940  0.9880952381  0.9849849850  0.9880952381  0.7817745803  4.8048048048  0.2347935170  0.2632822990  50            0.0571723461 
0.9969969970  1.0000000000  1.0000000000  0.9761904762  0.9909909910  1.0000000000  0.9969969970  1.0000000000  0.8345323741  5.7657657658  0.1522080105  0.2632822990  60            0.0587874174 
0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9879879880  0.9880952381  0.8465227818  6.7267267267  0.0665013015  0.2634105682  70            0.0601078749 
0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9969969970  1.0000000000  0.9939939940  1.0000000000  0.8129496403  7.6876876877  0.0366909198  0.2634105682  80            0.0591467857 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8393285372  8.6486486486  0.0475768209  0.2634105682  90            0.0578931093 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8057553957  9.6096096096  0.0335640792  0.2634105682  100           0.0552981615 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7817745803  10.570570570  0.0273397388  0.2634105682  110           0.0570398808 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  11.531531531  0.0309884275  0.2634105682  120           0.0577132463 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  12.492492492  0.0112792406  0.2634105682  130           0.0604475260 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  13.453453453  0.0060334907  0.2634105682  140           0.0601334572 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  14.414414414  0.0045871159  0.2634105682  150           0.0581657410 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  15.375375375  0.0175854167  0.2634105682  160           0.0579900503 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  16.336336336  0.0070511808  0.2634105682  170           0.0524548769 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  17.297297297  0.0041252159  0.2634105682  180           0.0577688217 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  18.258258258  0.0046367721  0.2634105682  190           0.0576769829 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  19.219219219  0.0053547160  0.2634105682  200           0.0565222263 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7985611511  20.180180180  0.0013057619  0.2634105682  210           0.0556120872 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8033573141  21.141141141  0.0028176363  0.2634105682  220           0.0589081287 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  22.102102102  0.0029910019  0.2634105682  230           0.0567941666 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4864864865  0.4404761905  0.3813813814  0.4166666667  0.3903903904  0.3809523810  0.3933933934  0.3928571429  0.3812949640  0.0000000000  3.7876014709  0.1362590790  0             0.3771862984 
0.5675675676  0.5833333333  0.5735735736  0.6309523810  0.6066066066  0.6309523810  0.5795795796  0.5476190476  0.4916067146  0.9609609610  3.1120489120  0.2167758942  10            0.0716868401 
0.7297297297  0.7619047619  0.7417417417  0.7500000000  0.7177177177  0.7619047619  0.7297297297  0.7619047619  0.6474820144  1.9219219219  2.4062811852  0.2168154716  20            0.0691095591 
0.8228228228  0.8809523810  0.8138138138  0.8571428571  0.8018018018  0.8333333333  0.8198198198  0.8333333333  0.7050359712  2.8828828829  2.1983133316  0.2168154716  30            0.0703993559 
0.9399399399  0.9166666667  0.9159159159  0.8571428571  0.8798798799  0.9166666667  0.9219219219  0.8928571429  0.7386091127  3.8438438438  1.7989762187  0.2989482880  40            0.0685962439 
0.9789789790  0.9880952381  0.9819819820  1.0000000000  0.9609609610  0.9761904762  0.9849849850  0.9761904762  0.7769784173  4.8048048048  1.3851122856  0.2989482880  50            0.0700031757 
0.9759759760  0.9880952381  0.9819819820  0.9642857143  0.9399399399  1.0000000000  0.9729729730  0.9642857143  0.7889688249  5.7657657658  1.2129240155  0.3830871582  60            0.0696933031 
0.9819819820  1.0000000000  1.0000000000  1.0000000000  0.9759759760  0.9880952381  0.9729729730  0.9880952381  0.8057553957  6.7267267267  1.0228148580  0.3830871582  70            0.0701500416 
0.9459459459  0.9523809524  0.9609609610  0.9642857143  0.9339339339  0.9166666667  0.9249249249  0.9404761905  0.7482014388  7.6876876877  0.8770158708  0.3830871582  80            0.0724064112 
0.9759759760  0.9761904762  0.9969969970  1.0000000000  0.9789789790  0.9761904762  0.9759759760  0.9761904762  0.8105515588  8.6486486486  0.7255817354  0.3830871582  90            0.0716813087 
0.9699699700  1.0000000000  0.9669669670  0.9404761905  0.9429429429  0.9880952381  0.9579579580  0.9642857143  0.7266187050  9.6096096096  0.6608740568  0.3830871582  100           0.0724587917 
0.9729729730  1.0000000000  0.9729729730  0.9880952381  0.9609609610  0.9880952381  0.9669669670  0.9761904762  0.8321342926  10.570570570  0.6939776719  0.3830871582  110           0.0699368477 
0.9789789790  1.0000000000  1.0000000000  0.9880952381  0.9639639640  1.0000000000  0.9549549550  0.9642857143  0.7170263789  11.531531531  0.6977034181  0.3830871582  120           0.0693886042 
0.9729729730  1.0000000000  0.9819819820  0.9880952381  0.9789789790  0.9642857143  0.9789789790  0.9642857143  0.8225419664  12.492492492  0.5993406504  0.3830871582  130           0.0709893703 
0.9699699700  0.9642857143  0.9939939940  0.9761904762  0.9789789790  0.9523809524  0.9789789790  0.9761904762  0.8009592326  13.453453453  0.5705497205  0.3830871582  140           0.0733172894 
0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.9849849850  1.0000000000  0.9939939940  1.0000000000  0.8417266187  14.414414414  0.5564896166  0.3830871582  150           0.0712983370 
0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.9879879880  1.0000000000  0.9939939940  0.9880952381  0.7721822542  15.375375375  0.4873056829  0.3830871582  160           0.0723123074 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9969969970  1.0000000000  0.8369304556  16.336336336  0.4092779398  0.3830871582  170           0.0733800411 
0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9879879880  1.0000000000  0.9939939940  0.9880952381  0.8345323741  17.297297297  0.3538570538  0.3830871582  180           0.0730125666 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.7745803357  18.258258258  0.3906266153  0.3830871582  190           0.0774948835 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.8033573141  19.219219219  0.3628371775  0.3830871582  200           0.0725613832 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9939939940  0.9880952381  0.7745803357  20.180180180  0.3433212608  0.3830871582  210           0.0797728777 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.9939939940  1.0000000000  0.9939939940  1.0000000000  0.8465227818  21.141141141  0.3862303659  0.3830871582  220           0.0721273661 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  1.0000000000  1.0000000000  0.8081534772  22.102102102  0.2843673036  0.3830871582  230           0.0718230963 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7841726619  23.063063063  0.3030440539  0.3830871582  240           0.0747813463 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  24.024024024  0.3036878794  0.3830871582  250           0.0825567245 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  24.984984985  0.2624367103  0.3830871582  260           0.0812554359 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  25.945945945  0.2856324524  0.3830871582  270           0.0718870878 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.7889688249  26.906906906  0.2582802638  0.3830871582  280           0.0697768450 
1.0000000000  1.0000000000  0.9969969970  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7697841727  27.867867867  0.2407782137  0.3830871582  290           0.0742339849 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  28.828828828  0.2515981868  0.3830871582  300           0.0711194038 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2173, in <module>
    main()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 2166, in main
    handle_keyboard_interrupt()
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1984, in handle_keyboard_interrupt
    traceback.print_exception(type(value), value, tb, limit=limit)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 104, in print_exception
    type(value), value, tb, limit=limit).format(chain=chain):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 509, in __init__
    capture_locals=capture_locals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 364, in extract
    f.line
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/traceback.py", line 286, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/linecache.py", line 137, in updatecache
    lines = fp.readlines()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/codecs.py", line 318, in decode
    def decode(self, input, final=False):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1865167) is killed by signal: Terminated. 
Exception ignored in: Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1865834) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.3333333333  0.3452380952  0.3213213213  0.3214285714  0.3153153153  0.3452380952  0.3783783784  0.3214285714  0.3453237410  0.0000000000  42.482643127  0.1364407539  0             0.3839037418 
0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2522522523  0.2500000000  0.2517985612  0.9609609610  35.854167938  0.3012027740  10            0.0764673233 
0.2522522523  0.2500000000  0.2582582583  0.2619047619  0.2552552553  0.2500000000  0.2552552553  0.2500000000  0.2517985612  1.9219219219  32.025280761  0.3012027740  20            0.0716479778 
0.3273273273  0.3095238095  0.3183183183  0.3214285714  0.3153153153  0.3214285714  0.3033033033  0.3214285714  0.3621103118  2.8828828829  30.046895599  0.3012027740  30            0.0739990234 
0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3741007194  3.8438438438  27.312397193  0.3012027740  40            0.0755197525 
0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3741007194  4.8048048048  28.497745513  0.3012027740  50            0.0753344774 
0.3753753754  0.3809523810  0.3633633634  0.3690476190  0.3753753754  0.3690476190  0.3603603604  0.3690476190  0.3741007194  5.7657657658  29.925490760  0.3012027740  60            0.0767691851 
0.3663663664  0.3690476190  0.3663663664  0.3809523810  0.3753753754  0.3690476190  0.3693693694  0.3690476190  0.3741007194  6.7267267267  34.120882797  0.3012027740  70            0.0810988426 
0.3723723724  0.3809523810  0.3693693694  0.3809523810  0.3753753754  0.3809523810  0.3723723724  0.3809523810  0.3741007194  7.6876876877  30.620415687  0.3012027740  80            0.0785962105 
0.3693693694  0.3690476190  0.3663663664  0.3809523810  0.3723723724  0.3809523810  0.3723723724  0.3809523810  0.3741007194  8.6486486486  33.064989471  0.3012027740  90            0.0788441896 
0.3693693694  0.3809523810  0.3693693694  0.3809523810  0.3693693694  0.3690476190  0.3723723724  0.3809523810  0.3717026379  9.6096096096  36.006239318  0.3012027740  100           0.0740144968 
0.3633633634  0.3809523810  0.3663663664  0.3690476190  0.3663663664  0.3690476190  0.3723723724  0.3690476190  0.3693045564  10.570570570  30.571313285  0.3012027740  110           0.0759226084 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2272, in update
    meta_train_loss_main += 50 * penalty   # 150 for coral
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  epoch         loss          mem_gb        step          step_time    
0.4054054054  0.4047619048  0.3903903904  0.4047619048  0.3843843844  0.4285714286  0.3993993994  0.3809523810  0.3741007194  0.0000000000  4.1875600815  0.1364407539  0             12.422362089 
0.5975975976  0.6309523810  0.6276276276  0.7142857143  0.6246246246  0.7023809524  0.6216216216  0.5833333333  0.5707434053  0.9609609610  3.6779251814  0.3011631966  10            0.0801753044 
0.8258258258  0.7619047619  0.7837837838  0.7857142857  0.7777777778  0.8452380952  0.7807807808  0.7738095238  0.6330935252  1.9219219219  2.6476779938  0.3011631966  20            0.0748711109 
0.9669669670  0.9642857143  0.9639639640  0.9166666667  0.9609609610  0.9642857143  0.9669669670  0.9404761905  0.7098321343  2.8828828829  2.0069718838  0.3011631966  30            0.0757597923 
0.9789789790  0.9761904762  0.9699699700  0.9523809524  0.9369369369  0.9642857143  0.9459459459  0.9285714286  0.7050359712  3.8438438438  1.5033633947  0.3011631966  40            0.0766072035 
0.9939939940  1.0000000000  0.9879879880  0.9880952381  0.9759759760  1.0000000000  0.9819819820  0.9761904762  0.7721822542  4.8048048048  1.2474737287  0.3011631966  50            0.0762165070 
0.9849849850  1.0000000000  1.0000000000  1.0000000000  0.9909909910  1.0000000000  0.9789789790  0.9761904762  0.7529976019  5.7657657658  1.1060650408  0.3011631966  60            0.0771569967 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9909909910  1.0000000000  0.8033573141  6.7267267267  0.9906211376  0.3011674881  70            0.0776650190 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9849849850  0.9642857143  0.7338129496  7.6876876877  0.9355612814  0.3011674881  80            0.0771688223 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.9939939940  1.0000000000  0.9939939940  0.9880952381  0.8081534772  8.6486486486  0.9550726533  0.3011674881  90            0.0771836519 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  1.0000000000  0.8393285372  9.6096096096  0.9414428651  0.3011674881  100           0.0840912819 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  1.0000000000  0.8417266187  10.570570570  0.9284559488  0.3011674881  110           0.0757486820 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.8225419664  11.531531531  0.9106850982  0.3011674881  120           0.0756162405 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  12.492492492  0.8704710603  0.3011674881  130           0.0766829729 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  13.453453453  0.8627232850  0.3011674881  140           0.0757461309 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  14.414414414  0.8639264107  0.3011674881  150           0.0765176535 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  15.375375375  0.8432847440  0.3011674881  160           0.0761722565 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8177458034  16.336336336  0.8200588644  0.3011674881  170           0.0770093441 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  17.297297297  0.8115268469  0.3011674881  180           0.0777972698 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  18.258258258  0.8321264267  0.3011674881  190           0.0755751133 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8081534772  19.219219219  0.8226090312  0.3011674881  200           0.0769019604 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8321342926  20.180180180  0.8190463603  0.3011674881  210           0.0759212494 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  21.141141141  0.8137397885  0.3011674881  220           0.0759648085 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  22.102102102  0.7516936421  0.3011674881  230           0.0749032736 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8585131894  23.063063063  0.7964643955  0.3011674881  240           0.0754782677 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8057553957  24.024024024  0.7817769527  0.3011674881  250           0.0757799387 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8681055156  24.984984985  0.7777915061  0.3011674881  260           0.0761134863 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8177458034  25.945945945  0.7839638591  0.3011674881  270           0.0731370687 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  26.906906906  0.8016359329  0.3011674881  280           0.0753217220 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  27.867867867  0.7484099925  0.3011674881  290           0.1021072865 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  28.828828828  0.7882260799  0.3011674881  300           0.0755403042 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  29.789789789  0.7325718939  0.3011674881  310           0.0749409676 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  30.750750750  0.7797769845  0.3833489418  320           0.0745324135 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  31.711711711  0.7137520134  0.3833489418  330           0.0743860722 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  32.672672672  0.7489146113  0.3833489418  340           0.0767823696 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  33.633633633  0.7331437349  0.3833489418  350           0.0746803522 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  34.594594594  0.7233889997  0.3833489418  360           0.0751481056 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  35.555555555  0.7187867403  0.3833489418  370           0.0747663021 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  36.516516516  0.7116939008  0.3833489418  380           0.0733345985 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8681055156  37.477477477  0.6792571247  0.3833489418  390           0.0746069670 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  38.438438438  0.6973567128  0.3833489418  400           0.0746968746 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  39.399399399  0.7044059753  0.3833489418  410           0.0756536961 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  40.360360360  0.7090021014  0.3833489418  420           0.0747892380 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  41.321321321  0.7291403890  0.3833489418  430           0.0747745275 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  42.282282282  0.6816034973  0.3833489418  440           0.0808361530 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8057553957  43.243243243  0.6873249769  0.3833489418  450           0.0759800673 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  44.204204204  0.7036276698  0.3833489418  460           0.0750130415 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  45.165165165  0.7439320445  0.3833489418  470           0.0716432333 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  46.126126126  0.6872000933  0.3833489418  480           0.0737995625 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  47.087087087  0.7348402083  0.3833489418  490           0.0746166468 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7913669065  48.048048048  0.7496925414  0.3833489418  500           0.0752194166 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  49.009009009  0.7411704004  0.3833489418  510           0.0748084784 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  49.969969970  0.6767477810  0.3833489418  520           0.0744976759 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  50.930930930  0.6811745703  0.3833489418  530           0.0770856857 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8417266187  51.891891891  0.6848295331  0.3833489418  540           0.0745777845 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  52.852852852  0.7730782151  0.3833489418  550           0.0746582747 
0.9879879880  0.9880952381  1.0000000000  0.9880952381  0.9879879880  1.0000000000  0.9909909910  0.9642857143  0.7026378897  53.813813813  0.7814980090  0.3833489418  560           0.0762657404 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  54.774774774  0.7607220769  0.3833489418  570           0.0751223326 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8609112710  55.735735735  0.6838793993  0.3833489418  580           0.0753193378 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  56.696696696  0.7600583732  0.3833489418  590           0.0764926910 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  57.657657657  0.6841077328  0.3833489418  600           0.0743659019 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8920863309  58.618618618  0.7357066333  0.3833489418  610           0.0732565165 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7889688249  59.579579579  0.6742980897  0.3833489418  620           0.0780584097 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  60.540540540  0.7059713304  0.3833489418  630           0.0722379446 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  61.501501501  0.6794734478  0.3833489418  640           0.0743644238 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  62.462462462  0.7180851698  0.3833489418  650           0.0750055552 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  63.423423423  0.7052041709  0.3833489418  660           0.0748901129 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  64.384384384  0.7304642379  0.3833489418  670           0.0799461603 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  65.345345345  0.6839812458  0.3833489418  680           0.0721482992 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  66.306306306  0.6822237134  0.3833489418  690           0.0739402533 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7721822542  67.267267267  0.7333102405  0.3833489418  700           0.0744987011 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  68.228228228  0.6990601063  0.3833489418  710           0.0728772163 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  69.189189189  0.6693769634  0.3833489418  720           0.0749624729 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8105515588  70.150150150  0.6789746284  0.3833489418  730           0.0750442028 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  71.111111111  0.6841860354  0.3833489418  740           0.0749274254 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  72.072072072  0.7586391747  0.3833489418  750           0.0746951580 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  73.033033033  0.6815198779  0.3833489418  760           0.0763721466 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  73.993993994  0.6970990002  0.3833489418  770           0.0731040239 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  74.954954955  0.6847471714  0.3833489418  780           0.0767473936 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  75.915915915  0.6722997189  0.3833489418  790           0.0766468287 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  76.876876876  0.6654710770  0.3833489418  800           0.0757497311 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  77.837837837  0.6731814623  0.3833489418  810           0.0758444786 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  78.798798798  0.6516129792  0.3833489418  820           0.0738243103 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  79.759759759  0.6931594849  0.3833489418  830           0.0742517471 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  80.720720720  0.6589841664  0.3833489418  840           0.0747896194 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  81.681681681  0.6427904546  0.3833489418  850           0.0736795425 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7314148681  82.642642642  0.6796599805  0.3833489418  860           0.0744246483 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  83.603603603  0.7066088915  0.3833489418  870           0.0755061150 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  84.564564564  0.6724587560  0.3833489418  880           0.0733658791 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  85.525525525  0.6606581092  0.3833489418  890           0.0753229380 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  86.486486486  0.6652682424  0.3833489418  900           0.0785875559 
1.0000000000  1.0000000000  0.9969969970  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9642857143  0.6882494005  87.447447447  0.6671632648  0.3833489418  910           0.0744069338 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  88.408408408  0.6963773012  0.3833489418  920           0.0732283115 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9939939940  0.9880952381  1.0000000000  1.0000000000  0.8729016787  89.369369369  0.7027073503  0.3833489418  930           0.0738986492 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.7745803357  90.330330330  0.7183480978  0.3833489418  940           0.0726582527 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.8513189448  91.291291291  0.7581363499  0.3833489418  950           0.0744178772 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.8273381295  92.252252252  0.7310494542  0.3833489418  960           0.0750810146 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  93.213213213  0.7429952621  0.3833489418  970           0.0741895914 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  94.174174174  0.7047592521  0.3833489418  980           0.0763741970 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  95.135135135  0.6994668365  0.3833489418  990           0.0742927551 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  96.096096096  0.6906888962  0.3833489418  1000          0.0762925148 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  97.057057057  0.6680742562  0.3833489418  1010          0.0727020025 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  98.018018018  0.6748262882  0.3833489418  1020          0.0759685278 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  98.978978979  0.6489442885  0.3833489418  1030          0.0745479107 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.4054054054  0.4047619048  0.3903903904  0.4047619048  0.3843843844  0.4285714286  0.3993993994  0.3809523810  0.3741007194  0.3741007194  0.3741007194  0.3693045564  0.0000000000  4.1875600815  0.1364407539  0             0.4417858124 
0.5975975976  0.6309523810  0.6276276276  0.7142857143  0.6246246246  0.7023809524  0.6216216216  0.5833333333  0.5707434053  0.4964028777  0.5035971223  0.4700239808  0.9609609610  3.6779251814  0.2990717888  10            0.0762521267 
0.8258258258  0.7857142857  0.7867867868  0.7619047619  0.7777777778  0.8333333333  0.7747747748  0.7619047619  0.6426858513  0.6498800959  0.6187050360  0.6258992806  1.9219219219  2.6496847868  0.2990717888  20            0.0750098705 
0.9429429429  0.9523809524  0.9489489489  0.8809523810  0.9189189189  0.9285714286  0.9489489489  0.9285714286  0.6402877698  0.6786570743  0.6738609113  0.7002398082  2.8828828829  1.9595537782  0.2990717888  30            0.0763744593 
0.9819819820  0.9880952381  1.0000000000  0.9761904762  0.9849849850  1.0000000000  0.9759759760  0.9761904762  0.7362110312  0.7122302158  0.7194244604  0.7314148681  3.8438438438  1.4475978017  0.3011674881  40            0.0753080606 
0.9909909910  0.9880952381  0.9939939940  1.0000000000  0.9849849850  1.0000000000  0.9879879880  1.0000000000  0.7817745803  0.7074340528  0.7529976019  0.7793764988  4.8048048048  1.1855529308  0.3011674881  50            0.0733861446 
0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9939939940  0.9761904762  0.7362110312  0.7218225420  0.7410071942  0.7697841727  5.7657657658  0.9908751726  0.3011674881  60            0.0752376795 
0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9939939940  1.0000000000  0.9939939940  0.9880952381  0.8009592326  0.7434052758  0.7601918465  0.7601918465  6.7267267267  0.9317509115  0.3011674881  70            0.0747292757 
0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.8009592326  0.7338129496  0.7553956835  0.7410071942  7.6876876877  0.9939917028  0.3011674881  80            0.0748638630 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8249400480  0.7290167866  0.8009592326  0.8081534772  8.6486486486  0.9683657169  0.3011674881  90            0.0740532160 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8081534772  0.7218225420  0.7793764988  0.7410071942  9.6096096096  0.8973912776  0.3011674881  100           0.0756922722 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7458033573  0.8297362110  0.8153477218  10.570570570  0.8438590229  0.3011674881  110           0.0722689629 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7290167866  0.8081534772  0.7913669065  11.531531531  0.8853485703  0.3011674881  120           0.0739238739 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7242206235  0.8153477218  0.8177458034  12.492492492  0.8503940642  0.3011674881  130           0.0734366894 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8345323741  0.7314148681  0.7961630695  0.8057553957  13.453453453  0.8321964920  0.3011674881  140           0.0754280806 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8489208633  0.7410071942  0.7841726619  0.8033573141  14.414414414  0.8387564600  0.3011674881  150           0.0751295567 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7482014388  0.8105515588  0.8153477218  15.375375375  0.8318118036  0.3011674881  160           0.0760771751 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  0.7170263789  0.8225419664  0.8345323741  16.336336336  0.8178850353  0.3011674881  170           0.0744181633 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8417266187  0.7218225420  0.7913669065  0.7937649880  17.297297297  0.8667780995  0.3011674881  180           0.0766062260 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7314148681  0.7913669065  0.7865707434  18.258258258  0.8419327915  0.3011674881  190           0.0755699635 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7937649880  0.7026378897  0.7338129496  0.7290167866  19.219219219  0.8855774701  0.3011674881  200           0.0732975960 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  0.7290167866  0.7577937650  0.7625899281  20.180180180  0.8369875014  0.3011674881  210           0.0748274088 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7386091127  0.8177458034  0.8249400480  21.141141141  0.9102491736  0.3011674881  220           0.0745759487 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7362110312  0.8129496403  0.8177458034  22.102102102  0.8271655202  0.3011674881  230           0.0737200975 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  0.7266187050  0.7961630695  0.7793764988  23.063063063  0.8382748425  0.3029484749  240           0.0759691477 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7338129496  0.8225419664  0.8153477218  24.024024024  0.7842747331  0.3029484749  250           0.0737365007 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7362110312  0.8225419664  0.8201438849  24.984984985  0.8065771759  0.3029484749  260           0.0755570412 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7170263789  0.7985611511  0.7961630695  25.945945945  0.7816011310  0.3029484749  270           0.0745832443 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  0.7026378897  0.7721822542  0.7865707434  26.906906906  0.7419746220  0.3029484749  280           0.0763420820 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8057553957  0.7314148681  0.7649880096  0.7721822542  27.867867867  0.7820717871  0.3029484749  290           0.0756875277 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7146282974  0.8297362110  0.8297362110  28.828828828  0.7680886924  0.3029484749  300           0.0740640402 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  0.6954436451  0.7290167866  0.7553956835  29.789789789  0.7540334821  0.3029484749  310           0.0732235670 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7362110312  0.8153477218  0.8369304556  30.750750750  0.7218832195  0.3029484749  320           0.0746939182 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7434052758  0.8249400480  0.8465227818  31.711711711  0.7261933863  0.3029484749  330           0.0762641907 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7362110312  0.8081534772  0.8129496403  32.672672672  0.7744829059  0.3029484749  340           0.0745455980 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  0.6810551559  0.7458033573  0.7529976019  33.633633633  0.7164334655  0.3029484749  350           0.0740419149 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  0.6930455635  0.7673860911  0.7721822542  34.594594594  0.7349021733  0.3029484749  360           0.0730583429 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7362110312  0.8081534772  0.8129496403  35.555555555  0.7423269093  0.3029484749  370           0.0736159801 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7290167866  0.8297362110  0.8321342926  36.516516516  0.7171332359  0.3029484749  380           0.0737197638 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7266187050  0.7937649880  0.7769784173  37.477477477  0.7390079558  0.3029484749  390           0.0748507023 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  0.7194244604  0.7769784173  0.7769784173  38.438438438  0.7756048083  0.3029484749  400           0.0768426180 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7434052758  0.8033573141  0.8057553957  39.399399399  0.7303254128  0.3029484749  410           0.0734597206 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  0.7314148681  0.8177458034  0.8201438849  40.360360360  0.7027123690  0.3029484749  420           0.0737306356 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7769784173  0.6498800959  0.7170263789  0.7242206235  41.321321321  0.7180879354  0.3029484749  430           0.0766042233 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  0.7242206235  0.8153477218  0.8393285372  42.282282282  0.7138263226  0.3029484749  440           0.0720700264 
1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  0.7314148681  0.7937649880  0.8105515588  43.243243243  0.7063543379  0.3029484749  450           0.0754601955 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8896882494  0.7122302158  0.8201438849  0.8633093525  44.204204204  0.7550865054  0.3029484749  460           0.0747299433 
0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  0.6666666667  0.7194244604  0.7314148681  45.165165165  0.7374972403  0.3029484749  470           0.0739711285 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7002398082  0.7889688249  0.8057553957  46.126126126  0.7432495356  0.3029484749  480           0.0751140356 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7002398082  0.7937649880  0.7889688249  47.087087087  0.7395340562  0.3029484749  490           0.0747528076 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.6954436451  0.7961630695  0.8009592326  48.048048048  0.7075232804  0.3029484749  500           0.0757591009 
1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7050359712  0.8225419664  0.8129496403  49.009009009  0.7274799228  0.3029484749  510           0.0754981041 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  0.6858513189  0.7601918465  0.7745803357  49.969969970  0.7062337399  0.3029484749  520           0.0750253677 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7194244604  0.8201438849  0.8225419664  50.930930930  0.7194848716  0.3029484749  530           0.0744753838 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  0.6930455635  0.7865707434  0.8105515588  51.891891891  0.7083302796  0.3029484749  540           0.0740716934 
1.0000000000  0.9761904762  1.0000000000  0.9761904762  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.7122302158  0.6282973621  0.6762589928  0.6762589928  52.852852852  0.6853707135  0.3029484749  550           0.0743941784 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7074340528  0.7961630695  0.7913669065  53.813813813  0.7411211789  0.3029484749  560           0.0775089741 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6906474820  0.7793764988  0.7889688249  54.774774774  0.7164645731  0.3029484749  570           0.0743430614 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  0.7122302158  0.7961630695  0.8153477218  55.735735735  0.7205872893  0.3029484749  580           0.0760982513 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7026378897  0.7961630695  0.8273381295  56.696696696  0.6869811058  0.3029484749  590           0.0774982691 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7122302158  0.7889688249  0.7817745803  57.657657657  0.6783748269  0.3029484749  600           0.0749855757 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7026378897  0.7721822542  0.7793764988  58.618618618  0.6782540917  0.3029484749  610           0.0757157803 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7218225420  0.7649880096  0.7793764988  59.579579579  0.7415244162  0.3029484749  620           0.0747251034 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7817745803  0.6762589928  0.7338129496  0.7266187050  60.540540540  0.6799420476  0.3029484749  630           0.0753344774 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7074340528  0.8225419664  0.8201438849  61.501501501  0.6863793015  0.3029484749  640           0.0788992643 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7050359712  0.7841726619  0.7913669065  62.462462462  0.6908082664  0.3029484749  650           0.0732107878 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  0.7098321343  0.8105515588  0.8081534772  63.423423423  0.7002355158  0.3029484749  660           0.0714905739 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7841726619  0.6786570743  0.7338129496  0.7386091127  64.384384384  0.6858645916  0.3029484749  670           0.0731524229 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9761904762  0.7170263789  0.6474820144  0.6834532374  0.7026378897  65.345345345  0.7292562723  0.3029484749  680           0.0759516954 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8681055156  0.7098321343  0.8129496403  0.8153477218  66.306306306  0.7316114187  0.3029484749  690           0.0766739368 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7218225420  0.8105515588  0.8201438849  67.267267267  0.7224234760  0.3029484749  700           0.0765095711 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  0.7050359712  0.7386091127  0.7458033573  68.228228228  0.7299324393  0.3029484749  710           0.0759999752 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7098321343  0.7865707434  0.7721822542  69.189189189  0.7050064325  0.3029484749  720           0.0747054338 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.6906474820  0.8081534772  0.8297362110  70.150150150  0.7146663904  0.3029484749  730           0.0757930994 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7793764988  0.6690647482  0.7458033573  0.7242206235  71.111111111  0.6911362290  0.3029484749  740           0.0728464842 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  0.6762589928  0.7482014388  0.7410071942  72.072072072  0.6990841091  0.3029484749  750           0.0753827810 
1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9939939940  0.9761904762  0.8417266187  0.6858513189  0.7961630695  0.8177458034  73.033033033  0.6981432676  0.3029484749  760           0.0738547087 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  0.9880952381  0.9160671463  0.7098321343  0.8225419664  0.8633093525  73.993993994  0.7351858020  0.3029484749  770           0.0756590843 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8225419664  0.7218225420  0.7577937650  0.7505995204  74.954954955  0.7428264856  0.3029484749  780           0.0731117487 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8896882494  0.7577937650  0.8297362110  0.8561151079  75.915915915  0.6551871598  0.3029484749  790           0.0819398642 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7625899281  0.8129496403  0.8033573141  76.876876876  0.7225754261  0.3029484749  800           0.0750183582 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9642857143  0.8177458034  0.7242206235  0.7577937650  0.7482014388  77.837837837  0.6820511878  0.3029484749  810           0.0744089603 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8657074341  0.7505995204  0.7697841727  0.7697841727  78.798798798  0.6997324586  0.3029484749  820           0.0759426832 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7194244604  0.7769784173  0.7745803357  79.759759759  0.7010117471  0.3029484749  830           0.0731235981 
1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9761904762  0.9939939940  0.9761904762  0.7745803357  0.6666666667  0.7673860911  0.8249400480  80.720720720  0.6834119201  0.3029484749  840           0.0746689558 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.8513189448  0.7338129496  0.7937649880  0.7769784173  81.681681681  0.7045320332  0.3029484749  850           0.0736271620 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  0.6834532374  0.7410071942  0.7314148681  82.642642642  0.6676764846  0.3029484749  860           0.0782482624 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8729016787  0.7266187050  0.8009592326  0.7793764988  83.603603603  0.7340322852  0.3029484749  870           0.0731513500 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9064748201  0.7290167866  0.8273381295  0.8369304556  84.564564564  0.6799954772  0.3029484749  880           0.0739658356 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7146282974  0.7745803357  0.7769784173  85.525525525  0.6545151055  0.3029484749  890           0.0733222961 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.6906474820  0.7649880096  0.7577937650  86.486486486  0.6755143762  0.3029484749  900           0.0722345114 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.6906474820  0.7769784173  0.7649880096  87.447447447  0.6864044547  0.3029484749  910           0.0742611170 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7122302158  0.7961630695  0.8129496403  88.408408408  0.7026878715  0.3029484749  920           0.0747416258 
0.9969969970  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7553956835  0.6714628297  0.6930455635  0.6858513189  89.369369369  0.6736008584  0.3029484749  930           0.0735229254 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9939939940  0.9761904762  0.8177458034  0.6690647482  0.7649880096  0.8033573141  90.330330330  0.6968051076  0.3029484749  940           0.0747728348 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  0.7434052758  0.8057553957  0.8081534772  91.291291291  0.6507518649  0.3029484749  950           0.0740718603 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  0.8129496403  0.6810551559  0.7434052758  0.7458033573  92.252252252  0.6552294910  0.3029484749  960           0.0725027800 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7098321343  0.8105515588  0.7985611511  93.213213213  0.6900637984  0.3029484749  970           0.0741119623 
1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  0.6786570743  0.7362110312  0.7458033573  94.174174174  0.6772031069  0.3029484749  980           0.0740680933 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7122302158  0.7985611511  0.7889688249  95.135135135  0.6453700483  0.3029484749  990           0.0730739355 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  0.7050359712  0.7865707434  0.7985611511  96.096096096  0.6629917264  0.3029484749  1000          0.0739691496 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  0.6978417266  0.8081534772  0.7817745803  97.057057057  0.6526980937  0.3029484749  1010          0.0744114876 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6762589928  0.7721822542  0.7769784173  98.018018018  0.6375198960  0.3029484749  1020          0.0740385294 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7002398082  0.7961630695  0.8369304556  98.978978979  0.6666198671  0.3029484749  1030          0.0737400293 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7122302158  0.7793764988  0.8345323741  99.939939939  0.6955421984  0.3029484749  1040          0.0742068768 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7266187050  0.8177458034  0.8441247002  100.90090090  0.6910300076  0.3029484749  1050          0.0771189213 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7146282974  0.7865707434  0.7841726619  101.86186186  0.6644320309  0.3029484749  1060          0.0753543615 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7218225420  0.7937649880  0.7793764988  102.82282282  0.7035386264  0.3029484749  1070          0.0737806797 
0.9969969970  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9939939940  1.0000000000  0.8848920863  0.7122302158  0.8417266187  0.8705035971  103.78378378  0.7056773961  0.3029484749  1080          0.0753220558 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  0.6810551559  0.7338129496  0.7434052758  104.74474474  0.6553841114  0.3029484749  1090          0.0810479641 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7458033573  0.8345323741  0.8273381295  105.70570570  0.7339039147  0.3029484749  1100          0.0729722977 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  0.6882494005  0.7386091127  0.7314148681  106.66666666  0.7097415507  0.3029484749  1110          0.0762940407 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  0.7362110312  0.8057553957  0.8129496403  107.62762762  0.7138954043  0.3029484749  1120          0.0751020908 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7290167866  0.7985611511  0.7913669065  108.58858858  0.6877231359  0.3029484749  1130          0.0747615337 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7170263789  0.7937649880  0.7745803357  109.54954954  0.6557872653  0.3029484749  1140          0.0736783504 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7122302158  0.8033573141  0.7721822542  110.51051051  0.6870558619  0.3029484749  1150          0.0736042261 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  0.7314148681  0.8153477218  0.7937649880  111.47147147  0.6808478951  0.3029484749  1160          0.0808754206 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  0.6594724221  0.7505995204  0.7529976019  112.43243243  0.6783334494  0.3029484749  1170          0.0750459194 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7002398082  0.7865707434  0.7745803357  113.39339339  0.6757995188  0.3029484749  1180          0.0742481947 
1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7386091127  0.6546762590  0.6930455635  0.7050359712  114.35435435  0.6710423827  0.3029484749  1190          0.0733820438 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7410071942  0.6498800959  0.6882494005  0.7026378897  115.31531531  0.7333784401  0.3029484749  1200          0.0728471041 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7266187050  0.8369304556  0.8609112710  116.27627627  0.7507278144  0.3029484749  1210          0.0724608183 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  0.6978417266  0.7242206235  0.7290167866  117.23723723  0.6832180500  0.3029484749  1220          0.0729907751 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  0.6858513189  0.8105515588  0.7553956835  118.19819819  0.7044004321  0.3029484749  1230          0.0739824057 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8752997602  0.7242206235  0.8201438849  0.7745803357  119.15915915  0.7040655792  0.3029484749  1240          0.0755818367 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8057553957  0.6618705036  0.7410071942  0.7242206235  120.12012012  0.6866320074  0.3029484749  1250          0.0773406267 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8705035971  0.7553956835  0.8249400480  0.8153477218  121.08108108  0.6859976292  0.3029484749  1260          0.0724565506 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7505995204  0.8273381295  0.7937649880  122.04204204  0.7399666369  0.3029484749  1270          0.0741738796 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8585131894  0.7482014388  0.8129496403  0.7745803357  123.00300300  0.7574423671  0.3029484749  1280          0.0743999958 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9016786571  0.7553956835  0.8345323741  0.8513189448  123.96396396  0.7614723802  0.3029484749  1290          0.0764311314 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7386091127  0.8201438849  0.7985611511  124.92492492  0.7037595749  0.3029484749  1300          0.0798693895 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7410071942  0.8057553957  0.7937649880  125.88588588  0.7056720495  0.3029484749  1310          0.0731893539 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7362110312  0.7889688249  0.7937649880  126.84684684  0.6991574168  0.3029484749  1320          0.0773664951 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8968824940  0.7410071942  0.8225419664  0.8705035971  127.80780780  0.6748490691  0.3029484749  1330          0.0742409945 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7673860911  0.6738609113  0.7290167866  0.7338129496  128.76876876  0.6743559361  0.3029484749  1340          0.0826786757 
1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7122302158  0.7721822542  0.7745803357  129.72972972  0.7148951471  0.3029484749  1350          0.0747687101 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7362110312  0.8129496403  0.8273381295  130.69069069  0.6964383662  0.3029484749  1360          0.0770744085 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8992805755  0.7577937650  0.8249400480  0.8441247002  131.65165165  0.7101112604  0.3029484749  1370          0.0725624323 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7266187050  0.7937649880  0.8153477218  132.61261261  0.6929932892  0.3029484749  1380          0.0726312876 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8848920863  0.7505995204  0.8081534772  0.8057553957  133.57357357  0.7070890248  0.3029484749  1390          0.0721832514 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9160671463  0.7793764988  0.8345323741  0.8417266187  134.53453453  0.6783259213  0.3029484749  1400          0.0741524935 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9232613909  0.7482014388  0.8345323741  0.8633093525  135.49549549  0.7168173492  0.3029484749  1410          0.0756174803 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8944844125  0.7314148681  0.7841726619  0.7817745803  136.45645645  0.7065822244  0.3029484749  1420          0.0735781908 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8992805755  0.7410071942  0.8129496403  0.8369304556  137.41741741  0.6725606620  0.3029484749  1430          0.0778613091 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9040767386  0.7386091127  0.8009592326  0.8081534772  138.37837837  0.6554401040  0.3029484749  1440          0.0758773565 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9040767386  0.7362110312  0.8201438849  0.8489208633  139.33933933  0.6973467648  0.3029484749  1450          0.0767022133 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9088729017  0.7410071942  0.8153477218  0.8465227818  140.30030030  0.6701782763  0.3029484749  1460          0.0729160309 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  0.7314148681  0.8033573141  0.8441247002  141.26126126  0.6844714403  0.3029484749  1470          0.0745907545 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7146282974  0.7601918465  0.7817745803  142.22222222  0.6775163114  0.3029484749  1480          0.0740014791 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7242206235  0.7961630695  0.8249400480  143.18318318  0.6829060674  0.3029484749  1490          0.0737324953 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7290167866  0.7745803357  0.8105515588  144.14414414  0.6592422962  0.3029484749  1500          0.0743011713 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8920863309  0.7242206235  0.7793764988  0.8105515588  145.10510510  0.6723410130  0.3029484749  1510          0.0744590998 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7338129496  0.7841726619  0.8153477218  146.06606606  0.6638479054  0.3029484749  1520          0.0801733732 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7290167866  0.7673860911  0.8057553957  147.02702702  0.6215639949  0.3029484749  1530          0.0749958515 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7026378897  0.7529976019  0.7769784173  147.98798798  0.6584688127  0.3029484749  1540          0.0770594597 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8681055156  0.7050359712  0.7769784173  0.7793764988  148.94894894  0.6376432300  0.3029484749  1550          0.0729390144 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7434052758  0.8009592326  0.8441247002  149.90990990  0.6750140011  0.3029484749  1560          0.0743366957 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  0.8345323741  0.6810551559  0.7553956835  0.7889688249  150.87087087  0.7438893914  0.3029484749  1570          0.0738502979 
1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.9969969970  1.0000000000  0.8824940048  0.6930455635  0.8249400480  0.8273381295  151.83183183  0.8286825597  0.3029484749  1580          0.0727638483 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  0.7266187050  0.7553956835  0.7745803357  152.79279279  0.8398354709  0.3029484749  1590          0.0731335163 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8417266187  0.7314148681  0.7985611511  0.8057553957  153.75375375  0.8260847211  0.3029484749  1600          0.0742315292 
1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7601918465  0.6546762590  0.6954436451  0.6906474820  154.71471471  0.7918536842  0.3029484749  1610          0.0757081032 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7577937650  0.8105515588  0.8369304556  155.67567567  0.7058881938  0.3029484749  1620          0.0743880510 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  0.7434052758  0.7865707434  0.8033573141  156.63663663  0.7378184199  0.3029484749  1630          0.0738876820 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7362110312  0.7721822542  0.7889688249  157.59759759  0.7395332694  0.3029484749  1640          0.0733239412 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6762589928  0.7410071942  0.7434052758  158.55855855  0.7170080245  0.3029484749  1650          0.0752945662 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6930455635  0.7434052758  0.7577937650  159.51951951  0.7140065312  0.3029484749  1660          0.0737298965 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.6714628297  0.7434052758  0.7434052758  160.48048048  0.7678603470  0.3029484749  1670          0.0731387854 
1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7266187050  0.6474820144  0.6858513189  0.6858513189  161.44144144  0.7252574980  0.3029484749  1680          0.0743678570 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7074340528  0.7458033573  0.7673860911  162.40240240  0.6799066782  0.3029484749  1690          0.0732455492 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7841726619  0.6762589928  0.7362110312  0.7194244604  163.36336336  0.6796051443  0.3029484749  1700          0.0755343199 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7218225420  0.7817745803  0.7913669065  164.32432432  0.7120946646  0.3029484749  1710          0.0722190142 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.6618705036  0.7290167866  0.7314148681  165.28528528  0.7168842614  0.3029484749  1720          0.0744811296 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  0.6762589928  0.7505995204  0.7386091127  166.24624624  0.7218651414  0.3029484749  1730          0.0775032282 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8417266187  0.6714628297  0.7649880096  0.7529976019  167.20720720  0.7102561712  0.3029484749  1740          0.0731369495 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  0.6738609113  0.7601918465  0.7505995204  168.16816816  0.7223268569  0.3029484749  1750          0.0771243334 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6786570743  0.7505995204  0.7410071942  169.12912912  0.6788392842  0.3029484749  1760          0.0852597237 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8129496403  0.6594724221  0.7338129496  0.7218225420  170.09009009  0.6861634851  0.3029484749  1770          0.0724164009 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7002398082  0.7553956835  0.7458033573  171.05105105  0.7036213517  0.3029484749  1780          0.0744992495 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7817745803  0.6474820144  0.7170263789  0.7026378897  172.01201201  0.7196586907  0.3029484749  1790          0.0758725882 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7290167866  0.7697841727  0.7793764988  172.97297297  0.7232979476  0.3029484749  1800          0.0838585615 
1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8201438849  0.6594724221  0.7482014388  0.7338129496  173.93393393  0.7004684865  0.3029484749  1810          0.0837939262 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 328, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2276, in update
    meta_train_loss_main.backward(retain_graph=True)
AttributeError: 'float' object has no attribute 'backward'
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2276, in update
    meta_train_loss_main.backward(retain_graph=True)
AttributeError: 'float' object has no attribute 'backward'
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2276, in update
    meta_train_loss_main.backward(retain_graph=True)
AttributeError: 'float' object has no attribute 'backward'
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2274, in update
    self.opt_phi.zero_grad()
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 332, in <module>
    results['average_acc'] += acc
KeyError: 'average_acc'
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
1.4916067146  0.4054054054  0.4047619048  0.3903903904  0.4047619048  0.3843843844  0.4285714286  0.3993993994  0.3809523810  0.3741007194  0.3741007194  0.3741007194  0.3693045564  0.0000000000  4.1875600815  0.1364407539  0             0.4141602516 
2.0407673861  0.5975975976  0.6309523810  0.6276276276  0.7142857143  0.6246246246  0.7023809524  0.6216216216  0.5833333333  0.5707434053  0.4964028777  0.5035971223  0.4700239808  0.9609609610  3.6779251814  0.2169575691  10            0.0745645046 
2.5371702638  0.8258258258  0.7857142857  0.7867867868  0.7619047619  0.7777777778  0.8333333333  0.7747747748  0.7619047619  0.6426858513  0.6498800959  0.6187050360  0.6258992806  1.9219219219  2.6496847868  0.2990674973  20            0.0746180296 
2.6930455635  0.9429429429  0.9523809524  0.9489489489  0.8809523810  0.9189189189  0.9285714286  0.9489489489  0.9285714286  0.6402877698  0.6786570743  0.6738609113  0.7002398082  2.8828828829  1.9595537782  0.2990674973  30            0.0756933689 
2.8992805755  0.9819819820  0.9880952381  1.0000000000  0.9761904762  0.9849849850  1.0000000000  0.9759759760  0.9761904762  0.7362110312  0.7122302158  0.7194244604  0.7314148681  3.8438438438  1.4475978017  0.2990674973  40            0.0747218370 
3.0215827338  0.9909909910  0.9880952381  0.9939939940  1.0000000000  0.9849849850  1.0000000000  0.9879879880  1.0000000000  0.7817745803  0.7074340528  0.7529976019  0.7793764988  4.8048048048  1.1855529308  0.2990674973  50            0.0764924526 
2.9688249400  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9939939940  0.9761904762  0.7362110312  0.7218225420  0.7410071942  0.7697841727  5.7657657658  0.9908751726  0.2990674973  60            0.0776479244 
3.0647482014  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9939939940  1.0000000000  0.9939939940  0.9880952381  0.8009592326  0.7434052758  0.7601918465  0.7601918465  6.7267267267  0.9317509115  0.3012027740  70            0.0766395092 
3.0311750600  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.8009592326  0.7338129496  0.7553956835  0.7410071942  7.6876876877  0.9939917028  0.3012027740  80            0.0773647547 
3.1630695444  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8249400480  0.7290167866  0.8009592326  0.8081534772  8.6486486486  0.9683657169  0.3012027740  90            0.0774766207 
3.0503597122  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8081534772  0.7218225420  0.7793764988  0.7410071942  9.6096096096  0.8973912776  0.3012070656  100           0.0765501976 
3.2446043165  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7458033573  0.8297362110  0.8153477218  10.570570570  0.8438590229  0.3012070656  110           0.0759294033 
3.1678657074  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7290167866  0.8081534772  0.7913669065  11.531531531  0.8853485703  0.3012070656  120           0.0765971899 
3.2062350120  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7242206235  0.8153477218  0.8177458034  12.492492492  0.8503940642  0.3012070656  130           0.0769206762 
3.1678657074  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8345323741  0.7314148681  0.7961630695  0.8057553957  13.453453453  0.8321964920  0.3012070656  140           0.0757126331 
3.1774580336  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8489208633  0.7410071942  0.7841726619  0.8033573141  14.414414414  0.8387564600  0.3012070656  150           0.0748418808 
3.2326139089  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7482014388  0.8105515588  0.8153477218  15.375375375  0.8318118036  0.3012070656  160           0.0865375042 
3.2086330935  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  0.7170263789  0.8225419664  0.8345323741  16.336336336  0.8178850353  0.3012375832  170           0.0780456781 
3.1486810552  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8417266187  0.7218225420  0.7913669065  0.7937649880  17.297297297  0.8667780995  0.3012375832  180           0.0795895100 
3.1558752998  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7314148681  0.7913669065  0.7865707434  18.258258258  0.8419327915  0.3012375832  190           0.0772017717 
2.9592326139  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7937649880  0.7026378897  0.7338129496  0.7290167866  19.219219219  0.8855774701  0.3012375832  200           0.0935815096 
3.0575539568  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  0.7290167866  0.7577937650  0.7625899281  20.180180180  0.8369875014  0.3015856743  210           0.0953149796 
3.2398081535  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7386091127  0.8177458034  0.8249400480  21.141141141  0.9102491736  0.3016514778  220           0.0757263422 
3.2134292566  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7362110312  0.8129496403  0.8177458034  22.102102102  0.8271655202  0.3016514778  230           0.0776467323 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Process Process-2414:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 312, in _exit_function
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 45, in active_children
    _cleanup()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 55, in _cleanup
    if p._popen.poll() is not None:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2406710) is killed by signal: Terminated. 
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/logging/__init__.py", line 1930, in shutdown
    def shutdown(handlerList=_handlerList):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2405767) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 335, in <module>
    results['average_acc'] /= count
ZeroDivisionError: division by zero
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3729016787  0.4054054054  0.4047619048  0.3903903904  0.4047619048  0.3843843844  0.4285714286  0.3993993994  0.3809523810  0.3741007194  0.3741007194  0.3741007194  0.3693045564  0.0000000000  4.1875600815  0.1364407539  0             0.3939182758 
0.5101918465  0.5975975976  0.6309523810  0.6276276276  0.7142857143  0.6246246246  0.7023809524  0.6216216216  0.5833333333  0.5707434053  0.4964028777  0.5035971223  0.4700239808  0.9609609610  3.6779251814  0.2169575691  10            0.0768223286 
0.6342925659  0.8258258258  0.7857142857  0.7867867868  0.7619047619  0.7777777778  0.8333333333  0.7747747748  0.7619047619  0.6426858513  0.6498800959  0.6187050360  0.6258992806  1.9219219219  2.6496847868  0.2169971466  20            0.0729182482 
0.6732613909  0.9429429429  0.9523809524  0.9489489489  0.8809523810  0.9189189189  0.9285714286  0.9489489489  0.9285714286  0.6402877698  0.6786570743  0.6738609113  0.7002398082  2.8828828829  1.9595537782  0.2169971466  30            0.0750650406 
0.7248201439  0.9819819820  0.9880952381  1.0000000000  0.9761904762  0.9849849850  1.0000000000  0.9759759760  0.9761904762  0.7362110312  0.7122302158  0.7194244604  0.7314148681  3.8438438438  1.4475978017  0.3011631966  40            0.0745581865 
0.7553956835  0.9909909910  0.9880952381  0.9939939940  1.0000000000  0.9849849850  1.0000000000  0.9879879880  1.0000000000  0.7817745803  0.7074340528  0.7529976019  0.7793764988  4.8048048048  1.1855529308  0.3011631966  50            0.0761973143 
0.7422062350  0.9909909910  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.9939939940  0.9761904762  0.7362110312  0.7218225420  0.7410071942  0.7697841727  5.7657657658  0.9908751726  0.3011631966  60            0.0770166636 
0.7661870504  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9939939940  1.0000000000  0.9939939940  0.9880952381  0.8009592326  0.7434052758  0.7601918465  0.7601918465  6.7267267267  0.9317509115  0.3011631966  70            0.0745386124 
0.7577937650  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9969969970  1.0000000000  0.9939939940  0.9880952381  0.8009592326  0.7338129496  0.7553956835  0.7410071942  7.6876876877  0.9939917028  0.3011631966  80            0.0751577616 
0.7907673861  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8249400480  0.7290167866  0.8009592326  0.8081534772  8.6486486486  0.9683657169  0.3011631966  90            0.0759576082 
0.7625899281  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8081534772  0.7218225420  0.7793764988  0.7410071942  9.6096096096  0.8973912776  0.3011631966  100           0.0767426968 
0.8111510791  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7458033573  0.8297362110  0.8153477218  10.570570570  0.8438590229  0.3011631966  110           0.0772353172 
0.7919664269  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7290167866  0.8081534772  0.7913669065  11.531531531  0.8853485703  0.3011631966  120           0.0775857925 
0.8015587530  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7242206235  0.8153477218  0.8177458034  12.492492492  0.8503940642  0.3011631966  130           0.0752315283 
0.7919664269  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8345323741  0.7314148681  0.7961630695  0.8057553957  13.453453453  0.8321964920  0.3011631966  140           0.0759623528 
0.7943645084  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8489208633  0.7410071942  0.7841726619  0.8033573141  14.414414414  0.8387564600  0.3011631966  150           0.0765479326 
0.8081534772  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7482014388  0.8105515588  0.8153477218  15.375375375  0.8318118036  0.3011980057  160           0.0748533726 
0.8021582734  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  0.7170263789  0.8225419664  0.8345323741  16.336336336  0.8178850353  0.3011980057  170           0.0842888355 
0.7871702638  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8417266187  0.7218225420  0.7913669065  0.7937649880  17.297297297  0.8667780995  0.3011980057  180           0.0749831200 
0.7889688249  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7314148681  0.7913669065  0.7865707434  18.258258258  0.8419327915  0.3011980057  190           0.0759890556 
0.7398081535  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7937649880  0.7026378897  0.7338129496  0.7290167866  19.219219219  0.8855774701  0.3011980057  200           0.0750363827 
0.7643884892  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8081534772  0.7290167866  0.7577937650  0.7625899281  20.180180180  0.8369875014  0.3011980057  210           0.0751993895 
0.8099520384  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7386091127  0.8177458034  0.8249400480  21.141141141  0.9102491736  0.3011980057  220           0.0773796320 
0.8033573141  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7362110312  0.8129496403  0.8177458034  22.102102102  0.8271655202  0.3011980057  230           0.0768856525 
0.7817745803  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  0.7266187050  0.7961630695  0.7793764988  23.063063063  0.8382748425  0.3011980057  240           0.0772761822 
0.8003597122  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7338129496  0.8225419664  0.8153477218  24.024024024  0.7842747331  0.3011980057  250           0.0765327215 
0.8057553957  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7362110312  0.8225419664  0.8201438849  24.984984985  0.8065771759  0.3011980057  260           0.0748064280 
0.7853717026  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7170263789  0.7985611511  0.7961630695  25.945945945  0.7816011310  0.3011980057  270           0.0784448624 
0.7691846523  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8153477218  0.7026378897  0.7721822542  0.7865707434  26.906906906  0.7419746220  0.3011980057  280           0.0754114151 
0.7685851319  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8057553957  0.7314148681  0.7649880096  0.7721822542  27.867867867  0.7820717871  0.3011980057  290           0.0752483606 
0.8075539568  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7146282974  0.8297362110  0.8297362110  28.828828828  0.7680886924  0.3011980057  300           0.0730102301 
0.7500000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8201438849  0.6954436451  0.7290167866  0.7553956835  29.789789789  0.7540334821  0.3011980057  310           0.0766234875 
0.8123501199  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7362110312  0.8153477218  0.8369304556  30.750750750  0.7218832195  0.3011980057  320           0.0744584799 
0.8177458034  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7434052758  0.8249400480  0.8465227818  31.711711711  0.7261933863  0.3011980057  330           0.0780366182 
0.7985611511  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7362110312  0.8081534772  0.8129496403  32.672672672  0.7744829059  0.3012027740  340           0.0773431063 
0.7511990408  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  0.6810551559  0.7458033573  0.7529976019  33.633633633  0.7164334655  0.3012027740  350           0.0759103060 
0.7643884892  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8249400480  0.6930455635  0.7673860911  0.7721822542  34.594594594  0.7349021733  0.3012027740  360           0.0775812149 
0.7985611511  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7362110312  0.8081534772  0.8129496403  35.555555555  0.7423269093  0.3012027740  370           0.0756006479 
0.8153477218  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7290167866  0.8297362110  0.8321342926  36.516516516  0.7171332359  0.3012027740  380           0.0755400896 
0.7841726619  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7266187050  0.7937649880  0.7769784173  37.477477477  0.7390079558  0.3012027740  390           0.0761254787 
0.7727817746  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  0.7194244604  0.7769784173  0.7769784173  38.438438438  0.7756048083  0.3012027740  400           0.0757501364 
0.8015587530  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7434052758  0.8033573141  0.8057553957  39.399399399  0.7303254128  0.3012027740  410           0.0760720253 
0.8051558753  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  0.7314148681  0.8177458034  0.8201438849  40.360360360  0.7027123690  0.3012027740  420           0.0750427485 
0.7170263789  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7769784173  0.6498800959  0.7170263789  0.7242206235  41.321321321  0.7180879354  0.3012027740  430           0.0736045361 
0.8105515588  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  0.7242206235  0.8153477218  0.8393285372  42.282282282  0.7138263226  0.3027267456  440           0.0782096863 
0.7943645084  1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  0.7314148681  0.7937649880  0.8105515588  43.243243243  0.7063543379  0.3027267456  450           0.0799355507 
0.8213429257  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8896882494  0.7122302158  0.8201438849  0.8633093525  44.204204204  0.7550865054  0.3027267456  460           0.0749993563 
0.7284172662  0.9969969970  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  0.6666666667  0.7194244604  0.7314148681  45.165165165  0.7374972403  0.3027267456  470           0.0763344049 
0.7883693046  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7002398082  0.7889688249  0.8057553957  46.126126126  0.7432495356  0.3027267456  480           0.0733474255 
0.7829736211  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7002398082  0.7937649880  0.7889688249  47.087087087  0.7395340562  0.3027267456  490           0.0747542858 
0.7877697842  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.6954436451  0.7961630695  0.8009592326  48.048048048  0.7075232804  0.3027267456  500           0.0756720304 
0.7997601918  1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7050359712  0.8225419664  0.8129496403  49.009009009  0.7274799228  0.3028383255  510           0.0762913704 
0.7631894484  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8321342926  0.6858513189  0.7601918465  0.7745803357  49.969969970  0.7062337399  0.3028383255  520           0.0749971628 
0.8081534772  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7194244604  0.8201438849  0.8225419664  50.930930930  0.7194848716  0.3028383255  530           0.0747249603 
0.7853717026  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8513189448  0.6930455635  0.7865707434  0.8105515588  51.891891891  0.7083302796  0.3028383255  540           0.0757418156 
0.6732613909  1.0000000000  0.9761904762  1.0000000000  0.9761904762  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.7122302158  0.6282973621  0.6762589928  0.6762589928  52.852852852  0.6853707135  0.3028383255  550           0.0744927168 
0.7871702638  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7074340528  0.7961630695  0.7913669065  53.813813813  0.7411211789  0.3028383255  560           0.0761141062 
0.7739808153  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6906474820  0.7793764988  0.7889688249  54.774774774  0.7164645731  0.3028383255  570           0.0752122402 
0.7895683453  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8345323741  0.7122302158  0.7961630695  0.8153477218  55.735735735  0.7205872893  0.3028383255  580           0.0753879547 
0.7955635492  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7026378897  0.7961630695  0.8273381295  56.696696696  0.6869811058  0.3028383255  590           0.0745281219 
0.7799760192  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7122302158  0.7889688249  0.7817745803  57.657657657  0.6783748269  0.3028383255  600           0.0792842150 
0.7751798561  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.7026378897  0.7721822542  0.7793764988  58.618618618  0.6782540917  0.3028383255  610           0.0776836157 
0.7763788969  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7218225420  0.7649880096  0.7793764988  59.579579579  0.7415244162  0.3028383255  620           0.0775469303 
0.7296163070  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7817745803  0.6762589928  0.7338129496  0.7266187050  60.540540540  0.6799420476  0.3028383255  630           0.0773303032 
0.8027577938  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7074340528  0.8225419664  0.8201438849  61.501501501  0.6863793015  0.3028383255  640           0.0758820057 
0.7835731415  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7050359712  0.7841726619  0.7913669065  62.462462462  0.6908082664  0.3028383255  650           0.0759726763 
0.7925659472  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8417266187  0.7098321343  0.8105515588  0.8081534772  63.423423423  0.7002355158  0.3028383255  660           0.0748866796 
0.7338129496  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7841726619  0.6786570743  0.7338129496  0.7386091127  64.384384384  0.6858645916  0.3028383255  670           0.0737617254 
0.6876498801  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  0.9761904762  0.7170263789  0.6474820144  0.6834532374  0.7026378897  65.345345345  0.7292562723  0.3028383255  680           0.0753634691 
0.8015587530  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8681055156  0.7098321343  0.8129496403  0.8153477218  66.306306306  0.7316114187  0.3028383255  690           0.0798503876 
0.7991606715  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7218225420  0.8105515588  0.8201438849  67.267267267  0.7224234760  0.3028383255  700           0.0735851049 
0.7517985612  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8177458034  0.7050359712  0.7386091127  0.7458033573  68.228228228  0.7299324393  0.3028383255  710           0.0753413200 
0.7823741007  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7098321343  0.7865707434  0.7721822542  69.189189189  0.7050064325  0.3028383255  720           0.0747989893 
0.7937649880  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8465227818  0.6906474820  0.8081534772  0.8297362110  70.150150150  0.7146663904  0.3028383255  730           0.0758772135 
0.7296163070  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7793764988  0.6690647482  0.7458033573  0.7242206235  71.111111111  0.6911362290  0.3028383255  740           0.0745291471 
0.7482014388  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  0.6762589928  0.7482014388  0.7410071942  72.072072072  0.6990841091  0.3028383255  750           0.0769722462 
0.7853717026  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9939939940  0.9761904762  0.8417266187  0.6858513189  0.7961630695  0.8177458034  73.033033033  0.6981432676  0.3028383255  760           0.0747769833 
0.8279376499  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  0.9880952381  0.9160671463  0.7098321343  0.8225419664  0.8633093525  73.993993994  0.7351858020  0.3028383255  770           0.0752506495 
0.7631894484  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8225419664  0.7218225420  0.7577937650  0.7505995204  74.954954955  0.7428264856  0.3028383255  780           0.0757064104 
0.8333333333  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8896882494  0.7577937650  0.8297362110  0.8561151079  75.915915915  0.6551871598  0.3028383255  790           0.0742098093 
0.8141486811  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7625899281  0.8129496403  0.8033573141  76.876876876  0.7225754261  0.3028383255  800           0.0759840012 
0.7619904077  1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  0.9642857143  0.8177458034  0.7242206235  0.7577937650  0.7482014388  77.837837837  0.6820511878  0.3028383255  810           0.0733646870 
0.7889688249  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8657074341  0.7505995204  0.7697841727  0.7697841727  78.798798798  0.6997324586  0.3028383255  820           0.0761942625 
0.7787769784  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7194244604  0.7769784173  0.7745803357  79.759759759  0.7010117471  0.3028383255  830           0.0761638403 
0.7583932854  1.0000000000  0.9761904762  1.0000000000  0.9880952381  1.0000000000  0.9761904762  0.9939939940  0.9761904762  0.7745803357  0.6666666667  0.7673860911  0.8249400480  80.720720720  0.6834119201  0.3028383255  840           0.0784507513 
0.7889688249  1.0000000000  1.0000000000  1.0000000000  0.9761904762  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.8513189448  0.7338129496  0.7937649880  0.7769784173  81.681681681  0.7045320332  0.3028383255  850           0.0758405685 
0.7446043165  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8225419664  0.6834532374  0.7410071942  0.7314148681  82.642642642  0.6676764846  0.3028383255  860           0.0747594595 
0.7949640288  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.8729016787  0.7266187050  0.8009592326  0.7793764988  83.603603603  0.7340322852  0.3028383255  870           0.0773731709 
0.8249400480  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9064748201  0.7290167866  0.8273381295  0.8369304556  84.564564564  0.6799954772  0.3028383255  880           0.0752591610 
0.7811750600  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7146282974  0.7745803357  0.7769784173  85.525525525  0.6545151055  0.3028383255  890           0.0759643793 
0.7643884892  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.6906474820  0.7649880096  0.7577937650  86.486486486  0.6755143762  0.3028383255  900           0.0736540079 
0.7715827338  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.6906474820  0.7769784173  0.7649880096  87.447447447  0.6864044547  0.3028383255  910           0.0768080473 
0.7985611511  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7122302158  0.7961630695  0.8129496403  88.408408408  0.7026878715  0.3028383255  920           0.0748347998 
0.7014388489  0.9969969970  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7553956835  0.6714628297  0.6930455635  0.6858513189  89.369369369  0.6736008584  0.3028383255  930           0.0728237152 
0.7637889688  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.9939939940  0.9761904762  0.8177458034  0.6690647482  0.7649880096  0.8033573141  90.330330330  0.6968051076  0.3028383255  940           0.0749148369 
0.8093525180  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  0.7434052758  0.8057553957  0.8081534772  91.291291291  0.6507518649  0.3028383255  950           0.0762808084 
0.7458033573  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  0.8129496403  0.6810551559  0.7434052758  0.7458033573  92.252252252  0.6552294910  0.3028383255  960           0.0739538670 
0.7973621103  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7098321343  0.8105515588  0.7985611511  93.213213213  0.6900637984  0.3028383255  970           0.0733568430 
0.7386091127  1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7937649880  0.6786570743  0.7362110312  0.7458033573  94.174174174  0.6772031069  0.3028383255  980           0.0745548487 
0.7943645084  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7122302158  0.7985611511  0.7889688249  95.135135135  0.6453700483  0.3028383255  990           0.0763298273 
0.7889688249  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  0.7050359712  0.7865707434  0.7985611511  96.096096096  0.6629917264  0.3028383255  1000          0.0756670237 
0.7883693046  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  0.6978417266  0.8081534772  0.7817745803  97.057057057  0.6526980937  0.3028383255  1010          0.0747164011 
0.7655875300  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6762589928  0.7721822542  0.7769784173  98.018018018  0.6375198960  0.3028383255  1020          0.0758385181 
0.7943645084  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7002398082  0.7961630695  0.8369304556  98.978978979  0.6666198671  0.3028383255  1030          0.0747352123 
0.7907673861  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.7122302158  0.7793764988  0.8345323741  99.939939939  0.6955421984  0.3028383255  1040          0.0751975775 
0.8165467626  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7266187050  0.8177458034  0.8441247002  100.90090090  0.6910300076  0.3028383255  1050          0.0754679680 
0.7853717026  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8561151079  0.7146282974  0.7865707434  0.7841726619  101.86186186  0.6644320309  0.3028383255  1060          0.0752023697 
0.7835731415  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8393285372  0.7218225420  0.7937649880  0.7793764988  102.82282282  0.7035386264  0.3028383255  1070          0.0755816221 
0.8273381295  0.9969969970  1.0000000000  0.9969969970  1.0000000000  1.0000000000  0.9880952381  0.9939939940  1.0000000000  0.8848920863  0.7122302158  0.8417266187  0.8705035971  103.78378378  0.7056773961  0.3028383255  1080          0.0743467093 
0.7362110312  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7865707434  0.6810551559  0.7338129496  0.7434052758  104.74474474  0.6553841114  0.3028383255  1090          0.0735132694 
0.8237410072  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7458033573  0.8345323741  0.8273381295  105.70570570  0.7339039147  0.3028383255  1100          0.0752439499 
0.7368105516  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7889688249  0.6882494005  0.7386091127  0.7314148681  106.66666666  0.7097415507  0.3028383255  1110          0.0767151594 
0.8087529976  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  0.7362110312  0.8057553957  0.8129496403  107.62762762  0.7138954043  0.3028383255  1120          0.0728317022 
0.7973621103  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7290167866  0.7985611511  0.7913669065  108.58858858  0.6877231359  0.3028383255  1130          0.0760069132 
0.7835731415  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8489208633  0.7170263789  0.7937649880  0.7745803357  109.54954954  0.6557872653  0.3028383255  1140          0.0770041227 
0.7853717026  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8537170264  0.7122302158  0.8033573141  0.7721822542  110.51051051  0.6870558619  0.3028383255  1150          0.0754760981 
0.8015587530  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8657074341  0.7314148681  0.8153477218  0.7937649880  111.47147147  0.6808478951  0.3028383255  1160          0.0740258932 
0.7398081535  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7961630695  0.6594724221  0.7505995204  0.7529976019  112.43243243  0.6783334494  0.3028383255  1170          0.0718290091 
0.7727817746  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.7002398082  0.7865707434  0.7745803357  113.39339339  0.6757995188  0.3028383255  1180          0.0755064249 
0.6978417266  1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7386091127  0.6546762590  0.6930455635  0.7050359712  114.35435435  0.6710423827  0.3028383255  1190          0.0763632774 
0.6954436451  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7410071942  0.6498800959  0.6882494005  0.7026378897  115.31531531  0.7333784401  0.3028383255  1200          0.0732075930 
0.8285371703  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7266187050  0.8369304556  0.8609112710  116.27627627  0.7507278144  0.3028383255  1210          0.0745067358 
0.7326139089  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7793764988  0.6978417266  0.7242206235  0.7290167866  117.23723723  0.6832180500  0.3028383255  1220          0.0807288170 
0.7787769784  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  0.6858513189  0.8105515588  0.7553956835  118.19819819  0.7044004321  0.3028383255  1230          0.0763932943 
0.7985611511  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8752997602  0.7242206235  0.8201438849  0.7745803357  119.15915915  0.7040655792  0.3028383255  1240          0.0741247892 
0.7332134293  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8057553957  0.6618705036  0.7410071942  0.7242206235  120.12012012  0.6866320074  0.3028383255  1250          0.0738715172 
0.8165467626  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8705035971  0.7553956835  0.8249400480  0.8153477218  121.08108108  0.6859976292  0.3028383255  1260          0.0764892101 
0.8153477218  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7505995204  0.8273381295  0.7937649880  122.04204204  0.7399666369  0.3028383255  1270          0.0746949434 
0.7985611511  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  0.9969969970  0.9880952381  0.8585131894  0.7482014388  0.8129496403  0.7745803357  123.00300300  0.7574423671  0.3028383255  1280          0.0745723486 
0.8357314149  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9016786571  0.7553956835  0.8345323741  0.8513189448  123.96396396  0.7614723802  0.3028383255  1290          0.0759396553 
0.8111510791  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7386091127  0.8201438849  0.7985611511  124.92492492  0.7037595749  0.3028383255  1300          0.0762787104 
0.8033573141  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7410071942  0.8057553957  0.7937649880  125.88588588  0.7056720495  0.3028383255  1310          0.0739698410 
0.7991606715  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7362110312  0.7889688249  0.7937649880  126.84684684  0.6991574168  0.3028383255  1320          0.0756637812 
0.8327338129  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8968824940  0.7410071942  0.8225419664  0.8705035971  127.80780780  0.6748490691  0.3028383255  1330          0.0737534046 
0.7260191847  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7673860911  0.6738609113  0.7290167866  0.7338129496  128.76876876  0.6743559361  0.3028383255  1340          0.0760697842 
0.7793764988  1.0000000000  1.0000000000  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8585131894  0.7122302158  0.7721822542  0.7745803357  129.72972972  0.7148951471  0.3028383255  1350          0.0750340700 
0.8165467626  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7362110312  0.8129496403  0.8273381295  130.69069069  0.6964383662  0.3028383255  1360          0.0759667397 
0.8315347722  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8992805755  0.7577937650  0.8249400480  0.8441247002  131.65165165  0.7101112604  0.3028383255  1370          0.0729158640 
0.8033573141  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7266187050  0.7937649880  0.8153477218  132.61261261  0.6929932892  0.3028383255  1380          0.0737425566 
0.8123501199  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8848920863  0.7505995204  0.8081534772  0.8057553957  133.57357357  0.7070890248  0.3028383255  1390          0.0740632296 
0.8429256595  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9160671463  0.7793764988  0.8345323741  0.8417266187  134.53453453  0.6783259213  0.3028383255  1400          0.0766737938 
0.8423261391  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9232613909  0.7482014388  0.8345323741  0.8633093525  135.49549549  0.7168173492  0.3028383255  1410          0.0745285034 
0.7979616307  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8944844125  0.7314148681  0.7841726619  0.7817745803  136.45645645  0.7065822244  0.3028383255  1420          0.0767556906 
0.8225419664  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8992805755  0.7410071942  0.8129496403  0.8369304556  137.41741741  0.6725606620  0.3028383255  1430          0.0758963585 
0.8129496403  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9040767386  0.7386091127  0.8009592326  0.8081534772  138.37837837  0.6554401040  0.3028383255  1440          0.0775755882 
0.8273381295  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9040767386  0.7362110312  0.8201438849  0.8489208633  139.33933933  0.6973467648  0.3028383255  1450          0.0747157574 
0.8279376499  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9088729017  0.7410071942  0.8153477218  0.8465227818  140.30030030  0.6701782763  0.3028383255  1460          0.0768850803 
0.8147482014  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8800959233  0.7314148681  0.8033573141  0.8441247002  141.26126126  0.6844714403  0.3028383255  1470          0.0752042055 
0.7835731415  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8776978417  0.7146282974  0.7601918465  0.7817745803  142.22222222  0.6775163114  0.3028383255  1480          0.0746375084 
0.8039568345  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8705035971  0.7242206235  0.7961630695  0.8249400480  143.18318318  0.6829060674  0.3028383255  1490          0.0751923800 
0.8003597122  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7290167866  0.7745803357  0.8105515588  144.14414414  0.6592422962  0.3028383255  1500          0.0718754053 
0.8015587530  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8920863309  0.7242206235  0.7793764988  0.8105515588  145.10510510  0.6723410130  0.3028383255  1510          0.0740011454 
0.8051558753  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8872901679  0.7338129496  0.7841726619  0.8153477218  146.06606606  0.6638479054  0.3028383255  1520          0.0756312370 
0.7937649880  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7290167866  0.7673860911  0.8057553957  147.02702702  0.6215639949  0.3028383255  1530          0.0752152205 
0.7733812950  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8609112710  0.7026378897  0.7529976019  0.7769784173  147.98798798  0.6584688127  0.3028383255  1540          0.0755200863 
0.7823741007  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8681055156  0.7050359712  0.7769784173  0.7793764988  148.94894894  0.6376432300  0.3028383255  1550          0.0757472992 
0.8195443645  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8896882494  0.7434052758  0.8009592326  0.8441247002  149.90990990  0.6750140011  0.3028383255  1560          0.0781454086 
0.7649880096  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9761904762  1.0000000000  1.0000000000  0.8345323741  0.6810551559  0.7553956835  0.7889688249  150.87087087  0.7438893914  0.3028383255  1570          0.0753326416 
0.8069544365  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.9969969970  0.9880952381  0.9969969970  1.0000000000  0.8824940048  0.6930455635  0.8249400480  0.8273381295  151.83183183  0.8286825597  0.3028383255  1580          0.0749333382 
0.7709832134  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8273381295  0.7266187050  0.7553956835  0.7745803357  152.79279279  0.8398354709  0.3028383255  1590          0.0763323069 
0.7943645084  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969969970  1.0000000000  0.8417266187  0.7314148681  0.7985611511  0.8057553957  153.75375375  0.8260847211  0.3028383255  1600          0.0792039633 
0.7002398082  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7601918465  0.6546762590  0.6954436451  0.6906474820  154.71471471  0.7918536842  0.3028383255  1610          0.0805485487 
0.8195443645  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8729016787  0.7577937650  0.8105515588  0.8369304556  155.67567567  0.7058881938  0.3028383255  1620          0.0757269859 
0.7991606715  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8633093525  0.7434052758  0.7865707434  0.8033573141  156.63663663  0.7378184199  0.3028383255  1630          0.0763055563 
0.7853717026  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8441247002  0.7362110312  0.7721822542  0.7889688249  157.59759759  0.7395332694  0.3028383255  1640          0.0797073126 
0.7494004796  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6762589928  0.7410071942  0.7434052758  158.55855855  0.7170080245  0.3028383255  1650          0.0770933390 
0.7577937650  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8369304556  0.6930455635  0.7434052758  0.7577937650  159.51951951  0.7140065312  0.3028383255  1660          0.0763359070 
0.7470023981  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.8297362110  0.6714628297  0.7434052758  0.7434052758  160.48048048  0.7678603470  0.3028383255  1670          0.0744698524 
0.6864508393  1.0000000000  0.9880952381  1.0000000000  0.9880952381  1.0000000000  1.0000000000  1.0000000000  0.9880952381  0.7266187050  0.6474820144  0.6858513189  0.6858513189  161.44144144  0.7252574980  0.3028383255  1680          0.0796052217 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
RuntimeError: DataLoader worker (pid 2453512) is killed by signal: Terminated. 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 50, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2453142) is killed by signal: Terminated. 
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/logging/__init__.py", line 1930, in shutdown
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2452478) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 269, in <module>
    algorithm.to(device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.2818499127  0.2772925764  0.3043478261  0.2751091703  0.2956521739  0.2838427948  0.2782608696  0.2838427948  0.2782608696  0.2879581152  0.2809773124  0.2809773124  0.2774869110  0.0000000000  5.3416609764  0.1364407539  0             0.4060187340 
0.3058464223  0.4017467249  0.4347826087  0.4017467249  0.4086956522  0.3908296943  0.4521739130  0.3711790393  0.3913043478  0.3158813264  0.2966841187  0.3106457243  0.3001745201  0.6986899563  4.6673653603  0.2170152664  10            0.0791139364 
0.5610820244  0.7882096070  0.8086956522  0.7139737991  0.7304347826  0.7117903930  0.7565217391  0.6899563319  0.7130434783  0.6701570681  0.5532286213  0.4991273997  0.5218150087  1.3973799127  4.0051537514  0.2170152664  20            0.0721215010 
0.5021815009  0.8122270742  0.8434782609  0.7860262009  0.7739130435  0.7751091703  0.8260869565  0.7314410480  0.7739130435  0.5532286213  0.5165794066  0.4659685864  0.4729493892  2.0960698690  3.0200016975  0.3011631966  30            0.0760857105 
0.4681500873  0.8689956332  0.8521739130  0.8165938865  0.7391304348  0.7882096070  0.7913043478  0.7925764192  0.7391304348  0.4869109948  0.4677137871  0.4572425829  0.4607329843  2.7947598253  2.5695126772  0.3011631966  40            0.0766320229 
0.5767888307  0.9192139738  0.9217391304  0.8733624454  0.8260869565  0.8537117904  0.9043478261  0.8930131004  0.7913043478  0.6178010471  0.5619546248  0.5410122164  0.5863874346  3.4934497817  2.1923701048  0.3011631966  50            0.0769440174 
0.5095986038  0.8951965066  0.9043478261  0.8908296943  0.8434782609  0.8537117904  0.8695652174  0.8558951965  0.7826086957  0.5305410122  0.5008726003  0.4921465969  0.5148342059  4.1921397380  1.8621551514  0.3011631966  60            0.0740231752 
0.5301047120  0.8864628821  0.9043478261  0.8777292576  0.8521739130  0.8689956332  0.8695652174  0.8755458515  0.8000000000  0.5532286213  0.5183246073  0.5095986038  0.5392670157  4.8908296943  1.8337303996  0.3011631966  70            0.0762362003 
0.5811518325  0.9585152838  0.9217391304  0.9606986900  0.9304347826  0.9432314410  0.9391304348  0.9694323144  0.9130434783  0.6178010471  0.5305410122  0.5689354276  0.6073298429  5.5895196507  1.5497787476  0.3011631966  80            0.0804259539 
0.5314136126  0.9716157205  0.9478260870  0.9825327511  0.9478260870  0.9737991266  0.9478260870  0.9694323144  0.9043478261  0.5584642234  0.4991273997  0.5183246073  0.5497382199  6.2882096070  1.3538370371  0.3011631966  90            0.0753493071 
0.5261780105  0.9737991266  0.9391304348  0.9825327511  0.9652173913  0.9759825328  0.9652173913  0.9694323144  0.9130434783  0.5567190227  0.5078534031  0.5113438045  0.5287958115  6.9868995633  1.1807991982  0.3011631966  100           0.0745532274 
0.5436300175  0.9825327511  0.9478260870  0.9825327511  0.9652173913  0.9847161572  0.9652173913  0.9803493450  0.9478260870  0.5759162304  0.4956369983  0.5514834206  0.5514834206  7.6855895197  1.1976447999  0.3011631966  110           0.0748359919 
0.5226876091  0.9716157205  0.9304347826  0.9847161572  0.9391304348  0.9759825328  0.9565217391  0.9650655022  0.9217391304  0.5514834206  0.4781849913  0.5322862129  0.5287958115  8.3842794760  1.1592795551  0.3011631966  120           0.0763988018 
0.5200698080  0.9934497817  0.9739130435  0.9956331878  0.9565217391  0.9912663755  0.9652173913  0.9912663755  0.9478260870  0.5532286213  0.4834205934  0.5130890052  0.5305410122  9.0829694323  1.0798027098  0.3011631966  130           0.0765111685 
0.5287958115  0.9978165939  0.9913043478  1.0000000000  0.9739130435  0.9847161572  0.9565217391  0.9847161572  0.9391304348  0.5811518325  0.4764397906  0.5287958115  0.5287958115  9.7816593886  1.0491671085  0.3011631966  140           0.0760786295 
0.5279232112  0.9978165939  0.9913043478  1.0000000000  0.9826086957  0.9912663755  0.9565217391  0.9868995633  0.9391304348  0.5794066318  0.4677137871  0.5392670157  0.5253054101  10.480349345  0.9750803709  0.3013176918  150           0.0741538048 
0.5021815009  0.9890829694  0.9652173913  1.0000000000  0.9826086957  1.0000000000  0.9739130435  0.9978165939  0.9565217391  0.5253054101  0.4589877836  0.5095986038  0.5148342059  11.179039301  1.0015056372  0.3013176918  160           0.0774983883 
0.5135253054  0.9978165939  0.9739130435  1.0000000000  0.9739130435  1.0000000000  0.9739130435  0.9956331878  0.9478260870  0.5305410122  0.4502617801  0.5270506108  0.5462478185  11.877729257  0.9419082999  0.3013176918  170           0.0745775938 
0.4781849913  0.9978165939  0.9826086957  1.0000000000  0.9739130435  1.0000000000  0.9913043478  0.9978165939  0.9739130435  0.5043630017  0.4467713787  0.4694589878  0.4921465969  12.576419214  0.9774313569  0.3013176918  180           0.0773894072 
0.5497382199  0.9978165939  0.9826086957  0.9956331878  0.9652173913  0.9956331878  0.9739130435  0.9825327511  0.9652173913  0.5968586387  0.4851657941  0.5514834206  0.5654450262  13.275109170  0.9125205934  0.3013582230  190           0.0770613194 
0.5095986038  1.0000000000  1.0000000000  0.9978165939  0.9652173913  0.9956331878  0.9739130435  0.9912663755  0.9739130435  0.5706806283  0.4537521815  0.5200698080  0.4938917976  13.973799126  0.9540586174  0.3013582230  200           0.0775023699 
0.4864746946  1.0000000000  1.0000000000  1.0000000000  0.9652173913  0.9978165939  0.9826086957  0.9978165939  0.9478260870  0.5357766143  0.4345549738  0.4956369983  0.4799301920  14.672489083  0.9254242897  0.3013582230  210           0.0759150982 
0.5205061082  1.0000000000  0.9565217391  1.0000000000  0.9826086957  1.0000000000  0.9826086957  1.0000000000  0.9739130435  0.5410122164  0.4554973822  0.5270506108  0.5584642234  15.371179039  0.8985457897  0.3013582230  220           0.0794914007 
0.4821116928  1.0000000000  0.9913043478  0.9978165939  0.9652173913  0.9978165939  0.9739130435  0.9890829694  0.9478260870  0.5183246073  0.4188481675  0.4799301920  0.5113438045  16.069868995  0.8843178868  0.3013582230  230           0.0749014139 
0.4720767888  1.0000000000  0.9826086957  1.0000000000  0.9739130435  1.0000000000  0.9826086957  1.0000000000  0.9652173913  0.4886561955  0.4188481675  0.4886561955  0.4921465969  16.768558952  0.8960870743  0.3013582230  240           0.1002976656 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2272, in update
    meta_train_loss_main += 1.0 * penalty   # 150 for coral
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.1967713787  0.2008733624  0.2173913043  0.1855895197  0.2086956522  0.1986899563  0.2000000000  0.1877729258  0.1913043478  0.2006980803  0.1902268761  0.1972076789  0.1989528796  0.0000000000  5.3416609764  0.1364407539  0             117.04335880 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.1967713787  0.2008733624  0.2173913043  0.1855895197  0.2086956522  0.1986899563  0.2000000000  0.1877729258  0.1913043478  0.2006980803  0.1902268761  0.1972076789  0.1989528796  0.0000000000  5.3416609764  0.1364407539  0             0.3991870880 
0.3411867365  0.3362445415  0.3478260870  0.3646288210  0.3913043478  0.3842794760  0.4173913043  0.3864628821  0.3391304348  0.3438045375  0.3350785340  0.3211169284  0.3647469459  0.6986899563  4.9256489277  0.2169575691  10            0.0763754129 
0.3542757417  0.4541484716  0.4608695652  0.4475982533  0.4434782609  0.4432314410  0.4434782609  0.4301310044  0.4086956522  0.3804537522  0.3472949389  0.3455497382  0.3438045375  1.3973799127  4.7318486214  0.2169952393  20            0.0740518332 
0.4127399651  0.5873362445  0.5826086957  0.5327510917  0.5565217391  0.5371179039  0.5217391304  0.5000000000  0.5217391304  0.4799301920  0.4240837696  0.3664921466  0.3804537522  2.0960698690  4.5657914162  0.3011631966  30            0.0777051687 
0.3520942408  0.5786026201  0.5739130435  0.5021834061  0.5043478261  0.4912663755  0.5217391304  0.4628820961  0.4695652174  0.3874345550  0.3560209424  0.3333333333  0.3315881326  2.7947598253  4.3463024616  0.3011631966  40            0.0754354000 
0.5628272251  0.7903930131  0.7826086957  0.7336244541  0.7130434783  0.7510917031  0.6956521739  0.7248908297  0.7130434783  0.6090750436  0.5532286213  0.5305410122  0.5584642234  3.4934497817  4.1109853268  0.3011631966  50            0.0733509779 
0.5541012216  0.7838427948  0.7826086957  0.7183406114  0.6695652174  0.7336244541  0.7130434783  0.6965065502  0.6695652174  0.6352530541  0.5636998255  0.4991273997  0.5183246073  4.1921397380  3.7100406885  0.3011631966  60            0.0753796816 
0.5959860384  0.8165938865  0.7913043478  0.7794759825  0.7565217391  0.7772925764  0.7652173913  0.7641921397  0.7826086957  0.6614310646  0.6055846422  0.5357766143  0.5811518325  4.8908296943  3.4406155348  0.3011631966  70            0.0759250164 
0.6147469459  0.8384279476  0.8347826087  0.7969432314  0.8086956522  0.8144104803  0.8347826087  0.8056768559  0.8000000000  0.6666666667  0.6212914485  0.5689354276  0.6020942408  5.5895196507  3.1490550518  0.3011631966  80            0.0852102280 
0.5636998255  0.8384279476  0.8869565217  0.8187772926  0.8347826087  0.8078602620  0.8782608696  0.8056768559  0.8434782609  0.6125654450  0.5811518325  0.5130890052  0.5479930192  6.2882096070  2.8056532860  0.3011631966  90            0.0810959578 
0.5916230366  0.8755458515  0.8869565217  0.8427947598  0.8521739130  0.8231441048  0.8608695652  0.8340611354  0.8521739130  0.6317626527  0.5881326353  0.5532286213  0.5933682373  6.9868995633  2.7353571415  0.3011631966  100           0.0801695824 
0.5846422339  0.8558951965  0.9043478261  0.8537117904  0.8695652174  0.8318777293  0.8956521739  0.8427947598  0.8521739130  0.6230366492  0.6020942408  0.5497382199  0.5636998255  7.6855895197  2.5181889772  0.3011631966  110           0.0762698174 
0.5523560209  0.8537117904  0.8782608696  0.8580786026  0.8521739130  0.8449781659  0.8869565217  0.8362445415  0.8608695652  0.5898778360  0.5584642234  0.5253054101  0.5357766143  8.3842794760  2.3151820660  0.3011631966  120           0.0756701231 
0.5514834206  0.8820960699  0.9130434783  0.8580786026  0.8434782609  0.8406113537  0.9043478261  0.8427947598  0.8869565217  0.6160558464  0.5584642234  0.5130890052  0.5183246073  9.0829694323  2.2139648199  0.3011631966  130           0.0757803679 
0.5558464223  0.8864628821  0.8869565217  0.8886462882  0.8695652174  0.8646288210  0.8956521739  0.8755458515  0.8782608696  0.5898778360  0.5445026178  0.5375218150  0.5514834206  9.7816593886  2.2267587304  0.3011631966  140           0.0737772703 
0.5807155323  0.9082969432  0.9043478261  0.8951965066  0.8695652174  0.8755458515  0.9130434783  0.9126637555  0.8956521739  0.6230366492  0.5549738220  0.5567190227  0.5881326353  10.480349345  1.9326684475  0.3011631966  150           0.0754782438 
0.5122164049  0.9082969432  0.9130434783  0.9213973799  0.8695652174  0.8689956332  0.9130434783  0.8930131004  0.8956521739  0.5357766143  0.5218150087  0.5026178010  0.4886561955  11.179039301  2.0165463686  0.3011631966  160           0.0812942266 
0.4432809773  0.9235807860  0.9217391304  0.9082969432  0.8782608696  0.8777292576  0.9130434783  0.8711790393  0.8695652174  0.4642233857  0.4485165794  0.4467713787  0.4136125654  11.877729257  1.8342874169  0.3011631966  170           0.0768564463 
0.5091623037  0.9519650655  0.9478260870  0.9519650655  0.8956521739  0.9410480349  0.9565217391  0.9344978166  0.9043478261  0.5235602094  0.4991273997  0.5200698080  0.4938917976  12.576419214  1.8389481068  0.3011631966  180           0.0760702610 
0.5327225131  0.9039301310  0.9217391304  0.9126637555  0.8695652174  0.8755458515  0.9130434783  0.8864628821  0.8782608696  0.5567190227  0.5218150087  0.5200698080  0.5322862129  13.275109170  1.6454607368  0.3011631966  190           0.0753369808 
0.5000000000  0.9344978166  0.9304347826  0.9388646288  0.8695652174  0.9039301310  0.9217391304  0.9170305677  0.8869565217  0.5253054101  0.4834205934  0.4991273997  0.4921465969  13.973799126  1.6735839367  0.3011631966  200           0.0712390184 
0.4694589878  0.9650655022  0.9565217391  0.9650655022  0.9043478261  0.9410480349  0.9478260870  0.9323144105  0.8956521739  0.4781849913  0.4589877836  0.4956369983  0.4450261780  14.672489083  1.6211343646  0.3011631966  210           0.0758692026 
0.5200698080  0.9650655022  0.9391304348  0.9716157205  0.9217391304  0.9628820961  0.9478260870  0.9628820961  0.9130434783  0.5392670157  0.4886561955  0.5305410122  0.5218150087  15.371179039  1.4802548647  0.3011631966  220           0.0759889603 
0.5191972077  0.9563318777  0.9391304348  0.9323144105  0.8782608696  0.9170305677  0.9391304348  0.9082969432  0.8956521739  0.5671902269  0.4991273997  0.5095986038  0.5008726003  16.069868995  1.4979128122  0.3011631966  230           0.0731866837 
0.4873472949  0.9716157205  0.9565217391  0.9781659389  0.9304347826  0.9759825328  0.9391304348  0.9606986900  0.9043478261  0.4904013962  0.4851657941  0.4973821990  0.4764397906  16.768558952  1.4017123818  0.3011631966  240           0.0757190466 
0.4947643979  0.9694323144  0.9565217391  0.9803493450  0.9217391304  0.9628820961  0.9478260870  0.9694323144  0.9130434783  0.5148342059  0.4712041885  0.4991273997  0.4938917976  17.467248908  1.3784018040  0.3011631966  250           0.0762621880 
0.5100349040  0.9825327511  0.9565217391  0.9628820961  0.8956521739  0.9454148472  0.9565217391  0.9650655022  0.9130434783  0.5514834206  0.4712041885  0.5130890052  0.5043630017  18.165938864  1.3138758540  0.3011631966  260           0.0792329550 
0.5043630017  0.9716157205  0.9478260870  0.9868995633  0.9391304348  0.9825327511  0.9217391304  0.9737991266  0.8956521739  0.5270506108  0.5026178010  0.4991273997  0.4886561955  18.864628821  1.3602711678  0.3011631966  270           0.0800747156 
0.4834205934  0.9847161572  0.9565217391  0.9781659389  0.9043478261  0.9737991266  0.9652173913  0.9672489083  0.9217391304  0.5165794066  0.4537521815  0.5008726003  0.4624781850  19.563318777  1.2932315826  0.3011631966  280           0.0784664154 
0.4938917976  0.9868995633  0.9565217391  0.9890829694  0.9478260870  0.9912663755  0.9565217391  0.9868995633  0.9217391304  0.5287958115  0.4746945899  0.4956369983  0.4764397906  20.262008733  1.1977869868  0.3012223244  290           0.0763020992 
0.4528795812  0.9934497817  0.9913043478  0.9868995633  0.9478260870  0.9759825328  0.9652173913  0.9563318777  0.9304347826  0.4816753927  0.4275741710  0.4729493892  0.4293193717  20.960698690  1.1878678322  0.3012223244  300           0.0792136908 
0.4781849913  0.9934497817  0.9739130435  0.9912663755  0.9652173913  0.9890829694  0.9478260870  0.9803493450  0.9130434783  0.5026178010  0.4589877836  0.4973821990  0.4537521815  21.659388646  1.1955173850  0.3013181686  310           0.0902893305 
0.4995636998  0.9934497817  0.9652173913  0.9934497817  0.9565217391  0.9912663755  0.9565217391  0.9847161572  0.9130434783  0.5497382199  0.4712041885  0.5043630017  0.4729493892  22.358078602  1.1418597102  0.3013181686  320           0.0772428036 
0.5130890052  0.9934497817  0.9739130435  0.9890829694  0.9652173913  0.9890829694  0.9652173913  0.9825327511  0.9217391304  0.5671902269  0.4816753927  0.5043630017  0.4991273997  23.056768559  1.1425886452  0.3013181686  330           0.0818151951 
0.4969458988  0.9934497817  0.9652173913  0.9978165939  0.9739130435  0.9956331878  0.9652173913  0.9890829694  0.9130434783  0.5392670157  0.4746945899  0.4886561955  0.4851657941  23.755458515  1.0709514022  0.3013181686  340           0.0793874979 
0.5056719023  0.9956331878  0.9739130435  0.9956331878  0.9652173913  0.9956331878  0.9565217391  0.9847161572  0.9130434783  0.5549738220  0.4712041885  0.5043630017  0.4921465969  24.454148471  1.0700980067  0.3013181686  350           0.0941523314 
0.4825479930  0.9978165939  0.9913043478  0.9978165939  0.9565217391  0.9912663755  0.9565217391  0.9781659389  0.9391304348  0.5270506108  0.4485165794  0.4869109948  0.4677137871  25.152838427  1.1212214649  0.3013181686  360           0.0784622908 
0.5069808028  0.9978165939  0.9739130435  1.0000000000  0.9739130435  0.9956331878  0.9565217391  0.9912663755  0.9391304348  0.5532286213  0.4746945899  0.5026178010  0.4973821990  25.851528384  1.0429202080  0.3013181686  370           0.0784463882 
0.5349040140  0.9912663755  0.9565217391  0.9978165939  0.9652173913  0.9956331878  0.9652173913  0.9956331878  0.9217391304  0.5759162304  0.5113438045  0.5235602094  0.5287958115  26.550218340  1.0551895440  0.3013181686  380           0.0818597555 
0.5026178010  0.9978165939  0.9739130435  1.0000000000  0.9739130435  0.9978165939  0.9565217391  0.9934497817  0.9391304348  0.5479930192  0.4624781850  0.5061082024  0.4938917976  27.248908296  1.0358974457  0.3013181686  390           0.0772858381 
0.5143979058  0.9978165939  0.9739130435  1.0000000000  0.9826086957  0.9978165939  0.9652173913  0.9956331878  0.9565217391  0.5654450262  0.4886561955  0.4973821990  0.5061082024  27.947598253  1.0430364609  0.3013181686  400           0.0855125189 
0.5244328098  0.9978165939  0.9739130435  1.0000000000  0.9739130435  0.9934497817  0.9565217391  0.9912663755  0.9478260870  0.5811518325  0.4781849913  0.5183246073  0.5200698080  28.646288209  0.9789468408  0.3013181686  410           0.0743072033 
0.5043630017  0.9978165939  0.9565217391  1.0000000000  0.9739130435  0.9978165939  0.9739130435  0.9934497817  0.9478260870  0.5445026178  0.4834205934  0.4956369983  0.4938917976  29.344978165  1.0283937991  0.3013181686  420           0.0765359879 
0.4873472949  0.9978165939  0.9913043478  1.0000000000  0.9739130435  0.9956331878  0.9652173913  0.9912663755  0.9565217391  0.5392670157  0.4589877836  0.4764397906  0.4746945899  30.043668122  1.0348526180  0.3013181686  430           0.0759566069 
0.5139616056  0.9978165939  0.9565217391  0.9978165939  0.9652173913  0.9978165939  0.9652173913  0.9934497817  0.9217391304  0.5654450262  0.4764397906  0.5165794066  0.4973821990  30.742358078  1.0434525251  0.3013181686  440           0.0819246292 
0.5143979058  0.9978165939  0.9826086957  1.0000000000  0.9652173913  0.9978165939  0.9565217391  0.9956331878  0.9478260870  0.5671902269  0.4764397906  0.5026178010  0.5113438045  31.441048034  1.0578269005  0.3013181686  450           0.0776566267 
0.4895287958  0.9978165939  0.9913043478  1.0000000000  0.9739130435  0.9956331878  0.9565217391  0.9912663755  0.9565217391  0.5375218150  0.4554973822  0.4956369983  0.4694589878  32.139737991  0.9995667100  0.3013181686  460           0.0773809195 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 329, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 355, in __iter__
    return self._get_iterator()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 301, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 914, in __init__
    w.start()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/util.py", line 319, in _exit_function
    p.join()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 122, in join
    assert self._parent_pid == os.getpid(), 'can only join a child process'
AssertionError: can only join a child process
Traceback (most recent call last):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2807959) is killed by signal: Terminated. 
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 269, in <module>
    algorithm.to(device)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 673, in to
    return self._apply(convert)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 387, in _apply
    module._apply(fn)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 409, in _apply
    param_applied = fn(param)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 671, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2264, in update
    feat_ab = self.featurizer(d_b_x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/normalization.py", line 171, in forward
    input, self.normalized_shape, self.weight, self.bias, self.eps)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2205, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA error: device-side assert triggered
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
Traceback (most recent call last):
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/usr/pycharm/pycharm-2021.3.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 306, in <module>
    step_vals = algorithm.update(minibatches_device, uda_device)   # 返回的是loss 字典
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/algorithms.py", line 2264, in update
    feat_ab = self.featurizer(d_b_x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/networks.py", line 284, in forward
    x = self.layer1(x)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py", line 119, in forward
    input = module(input)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/normalization.py", line 171, in forward
    input, self.normalized_shape, self.weight, self.bias, self.eps)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py", line 2205, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA error: device-side assert triggered
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
A->B
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3314814815  0.3179012346  0.3148148148  0.3888888889  0.3827160494  0.3780864198  0.3333333333  0.3518518519  0.3395061728  0.3259259259  0.3345679012  0.3197530864  0.3456790123  0.0000000000  4.5427684784  0.1364407539  0             0.3787689209 
0.6055555556  0.6496913580  0.6790123457  0.6589506173  0.6666666667  0.6666666667  0.6666666667  0.6527777778  0.6419753086  0.6148148148  0.6123456790  0.5975308642  0.5975308642  0.4938271605  3.9139316082  0.2169637680  10            0.0761846542 
0.5771604938  0.6929012346  0.6481481481  0.6651234568  0.6604938272  0.6574074074  0.6419753086  0.6466049383  0.6172839506  0.6333333333  0.5530864198  0.5790123457  0.5432098765  0.9876543210  3.5868649721  0.2169637680  20            0.0724388599 
0.6620370370  0.6712962963  0.6481481481  0.6712962963  0.6604938272  0.6697530864  0.6419753086  0.6481481481  0.6296296296  0.7000000000  0.6592592593  0.6370370370  0.6518518519  1.4814814815  3.1134026766  0.2990694046  30            0.0733005524 
0.7240740741  0.8148148148  0.7777777778  0.8209876543  0.7654320988  0.7993827160  0.7654320988  0.8055555556  0.7407407407  0.7481481481  0.6987654321  0.7197530864  0.7296296296  1.9753086420  2.7026739120  0.3011693954  40            0.0732264757 
0.7145061728  0.8179012346  0.7777777778  0.8148148148  0.7839506173  0.8163580247  0.7839506173  0.8179012346  0.7654320988  0.7246913580  0.7000000000  0.7098765432  0.7234567901  2.4691358025  2.3866310120  0.3011693954  50            0.0726459026 
0.7743827160  0.8503086420  0.7962962963  0.8703703704  0.8086419753  0.8549382716  0.8024691358  0.8626543210  0.8271604938  0.8000000000  0.7271604938  0.7740740741  0.7962962963  2.9629629630  2.1978953362  0.3011693954  60            0.0743433952 
0.7580246914  0.8595679012  0.8148148148  0.8765432099  0.8148148148  0.8487654321  0.8395061728  0.8626543210  0.8333333333  0.7753086420  0.7185185185  0.7555555556  0.7827160494  3.4567901235  2.0059275031  0.3011755943  70            0.0738863230 
0.7787037037  0.8858024691  0.8333333333  0.8873456790  0.8395061728  0.8549382716  0.8456790123  0.8858024691  0.8641975309  0.8098765432  0.7259259259  0.7839506173  0.7950617284  3.9506172840  1.9683536410  0.3011755943  80            0.0736245632 
0.8271604938  0.9737654321  0.9259259259  0.9598765432  0.9567901235  0.9367283951  0.9074074074  0.9567901235  0.9074074074  0.7975308642  0.7925925926  0.8469135802  0.8716049383  4.4444444444  1.9891068935  0.3011755943  90            0.0751553059 
0.7188271605  0.8827160494  0.8456790123  0.8981481481  0.8641975309  0.8765432099  0.8518518519  0.8904320988  0.8456790123  0.7333333333  0.6950617284  0.7135802469  0.7333333333  4.9382716049  1.8354401588  0.3011755943  100           0.0744649887 
0.8453703704  0.9814814815  0.9382716049  0.9614197531  0.9259259259  0.9382716049  0.9074074074  0.9675925926  0.9197530864  0.8345679012  0.7950617284  0.8679012346  0.8839506173  5.4320987654  1.7560074568  0.3011970520  110           0.0733448267 
0.7629629630  0.9645061728  0.9074074074  0.9675925926  0.9506172840  0.9490740741  0.9320987654  0.9567901235  0.9259259259  0.7555555556  0.7209876543  0.7691358025  0.8061728395  5.9259259259  1.6702455163  0.3011970520  120           0.0726907253 
0.7756172840  0.9830246914  0.9814814815  0.9907407407  0.9753086420  0.9706790123  0.9691358025  0.9753086420  0.9320987654  0.7296296296  0.7666666667  0.7901234568  0.8160493827  6.4197530864  1.5078418493  0.3011970520  130           0.0751214504 
0.7641975309  0.9521604938  0.8888888889  0.9567901235  0.9320987654  0.9290123457  0.9074074074  0.9490740741  0.9012345679  0.7802469136  0.7135802469  0.7629629630  0.8000000000  6.9135802469  1.5103357434  0.3011970520  140           0.0740970850 
0.8006172840  0.9907407407  0.9876543210  0.9938271605  0.9876543210  0.9706790123  0.9691358025  0.9783950617  0.9382716049  0.7666666667  0.7790123457  0.8135802469  0.8432098765  7.4074074074  1.3902406693  0.3011970520  150           0.0734380960 
0.7496913580  0.9922839506  0.9938271605  1.0000000000  1.0000000000  0.9799382716  0.9753086420  0.9783950617  0.9382716049  0.6901234568  0.7481481481  0.7814814815  0.7790123457  7.9012345679  1.3160675764  0.3011970520  160           0.0729981422 
0.7975308642  0.9953703704  0.9938271605  0.9969135802  1.0000000000  0.9861111111  0.9938271605  0.9845679012  0.9444444444  0.7567901235  0.7666666667  0.8172839506  0.8493827160  8.3950617284  1.2625007629  0.3011970520  170           0.0736587048 
0.7885802469  0.9953703704  0.9938271605  0.9984567901  0.9938271605  0.9845679012  0.9938271605  0.9830246914  0.9444444444  0.7469135802  0.7629629630  0.8135802469  0.8308641975  8.8888888889  1.1956058264  0.3832964897  180           0.0763452768 
0.7716049383  0.9938271605  0.9938271605  0.9984567901  1.0000000000  0.9891975309  0.9876543210  0.9845679012  0.9444444444  0.7222222222  0.7481481481  0.8024691358  0.8135802469  9.3827160494  1.1645304680  0.3832964897  190           0.0777641773 
0.8163580247  0.9953703704  0.9938271605  0.9984567901  1.0000000000  0.9891975309  0.9876543210  0.9907407407  0.9444444444  0.7925925926  0.7679012346  0.8345679012  0.8703703704  9.8765432099  1.0989856005  0.3832964897  200           0.0729154825 
0.7932098765  0.9953703704  0.9876543210  0.9969135802  0.9938271605  0.9938271605  0.9876543210  0.9953703704  0.9506172840  0.7827160494  0.7308641975  0.8111111111  0.8481481481  10.370370370  1.0915806770  0.3832964897  210           0.0758500576 
0.8163580247  0.9969135802  0.9938271605  0.9984567901  0.9938271605  0.9953703704  1.0000000000  0.9953703704  0.9506172840  0.8148148148  0.7506172840  0.8370370370  0.8629629630  10.864197530  1.1054042459  0.3832964897  220           0.0740595818 
0.8018518519  0.9953703704  0.9938271605  0.9984567901  0.9938271605  0.9938271605  1.0000000000  0.9953703704  0.9506172840  0.7913580247  0.7370370370  0.8234567901  0.8555555556  11.358024691  1.0374162018  0.3832964897  230           0.0746330976 
0.8070987654  0.9969135802  0.9938271605  1.0000000000  0.9938271605  0.9922839506  0.9938271605  0.9876543210  0.9506172840  0.7802469136  0.7777777778  0.8271604938  0.8432098765  11.851851851  1.0396656811  0.3832964897  240           0.0755016565 
0.7984567901  0.9969135802  0.9938271605  1.0000000000  0.9938271605  0.9969135802  1.0000000000  0.9953703704  0.9506172840  0.7876543210  0.7395061728  0.8234567901  0.8432098765  12.345679012  1.0177239180  0.3832964897  250           0.0758755207 
0.8160493827  0.9984567901  0.9938271605  1.0000000000  1.0000000000  0.9953703704  1.0000000000  0.9984567901  0.9567901235  0.8037037037  0.7753086420  0.8308641975  0.8543209877  12.839506172  1.0109336019  0.3832964897  260           0.0742791414 
0.8046296296  0.9984567901  1.0000000000  1.0000000000  0.9938271605  0.9922839506  0.9876543210  0.9907407407  0.9753086420  0.7962962963  0.7753086420  0.8123456790  0.8345679012  13.333333333  1.0635942996  0.3832964897  270           0.0752215385 
0.7938271605  0.9984567901  0.9938271605  1.0000000000  1.0000000000  0.9938271605  1.0000000000  0.9984567901  0.9567901235  0.7740740741  0.7506172840  0.8135802469  0.8370370370  13.827160493  0.9633982539  0.3832964897  280           0.0741573811 
0.8086419753  0.9984567901  0.9938271605  1.0000000000  1.0000000000  0.9984567901  1.0000000000  0.9984567901  0.9567901235  0.8000000000  0.7543209877  0.8296296296  0.8506172840  14.320987654  0.9477597415  0.3832964897  290           0.0752562284 
0.8129629630  0.9984567901  0.9938271605  1.0000000000  1.0000000000  0.9984567901  1.0000000000  0.9984567901  0.9567901235  0.8111111111  0.7580246914  0.8358024691  0.8469135802  14.814814814  0.9306955099  0.3832964897  300           0.0750012875 
0.7891975309  0.9969135802  1.0000000000  1.0000000000  0.9938271605  0.9922839506  1.0000000000  0.9922839506  0.9753086420  0.7617283951  0.7666666667  0.8074074074  0.8209876543  15.308641975  0.9693866968  0.3832964897  310           0.0753297091 
0.8055555556  1.0000000000  0.9938271605  1.0000000000  1.0000000000  0.9969135802  1.0000000000  0.9984567901  0.9567901235  0.7913580247  0.7604938272  0.8283950617  0.8419753086  15.802469135  0.9321180761  0.3832964897  320           0.0742564917 
0.8086419753  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.7962962963  0.7518518519  0.8320987654  0.8543209877  16.296296296  0.9171229124  0.3832964897  330           0.0737452984 
0.8111111111  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.8024691358  0.7456790123  0.8333333333  0.8629629630  16.790123456  0.9471314251  0.3832964897  340           0.0728687286 
0.8268518519  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9953703704  1.0000000000  0.9984567901  0.9691358025  0.8185185185  0.7790123457  0.8456790123  0.8641975309  17.283950617  0.8921619356  0.3832964897  350           0.0730741262 
0.8203703704  1.0000000000  0.9938271605  1.0000000000  1.0000000000  0.9984567901  1.0000000000  0.9984567901  0.9567901235  0.8160493827  0.7629629630  0.8382716049  0.8641975309  17.777777777  0.9044829249  0.3832964897  360           0.0746173382 
0.8299382716  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9567901235  0.8283950617  0.7666666667  0.8518518519  0.8728395062  18.271604938  0.8998189509  0.3832964897  370           0.0754047155 
0.8135802469  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969135802  1.0000000000  0.9984567901  0.9753086420  0.8024691358  0.7716049383  0.8333333333  0.8469135802  18.765432098  0.9028805614  0.3832964897  380           0.0775310993 
0.8000000000  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.7851851852  0.7419753086  0.8172839506  0.8555555556  19.259259259  0.8847963393  0.3832964897  390           0.0750981569 
0.8429012346  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9567901235  0.8444444444  0.7765432099  0.8654320988  0.8851851852  19.753086419  0.9378139794  0.3832964897  400           0.0729919672 
0.7975308642  1.0000000000  0.9938271605  1.0000000000  1.0000000000  0.9984567901  1.0000000000  0.9984567901  0.9629629630  0.7765432099  0.7555555556  0.8172839506  0.8407407407  20.246913580  0.8734838009  0.3832964897  410           0.0748911858 
0.8117283951  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  1.0000000000  0.9984567901  0.9629629630  0.7987654321  0.7703703704  0.8358024691  0.8419753086  20.740740740  0.8605186939  0.3832964897  420           0.0745687008 
0.8172839506  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9691358025  0.8148148148  0.7506172840  0.8407407407  0.8629629630  21.234567901  0.9114114404  0.3832964897  430           0.0744697332 
0.8370370370  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9969135802  1.0000000000  1.0000000000  0.9753086420  0.8432098765  0.7839506173  0.8530864198  0.8679012346  21.728395061  0.9010391772  0.3832964897  440           0.0733309031 
0.8101851852  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.8012345679  0.7506172840  0.8320987654  0.8567901235  22.222222222  0.8929822326  0.3832964897  450           0.0814471722 
0.8067901235  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9753086420  0.7925925926  0.7555555556  0.8296296296  0.8493827160  22.716049382  0.8352630019  0.3832964897  460           0.0753344536 
0.8243827160  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.8234567901  0.7666666667  0.8469135802  0.8604938272  23.209876543  0.9024679542  0.3832964897  470           0.0770034313 
0.8271604938  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9753086420  0.8283950617  0.7679012346  0.8481481481  0.8641975309  23.703703703  0.8764753103  0.3832964897  480           0.0745473385 
0.7879629630  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.7567901235  0.7469135802  0.8111111111  0.8370370370  24.197530864  0.8516684711  0.3832964897  490           0.0784217834 
0.8129629630  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9629629630  0.8074074074  0.7481481481  0.8320987654  0.8641975309  24.691358024  0.8562454045  0.3832964897  500           0.0755716085 
0.8203703704  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9984567901  0.9691358025  0.8123456790  0.7592592593  0.8493827160  0.8604938272  25.185185185  0.8630810797  0.3832964897  510           0.0775404215 
0.8456790123  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9814814815  0.8555555556  0.7790123457  0.8654320988  0.8827160494  25.679012345  0.8724206448  0.3832964897  520           0.0767592907 
0.8398148148  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8456790123  0.7827160494  0.8691358025  0.8617283951  26.172839506  0.8288864315  0.3833513260  530           0.0777122498 
0.8262345679  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8320987654  0.7592592593  0.8493827160  0.8641975309  26.666666666  0.8417609572  0.3833513260  540           0.0751940489 
0.8280864198  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9691358025  0.8320987654  0.7592592593  0.8506172840  0.8703703704  27.160493827  0.8434481084  0.3833513260  550           0.0768634081 
0.8148148148  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9814814815  0.8074074074  0.7592592593  0.8395061728  0.8530864198  27.654320987  0.8311794400  0.3833513260  560           0.0762251854 
0.8376543210  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8456790123  0.7790123457  0.8654320988  0.8604938272  28.148148148  0.7959010959  0.3833513260  570           0.0776124239 
0.8459876543  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9876543210  0.8543209877  0.7790123457  0.8728395062  0.8777777778  28.641975308  0.8142378211  0.3833513260  580           0.0749301910 
0.8262345679  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8308641975  0.7604938272  0.8469135802  0.8666666667  29.135802469  0.8050466418  0.3833513260  590           0.0722855568 
0.8358024691  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9814814815  0.8395061728  0.7679012346  0.8617283951  0.8740740741  29.629629629  0.8252801597  0.3833513260  600           0.0747817516 
0.8317901235  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8370370370  0.7617283951  0.8530864198  0.8753086420  30.123456790  0.7900328040  0.3833513260  610           0.0810091734 
0.8271604938  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8271604938  0.7604938272  0.8481481481  0.8728395062  30.617283950  0.8236040115  0.3833513260  620           0.0720951080 
0.8061728395  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9629629630  0.7987654321  0.7419753086  0.8308641975  0.8530864198  31.111111111  0.8397653520  0.3833513260  630           0.0833513498 
0.8296296296  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9814814815  0.8358024691  0.7654320988  0.8493827160  0.8679012346  31.604938271  0.8108501494  0.3833513260  640           0.0750574827 
0.8253086420  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8259259259  0.7592592593  0.8456790123  0.8703703704  32.098765432  0.7968284309  0.3833513260  650           0.0790586710 
0.8401234568  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9753086420  0.8518518519  0.7691358025  0.8604938272  0.8790123457  32.592592592  0.8207746148  0.3833513260  660           0.0752008438 
0.8398148148  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.9876543210  0.8481481481  0.7740740741  0.8604938272  0.8765432099  33.086419753  0.7741767406  0.3833513260  670           0.0976073980 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3614197531  0.3395061728  0.3333333333  0.3209876543  0.3765432099  0.3333333333  0.3580246914  0.3472222222  0.3827160494  0.3469135802  0.3666666667  0.3814814815  0.3506172840  0.0000000000  4.4635930061  0.1364407539  0             0.3826806545 
0.6429012346  0.6574074074  0.6543209877  0.6188271605  0.6358024691  0.6527777778  0.6049382716  0.6450617284  0.6358024691  0.6358024691  0.6543209877  0.6530864198  0.6283950617  0.4938271605  3.9260170937  0.2990632057  10            0.0775506258 
0.5901234568  0.7361111111  0.6975308642  0.6543209877  0.6049382716  0.6651234568  0.7222222222  0.6743827160  0.6913580247  0.5580246914  0.6024691358  0.6037037037  0.5962962963  0.9876543210  3.5286206007  0.2990632057  20            0.0751076221 
0.6209876543  0.6929012346  0.6790123457  0.6543209877  0.6913580247  0.6327160494  0.6666666667  0.6496913580  0.6604938272  0.6098765432  0.6246913580  0.6382716049  0.6111111111  1.4814814815  3.0289313555  0.2990632057  30            0.0715938807 
0.7283950617  0.8348765432  0.8148148148  0.7608024691  0.7160493827  0.8132716049  0.8518518519  0.8395061728  0.8518518519  0.7049382716  0.7518518519  0.7320987654  0.7246913580  1.9753086420  2.5512418509  0.2990632057  40            0.0738758087 
0.7250000000  0.8688271605  0.8580246914  0.7669753086  0.7345679012  0.8194444444  0.8456790123  0.8441358025  0.8641975309  0.7135802469  0.7296296296  0.7222222222  0.7345679012  2.4691358025  2.3078505278  0.2990632057  50            0.0740161657 
0.7456790123  0.8734567901  0.8580246914  0.7762345679  0.7345679012  0.8271604938  0.8827160494  0.8487654321  0.8703703704  0.7382716049  0.7543209877  0.7345679012  0.7555555556  2.9629629630  2.1896298170  0.3040957451  60            0.0734345198 
0.7456790123  0.8750000000  0.8765432099  0.7824074074  0.7160493827  0.8271604938  0.8703703704  0.8518518519  0.8703703704  0.7407407407  0.7530864198  0.7308641975  0.7580246914  3.4567901235  2.0842432380  0.3040957451  70            0.0744007111 
0.7382716049  0.8811728395  0.8641975309  0.7839506173  0.7222222222  0.8333333333  0.8703703704  0.8487654321  0.8765432099  0.7370370370  0.7407407407  0.7271604938  0.7481481481  3.9506172840  2.0554933310  0.3040957451  80            0.0745974779 
0.7058641975  0.8657407407  0.8641975309  0.7484567901  0.7592592593  0.7901234568  0.7901234568  0.8333333333  0.8456790123  0.6987654321  0.6975308642  0.7135802469  0.7135802469  4.4444444444  2.0899229288  0.3040957451  90            0.0729301214 
0.7765432099  0.8827160494  0.8518518519  0.7762345679  0.7592592593  0.8317901235  0.8703703704  0.8425925926  0.8888888889  0.7679012346  0.7827160494  0.7679012346  0.7876543210  4.9382716049  2.0304464102  0.3040957451  100           0.0752074480 
0.7651234568  0.8950617284  0.8580246914  0.8441358025  0.8024691358  0.9135802469  0.8888888889  0.9197530864  0.8950617284  0.7666666667  0.7654320988  0.7530864198  0.7753086420  5.4320987654  1.9608162403  0.3041019440  110           0.0761265039 
0.7379629630  0.8981481481  0.8765432099  0.7947530864  0.7592592593  0.8441358025  0.8765432099  0.8580246914  0.8827160494  0.7320987654  0.7407407407  0.7283950617  0.7506172840  5.9259259259  1.9029592395  0.3041019440  120           0.0732578278 
0.7700617284  0.9089506173  0.8888888889  0.8348765432  0.7839506173  0.8996913580  0.8950617284  0.9027777778  0.9012345679  0.7666666667  0.7765432099  0.7518518519  0.7851851852  6.4197530864  1.8150104165  0.3041019440  130           0.0766079664 
0.7851851852  0.9151234568  0.9074074074  0.8456790123  0.7901234568  0.9151234568  0.9012345679  0.9151234568  0.9135802469  0.7814814815  0.7925925926  0.7617283951  0.8049382716  6.9135802469  1.8208725691  0.3041019440  140           0.0735642195 
0.7484567901  0.9166666667  0.8765432099  0.8395061728  0.7901234568  0.8996913580  0.8765432099  0.8981481481  0.8888888889  0.7370370370  0.7543209877  0.7358024691  0.7666666667  7.4074074074  1.6911217332  0.3041019440  150           0.0717607737 
0.8268518519  0.9166666667  0.8888888889  0.8425925926  0.7962962963  0.9074074074  0.9012345679  0.9166666667  0.9074074074  0.8259259259  0.8469135802  0.8049382716  0.8296296296  7.9012345679  1.6781466603  0.3862504959  160           0.0746278763 
0.7762345679  0.9382716049  0.9259259259  0.8595679012  0.8209876543  0.9212962963  0.9074074074  0.9228395062  0.8950617284  0.7679012346  0.7888888889  0.7580246914  0.7901234568  8.3950617284  1.6630807042  0.3862504959  170           0.0796962261 
0.7685185185  0.9459876543  0.9259259259  0.8858024691  0.8333333333  0.9290123457  0.8950617284  0.9382716049  0.9135802469  0.7604938272  0.7765432099  0.7530864198  0.7839506173  8.8888888889  1.6484977484  0.3862504959  180           0.0744647503 
0.8098765432  0.9429012346  0.9197530864  0.8395061728  0.7839506173  0.9043209877  0.9074074074  0.9058641975  0.8950617284  0.7913580247  0.8209876543  0.7839506173  0.8432098765  9.3827160494  1.6360908151  0.3862504959  190           0.0751266956 
0.7876543210  0.9629629630  0.9320987654  0.8842592593  0.8333333333  0.9212962963  0.9135802469  0.9290123457  0.9135802469  0.7790123457  0.7938271605  0.7740740741  0.8037037037  9.8765432099  1.5459101796  0.3862504959  200           0.0779971361 
0.8074074074  0.9691358025  0.9506172840  0.9413580247  0.8456790123  0.9675925926  0.9197530864  0.9537037037  0.9259259259  0.8024691358  0.8135802469  0.7975308642  0.8160493827  10.370370370  1.5523258805  0.3862504959  210           0.0766840696 
0.7947530864  0.9737654321  0.9567901235  0.8981481481  0.8456790123  0.9290123457  0.9135802469  0.9320987654  0.9197530864  0.7777777778  0.8000000000  0.7901234568  0.8111111111  10.864197530  1.5220864892  0.3862504959  220           0.0746606588 
0.8080246914  0.9799382716  0.9691358025  0.9367283951  0.8518518519  0.9552469136  0.9135802469  0.9475308642  0.9259259259  0.8000000000  0.8135802469  0.8000000000  0.8185185185  11.358024691  1.4883845091  0.3862504959  230           0.0748567343 
0.8293209877  0.9753086420  0.9629629630  0.9552469136  0.8950617284  0.9737654321  0.9259259259  0.9614197531  0.9444444444  0.8148148148  0.8283950617  0.8308641975  0.8432098765  11.851851851  1.4487632990  0.3862504959  240           0.0738231182 
0.8444444444  0.9799382716  0.9753086420  0.9459876543  0.8703703704  0.9660493827  0.9197530864  0.9521604938  0.9320987654  0.8407407407  0.8481481481  0.8308641975  0.8580246914  12.345679012  1.4000897288  0.3862504959  250           0.0739208460 
0.8401234568  0.9922839506  0.9753086420  0.9629629630  0.8950617284  0.9737654321  0.9197530864  0.9552469136  0.9444444444  0.8358024691  0.8432098765  0.8333333333  0.8481481481  12.839506172  1.3998358607  0.3862504959  260           0.0844043016 
0.8089506173  0.9830246914  0.9629629630  0.9799382716  0.9197530864  0.9830246914  0.9259259259  0.9768518519  0.9320987654  0.7950617284  0.8111111111  0.8111111111  0.8185185185  13.333333333  1.4448833227  0.3862504959  270           0.0733029127 
0.8719135802  0.9861111111  0.9567901235  0.9151234568  0.8456790123  0.9382716049  0.9135802469  0.9444444444  0.9074074074  0.8765432099  0.8814814815  0.8419753086  0.8876543210  13.827160493  1.3237353086  0.3862504959  280           0.0763095140 
0.8564814815  0.9969135802  0.9876543210  0.9598765432  0.9012345679  0.9753086420  0.9259259259  0.9629629630  0.9444444444  0.8456790123  0.8604938272  0.8419753086  0.8777777778  14.320987654  1.3280380487  0.3862504959  290           0.0737208366 
0.7867283951  0.9845679012  0.9753086420  0.9444444444  0.8888888889  0.9537037037  0.9074074074  0.9552469136  0.9259259259  0.7740740741  0.7925925926  0.7901234568  0.7901234568  14.814814814  1.2809825540  0.3862504959  300           0.0750553131 
0.8379629630  0.9953703704  0.9753086420  0.9861111111  0.9320987654  0.9861111111  0.9259259259  0.9768518519  0.9567901235  0.8259259259  0.8382716049  0.8345679012  0.8530864198  15.308641975  1.2211108923  0.3862504959  310           0.0727929115 
0.8299382716  0.9984567901  0.9753086420  0.9753086420  0.9074074074  0.9799382716  0.9197530864  0.9691358025  0.9320987654  0.8259259259  0.8382716049  0.8160493827  0.8395061728  15.802469135  1.2112716556  0.3862504959  320           0.0728616714 
0.8549382716  1.0000000000  0.9876543210  0.9814814815  0.9074074074  0.9814814815  0.9197530864  0.9675925926  0.9444444444  0.8506172840  0.8629629630  0.8395061728  0.8666666667  16.296296296  1.2012617588  0.3862504959  330           0.0747901917 
0.8416666667  1.0000000000  0.9814814815  0.9814814815  0.9197530864  0.9814814815  0.9259259259  0.9691358025  0.9444444444  0.8358024691  0.8506172840  0.8320987654  0.8481481481  16.790123456  1.2343538404  0.3862504959  340           0.0732452154 
0.8342592593  0.9984567901  0.9814814815  0.9861111111  0.9320987654  0.9845679012  0.9259259259  0.9753086420  0.9444444444  0.8283950617  0.8432098765  0.8246913580  0.8407407407  17.283950617  1.1581429362  0.3862504959  350           0.0760183334 
0.8453703704  0.9984567901  0.9938271605  0.9830246914  0.9197530864  0.9861111111  0.9259259259  0.9768518519  0.9444444444  0.8444444444  0.8530864198  0.8345679012  0.8493827160  17.777777777  1.1299571157  0.3862504959  360           0.0760805607 
0.8429012346  0.9922839506  0.9876543210  0.9938271605  0.9506172840  0.9907407407  0.9506172840  0.9799382716  0.9444444444  0.8234567901  0.8469135802  0.8432098765  0.8580246914  18.271604938  1.1087146997  0.3862504959  370           0.0805497646 
0.8450617284  0.9984567901  0.9938271605  0.9814814815  0.9135802469  0.9876543210  0.9259259259  0.9753086420  0.9444444444  0.8481481481  0.8518518519  0.8296296296  0.8506172840  18.765432098  1.0983612537  0.3862504959  380           0.0795200586 
0.8111111111  0.9969135802  0.9876543210  0.9675925926  0.9074074074  0.9706790123  0.9259259259  0.9753086420  0.9259259259  0.8000000000  0.8135802469  0.8098765432  0.8209876543  19.259259259  1.1052989244  0.3862504959  390           0.0729664326 
0.8672839506  1.0000000000  0.9938271605  0.9938271605  0.9320987654  0.9876543210  0.9382716049  0.9783950617  0.9506172840  0.8654320988  0.8777777778  0.8456790123  0.8802469136  19.753086419  1.1391960382  0.3862504959  400           0.0728019953 
0.8351851852  0.9984567901  0.9938271605  0.9907407407  0.9444444444  0.9907407407  0.9320987654  0.9830246914  0.9506172840  0.8296296296  0.8456790123  0.8246913580  0.8407407407  20.246913580  1.0490570784  0.3862504959  410           0.0729401112 
0.8067901235  0.9876543210  0.9753086420  0.9830246914  0.9444444444  0.9907407407  0.9320987654  0.9845679012  0.9444444444  0.7987654321  0.8111111111  0.8024691358  0.8148148148  20.740740740  1.0045575798  0.3862504959  420           0.0746879339 
0.8290123457  1.0000000000  0.9876543210  0.9984567901  0.9629629630  0.9938271605  0.9444444444  0.9907407407  0.9444444444  0.8111111111  0.8395061728  0.8259259259  0.8395061728  21.234567901  1.1500692606  0.3862504959  430           0.0748932600 
0.8145061728  0.9969135802  0.9876543210  0.9814814815  0.9197530864  0.9907407407  0.9320987654  0.9830246914  0.9320987654  0.8024691358  0.8246913580  0.8086419753  0.8222222222  21.728395061  1.0933218479  0.3862504959  440           0.0735161543 
0.8138888889  0.9938271605  0.9814814815  0.9984567901  0.9691358025  0.9984567901  0.9506172840  0.9969135802  0.9567901235  0.7851851852  0.8259259259  0.8172839506  0.8271604938  22.222222222  1.0618384421  0.3862504959  450           0.0726558208 
0.8540123457  1.0000000000  0.9938271605  0.9799382716  0.9135802469  0.9891975309  0.9259259259  0.9799382716  0.9444444444  0.8530864198  0.8580246914  0.8358024691  0.8691358025  22.716049382  1.0036194384  0.3862504959  460           0.0744095325 
0.8135802469  0.9907407407  0.9753086420  0.9938271605  0.9506172840  0.9969135802  0.9320987654  0.9907407407  0.9629629630  0.7975308642  0.8234567901  0.8098765432  0.8234567901  23.209876543  1.0514517426  0.3862504959  470           0.0740477562 
0.8425925926  0.9984567901  0.9876543210  0.9984567901  0.9691358025  0.9969135802  0.9506172840  0.9969135802  0.9567901235  0.8296296296  0.8567901235  0.8333333333  0.8506172840  23.703703703  1.0337169409  0.3862504959  480           0.0732905865 
0.8716049383  1.0000000000  0.9938271605  0.9938271605  0.9320987654  0.9938271605  0.9444444444  0.9861111111  0.9567901235  0.8716049383  0.8790123457  0.8419753086  0.8938271605  24.197530864  0.9868447423  0.3862504959  490           0.0728724241 
0.8503086420  0.9984567901  0.9938271605  1.0000000000  0.9567901235  0.9984567901  0.9506172840  0.9984567901  0.9506172840  0.8395061728  0.8592592593  0.8481481481  0.8543209877  24.691358024  1.0374503195  0.3862504959  500           0.0767830849 
0.8429012346  0.9984567901  0.9938271605  1.0000000000  0.9629629630  0.9984567901  0.9629629630  0.9984567901  0.9567901235  0.8296296296  0.8493827160  0.8407407407  0.8518518519  25.185185185  0.9898224056  0.3862504959  510           0.0747823954 
0.8413580247  1.0000000000  0.9938271605  0.9938271605  0.9444444444  0.9953703704  0.9320987654  0.9907407407  0.9567901235  0.8370370370  0.8407407407  0.8296296296  0.8580246914  25.679012345  1.0115802765  0.3862504959  520           0.0739679337 
0.8175925926  0.9953703704  0.9753086420  0.9984567901  0.9814814815  0.9984567901  0.9567901235  0.9984567901  0.9753086420  0.7987654321  0.8234567901  0.8160493827  0.8320987654  26.172839506  0.9979321778  0.3862504959  530           0.0732549667 
0.8725308642  1.0000000000  0.9938271605  0.9876543210  0.9197530864  0.9891975309  0.9259259259  0.9830246914  0.9567901235  0.8790123457  0.8641975309  0.8518518519  0.8950617284  26.666666666  1.0166560113  0.3862504959  540           0.0715941429 
0.8274691358  1.0000000000  0.9876543210  0.9984567901  0.9691358025  0.9953703704  0.9506172840  0.9984567901  0.9567901235  0.8135802469  0.8370370370  0.8209876543  0.8382716049  27.160493827  1.0519963324  0.3862504959  550           0.0739467144 
0.8348765432  1.0000000000  0.9876543210  1.0000000000  0.9691358025  0.9969135802  0.9629629630  0.9984567901  0.9506172840  0.8160493827  0.8456790123  0.8308641975  0.8469135802  27.654320987  0.9774404585  0.3862504959  560           0.0721667290 
0.8243827160  1.0000000000  0.9876543210  1.0000000000  0.9753086420  0.9969135802  0.9567901235  1.0000000000  0.9567901235  0.8123456790  0.8320987654  0.8172839506  0.8358024691  28.148148148  0.9481835663  0.3862504959  570           0.0736220360 
0.8367283951  1.0000000000  0.9876543210  1.0000000000  0.9814814815  0.9969135802  0.9506172840  1.0000000000  0.9567901235  0.8271604938  0.8444444444  0.8246913580  0.8506172840  28.641975308  0.9353221059  0.3862504959  580           0.0737421274 
0.8475308642  1.0000000000  0.9876543210  1.0000000000  0.9814814815  0.9953703704  0.9506172840  1.0000000000  0.9629629630  0.8419753086  0.8530864198  0.8320987654  0.8629629630  29.135802469  0.9356915772  0.3862504959  590           0.0812650919 
0.8493827160  1.0000000000  0.9938271605  1.0000000000  0.9753086420  0.9953703704  0.9567901235  1.0000000000  0.9506172840  0.8395061728  0.8506172840  0.8395061728  0.8679012346  29.629629629  0.9524339676  0.3862504959  600           0.0735792637 
0.8651234568  1.0000000000  0.9938271605  0.9984567901  0.9506172840  0.9953703704  0.9567901235  0.9953703704  0.9567901235  0.8691358025  0.8691358025  0.8395061728  0.8827160494  30.123456790  0.9145883441  0.3862504959  610           0.0750303745 
0.8320987654  1.0000000000  0.9876543210  1.0000000000  0.9814814815  0.9969135802  0.9567901235  1.0000000000  0.9567901235  0.8222222222  0.8370370370  0.8209876543  0.8481481481  30.617283950  0.9334209383  0.3862504959  620           0.0742739677 
0.8484567901  1.0000000000  0.9876543210  1.0000000000  0.9691358025  0.9969135802  0.9629629630  0.9969135802  0.9567901235  0.8320987654  0.8567901235  0.8382716049  0.8666666667  31.111111111  0.9774043798  0.3862504959  630           0.0741960287 
0.8305555556  1.0000000000  0.9876543210  1.0000000000  0.9691358025  0.9969135802  0.9506172840  0.9969135802  0.9629629630  0.8222222222  0.8320987654  0.8172839506  0.8506172840  31.604938271  0.9391882658  0.3862504959  640           0.0775641680 
0.8419753086  1.0000000000  0.9876543210  1.0000000000  0.9691358025  0.9984567901  0.9506172840  1.0000000000  0.9567901235  0.8333333333  0.8469135802  0.8320987654  0.8555555556  32.098765432  0.9069283485  0.3862504959  650           0.0731230021 
0.8280864198  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8172839506  0.8333333333  0.8197530864  0.8419753086  32.592592592  0.9295456409  0.3862504959  660           0.0723356485 
0.8364197531  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9567901235  0.8246913580  0.8432098765  0.8234567901  0.8543209877  33.086419753  0.9026417911  0.3862504959  670           0.0760652542 
0.8280864198  1.0000000000  0.9876543210  1.0000000000  0.9691358025  0.9984567901  0.9567901235  1.0000000000  0.9567901235  0.8234567901  0.8308641975  0.8160493827  0.8419753086  33.580246913  0.9031340539  0.3862504959  680           0.0716517925 
0.8200617284  1.0000000000  0.9814814815  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9567901235  0.8037037037  0.8222222222  0.8172839506  0.8370370370  34.074074074  0.9257382989  0.3862504959  690           0.0736123085 
0.8500000000  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9444444444  0.9984567901  0.9567901235  0.8456790123  0.8580246914  0.8283950617  0.8679012346  34.567901234  0.9131382287  0.3862504959  700           0.0738517761 
0.8240740741  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9691358025  0.8086419753  0.8296296296  0.8172839506  0.8407407407  35.061728395  0.9217308342  0.3862504959  710           0.0753736019 
0.8481481481  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9567901235  0.8432098765  0.8555555556  0.8320987654  0.8617283951  35.555555555  0.9003658831  0.3862504959  720           0.0750517130 
0.8320987654  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8234567901  0.8320987654  0.8234567901  0.8493827160  36.049382716  0.9147697330  0.3862504959  730           0.0753667355 
0.8524691358  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9567901235  0.8506172840  0.8580246914  0.8358024691  0.8654320988  36.543209876  0.8791042686  0.3862504959  740           0.0733356953 
0.8432098765  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8333333333  0.8456790123  0.8333333333  0.8604938272  37.037037037  0.9157251716  0.3862504959  750           0.0719989538 
0.8277777778  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8074074074  0.8333333333  0.8197530864  0.8506172840  37.530864197  0.9070333183  0.3862504959  760           0.0746824265 
0.8512345679  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9444444444  0.9984567901  0.9629629630  0.8493827160  0.8530864198  0.8283950617  0.8740740741  38.024691358  0.8859562635  0.3862504959  770           0.0768870831 
0.8108024691  0.9984567901  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.7913580247  0.8086419753  0.8098765432  0.8333333333  38.518518518  0.9047090232  0.3862504959  780           0.0747786760 
0.8388888889  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8259259259  0.8469135802  0.8234567901  0.8592592593  39.012345679  0.8972844183  0.3862504959  790           0.0731405020 
0.8320987654  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9691358025  1.0000000000  0.9691358025  0.8185185185  0.8333333333  0.8246913580  0.8518518519  39.506172839  0.8461982131  0.3862504959  800           0.0751303911 
0.8259259259  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9691358025  0.8061728395  0.8320987654  0.8172839506  0.8481481481  40.000000000  0.8802932560  0.3862504959  810           0.0755236626 
0.8280864198  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9753086420  0.8246913580  0.8308641975  0.8098765432  0.8469135802  40.493827160  0.9213916779  0.3862504959  820           0.0738654375 
0.8382716049  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8283950617  0.8469135802  0.8246913580  0.8530864198  40.987654321  0.8946359217  0.3862504959  830           0.0744099140 
0.8530864198  1.0000000000  0.9938271605  1.0000000000  0.9691358025  0.9984567901  0.9444444444  1.0000000000  0.9629629630  0.8493827160  0.8555555556  0.8308641975  0.8765432099  41.481481481  0.8626734138  0.3862504959  840           0.0750877619 
0.8438271605  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9567901235  0.8345679012  0.8506172840  0.8296296296  0.8604938272  41.975308642  0.8690266788  0.3862504959  850           0.0739738703 
0.8253086420  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9691358025  0.8049382716  0.8320987654  0.8172839506  0.8469135802  42.469135802  0.9049528241  0.3862504959  860           0.0741216898 
0.8688271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9382716049  1.0000000000  0.9567901235  0.8666666667  0.8666666667  0.8506172840  0.8913580247  42.962962963  0.8763269722  0.3862504959  870           0.0752012253 
0.8243827160  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9382716049  1.0000000000  0.9753086420  0.8185185185  0.8259259259  0.8098765432  0.8432098765  43.456790123  0.8723128319  0.3862504959  880           0.0750172377 
0.8188271605  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8098765432  0.8185185185  0.8086419753  0.8382716049  43.950617284  0.8493559957  0.3862504959  890           0.0739742279 
0.8364197531  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9444444444  1.0000000000  0.9691358025  0.8283950617  0.8370370370  0.8271604938  0.8530864198  44.444444444  0.8235106945  0.3862504959  900           0.0736770391 
0.8410493827  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9753086420  0.8320987654  0.8432098765  0.8283950617  0.8604938272  44.938271604  0.8630961120  0.3862504959  910           0.0731644154 
0.8561728395  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8518518519  0.8543209877  0.8407407407  0.8777777778  45.432098765  0.8426765978  0.3862504959  920           0.0727486134 
0.8302469136  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8197530864  0.8333333333  0.8185185185  0.8493827160  45.925925925  0.8370921075  0.3862504959  930           0.0720646620 
0.8620370370  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8617283951  0.8617283951  0.8370370370  0.8876543210  46.419753086  0.8513028085  0.3862504959  940           0.0749751568 
0.8317901235  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9444444444  1.0000000000  0.9753086420  0.8259259259  0.8370370370  0.8123456790  0.8518518519  46.913580246  0.8123847663  0.3862504959  950           0.0747967482 
0.8302469136  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9753086420  0.8271604938  0.8320987654  0.8111111111  0.8506172840  47.407407407  0.8615060687  0.3862504959  960           0.0749598026 
0.8558641975  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8604938272  0.8530864198  0.8358024691  0.8740740741  47.901234567  0.8352394640  0.3862504959  970           0.0753636599 
0.8478395062  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8493827160  0.8493827160  0.8246913580  0.8679012346  48.395061728  0.8252928913  0.3862504959  980           0.0743788481 
0.8324074074  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8296296296  0.8333333333  0.8111111111  0.8555555556  48.888888888  0.8285823047  0.3862504959  990           0.0752460003 
0.8416666667  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8382716049  0.8432098765  0.8234567901  0.8617283951  49.382716049  0.8405557215  0.3862504959  1000          0.0731989622 
0.8314814815  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9444444444  1.0000000000  0.9753086420  0.8234567901  0.8345679012  0.8172839506  0.8506172840  49.876543209  0.8278541446  0.3862504959  1010          0.0746651649 
0.8175925926  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9814814815  0.8049382716  0.8197530864  0.8061728395  0.8395061728  50.370370370  0.7958384633  0.3862504959  1020          0.0726898909 
0.8345679012  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8271604938  0.8358024691  0.8185185185  0.8567901235  50.864197530  0.8051368058  0.3862504959  1030          0.0742279291 
0.8287037037  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9876543210  0.8172839506  0.8308641975  0.8172839506  0.8493827160  51.358024691  0.8429964185  0.3862504959  1040          0.0737542391 
0.8320987654  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9691358025  0.8259259259  0.8345679012  0.8172839506  0.8506172840  51.851851851  0.7929733396  0.3862504959  1050          0.0723763943 
0.8376543210  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8320987654  0.8382716049  0.8246913580  0.8555555556  52.345679012  0.8062099218  0.3862504959  1060          0.0749438524 
0.8398148148  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8333333333  0.8395061728  0.8246913580  0.8617283951  52.839506172  0.8630168796  0.3862504959  1070          0.0715839624 
0.8074074074  1.0000000000  0.9814814815  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9814814815  0.7938271605  0.8123456790  0.7987654321  0.8246913580  53.333333333  0.8549147308  0.3862504959  1080          0.0742588997 
0.8419753086  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9691358025  0.8345679012  0.8407407407  0.8271604938  0.8654320988  53.827160493  0.8128071725  0.3862504959  1090          0.0750928879 
0.8435185185  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9506172840  1.0000000000  0.9691358025  0.8370370370  0.8432098765  0.8308641975  0.8629629630  54.320987654  0.8027189136  0.3862504959  1100          0.0754328728 
0.8333333333  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9444444444  1.0000000000  0.9691358025  0.8234567901  0.8320987654  0.8222222222  0.8555555556  54.814814814  0.8070021272  0.3862504959  1110          0.0752158403 
0.8302469136  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9753086420  0.8222222222  0.8345679012  0.8160493827  0.8481481481  55.308641975  0.7843649685  0.3862504959  1120          0.0737366438 
0.8496913580  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9629629630  0.8432098765  0.8530864198  0.8308641975  0.8716049383  55.802469135  0.7828426778  0.3862504959  1130          0.0724347115 
0.8271604938  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8160493827  0.8271604938  0.8160493827  0.8493827160  56.296296296  0.7993936479  0.3862504959  1140          0.0739150047 
0.8401234568  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8345679012  0.8382716049  0.8246913580  0.8629629630  56.790123456  0.7878000796  0.3862504959  1150          0.0739341736 
0.8404320988  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8370370370  0.8419753086  0.8234567901  0.8592592593  57.283950617  0.8218942881  0.3862504959  1160          0.0790419340 
0.8586419753  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9629629630  1.0000000000  0.9629629630  0.8555555556  0.8543209877  0.8432098765  0.8814814815  57.777777777  0.7961666644  0.3862504959  1170          0.0768691301 
0.8456790123  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9629629630  1.0000000000  0.9567901235  0.8395061728  0.8469135802  0.8296296296  0.8666666667  58.271604938  0.7831379831  0.3862504959  1180          0.0746135235 
0.8228395062  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8160493827  0.8259259259  0.8086419753  0.8407407407  58.765432098  0.7712432206  0.3862504959  1190          0.0743101597 
0.8385802469  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8320987654  0.8395061728  0.8222222222  0.8604938272  59.259259259  0.7708496749  0.3862504959  1200          0.0748719931 
0.8064814815  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.7851851852  0.8123456790  0.8012345679  0.8271604938  59.753086419  0.7781036854  0.3862504959  1210          0.0751543283 
0.8280864198  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8148148148  0.8296296296  0.8185185185  0.8493827160  60.246913580  0.7600011706  0.3862504959  1220          0.0730952501 
0.8342592593  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8234567901  0.8345679012  0.8197530864  0.8592592593  60.740740740  0.7570823848  0.3862504959  1230          0.0739674568 
0.8305555556  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8148148148  0.8320987654  0.8222222222  0.8530864198  61.234567901  0.7862875342  0.3862504959  1240          0.0735576630 
0.8398148148  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8271604938  0.8419753086  0.8271604938  0.8629629630  61.728395061  0.7835474551  0.3862504959  1250          0.0739243984 
0.8299382716  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9629629630  0.8197530864  0.8296296296  0.8172839506  0.8530864198  62.222222222  0.7595648706  0.3862504959  1260          0.0737472057 
0.8311728395  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8185185185  0.8395061728  0.8172839506  0.8493827160  62.716049382  0.7928270936  0.3862504959  1270          0.0743144751 
0.8555555556  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8493827160  0.8518518519  0.8407407407  0.8802469136  63.209876543  0.8154885054  0.3862504959  1280          0.0736177921 
0.8410493827  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9691358025  0.8333333333  0.8456790123  0.8222222222  0.8629629630  63.703703703  0.7827440858  0.3862504959  1290          0.0736698627 
0.8416666667  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8370370370  0.8456790123  0.8197530864  0.8641975309  64.197530864  0.8055236995  0.3862504959  1300          0.0741715431 
0.8447530864  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9629629630  1.0000000000  0.9753086420  0.8395061728  0.8481481481  0.8246913580  0.8666666667  64.691358024  0.7909360230  0.3862504959  1310          0.0747260332 
0.8330246914  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9753086420  0.8185185185  0.8370370370  0.8197530864  0.8567901235  65.185185185  0.7667571902  0.3862504959  1320          0.0735210180 
0.8401234568  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9691358025  0.8283950617  0.8432098765  0.8246913580  0.8641975309  65.679012345  0.7624266565  0.3862504959  1330          0.0751128435 
0.8296296296  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8172839506  0.8320987654  0.8172839506  0.8518518519  66.172839506  0.7379761457  0.3862504959  1340          0.0738300562 
0.8333333333  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8197530864  0.8395061728  0.8197530864  0.8543209877  66.666666666  0.7428281605  0.3862504959  1350          0.0748743534 
0.8243827160  1.0000000000  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8111111111  0.8259259259  0.8135802469  0.8469135802  67.160493827  0.8246006191  0.3862504959  1360          0.0742315531 
0.8512345679  1.0000000000  0.9938271605  1.0000000000  0.9567901235  1.0000000000  0.9382716049  1.0000000000  0.9629629630  0.8444444444  0.8518518519  0.8320987654  0.8765432099  67.654320987  0.7654845059  0.3862504959  1370          0.0736381054 
0.8283950617  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8209876543  0.8283950617  0.8160493827  0.8481481481  68.148148148  0.7768147886  0.3862504959  1380          0.0745503664 
0.8395061728  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8283950617  0.8370370370  0.8271604938  0.8654320988  68.641975308  0.7730892539  0.3862504959  1390          0.0739428997 
0.8490740741  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8382716049  0.8469135802  0.8333333333  0.8777777778  69.135802469  0.7292421877  0.3862504959  1400          0.0720427036 
0.8234567901  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8098765432  0.8259259259  0.8148148148  0.8432098765  69.629629629  0.7897156835  0.3862504959  1410          0.0723490715 
0.8580246914  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9382716049  1.0000000000  0.9629629630  0.8456790123  0.8555555556  0.8419753086  0.8888888889  70.123456790  0.7449624658  0.3862504959  1420          0.0745616436 
0.8308641975  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8185185185  0.8345679012  0.8197530864  0.8506172840  70.617283950  0.7299762964  0.3862504959  1430          0.0747146845 
0.8456790123  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9382716049  1.0000000000  0.9629629630  0.8358024691  0.8506172840  0.8320987654  0.8641975309  71.111111111  0.7851565003  0.3862504959  1440          0.0743297338 
0.8305555556  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8209876543  0.8271604938  0.8234567901  0.8506172840  71.604938271  0.7509342372  0.3862504959  1450          0.0747592926 
0.8447530864  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8333333333  0.8432098765  0.8320987654  0.8703703704  72.098765432  0.7726361692  0.3862504959  1460          0.0744255304 
0.8391975309  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8283950617  0.8444444444  0.8259259259  0.8580246914  72.592592592  0.7488155186  0.3862504959  1470          0.0760281324 
0.8250000000  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9876543210  0.8123456790  0.8246913580  0.8185185185  0.8444444444  73.086419753  0.7740256608  0.3862504959  1480          0.0711842775 
0.8404320988  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9814814815  0.8320987654  0.8419753086  0.8246913580  0.8629629630  73.580246913  0.7815945387  0.3862504959  1490          0.0742261171 
0.8250000000  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8172839506  0.8234567901  0.8098765432  0.8493827160  74.074074074  0.7315874338  0.3862504959  1500          0.0735639095 
0.8348765432  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8283950617  0.8370370370  0.8197530864  0.8543209877  74.567901234  0.7484748483  0.3862504959  1510          0.0737689257 
0.8311728395  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8234567901  0.8296296296  0.8222222222  0.8493827160  75.061728395  0.7316579580  0.3862504959  1520          0.0738984823 
0.8466049383  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9444444444  1.0000000000  0.9814814815  0.8370370370  0.8469135802  0.8358024691  0.8666666667  75.555555555  0.7195951760  0.3862504959  1530          0.0751346588 
0.8345679012  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9814814815  0.8296296296  0.8333333333  0.8209876543  0.8543209877  76.049382716  0.7595643282  0.3862504959  1540          0.0756600618 
0.8256172840  1.0000000000  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8172839506  0.8222222222  0.8135802469  0.8493827160  76.543209876  0.7558938026  0.3862504959  1550          0.0738013983 
0.8472222222  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8333333333  0.8506172840  0.8333333333  0.8716049383  77.037037037  0.7196647942  0.3862504959  1560          0.0742715836 
0.8274691358  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9753086420  0.8222222222  0.8246913580  0.8135802469  0.8493827160  77.530864197  0.7551414371  0.3862504959  1570          0.0757188559 
0.8246913580  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8111111111  0.8246913580  0.8148148148  0.8481481481  78.024691358  0.6890690744  0.3862504959  1580          0.0722231388 
0.8203703704  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8074074074  0.8197530864  0.8074074074  0.8469135802  78.518518518  0.7214561284  0.3862504959  1590          0.0753642559 
0.8253086420  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8148148148  0.8259259259  0.8123456790  0.8481481481  79.012345679  0.7623497605  0.3862504959  1600          0.0752618551 
0.8413580247  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8320987654  0.8382716049  0.8308641975  0.8641975309  79.506172839  0.7603279948  0.3862504959  1610          0.0744749784 
0.8200617284  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8086419753  0.8197530864  0.8074074074  0.8444444444  80.000000000  0.7441464961  0.3862504959  1620          0.0750428915 
0.8175925926  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8049382716  0.8160493827  0.8086419753  0.8407407407  80.493827160  0.7097532451  0.3862504959  1630          0.0744368076 
0.8200617284  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8049382716  0.8209876543  0.8098765432  0.8444444444  80.987654321  0.7255649090  0.3862504959  1640          0.0756213427 
0.8246913580  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8197530864  0.8283950617  0.8074074074  0.8432098765  81.481481481  0.7327252865  0.3862504959  1650          0.0705979347 
0.8330246914  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9814814815  0.8296296296  0.8320987654  0.8160493827  0.8543209877  81.975308642  0.7032458067  0.3862504959  1660          0.0761530399 
0.8234567901  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8160493827  0.8222222222  0.8111111111  0.8444444444  82.469135802  0.7219122350  0.3862504959  1670          0.0754132986 
0.8518518519  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8432098765  0.8493827160  0.8370370370  0.8777777778  82.962962963  0.7070548773  0.3862504959  1680          0.0753526211 
0.8308641975  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8197530864  0.8345679012  0.8160493827  0.8530864198  83.456790123  0.7167695165  0.3862504959  1690          0.0745812654 
0.8398148148  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8296296296  0.8395061728  0.8259259259  0.8641975309  83.950617284  0.6825303495  0.3862504959  1700          0.0734893084 
0.8373456790  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8259259259  0.8358024691  0.8246913580  0.8629629630  84.444444444  0.7038181543  0.3862504959  1710          0.0779930115 
0.8413580247  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8296296296  0.8419753086  0.8308641975  0.8629629630  84.938271604  0.6943531811  0.3862504959  1720          0.0774032593 
0.8626543210  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9567901235  1.0000000000  0.9629629630  0.8481481481  0.8555555556  0.8469135802  0.9000000000  85.432098765  0.7070496440  0.3862504959  1730          0.0808351040 
0.8333333333  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8246913580  0.8345679012  0.8209876543  0.8530864198  85.925925925  0.7295394540  0.3862504959  1740          0.0735843658 
0.8354938272  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8259259259  0.8345679012  0.8259259259  0.8555555556  86.419753086  0.7223781705  0.3862504959  1750          0.0747581959 
0.8108024691  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.7925925926  0.8098765432  0.8000000000  0.8407407407  86.913580246  0.7184574544  0.3862504959  1760          0.0734638453 
0.8370370370  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8259259259  0.8395061728  0.8234567901  0.8592592593  87.407407407  0.7221963525  0.3862504959  1770          0.0730986834 
0.8305555556  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8135802469  0.8345679012  0.8197530864  0.8543209877  87.901234567  0.7053169608  0.3862504959  1780          0.0760114431 
0.8379629630  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8283950617  0.8382716049  0.8222222222  0.8629629630  88.395061728  0.7304281175  0.3862504959  1790          0.0770255327 
0.8231481481  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8111111111  0.8259259259  0.8123456790  0.8432098765  88.888888888  0.7000096142  0.3862504959  1800          0.0729241133 
0.8253086420  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8135802469  0.8259259259  0.8160493827  0.8456790123  89.382716049  0.7089611948  0.3862504959  1810          0.0771911860 
0.8401234568  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8234567901  0.8395061728  0.8320987654  0.8654320988  89.876543209  0.7180217922  0.3862504959  1820          0.0740988970 
0.8104938272  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.7962962963  0.8098765432  0.8012345679  0.8345679012  90.370370370  0.7282497406  0.3862504959  1830          0.0745495319 
0.8222222222  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8098765432  0.8197530864  0.8074074074  0.8518518519  90.864197530  0.7020647943  0.3862504959  1840          0.0757948160 
0.8351851852  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8222222222  0.8395061728  0.8209876543  0.8580246914  91.358024691  0.7259273231  0.3862504959  1850          0.0725251913 
0.8256172840  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8172839506  0.8246913580  0.8123456790  0.8481481481  91.851851851  0.6947806656  0.3862504959  1860          0.0739714384 
0.8135802469  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  1.0000000000  0.7975308642  0.8123456790  0.8061728395  0.8382716049  92.345679012  0.7339105248  0.3862504959  1870          0.0761744022 
0.8472222222  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8333333333  0.8432098765  0.8345679012  0.8777777778  92.839506172  0.6756945848  0.3862504959  1880          0.0754928112 
0.8453703704  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8283950617  0.8407407407  0.8345679012  0.8777777778  93.333333333  0.7509266853  0.3862504959  1890          0.0746623755 
0.8339506173  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8234567901  0.8308641975  0.8246913580  0.8567901235  93.827160493  0.6723918617  0.3862504959  1900          0.0730225563 
0.8160493827  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8061728395  0.8123456790  0.8086419753  0.8370370370  94.320987654  0.7228097022  0.3862504959  1910          0.0731031179 
0.8422839506  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8271604938  0.8395061728  0.8320987654  0.8703703704  94.814814814  0.6988434494  0.3862504959  1920          0.0775137186 
0.8589506173  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9629629630  0.8395061728  0.8567901235  0.8456790123  0.8938271605  95.308641975  0.6828554571  0.3862504959  1930          0.0758840799 
0.8111111111  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.7950617284  0.8111111111  0.8024691358  0.8358024691  95.802469135  0.6964141369  0.3862504959  1940          0.0758006811 
0.8191358025  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8037037037  0.8222222222  0.8086419753  0.8419753086  96.296296296  0.6945999682  0.3862504959  1950          0.0755335093 
0.8280864198  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8061728395  0.8320987654  0.8246913580  0.8493827160  96.790123456  0.6674183607  0.3862504959  1960          0.0724386454 
0.8413580247  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8172839506  0.8419753086  0.8407407407  0.8654320988  97.283950617  0.7082099557  0.3862504959  1970          0.0745632410 
0.8317901235  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8185185185  0.8320987654  0.8222222222  0.8543209877  97.777777777  0.7003676593  0.3862504959  1980          0.0736477137 
0.8237654321  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8123456790  0.8234567901  0.8098765432  0.8493827160  98.271604938  0.7322549224  0.3862504959  1990          0.0732829332 
0.8330246914  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8222222222  0.8296296296  0.8209876543  0.8592592593  98.765432098  0.7036435306  0.3862504959  2000          0.0753765345 
0.8391975309  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8345679012  0.8370370370  0.8234567901  0.8617283951  99.259259259  0.7182886720  0.3862504959  2010          0.0732656240 
0.8203703704  1.0000000000  0.9938271605  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8049382716  0.8222222222  0.8111111111  0.8432098765  99.753086419  0.6942966461  0.3862504959  2020          0.0726624250 
0.8256172840  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8160493827  0.8259259259  0.8111111111  0.8493827160  100.24691358  0.7199978411  0.3862504959  2030          0.0757199049 
0.8391975309  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8283950617  0.8358024691  0.8246913580  0.8679012346  100.74074074  0.6814979851  0.3862504959  2040          0.0738571882 
0.8240740741  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8061728395  0.8271604938  0.8160493827  0.8469135802  101.23456790  0.6647927940  0.3862504959  2050          0.0747702360 
0.8299382716  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8160493827  0.8283950617  0.8185185185  0.8567901235  101.72839506  0.6917941332  0.3862504959  2060          0.0744503736 
0.8157407407  1.0000000000  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  1.0000000000  0.7962962963  0.8209876543  0.8086419753  0.8370370370  102.22222222  0.7054840386  0.3862504959  2070          0.0729123831 
0.8703703704  1.0000000000  0.9938271605  1.0000000000  0.9506172840  1.0000000000  0.9444444444  1.0000000000  0.9691358025  0.8592592593  0.8641975309  0.8530864198  0.9049382716  102.71604938  0.7003865957  0.3862504959  2080          0.0745368481 
0.8382716049  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8296296296  0.8358024691  0.8209876543  0.8666666667  103.20987654  0.6686154902  0.3862504959  2090          0.0721925259 
0.8098765432  1.0000000000  0.9938271605  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  1.0000000000  0.7876543210  0.8135802469  0.8024691358  0.8358024691  103.70370370  0.6881403923  0.3862504959  2100          0.0718472004 
0.8302469136  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8160493827  0.8308641975  0.8185185185  0.8555555556  104.19753086  0.6495168984  0.3862504959  2110          0.0731512785 
0.8388888889  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8308641975  0.8320987654  0.8222222222  0.8703703704  104.69135802  0.6779311836  0.3862504959  2120          0.0750297546 
0.8308641975  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8160493827  0.8296296296  0.8209876543  0.8567901235  105.18518518  0.6791174173  0.3862504959  2130          0.0741250515 
0.8401234568  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8234567901  0.8407407407  0.8283950617  0.8679012346  105.67901234  0.6658841908  0.3862504959  2140          0.0756747961 
0.8379629630  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8222222222  0.8382716049  0.8271604938  0.8641975309  106.17283950  0.6505543649  0.3862504959  2150          0.0761317730 
0.8268518519  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8135802469  0.8234567901  0.8160493827  0.8543209877  106.66666666  0.7075146854  0.3862504959  2160          0.0734938383 
0.8299382716  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8172839506  0.8283950617  0.8197530864  0.8543209877  107.16049382  0.6836876631  0.3862504959  2170          0.0746577978 
0.8348765432  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8222222222  0.8308641975  0.8246913580  0.8617283951  107.65432098  0.6633181930  0.3862504959  2180          0.0738261938 
0.8219135802  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8000000000  0.8222222222  0.8185185185  0.8469135802  108.14814814  0.7151267469  0.3862504959  2190          0.0729230165 
0.8395061728  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8283950617  0.8395061728  0.8271604938  0.8629629630  108.64197530  0.6797172666  0.3862504959  2200          0.0711483955 
0.8225308642  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8012345679  0.8222222222  0.8160493827  0.8506172840  109.13580246  0.6764992774  0.3862504959  2210          0.0750804424 
0.8212962963  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8012345679  0.8222222222  0.8135802469  0.8481481481  109.62962962  0.6641568601  0.3862504959  2220          0.0741042614 
0.8246913580  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8135802469  0.8246913580  0.8074074074  0.8530864198  110.12345679  0.6683981597  0.3862504959  2230          0.0735507011 
0.8234567901  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8074074074  0.8246913580  0.8098765432  0.8518518519  110.61728395  0.6559927523  0.3862504959  2240          0.0748643160 
0.8240740741  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8012345679  0.8271604938  0.8160493827  0.8518518519  111.11111111  0.6774810970  0.3862504959  2250          0.0744803667 
0.8101851852  1.0000000000  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.7839506173  0.8148148148  0.8086419753  0.8333333333  111.60493827  0.6895504653  0.3862504959  2260          0.0751084089 
0.8475308642  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8296296296  0.8444444444  0.8370370370  0.8790123457  112.09876543  0.6614949644  0.3862504959  2270          0.0753731012 
0.8228395062  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.7925925926  0.8271604938  0.8185185185  0.8530864198  112.59259259  0.7045769989  0.3862504959  2280          0.0733086348 
0.8336419753  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8123456790  0.8308641975  0.8296296296  0.8617283951  113.08641975  0.6801827312  0.3862504959  2290          0.0739278316 
0.8314814815  1.0000000000  1.0000000000  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8086419753  0.8320987654  0.8222222222  0.8629629630  113.58024691  0.6897490025  0.3862504959  2300          0.0787546158 
0.8330246914  1.0000000000  1.0000000000  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8111111111  0.8358024691  0.8222222222  0.8629629630  114.07407407  0.6631353140  0.3862504959  2310          0.0747940302 
0.8617283951  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8481481481  0.8543209877  0.8493827160  0.8950617284  114.56790123  0.7000812829  0.3862504959  2320          0.0745927095 
0.8219135802  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.7962962963  0.8209876543  0.8209876543  0.8493827160  115.06172839  0.7098214388  0.3862504959  2330          0.0748203754 
0.8675925926  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9567901235  1.0000000000  0.9691358025  0.8481481481  0.8629629630  0.8543209877  0.9049382716  115.55555555  0.6729650557  0.3862504959  2340          0.0760973692 
0.8314814815  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8160493827  0.8296296296  0.8185185185  0.8617283951  116.04938271  0.6671159029  0.3862504959  2350          0.0729202986 
0.8231481481  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8037037037  0.8259259259  0.8123456790  0.8506172840  116.54320987  0.6688935637  0.3862504959  2360          0.0745350122 
0.8459876543  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8271604938  0.8456790123  0.8333333333  0.8777777778  117.03703703  0.6832291186  0.3862504959  2370          0.0729001522 
0.8370370370  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8197530864  0.8395061728  0.8246913580  0.8641975309  117.53086419  0.6851014495  0.3862504959  2380          0.0725443602 
0.8320987654  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8160493827  0.8333333333  0.8234567901  0.8555555556  118.02469135  0.6593756437  0.3862504959  2390          0.0730139017 
0.8401234568  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8320987654  0.8407407407  0.8222222222  0.8654320988  118.51851851  0.6706147730  0.3862504959  2400          0.0746171713 
0.8345679012  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8209876543  0.8358024691  0.8185185185  0.8629629630  119.01234567  0.6802282274  0.3862504959  2410          0.0726707697 
0.8432098765  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8271604938  0.8419753086  0.8283950617  0.8753086420  119.50617283  0.6729142189  0.3862504959  2420          0.0753600836 
0.8203703704  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.7925925926  0.8259259259  0.8148148148  0.8481481481  120.00000000  0.6723678410  0.3862504959  2430          0.0768904448 
0.8361111111  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8185185185  0.8370370370  0.8271604938  0.8617283951  120.49382716  0.6558597028  0.3862504959  2440          0.0739794254 
0.8361111111  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8209876543  0.8333333333  0.8246913580  0.8654320988  120.98765432  0.6704811990  0.3862504959  2450          0.0736421347 
0.8271604938  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8111111111  0.8283950617  0.8172839506  0.8518518519  121.48148148  0.6825375080  0.3862504959  2460          0.0719479084 
0.8320987654  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8148148148  0.8308641975  0.8222222222  0.8604938272  121.97530864  0.6920214236  0.3862504959  2470          0.0756263256 
0.8324074074  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8172839506  0.8320987654  0.8222222222  0.8580246914  122.46913580  0.6692346632  0.3862504959  2480          0.0751258373 
0.8330246914  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8185185185  0.8320987654  0.8234567901  0.8580246914  122.96296296  0.6667482615  0.3862504959  2490          0.0765569687 
0.8367283951  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8246913580  0.8358024691  0.8222222222  0.8641975309  123.45679012  0.6940680206  0.3862504959  2500          0.0746025085 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3555555556  0.3364197531  0.3271604938  0.3225308642  0.3456790123  0.3348765432  0.3518518519  0.3333333333  0.3703703704  0.3432098765  0.3617283951  0.3666666667  0.3506172840  0.0000000000  3.7277758121  0.1006202698  0             0.3659358025 
0.6527777778  0.6651234568  0.6851851852  0.6296296296  0.6481481481  0.6481481481  0.6358024691  0.6358024691  0.6419753086  0.6617283951  0.6567901235  0.6530864198  0.6395061728  0.4938271605  3.1845775127  0.1811370850  10            0.0571584702 
0.5604938272  0.6944444444  0.6790123457  0.6234567901  0.6049382716  0.6280864198  0.6358024691  0.5941358025  0.6481481481  0.5444444444  0.5641975309  0.5604938272  0.5728395062  0.9876543210  2.7319903612  0.1811370850  20            0.0571961403 
0.6120370370  0.7098765432  0.7037037037  0.6527777778  0.6851851852  0.6419753086  0.6728395062  0.6496913580  0.6604938272  0.6012345679  0.6148148148  0.6271604938  0.6049382716  1.4814814815  2.2007509351  0.3474698067  30            0.0590166092 
0.7407407407  0.8395061728  0.8333333333  0.7654320988  0.7283950617  0.8209876543  0.8641975309  0.8395061728  0.8580246914  0.7234567901  0.7617283951  0.7259259259  0.7518518519  1.9753086420  1.6781885982  0.3474698067  40            0.0562222958 
0.7120370370  0.8533950617  0.8395061728  0.7515432099  0.7592592593  0.8009259259  0.8271604938  0.8317901235  0.8395061728  0.7000000000  0.7135802469  0.7123456790  0.7222222222  2.4691358025  1.4889444351  0.3474698067  50            0.0564310789 
0.7493827160  0.8580246914  0.8395061728  0.7746913580  0.7283950617  0.8317901235  0.8703703704  0.8441358025  0.8703703704  0.7160493827  0.7691358025  0.7456790123  0.7666666667  2.9629629630  1.3379114985  0.3474698067  60            0.0566873074 
0.7200617284  0.8811728395  0.8703703704  0.8240740741  0.7962962963  0.8780864198  0.8641975309  0.8734567901  0.8641975309  0.6901234568  0.7222222222  0.7234567901  0.7444444444  3.4567901235  1.2423376322  0.3474698067  70            0.0585340261 
0.7623456790  0.8827160494  0.8456790123  0.7793209877  0.7469135802  0.8333333333  0.8765432099  0.8441358025  0.8827160494  0.7444444444  0.7728395062  0.7604938272  0.7716049383  3.9506172840  1.1350735605  0.3474698067  80            0.0579037428 
0.7179012346  0.8425925926  0.8580246914  0.8194444444  0.7777777778  0.8703703704  0.8148148148  0.8796296296  0.8148148148  0.6938271605  0.7148148148  0.7111111111  0.7518518519  4.4444444444  1.1490733087  0.3474698067  90            0.0574023724 
0.7944444444  0.8703703704  0.8641975309  0.7608024691  0.7407407407  0.8256172840  0.8641975309  0.8348765432  0.8765432099  0.7851851852  0.7950617284  0.7888888889  0.8086419753  4.9382716049  1.0984514177  0.3474698067  100           0.0560006857 
0.7524691358  0.8950617284  0.8765432099  0.8827160494  0.8148148148  0.9228395062  0.8827160494  0.9135802469  0.8765432099  0.7370370370  0.7506172840  0.7481481481  0.7740740741  5.4320987654  1.0594146490  0.3474698067  110           0.0536404133 
0.7512345679  0.9166666667  0.9012345679  0.8163580247  0.7777777778  0.8703703704  0.8765432099  0.8672839506  0.8888888889  0.7395061728  0.7567901235  0.7358024691  0.7728395062  5.9259259259  0.9280447781  0.3474698067  120           0.0571935415 
0.8132716049  0.9182098765  0.9012345679  0.8858024691  0.8209876543  0.9537037037  0.9197530864  0.9398148148  0.9259259259  0.8037037037  0.8234567901  0.7864197531  0.8395061728  6.4197530864  0.8695520282  0.3474698067  130           0.0585746050 
0.7922839506  0.9336419753  0.9012345679  0.8904320988  0.8333333333  0.9429012346  0.9135802469  0.9398148148  0.9135802469  0.7876543210  0.8012345679  0.7740740741  0.8061728395  6.9135802469  0.9008635998  0.3474698067  140           0.0645248652 
0.7666666667  0.9382716049  0.9074074074  0.8904320988  0.8456790123  0.9367283951  0.8950617284  0.9382716049  0.9074074074  0.7629629630  0.7728395062  0.7530864198  0.7777777778  7.4074074074  0.7538303733  0.3474698067  150           0.0579183817 
0.8438271605  0.9475308642  0.9012345679  0.8904320988  0.8333333333  0.9567901235  0.9320987654  0.9382716049  0.9135802469  0.8395061728  0.8506172840  0.8160493827  0.8691358025  7.9012345679  0.7547505498  0.3474698067  160           0.0569179773 
0.7873456790  0.9567901235  0.9259259259  0.8703703704  0.8395061728  0.9320987654  0.9074074074  0.9259259259  0.9135802469  0.7740740741  0.7975308642  0.7679012346  0.8098765432  8.3950617284  0.7221469164  0.3474698067  170           0.0647948027 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
B->A
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3555555556  0.3364197531  0.3271604938  0.3225308642  0.3456790123  0.3348765432  0.3518518519  0.3333333333  0.3703703704  0.3432098765  0.3617283951  0.3666666667  0.3506172840  0.0000000000  3.7277758121  0.1006202698  0             0.3682284355 
0.6527777778  0.6651234568  0.6851851852  0.6296296296  0.6481481481  0.6481481481  0.6358024691  0.6358024691  0.6419753086  0.6617283951  0.6567901235  0.6530864198  0.6395061728  0.4938271605  3.1845775127  0.3474698067  10            0.0590329409 
0.5604938272  0.6944444444  0.6790123457  0.6234567901  0.6049382716  0.6280864198  0.6358024691  0.5941358025  0.6481481481  0.5444444444  0.5641975309  0.5604938272  0.5728395062  0.9876543210  2.7319903612  0.3474698067  20            0.0546126366 
0.6120370370  0.7098765432  0.7037037037  0.6527777778  0.6851851852  0.6419753086  0.6728395062  0.6496913580  0.6604938272  0.6012345679  0.6148148148  0.6271604938  0.6049382716  1.4814814815  2.2007509351  0.3474698067  30            0.0589671373 
0.7407407407  0.8395061728  0.8333333333  0.7654320988  0.7283950617  0.8209876543  0.8641975309  0.8395061728  0.8580246914  0.7234567901  0.7617283951  0.7259259259  0.7518518519  1.9753086420  1.6781885982  0.3474698067  40            0.0573449373 
0.7120370370  0.8533950617  0.8395061728  0.7515432099  0.7592592593  0.8009259259  0.8271604938  0.8317901235  0.8395061728  0.7000000000  0.7135802469  0.7123456790  0.7222222222  2.4691358025  1.4889444351  0.3474698067  50            0.0569733381 
0.7493827160  0.8580246914  0.8395061728  0.7746913580  0.7283950617  0.8317901235  0.8703703704  0.8441358025  0.8703703704  0.7160493827  0.7691358025  0.7456790123  0.7666666667  2.9629629630  1.3379114985  0.3474698067  60            0.0564999819 
0.7200617284  0.8811728395  0.8703703704  0.8240740741  0.7962962963  0.8780864198  0.8641975309  0.8734567901  0.8641975309  0.6901234568  0.7222222222  0.7234567901  0.7444444444  3.4567901235  1.2423376322  0.3474698067  70            0.0578176737 
0.7623456790  0.8827160494  0.8456790123  0.7793209877  0.7469135802  0.8333333333  0.8765432099  0.8441358025  0.8827160494  0.7444444444  0.7728395062  0.7604938272  0.7716049383  3.9506172840  1.1350735605  0.3474698067  80            0.0581362009 
0.7179012346  0.8425925926  0.8580246914  0.8194444444  0.7777777778  0.8703703704  0.8148148148  0.8796296296  0.8148148148  0.6938271605  0.7148148148  0.7111111111  0.7518518519  4.4444444444  1.1490733087  0.3474698067  90            0.0574755430 
0.7944444444  0.8703703704  0.8641975309  0.7608024691  0.7407407407  0.8256172840  0.8641975309  0.8348765432  0.8765432099  0.7851851852  0.7950617284  0.7888888889  0.8086419753  4.9382716049  1.0984514177  0.3474698067  100           0.0580269814 
0.7524691358  0.8950617284  0.8765432099  0.8827160494  0.8148148148  0.9228395062  0.8827160494  0.9135802469  0.8765432099  0.7370370370  0.7506172840  0.7481481481  0.7740740741  5.4320987654  1.0594146490  0.3474698067  110           0.0593999624 
0.7512345679  0.9166666667  0.9012345679  0.8163580247  0.7777777778  0.8703703704  0.8765432099  0.8672839506  0.8888888889  0.7395061728  0.7567901235  0.7358024691  0.7728395062  5.9259259259  0.9280447781  0.3474698067  120           0.0555220604 
0.8132716049  0.9182098765  0.9012345679  0.8858024691  0.8209876543  0.9537037037  0.9197530864  0.9398148148  0.9259259259  0.8037037037  0.8234567901  0.7864197531  0.8395061728  6.4197530864  0.8695520282  0.3474698067  130           0.0562764406 
0.7922839506  0.9336419753  0.9012345679  0.8904320988  0.8333333333  0.9429012346  0.9135802469  0.9398148148  0.9135802469  0.7876543210  0.8012345679  0.7740740741  0.8061728395  6.9135802469  0.9008635998  0.3474698067  140           0.0581162691 
0.7666666667  0.9382716049  0.9074074074  0.8904320988  0.8456790123  0.9367283951  0.8950617284  0.9382716049  0.9074074074  0.7629629630  0.7728395062  0.7530864198  0.7777777778  7.4074074074  0.7538303733  0.3474698067  150           0.0570366144 
0.8438271605  0.9475308642  0.9012345679  0.8904320988  0.8333333333  0.9567901235  0.9320987654  0.9382716049  0.9135802469  0.8395061728  0.8506172840  0.8160493827  0.8691358025  7.9012345679  0.7547505498  0.3474698067  160           0.0584811687 
0.7873456790  0.9567901235  0.9259259259  0.8703703704  0.8395061728  0.9320987654  0.9074074074  0.9259259259  0.9135802469  0.7740740741  0.7975308642  0.7679012346  0.8098765432  8.3950617284  0.7221469164  0.3474698067  170           0.0553466558 
0.8037037037  0.9614197531  0.9135802469  0.9537037037  0.8888888889  0.9706790123  0.9382716049  0.9537037037  0.9259259259  0.7876543210  0.8086419753  0.7975308642  0.8209876543  8.8888888889  0.6911019683  0.3474698067  180           0.0591509581 
0.8228395062  0.9737654321  0.9197530864  0.8966049383  0.8641975309  0.9429012346  0.9197530864  0.9429012346  0.9197530864  0.8111111111  0.8283950617  0.8037037037  0.8481481481  9.3827160494  0.6615296841  0.3474698067  190           0.0568402529 
0.8225308642  0.9783950617  0.9444444444  0.9212962963  0.8641975309  0.9506172840  0.9135802469  0.9398148148  0.9259259259  0.8074074074  0.8283950617  0.8061728395  0.8481481481  9.8765432099  0.6005062878  0.3474698067  200           0.0581763744 
0.8055555556  0.9660493827  0.9629629630  0.9660493827  0.9074074074  0.9845679012  0.9259259259  0.9675925926  0.9506172840  0.7925925926  0.8086419753  0.8037037037  0.8172839506  10.370370370  0.5233685911  0.3474698067  210           0.0568808556 
0.8308641975  0.9814814815  0.9814814815  0.9583333333  0.8888888889  0.9783950617  0.9259259259  0.9521604938  0.9444444444  0.8172839506  0.8358024691  0.8185185185  0.8518518519  10.864197530  0.4633828491  0.3474698067  220           0.0563719511 
0.8314814815  0.9845679012  0.9753086420  0.9629629630  0.8827160494  0.9783950617  0.9259259259  0.9552469136  0.9444444444  0.8172839506  0.8345679012  0.8209876543  0.8530864198  11.358024691  0.4794526488  0.3474698067  230           0.0586669922 
0.8175925926  0.9845679012  0.9753086420  0.9753086420  0.9012345679  0.9814814815  0.9444444444  0.9675925926  0.9567901235  0.8037037037  0.8172839506  0.8135802469  0.8358024691  11.851851851  0.5211111724  0.3474698067  240           0.0591536760 
0.8228395062  0.9861111111  0.9814814815  0.9660493827  0.8888888889  0.9814814815  0.9259259259  0.9675925926  0.9506172840  0.8172839506  0.8283950617  0.8098765432  0.8358024691  12.345679012  0.4704365551  0.3474698067  250           0.0562618256 
0.8388888889  0.9969135802  0.9938271605  0.9675925926  0.8827160494  0.9783950617  0.9259259259  0.9614197531  0.9506172840  0.8345679012  0.8444444444  0.8197530864  0.8567901235  12.839506172  0.4175235808  0.3474698067  260           0.0561641216 
0.8114197531  0.9830246914  0.9629629630  0.9907407407  0.9320987654  0.9907407407  0.9444444444  0.9814814815  0.9567901235  0.8049382716  0.8123456790  0.8061728395  0.8222222222  13.333333333  0.4612697899  0.3474698067  270           0.0553951263 
0.8179012346  0.9969135802  0.9876543210  0.9660493827  0.8888888889  0.9706790123  0.9320987654  0.9552469136  0.9320987654  0.8049382716  0.8246913580  0.8061728395  0.8358024691  13.827160493  0.3563375667  0.3474698067  280           0.0576274157 
0.8444444444  0.9984567901  0.9938271605  0.9907407407  0.9320987654  0.9876543210  0.9444444444  0.9722222222  0.9567901235  0.8296296296  0.8481481481  0.8308641975  0.8691358025  14.320987654  0.3692487299  0.3474698067  290           0.0569553614 
0.8277777778  0.9969135802  0.9876543210  0.9799382716  0.9135802469  0.9845679012  0.9320987654  0.9691358025  0.9444444444  0.8197530864  0.8296296296  0.8135802469  0.8481481481  14.814814814  0.3115990087  0.3474698067  300           0.0592514515 
0.8216049383  0.9922839506  0.9814814815  0.9938271605  0.9444444444  0.9938271605  0.9444444444  0.9876543210  0.9506172840  0.8061728395  0.8296296296  0.8098765432  0.8407407407  15.308641975  0.2903142482  0.3474698067  310           0.0590683937 
0.8277777778  0.9953703704  0.9753086420  0.9938271605  0.9629629630  0.9922839506  0.9444444444  0.9845679012  0.9567901235  0.8160493827  0.8333333333  0.8197530864  0.8419753086  15.802469135  0.2722951069  0.3474698067  320           0.0594814539 
0.8481481481  1.0000000000  0.9938271605  0.9922839506  0.9320987654  0.9891975309  0.9382716049  0.9799382716  0.9506172840  0.8419753086  0.8469135802  0.8320987654  0.8716049383  16.296296296  0.2696825117  0.3474698067  330           0.0568478823 
0.8401234568  1.0000000000  0.9938271605  0.9938271605  0.9506172840  0.9907407407  0.9444444444  0.9814814815  0.9444444444  0.8259259259  0.8444444444  0.8271604938  0.8629629630  16.790123456  0.2793814018  0.3474698067  340           0.0572471380 
0.8404320988  1.0000000000  0.9938271605  0.9938271605  0.9629629630  0.9907407407  0.9444444444  0.9799382716  0.9567901235  0.8234567901  0.8469135802  0.8259259259  0.8654320988  17.283950617  0.2349748284  0.3474698067  350           0.0588043451 
0.8370370370  1.0000000000  0.9938271605  0.9845679012  0.9320987654  0.9907407407  0.9444444444  0.9799382716  0.9506172840  0.8283950617  0.8382716049  0.8234567901  0.8580246914  17.777777777  0.2358816192  0.3474698067  360           0.0583539963 
0.8237654321  0.9953703704  0.9938271605  0.9969135802  0.9753086420  0.9953703704  0.9567901235  0.9907407407  0.9629629630  0.8024691358  0.8308641975  0.8160493827  0.8456790123  18.271604938  0.2236019909  0.3474698067  370           0.0577658653 
0.8515432099  1.0000000000  0.9938271605  0.9953703704  0.9567901235  0.9907407407  0.9444444444  0.9861111111  0.9567901235  0.8419753086  0.8493827160  0.8382716049  0.8765432099  18.765432098  0.1906240001  0.3474698067  380           0.0622008324 
0.7953703704  0.9876543210  0.9691358025  0.9861111111  0.9506172840  0.9969135802  0.9382716049  0.9876543210  0.9506172840  0.7777777778  0.7987654321  0.7938271605  0.8111111111  19.259259259  0.2110786587  0.3474698067  390           0.0570375443 
0.8425925926  0.9969135802  0.9938271605  0.9969135802  0.9629629630  0.9953703704  0.9506172840  0.9922839506  0.9629629630  0.8345679012  0.8456790123  0.8283950617  0.8617283951  19.753086419  0.2401058257  0.3474698067  400           0.0563912153 
0.8472222222  1.0000000000  0.9938271605  0.9984567901  0.9629629630  0.9969135802  0.9567901235  0.9907407407  0.9691358025  0.8259259259  0.8580246914  0.8370370370  0.8679012346  20.246913580  0.1678016163  0.3474698067  410           0.0567009926 
0.8166666667  0.9969135802  0.9876543210  0.9876543210  0.9444444444  0.9907407407  0.9382716049  0.9861111111  0.9506172840  0.8049382716  0.8148148148  0.8098765432  0.8370370370  20.740740740  0.1615980610  0.3474698067  420           0.0569886208 
0.8203703704  0.9969135802  0.9876543210  0.9984567901  0.9753086420  0.9969135802  0.9629629630  0.9953703704  0.9567901235  0.7950617284  0.8320987654  0.8172839506  0.8370370370  21.234567901  0.1505208567  0.3474698067  430           0.0563869715 
0.8367283951  1.0000000000  0.9876543210  0.9938271605  0.9629629630  0.9938271605  0.9444444444  0.9891975309  0.9567901235  0.8345679012  0.8419753086  0.8172839506  0.8530864198  21.728395061  0.1292514719  0.3474698067  440           0.0565721989 
0.8256172840  0.9953703704  0.9876543210  1.0000000000  0.9753086420  0.9984567901  0.9629629630  0.9969135802  0.9629629630  0.8061728395  0.8395061728  0.8172839506  0.8395061728  22.222222222  0.1359435134  0.3474698067  450           0.0580612659 
0.8376543210  0.9984567901  0.9876543210  1.0000000000  0.9753086420  0.9984567901  0.9629629630  0.9984567901  0.9629629630  0.8222222222  0.8493827160  0.8222222222  0.8567901235  22.716049382  0.1168528777  0.3474698067  460           0.0565958261 
0.8348765432  0.9984567901  0.9814814815  0.9984567901  0.9691358025  0.9969135802  0.9444444444  0.9984567901  0.9629629630  0.8320987654  0.8358024691  0.8222222222  0.8493827160  23.209876543  0.1474915065  0.3474698067  470           0.0596251488 
0.8197530864  0.9938271605  0.9753086420  1.0000000000  0.9691358025  0.9984567901  0.9567901235  0.9984567901  0.9691358025  0.7913580247  0.8320987654  0.8172839506  0.8382716049  23.703703703  0.1401203141  0.3474698067  480           0.0575007200 
0.8768518519  1.0000000000  0.9938271605  0.9984567901  0.9814814815  0.9969135802  0.9567901235  0.9922839506  0.9629629630  0.8641975309  0.8790123457  0.8617283951  0.9024691358  24.197530864  0.1135022040  0.3474698067  490           0.0581359863 
0.8475308642  0.9969135802  0.9876543210  1.0000000000  0.9814814815  0.9969135802  0.9567901235  0.9969135802  0.9753086420  0.8345679012  0.8518518519  0.8345679012  0.8691358025  24.691358024  0.1044565130  0.3474698067  500           0.0579920530 
0.8564814815  0.9984567901  0.9938271605  1.0000000000  0.9753086420  0.9969135802  0.9567901235  0.9969135802  0.9629629630  0.8555555556  0.8555555556  0.8358024691  0.8790123457  25.185185185  0.1205275871  0.3474698067  510           0.0583850622 
0.8212962963  0.9969135802  0.9814814815  0.9984567901  0.9629629630  0.9984567901  0.9444444444  0.9984567901  0.9691358025  0.8148148148  0.8209876543  0.8135802469  0.8358024691  25.679012345  0.0990238883  0.3475522995  520           0.0580550909 
0.8388888889  0.9984567901  0.9876543210  1.0000000000  0.9691358025  0.9969135802  0.9506172840  1.0000000000  0.9629629630  0.8222222222  0.8481481481  0.8296296296  0.8555555556  26.172839506  0.1133593932  0.3475522995  530           0.0560411453 
0.8620370370  1.0000000000  0.9938271605  1.0000000000  0.9629629630  0.9953703704  0.9444444444  0.9984567901  0.9629629630  0.8629629630  0.8530864198  0.8432098765  0.8888888889  26.666666666  0.1128094923  0.3475522995  540           0.0573305130 
0.8342592593  0.9984567901  0.9814814815  1.0000000000  0.9753086420  0.9984567901  0.9567901235  1.0000000000  0.9814814815  0.8222222222  0.8444444444  0.8197530864  0.8506172840  27.160493827  0.0969474506  0.3475522995  550           0.0574838638 
0.8490740741  1.0000000000  0.9938271605  1.0000000000  0.9753086420  0.9984567901  0.9629629630  0.9984567901  0.9753086420  0.8333333333  0.8555555556  0.8370370370  0.8703703704  27.654320987  0.0883295096  0.3475522995  560           0.0598497629 
0.8398148148  0.9984567901  0.9876543210  1.0000000000  0.9753086420  0.9984567901  0.9567901235  1.0000000000  0.9753086420  0.8222222222  0.8493827160  0.8296296296  0.8580246914  28.148148148  0.0756988660  0.3475522995  570           0.0594651937 
0.8438271605  1.0000000000  0.9876543210  1.0000000000  0.9691358025  0.9969135802  0.9444444444  1.0000000000  0.9753086420  0.8370370370  0.8506172840  0.8271604938  0.8604938272  28.641975308  0.0982957225  0.3475522995  580           0.0573094368 
0.8290123457  0.9938271605  0.9876543210  1.0000000000  0.9691358025  0.9984567901  0.9567901235  1.0000000000  0.9814814815  0.8148148148  0.8370370370  0.8160493827  0.8481481481  29.135802469  0.0902331945  0.3476352692  590           0.0600816965 
0.8441358025  1.0000000000  0.9938271605  1.0000000000  0.9753086420  0.9984567901  0.9567901235  1.0000000000  0.9753086420  0.8197530864  0.8506172840  0.8395061728  0.8666666667  29.629629629  0.0998563834  0.3476352692  600           0.0618550539 
0.8379629630  1.0000000000  0.9876543210  1.0000000000  0.9753086420  0.9984567901  0.9629629630  1.0000000000  0.9691358025  0.8111111111  0.8469135802  0.8358024691  0.8580246914  30.123456790  0.0682969835  0.3476352692  610           0.0621448517 
0.8586419753  1.0000000000  0.9938271605  1.0000000000  0.9691358025  0.9969135802  0.9444444444  1.0000000000  0.9691358025  0.8506172840  0.8592592593  0.8419753086  0.8827160494  30.617283950  0.0709632654  0.3476352692  620           0.0584436178 
0.8290123457  0.9984567901  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8024691358  0.8395061728  0.8283950617  0.8456790123  31.111111111  0.0965275101  0.3476352692  630           0.0574057341 
0.8500000000  1.0000000000  0.9938271605  1.0000000000  0.9753086420  0.9984567901  0.9506172840  1.0000000000  0.9691358025  0.8444444444  0.8493827160  0.8345679012  0.8716049383  31.604938271  0.0660201654  0.3476352692  640           0.0600964308 
0.8382716049  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8271604938  0.8419753086  0.8271604938  0.8567901235  32.098765432  0.0547009174  0.3476352692  650           0.0569481850 
0.8484567901  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9753086420  0.8333333333  0.8530864198  0.8395061728  0.8679012346  32.592592592  0.0739542767  0.3476352692  660           0.0591808319 
0.8308641975  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8123456790  0.8382716049  0.8246913580  0.8481481481  33.086419753  0.0454662288  0.3476352692  670           0.0574872971 
0.8234567901  0.9984567901  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9876543210  0.8098765432  0.8222222222  0.8172839506  0.8444444444  33.580246913  0.0462154148  0.3476352692  680           0.0564628124 
0.8200617284  0.9984567901  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8098765432  0.8222222222  0.8086419753  0.8395061728  34.074074074  0.0677203964  0.3476352692  690           0.0585497379 
0.8364197531  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8160493827  0.8456790123  0.8259259259  0.8580246914  34.567901234  0.0668728445  0.3476352692  700           0.0591331482 
0.8311728395  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8086419753  0.8407407407  0.8222222222  0.8530864198  35.061728395  0.0453409497  0.3476352692  710           0.0574506760 
0.8583333333  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9506172840  1.0000000000  0.9629629630  0.8493827160  0.8555555556  0.8456790123  0.8827160494  35.555555555  0.0634032181  0.3476352692  720           0.0567400932 
0.8253086420  0.9984567901  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8148148148  0.8259259259  0.8148148148  0.8456790123  36.049382716  0.0883563131  0.3476352692  730           0.0584506750 
0.8370370370  1.0000000000  0.9814814815  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8234567901  0.8395061728  0.8308641975  0.8543209877  36.543209876  0.0772382278  0.3476352692  740           0.0595139742 
0.8475308642  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9753086420  0.8296296296  0.8518518519  0.8407407407  0.8679012346  37.037037037  0.0629721861  0.3476352692  750           0.0570706367 
0.8574074074  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8456790123  0.8592592593  0.8432098765  0.8814814815  37.530864197  0.0523287602  0.3476352692  760           0.0602438927 
0.8441358025  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9444444444  1.0000000000  0.9691358025  0.8358024691  0.8407407407  0.8370370370  0.8629629630  38.024691358  0.0582074139  0.3476352692  770           0.0563406467 
0.8212962963  0.9984567901  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8024691358  0.8222222222  0.8148148148  0.8456790123  38.518518518  0.0406732408  0.3476352692  780           0.0571654558 
0.8719135802  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9506172840  0.9984567901  0.9753086420  0.8666666667  0.8604938272  0.8555555556  0.9049382716  39.012345679  0.0549319342  0.3476352692  790           0.0582895994 
0.8484567901  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9814814815  0.8308641975  0.8506172840  0.8407407407  0.8716049383  39.506172839  0.0321110073  0.3476352692  800           0.0629859686 
0.8620370370  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9629629630  0.9984567901  0.9691358025  0.8407407407  0.8592592593  0.8580246914  0.8901234568  40.000000000  0.0473512275  0.3476352692  810           0.0587759972 
0.8212962963  1.0000000000  0.9938271605  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.7987654321  0.8234567901  0.8222222222  0.8407407407  40.493827160  0.0623082272  0.3476352692  820           0.0638596773 
0.8515432099  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9444444444  1.0000000000  0.9629629630  0.8407407407  0.8444444444  0.8432098765  0.8777777778  40.987654321  0.0474179700  0.3476352692  830           0.0656614304 
0.8240740741  0.9984567901  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9753086420  0.7987654321  0.8283950617  0.8172839506  0.8518518519  41.481481481  0.0450084450  0.3476352692  840           0.0606151104 
0.8330246914  0.9984567901  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9753086420  0.8111111111  0.8345679012  0.8222222222  0.8641975309  41.975308642  0.0395297259  0.3476352692  850           0.0607999802 
0.8385802469  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8209876543  0.8456790123  0.8259259259  0.8617283951  42.469135802  0.0529627118  0.3476352692  860           0.0599021196 
0.8333333333  1.0000000000  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9814814815  0.8061728395  0.8382716049  0.8296296296  0.8592592593  42.962962963  0.0363036514  0.3476352692  870           0.0595067263 
0.8651234568  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9506172840  1.0000000000  0.9876543210  0.8592592593  0.8567901235  0.8456790123  0.8987654321  43.456790123  0.0405401030  0.3476352692  880           0.0599961758 
0.8225308642  1.0000000000  0.9938271605  1.0000000000  0.9938271605  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8061728395  0.8271604938  0.8135802469  0.8432098765  43.950617284  0.0332040977  0.3476352692  890           0.0565595388 
0.8401234568  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8271604938  0.8395061728  0.8283950617  0.8654320988  44.444444444  0.0266357094  0.3476352692  900           0.0610837698 
0.8484567901  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8333333333  0.8506172840  0.8358024691  0.8740740741  44.938271604  0.0249486404  0.3476352692  910           0.0583403587 
0.8385802469  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8234567901  0.8395061728  0.8308641975  0.8604938272  45.432098765  0.0221117618  0.3476352692  920           0.0559538841 
0.8475308642  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9876543210  0.8271604938  0.8469135802  0.8419753086  0.8740740741  45.925925925  0.0227298582  0.3476352692  930           0.0577341557 
0.8493827160  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8333333333  0.8493827160  0.8382716049  0.8765432099  46.419753086  0.0298586333  0.3476352692  940           0.0593203068 
0.8515432099  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8358024691  0.8518518519  0.8382716049  0.8802469136  46.913580246  0.0236561404  0.3476352692  950           0.0593981504 
0.8391975309  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8234567901  0.8382716049  0.8296296296  0.8654320988  47.407407407  0.0247453891  0.3476352692  960           0.0587743521 
0.8475308642  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8271604938  0.8506172840  0.8395061728  0.8728395062  47.901234567  0.0210795229  0.3476352692  970           0.0546872377 
0.8450617284  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8320987654  0.8444444444  0.8333333333  0.8703703704  48.395061728  0.0208954515  0.3476352692  980           0.0628759384 
0.8413580247  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8246913580  0.8444444444  0.8333333333  0.8629629630  48.888888888  0.0300186840  0.3476352692  990           0.0571870804 
0.8675925926  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9691358025  0.8518518519  0.8617283951  0.8530864198  0.9037037037  49.382716049  0.0338516640  0.3476352692  1000          0.0579476595 
0.8527777778  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9753086420  0.8358024691  0.8518518519  0.8444444444  0.8790123457  49.876543209  0.0365360610  0.3476352692  1010          0.0580777645 
0.8237654321  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8074074074  0.8271604938  0.8148148148  0.8456790123  50.370370370  0.0224307839  0.3476352692  1020          0.0580623388 
0.8478395062  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8345679012  0.8419753086  0.8370370370  0.8777777778  50.864197530  0.0183370994  0.3476352692  1030          0.0561020136 
0.8466049383  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8246913580  0.8456790123  0.8419753086  0.8740740741  51.358024691  0.0283686515  0.3476352692  1040          0.0577560425 
0.8577160494  1.0000000000  0.9938271605  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9753086420  0.8333333333  0.8530864198  0.8518518519  0.8925925926  51.851851851  0.0194777663  0.3476352692  1050          0.0580491304 
0.8518518519  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8395061728  0.8469135802  0.8419753086  0.8790123457  52.345679012  0.0242661402  0.3476352692  1060          0.0566385269 
0.8407407407  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9691358025  1.0000000000  0.9876543210  0.8271604938  0.8382716049  0.8345679012  0.8629629630  52.839506172  0.0107673978  0.3476352692  1070          0.0587218046 
0.8274691358  1.0000000000  0.9876543210  1.0000000000  0.9938271605  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8197530864  0.8283950617  0.8148148148  0.8469135802  53.333333333  0.0246524500  0.3476352692  1080          0.0573771954 
0.8589506173  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8555555556  0.8543209877  0.8407407407  0.8851851852  53.827160493  0.0175512499  0.3476352692  1090          0.0580933094 
0.8274691358  1.0000000000  0.9938271605  1.0000000000  1.0000000000  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8024691358  0.8333333333  0.8234567901  0.8506172840  54.320987654  0.0231046527  0.3476352692  1100          0.0584714413 
0.8614197531  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8543209877  0.8567901235  0.8469135802  0.8876543210  54.814814814  0.0240339599  0.3476352692  1110          0.0574779272 
0.8500000000  1.0000000000  0.9876543210  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9938271605  0.8370370370  0.8506172840  0.8370370370  0.8753086420  55.308641975  0.0140534649  0.3476352692  1120          0.0565177917 
0.8345679012  1.0000000000  0.9938271605  1.0000000000  0.9814814815  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8234567901  0.8333333333  0.8209876543  0.8604938272  55.802469135  0.0157260363  0.3476352692  1130          0.0585688114 
0.8395061728  1.0000000000  0.9876543210  1.0000000000  0.9876543210  1.0000000000  0.9629629630  1.0000000000  0.9876543210  0.8246913580  0.8407407407  0.8308641975  0.8617283951  56.296296296  0.0128160005  0.3476352692  1140          0.0584484100 
0.8419753086  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9814814815  0.8271604938  0.8444444444  0.8296296296  0.8666666667  56.790123456  0.0143978395  0.3476352692  1150          0.0553143263 
0.8472222222  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9691358025  1.0000000000  0.9814814815  0.8271604938  0.8493827160  0.8370370370  0.8753086420  57.283950617  0.0230501718  0.3476352692  1160          0.0556567430 
0.8759259259  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9753086420  0.8691358025  0.8703703704  0.8567901235  0.9074074074  57.777777777  0.0219459377  0.3476352692  1170          0.0575326920 
0.8361111111  1.0000000000  0.9938271605  1.0000000000  0.9753086420  1.0000000000  0.9567901235  1.0000000000  0.9876543210  0.8283950617  0.8283950617  0.8259259259  0.8617283951  58.271604938  0.0188717993  0.3476352692  1180          0.0578058004 
0.8379629630  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8259259259  0.8320987654  0.8296296296  0.8641975309  58.765432098  0.0140268459  0.3476352692  1190          0.0566360712 
0.8422839506  1.0000000000  0.9876543210  1.0000000000  0.9814814815  1.0000000000  0.9629629630  1.0000000000  0.9938271605  0.8271604938  0.8407407407  0.8308641975  0.8703703704  59.259259259  0.0111501753  0.3476352692  1200          0.0579325914 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1->pu3
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3512900032  0.4533132530  0.4759036145  0.4442771084  0.4397590361  0.4715568862  0.4821428571  0.3939849624  0.4670658683  0.3783132530  0.3333333333  0.3164251208  0.3770883055  0.0000000000  3.5291385651  0.1006202698  0             3.8092188835 
0.4376372009  0.7334337349  0.7168674699  0.8915662651  0.8433734940  0.7859281437  0.7797619048  0.8375939850  0.8323353293  0.3253012048  0.4685990338  0.3671497585  0.5894988067  0.4819277108  1.9100953817  0.2653985023  10            0.0612068176 
0.3930979634  0.9457831325  0.9036144578  0.9397590361  0.8915662651  0.9251497006  0.8928571429  0.9924812030  0.9700598802  0.3686746988  0.3623188406  0.3091787440  0.5322195704  0.9638554217  0.8316416025  0.2653985023  20            0.0566943407 
0.4600645882  0.9909638554  0.9759036145  0.8915662651  0.8192771084  0.9625748503  0.9345238095  0.9894736842  0.9940119760  0.4361445783  0.5048309179  0.3599033816  0.5393794749  1.4457831325  0.4537462622  0.2653985023  30            0.0570428133 
0.4444606936  0.9864457831  0.9698795181  0.9201807229  0.8614457831  0.9820359281  0.9761904762  0.9954887218  0.9940119760  0.4313253012  0.4927536232  0.3454106280  0.5083532220  1.9277108434  0.3097186789  0.2653985023  40            0.0563659191 
0.4450644194  0.9789156627  0.9638554217  0.9638554217  0.9036144578  0.9670658683  0.9404761905  0.9894736842  0.9700598802  0.4554216867  0.4661835749  0.3550724638  0.5035799523  2.4096385542  0.1981040284  0.2653985023  50            0.0568491459 
0.4487193421  0.9879518072  0.9759036145  0.9683734940  0.9096385542  0.9880239521  0.9880952381  0.9909774436  0.9880239521  0.4506024096  0.4855072464  0.3647342995  0.4940334129  2.8915662651  0.1301756520  0.2653985023  60            0.0563453436 
0.4770361304  0.9954819277  0.9939759036  0.9397590361  0.8554216867  0.9940119760  0.9880952381  0.9924812030  0.9940119760  0.4506024096  0.5386473430  0.4033816425  0.5155131265  3.3734939759  0.1073551020  0.2653985023  70            0.0576858997 
0.4944281293  0.9849397590  0.9638554217  0.8795180723  0.8072289157  0.9970059880  0.9880952381  0.9984962406  0.9940119760  0.5301204819  0.4685990338  0.4396135266  0.5393794749  3.8554216867  0.1082917791  0.2653985023  80            0.0573336124 
0.4390472512  0.9879518072  0.9759036145  0.9864457831  0.9457831325  0.9850299401  0.9761904762  1.0000000000  1.0000000000  0.4795180723  0.4106280193  0.3743961353  0.4916467780  4.3373493976  0.1628758326  0.2653985023  90            0.0562762976 
0.4992307093  1.0000000000  1.0000000000  0.8373493976  0.7710843373  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4457831325  0.5676328502  0.4178743961  0.5656324582  4.8192771084  0.1523667119  0.2653985023  100           0.0583064318 
0.4715202792  0.9864457831  0.9578313253  0.9638554217  0.9036144578  0.9970059880  0.9880952381  1.0000000000  1.0000000000  0.5132530120  0.4468599034  0.3961352657  0.5298329356  5.3012048193  0.0598516364  0.2653985023  110           0.0562055349 
0.4444765607  0.9954819277  0.9939759036  0.9743975904  0.9216867470  0.9940119760  0.9880952381  1.0000000000  1.0000000000  0.4289156627  0.5072463768  0.3381642512  0.5035799523  5.7831325301  0.0514730154  0.2655153275  120           0.0580455780 
0.4637522835  0.9954819277  0.9939759036  0.9608433735  0.9036144578  0.9955089820  0.9821428571  1.0000000000  1.0000000000  0.4963855422  0.4444444444  0.4082125604  0.5059665871  6.2650602410  0.0379236196  0.2655153275  130           0.0576775074 
0.4842058039  1.0000000000  1.0000000000  0.8840361446  0.8132530120  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5060240964  0.4613526570  0.4396135266  0.5298329356  6.7469879518  0.0394074661  0.2655153275  140           0.0569489479 
0.4535401438  1.0000000000  1.0000000000  0.9774096386  0.9096385542  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4554216867  0.5072463768  0.3550724638  0.4964200477  7.2289156627  0.0399872769  0.2655153275  150           0.0563009977 
0.4637207576  1.0000000000  1.0000000000  0.9216867470  0.8554216867  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4650602410  0.4903381643  0.3768115942  0.5226730310  7.7108433735  0.0312690342  0.2655153275  160           0.0581803083 
0.4468847442  1.0000000000  1.0000000000  0.9442771084  0.8734939759  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4409638554  0.5000000000  0.3429951691  0.5035799523  8.1927710843  0.0328518257  0.2655153275  170           0.0559113264 
0.4167722983  0.9984939759  0.9939759036  0.9939759036  0.9518072289  0.9940119760  0.9880952381  1.0000000000  1.0000000000  0.4265060241  0.4371980676  0.3236714976  0.4797136038  8.6746987952  0.0258636174  0.2655153275  180           0.0641421318 
0.4191704350  0.9984939759  0.9939759036  0.9894578313  0.9337349398  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4313253012  0.4420289855  0.3188405797  0.4844868735  9.1566265060  0.0415015025  0.2655153275  190           0.0562411070 
0.4673526071  1.0000000000  1.0000000000  0.8840361446  0.8373493976  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4626506024  0.4903381643  0.3961352657  0.5202863962  9.6385542169  0.0235126422  0.2655153275  200           0.0810207367 
0.4203954867  0.9984939759  0.9939759036  0.9924698795  0.9578313253  0.9985029940  0.9940476190  0.9984962406  0.9940119760  0.4265060241  0.4444444444  0.3309178744  0.4797136038  10.120481927  0.0343565635  0.2655153275  210           0.0608818769 
0.4540707015  1.0000000000  1.0000000000  0.8810240964  0.8253012048  1.0000000000  1.0000000000  0.9984962406  0.9940119760  0.4216867470  0.5241545894  0.3429951691  0.5274463007  10.602409638  0.0503120551  0.2655153275  220           0.0586517572 
0.4516666750  1.0000000000  1.0000000000  0.8930722892  0.8373493976  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4385542169  0.5048309179  0.3429951691  0.5202863962  11.084337349  0.0181212724  0.2655153275  230           0.0569575071 
0.4246740898  0.9969879518  0.9879518072  0.9984939759  0.9578313253  0.9910179641  0.9880952381  0.9984962406  0.9940119760  0.4843373494  0.3840579710  0.3792270531  0.4510739857  11.566265060  0.0316012879  0.2655153275  240           0.0571864843 
0.4354645971  1.0000000000  1.0000000000  0.9759036145  0.9156626506  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4481927711  0.4202898551  0.3888888889  0.4844868735  12.048192771  0.0158247375  0.2655153275  250           0.0584912062 
0.4384723495  1.0000000000  1.0000000000  0.9743975904  0.9096385542  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4554216867  0.4251207729  0.3864734300  0.4868735084  12.530120481  0.0243865761  0.2655153275  260           0.0564912796 
0.4517270945  1.0000000000  1.0000000000  0.9728915663  0.8915662651  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4578313253  0.4661835749  0.3864734300  0.4964200477  13.012048192  0.0125491929  0.2655153275  270           0.0569445133 
0.4210065574  0.9984939759  0.9939759036  1.0000000000  0.9638554217  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4265060241  0.4492753623  0.3309178744  0.4773269690  13.493975903  0.0247771742  0.2655153275  280           0.0559662819 
0.4667788132  1.0000000000  0.9879518072  0.8870481928  0.8132530120  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4963855422  0.4589371981  0.4082125604  0.5035799523  13.975903614  0.0266984751  0.2655153275  290           0.0586925745 
0.4716342594  1.0000000000  1.0000000000  0.9518072289  0.8674698795  0.9985029940  0.9940476190  0.9984962406  0.9940119760  0.4915662651  0.4637681159  0.4347826087  0.4964200477  14.457831325  0.0303785064  0.2655153275  300           0.0585481644 
0.4656172301  1.0000000000  0.9879518072  0.9442771084  0.8614457831  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4915662651  0.4492753623  0.4323671498  0.4892601432  14.939759036  0.0132950403  0.2655940056  310           0.0592586517 
0.4710520127  1.0000000000  1.0000000000  0.9141566265  0.8373493976  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4915662651  0.4685990338  0.4347826087  0.4892601432  15.421686747  0.0133108574  0.2655940056  320           0.0585598230 
0.4391668434  1.0000000000  1.0000000000  0.9954819277  0.9578313253  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4843373494  0.4106280193  0.4106280193  0.4510739857  15.903614457  0.0082297186  0.2655940056  330           0.0565759897 
0.4529637175  1.0000000000  1.0000000000  0.9608433735  0.8795180723  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4457831325  0.4830917874  0.3937198068  0.4892601432  16.385542168  0.0144935351  0.2655940056  340           0.0561635971 
0.4414846755  1.0000000000  1.0000000000  0.9728915663  0.8915662651  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4192771084  0.4927536232  0.3574879227  0.4964200477  16.867469879  0.0082111659  0.2655940056  350           0.0575038910 
0.4589518532  1.0000000000  1.0000000000  0.9352409639  0.8493975904  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4578313253  0.4734299517  0.4009661836  0.5035799523  17.349397590  0.0271797765  0.2655940056  360           0.0565393448 
0.4331053313  1.0000000000  1.0000000000  0.9864457831  0.9337349398  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4506024096  0.4492753623  0.3671497585  0.4653937947  17.831325301  0.0185575365  0.2655940056  370           0.0584491968 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1->pu3
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_test_ac  env5_test_ac  env6_test_ac  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3794855358  0.5180722892  0.5542168675  0.4668674699  0.4578313253  0.5254491018  0.5297619048  0.5172932331  0.5269461078  0.4120481928  0.3357487923  0.3381642512  0.4319809069  0.0000000000  4.2173113823  0.1364407539  0             0.3677289486 
0.4539786867  0.8162650602  0.7831325301  0.8569277108  0.8132530120  0.8263473054  0.8095238095  0.8796992481  0.8922155689  0.3831325301  0.4855072464  0.3816425121  0.5656324582  0.4819277108  2.7827592611  0.2170171738  10            0.0749257326 
0.3834822046  0.9246987952  0.9036144578  0.9292168675  0.8734939759  0.8922155689  0.8571428571  0.9774436090  0.9461077844  0.3759036145  0.3623188406  0.2801932367  0.5155131265  0.9638554217  1.6307012558  0.2170171738  20            0.0744504690 
0.4318183356  0.9683734940  0.9337349398  0.9216867470  0.8795180723  0.9685628743  0.9345238095  0.9984962406  0.9820359281  0.4506024096  0.4227053140  0.3623188406  0.4916467780  1.4457831325  1.3940491676  0.2170171738  30            0.0727606058 
0.4425396929  0.9894578313  0.9578313253  0.8885542169  0.8192771084  0.9925149701  0.9821428571  0.9984962406  0.9820359281  0.4096385542  0.4879227053  0.3236714976  0.5489260143  1.9277108434  1.1214622736  0.3012189865  40            0.0749868631 
0.4137389793  0.9864457831  0.9819277108  0.9231927711  0.8493975904  0.9880239521  0.9880952381  0.9984962406  0.9940119760  0.3542168675  0.4420289855  0.3599033816  0.4988066826  2.4096385542  0.9997505665  0.3012189865  50            0.0740359545 
0.4595731096  0.9879518072  0.9879518072  0.9186746988  0.8433734940  0.9955089820  0.9821428571  0.9924812030  0.9940119760  0.4409638554  0.5000000000  0.3961352657  0.5011933174  2.8915662651  0.9724412322  0.3012189865  60            0.0737015247 
0.4475246390  0.9834337349  0.9819277108  0.9277108434  0.8433734940  0.9835329341  0.9702380952  0.9909774436  0.9880239521  0.4409638554  0.4541062802  0.4033816425  0.4916467780  3.3734939759  0.9706032813  0.3012189865  70            0.0715872049 
0.4264383604  0.9894578313  0.9578313253  0.9397590361  0.8674698795  0.9940119760  0.9761904762  0.9984962406  0.9940119760  0.4433734940  0.4637681159  0.3236714976  0.4749403341  3.8554216867  0.9330814302  0.3012189865  80            0.0741175652 
0.4024222795  0.9849397590  0.9759036145  0.9834337349  0.9337349398  0.9970059880  0.9880952381  1.0000000000  1.0000000000  0.4168674699  0.4468599034  0.3115942029  0.4343675418  4.3373493976  0.9070234895  0.3012690544  90            0.0743943691 
0.4577990006  0.9984939759  0.9819277108  0.9246987952  0.8313253012  0.9970059880  0.9880952381  0.9984962406  0.9940119760  0.4385542169  0.5386473430  0.3647342995  0.4892601432  4.8192771084  0.8624213398  0.3012690544  100           0.0767064095 
0.4595472652  1.0000000000  1.0000000000  0.8870481928  0.8012048193  0.9955089820  0.9940476190  1.0000000000  0.9760479042  0.4240963855  0.5555555556  0.3454106280  0.5131264916  5.3012048193  0.8661212385  0.3012690544  110           0.0738583803 
0.3897614219  0.9849397590  0.9759036145  0.9924698795  0.9578313253  0.9880239521  0.9761904762  1.0000000000  1.0000000000  0.3951807229  0.4347826087  0.2971014493  0.4319809069  5.7831325301  0.8845591605  0.3012690544  120           0.0733483315 
0.4277787085  0.9969879518  0.9759036145  0.9487951807  0.8915662651  0.9970059880  0.9880952381  0.9984962406  0.9940119760  0.4385542169  0.4758454106  0.3647342995  0.4319809069  6.2650602410  0.8596315742  0.3012690544  130           0.0748207331 
0.4511853127  1.0000000000  1.0000000000  0.9623493976  0.8734939759  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4385542169  0.5362318841  0.3502415459  0.4797136038  6.7469879518  0.8536861241  0.3012690544  140           0.0731859207 
0.4151190977  0.9804216867  0.9698795181  1.0000000000  0.9759036145  0.9835329341  0.9702380952  1.0000000000  1.0000000000  0.4506024096  0.4106280193  0.3768115942  0.4224343675  7.2289156627  0.8470140159  0.3012690544  150           0.0745048523 
0.5072017203  0.9984939759  0.9939759036  0.8840361446  0.8132530120  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4963855422  0.5676328502  0.4492753623  0.5155131265  7.7108433735  0.8812327445  0.3012690544  160           0.0738166809 
0.4789569922  1.0000000000  1.0000000000  0.9548192771  0.8795180723  0.9970059880  0.9880952381  1.0000000000  1.0000000000  0.4963855422  0.5241545894  0.4251207729  0.4701670644  8.1927710843  0.8457789302  0.3012690544  170           0.0813250303 
0.4555130418  0.9924698795  0.9819277108  0.9984939759  0.9698795181  0.9850299401  0.9761904762  0.9969924812  0.9880239521  0.4746987952  0.5048309179  0.4033816425  0.4391408115  8.6746987952  0.8171989679  0.3012690544  180           0.0864118576 
0.4975615721  1.0000000000  1.0000000000  0.9126506024  0.8433734940  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4843373494  0.6038647343  0.3913043478  0.5107398568  9.1566265060  0.8258846581  0.3012690544  190           0.0784284353 
0.4782089376  1.0000000000  0.9879518072  0.9503012048  0.8734939759  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.5084337349  0.5120772947  0.3768115942  0.5155131265  9.6385542169  0.7754280806  0.3012690544  200           0.0747755527 
0.4771354902  0.9984939759  0.9939759036  0.9924698795  0.9457831325  0.9955089820  0.9940476190  1.0000000000  1.0000000000  0.4650602410  0.5990338164  0.3647342995  0.4797136038  10.120481927  0.7698486805  0.3012690544  210           0.0726120472 
0.4975456355  1.0000000000  1.0000000000  0.9066265060  0.8433734940  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4987951807  0.5942028986  0.3840579710  0.5131264916  10.602409638  0.7970424652  0.3012690544  220           0.0717899799 
0.4559843573  1.0000000000  1.0000000000  0.9759036145  0.8915662651  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4674698795  0.5386473430  0.3333333333  0.4844868735  11.084337349  0.8039420247  0.3012690544  230           0.0780153513 
0.4650493955  1.0000000000  1.0000000000  0.9713855422  0.8855421687  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4915662651  0.5265700483  0.3647342995  0.4773269690  11.566265060  0.8064492285  0.3012690544  240           0.0913310528 
0.4548414126  1.0000000000  1.0000000000  0.9879518072  0.9397590361  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4795180723  0.5241545894  0.3550724638  0.4606205251  12.048192771  0.7908416152  0.3012690544  250           0.0715551376 
0.4752559927  1.0000000000  1.0000000000  0.9638554217  0.8795180723  0.9985029940  0.9940476190  0.9984962406  0.9940119760  0.4939759036  0.5434782609  0.3671497585  0.4964200477  12.530120481  0.7644506931  0.3012690544  260           0.0750767946 
0.4728621518  1.0000000000  1.0000000000  0.9683734940  0.8855421687  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4939759036  0.5386473430  0.3695652174  0.4892601432  13.012048192  0.7875969350  0.3012690544  270           0.0737221241 
0.4891102371  1.0000000000  1.0000000000  0.9653614458  0.8855421687  1.0000000000  1.0000000000  0.9984962406  0.9940119760  0.5036144578  0.5458937198  0.4009661836  0.5059665871  13.493975903  0.8274968386  0.3012690544  280           0.0767247438 
0.4819231025  1.0000000000  1.0000000000  0.9804216867  0.8975903614  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4771084337  0.5724637681  0.3864734300  0.4916467780  13.975903614  0.7510278881  0.3012690544  290           0.0729205608 
0.4427872606  0.9969879518  0.9759036145  0.9969879518  0.9397590361  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4650602410  0.4951690821  0.3550724638  0.4558472554  14.457831325  0.7671494365  0.3012690544  300           0.0740598679 
0.4879544743  1.0000000000  1.0000000000  0.9608433735  0.8795180723  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4891566265  0.5434782609  0.4275362319  0.4916467780  14.939759036  0.7578562200  0.3833441734  310           0.0759160042 
0.4507009012  1.0000000000  0.9879518072  0.9894578313  0.9457831325  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4674698795  0.5000000000  0.4009661836  0.4343675418  15.421686747  0.7559385359  0.3833441734  320           0.0748525381 
0.4651561002  1.0000000000  0.9879518072  0.9804216867  0.8855421687  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4819277108  0.5072463768  0.4275362319  0.4439140811  15.903614457  0.7809744418  0.3833441734  330           0.0759425640 
0.4572786980  0.9984939759  0.9939759036  0.9879518072  0.9156626506  1.0000000000  1.0000000000  0.9984962406  0.9940119760  0.4433734940  0.5410628019  0.3840579710  0.4606205251  16.385542168  0.7594752610  0.3833441734  340           0.0764938831 
0.4608716767  1.0000000000  1.0000000000  0.9969879518  0.9397590361  0.9985029940  0.9940476190  1.0000000000  1.0000000000  0.4337349398  0.5555555556  0.3816425121  0.4725536993  16.867469879  0.7298612535  0.3833441734  350           0.0826477289 
0.4282919440  1.0000000000  1.0000000000  0.9382530120  0.8614457831  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.4096385542  0.5096618357  0.3260869565  0.4677804296  17.349397590  0.7319549680  0.3833441734  360           0.0871737003 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1,2->pu3
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_in_acc   env4_out_acc  env4_test_ac  env5_in_acc   env5_out_acc  env5_test_ac  env6_in_acc   env6_out_acc  env6_test_ac  env7_in_acc   env7_out_acc  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.3476006309  0.3599397590  0.3192771084  0.4156626506  0.4096385542  0.3727544910  0.3630952381  0.3894736842  0.3892215569  0.5301204819  0.5301204819  0.3445783133  0.5392749245  0.5361445783  0.3405797101  0.5543806647  0.5481927711  0.3623188406  0.5313432836  0.5119047619  0.3429256595  0.0000000000  10.365321159  0.2909131050  0             0.4480481148 
0.4722393379  0.8990963855  0.8734939759  0.7289156627  0.6867469880  0.9386227545  0.8869047619  0.8481203008  0.8263473054  0.9457831325  0.9518072289  0.5903614458  0.8489425982  0.8674698795  0.3574879227  0.8474320242  0.8614457831  0.4806763285  0.8462686567  0.8511904762  0.4604316547  0.4833836858  6.8234911919  0.4781041145  10            0.1350389004 
0.5837310665  0.9668674699  0.9638554217  0.8027108434  0.7168674699  0.9416167665  0.8988095238  0.9654135338  0.9580838323  0.9457831325  0.9397590361  0.6722891566  0.8867069486  0.8734939759  0.5338164251  0.8157099698  0.8072289157  0.5724637681  0.8880597015  0.8750000000  0.5563549161  0.9667673716  4.3725320339  0.6690397263  20            0.1272736549 
0.6452324364  0.8222891566  0.7469879518  0.8840361446  0.8373493976  0.9266467066  0.8630952381  0.9774436090  0.9461077844  0.9879518072  0.9879518072  0.7253012048  0.9531722054  0.9578313253  0.5748792271  0.9848942598  0.9879518072  0.6908212560  0.9970149254  1.0000000000  0.5899280576  1.4501510574  3.4411521196  0.6690397263  30            0.1272274733 
0.6126109170  0.9759036145  0.9759036145  0.8644578313  0.7831325301  0.9790419162  0.9523809524  0.9684210526  0.9461077844  0.9683734940  0.9819277108  0.6530120482  0.9018126888  0.8855421687  0.5555555556  0.8912386707  0.8915662651  0.6207729469  0.9089552239  0.8869047619  0.6211031175  1.9335347432  3.1772604465  0.6690397263  40            0.1318928957 
0.6981624653  0.8614457831  0.7831325301  0.8810240964  0.8253012048  0.9655688623  0.9464285714  0.9939849624  0.9640718563  0.9894578313  0.9939759036  0.7566265060  0.9803625378  0.9698795181  0.6256038647  0.9773413897  0.9698795181  0.7149758454  0.9955223881  0.9940476190  0.6954436451  2.4169184290  3.0275573015  0.6690397263  50            0.1292138100 
0.6668643294  0.9051204819  0.8614457831  0.8930722892  0.8373493976  0.9760479042  0.9523809524  0.9939849624  0.9760479042  0.9969879518  1.0000000000  0.7518072289  0.9697885196  0.9518072289  0.5555555556  0.9818731118  0.9759036145  0.7198067633  0.9970149254  1.0000000000  0.6402877698  2.9003021148  2.6360277653  0.6690397263  60            0.1400502205 
0.6379049929  0.9743975904  0.9578313253  0.8915662651  0.8313253012  0.9940119760  0.9642857143  0.9939849624  0.9760479042  0.9969879518  1.0000000000  0.7156626506  0.9335347432  0.9397590361  0.5072463768  0.9864048338  0.9939759036  0.6908212560  0.9970149254  1.0000000000  0.6378896882  3.3836858006  2.6175489426  0.6690397263  70            0.1385496616 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [8, 9, 10, 11]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1,2->pu3
Start training
average_acc   env0_in_acc   env0_out_acc  env10_test_a  env11_test_a  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_in_acc   env4_out_acc  env5_in_acc   env5_out_acc  env6_in_acc   env6_out_acc  env7_in_acc   env7_out_acc  env8_test_ac  env9_test_ac  epoch         loss          mem_gb        step          step_time    
0.3724929638  0.4201807229  0.4638554217  0.4154589372  0.3532219570  0.4743975904  0.4518072289  0.4431137725  0.4285714286  0.4195488722  0.4610778443  0.4412650602  0.4397590361  0.3564954683  0.3855421687  0.4244712991  0.4277108434  0.3778110945  0.3353293413  0.3855421687  0.3357487923  0.0000000000  9.8018226624  0.2909131050  0             0.4682424068 
0.6466865872  0.7816265060  0.7891566265  0.6690821256  0.6945107399  0.8855421687  0.8433734940  0.8532934132  0.8452380952  0.8451127820  0.8502994012  0.6807228916  0.6506024096  0.7160120846  0.6987951807  0.7205438066  0.7048192771  0.9055472264  0.8862275449  0.6144578313  0.6086956522  0.4833836858  7.8016294003  0.4781041145  10            0.1368849754 
0.7775969778  0.8915662651  0.9156626506  0.8140096618  0.6873508353  0.7469879518  0.7228915663  0.9251497006  0.8928571429  0.8736842105  0.8323353293  0.9864457831  0.9698795181  0.7311178248  0.7951807229  0.9546827795  0.9518072289  0.8305847076  0.8502994012  0.8626506024  0.7463768116  0.9667673716  5.3909746170  0.4811263084  20            0.1328232527 
0.7959212173  0.8192771084  0.7951807229  0.7632850242  0.8448687351  0.8930722892  0.8493975904  0.9071856287  0.8928571429  0.8947368421  0.8802395210  0.9638554217  0.9638554217  0.8232628399  0.8614457831  0.9577039275  0.9397590361  0.9610194903  0.9640718563  0.7301204819  0.8454106280  1.4501510574  4.3255914450  0.4811263084  30            0.1327066660 
0.8184941106  0.8795180723  0.8915662651  0.8115942029  0.7446300716  0.8222891566  0.7590361446  0.9206586826  0.8869047619  0.8977443609  0.9281437126  0.9849397590  0.9879518072  0.7613293051  0.7590361446  0.9667673716  0.9638554217  0.9580209895  0.9281437126  0.8506024096  0.8671497585  1.9335347432  3.7300758362  0.4812016487  40            0.1400561094 
0.7958938483  0.8644578313  0.8433734940  0.7777777778  0.8544152745  0.9186746988  0.8674698795  0.9386227545  0.9226190476  0.9593984962  0.9341317365  0.9804216867  0.9698795181  0.8534743202  0.8855421687  0.9682779456  0.9698795181  0.9850074963  0.9880239521  0.7277108434  0.8236714976  2.4169184290  3.4316125631  0.4828839302  50            0.1361083269 
0.7616995775  0.9006024096  0.8795180723  0.8091787440  0.7708830549  0.8750000000  0.8493975904  0.9670658683  0.9642857143  0.9624060150  0.9341317365  0.9969879518  1.0000000000  0.7356495468  0.7650602410  0.9954682779  0.9939759036  0.9700149925  0.9520958084  0.7710843373  0.6956521739  2.9003021148  3.1751334667  0.4828839302  60            0.1315257788 
0.7778539151  0.8975903614  0.8915662651  0.7729468599  0.8162291169  0.9201807229  0.8734939759  0.9326347305  0.8988095238  0.9654135338  0.9461077844  0.9969879518  1.0000000000  0.7779456193  0.8012048193  0.9652567976  0.9578313253  0.9880059970  0.9520958084  0.7927710843  0.7294685990  3.3836858006  3.0771298647  0.4828839302  70            0.1334538460 
0.7683202632  0.9518072289  0.9277108434  0.8212560386  0.7708830549  0.9352409639  0.8734939759  0.9910179641  0.9880952381  0.9864661654  0.9461077844  0.9894578313  0.9939759036  0.7930513595  0.8253012048  0.9894259819  0.9939759036  0.9670164918  0.9401197605  0.8072289157  0.6739130435  3.8670694864  2.8592169285  0.4828839302  80            0.1336420298 
0.7321160954  0.9728915663  0.9397590361  0.7898550725  0.7732696897  0.8539156627  0.7771084337  0.9970059880  0.9880952381  0.9909774436  0.9520958084  0.9759036145  0.9879518072  0.7054380665  0.7409638554  0.9728096677  0.9759036145  0.9430284858  0.9161676647  0.7493975904  0.6159420290  4.3504531722  2.8181016207  0.4828839302  90            0.1344532728 
0.7442181267  0.8734939759  0.8795180723  0.7149758454  0.7732696897  0.9698795181  0.8915662651  0.8817365269  0.8630952381  0.8857142857  0.8922155689  0.9277108434  0.9397590361  0.8262839879  0.8132530120  0.8897280967  0.8855421687  0.9835082459  0.9580838323  0.7084337349  0.7801932367  4.8338368580  3.0784649372  0.4828839302  100           0.1325876951 
0.7838093476  0.8719879518  0.8132530120  0.7681159420  0.8568019093  0.9774096386  0.8855421687  0.9101796407  0.8928571429  0.9699248120  0.9760479042  0.9713855422  0.9578313253  0.8927492447  0.8975903614  0.9818731118  0.9759036145  0.9970014993  1.0000000000  0.7277108434  0.7826086957  5.3172205438  3.0338078737  0.4828839302  110           0.1331668139 
0.7541838760  0.8765060241  0.8554216867  0.7222222222  0.8663484487  0.9442771084  0.8855421687  0.8997005988  0.8869047619  0.9714285714  0.9700598802  0.9909638554  1.0000000000  0.8141993958  0.8493975904  0.9456193353  0.9397590361  0.9970014993  1.0000000000  0.7397590361  0.6884057971  5.8006042296  2.7396907091  0.4828839302  120           0.1298232317 
0.7574666346  0.9352409639  0.9096385542  0.8164251208  0.7684964200  0.9201807229  0.8614457831  0.9520958084  0.9285714286  0.9939849624  0.9760479042  0.9969879518  1.0000000000  0.7084592145  0.7530120482  0.9894259819  0.9939759036  0.9865067466  0.9820359281  0.7927710843  0.6521739130  6.2839879154  2.5694329500  0.4828839302  130           0.1295380592 
0.7550642020  0.9111445783  0.8855421687  0.8115942029  0.7661097852  0.9608433735  0.8915662651  0.9416167665  0.9107142857  0.9819548872  0.9760479042  1.0000000000  1.0000000000  0.7854984894  0.7951807229  0.9879154079  0.9879518072  0.9985007496  0.9940119760  0.7831325301  0.6594202899  6.7673716012  2.3895115137  0.4828839302  140           0.1285566092 
0.7484015270  0.9367469880  0.9277108434  0.8019323671  0.7732696897  0.9412650602  0.8975903614  0.9640718563  0.9523809524  0.9969924812  0.9760479042  0.9969879518  1.0000000000  0.7779456193  0.8012048193  0.9954682779  0.9939759036  1.0000000000  0.9880239521  0.7807228916  0.6376811594  7.2507552870  2.3858451605  0.4828839302  150           0.1315647125 
0.7278803811  0.9518072289  0.9277108434  0.7922705314  0.7756563246  0.9171686747  0.8734939759  0.9805389222  0.9821428571  0.9969924812  0.9760479042  0.9969879518  1.0000000000  0.7371601208  0.7590361446  0.9984894260  0.9939759036  0.9895052474  0.9820359281  0.7518072289  0.5917874396  7.7341389728  2.1964462399  0.4828839302  160           0.1499646664 
0.7351138010  0.9457831325  0.9156626506  0.7995169082  0.7804295943  0.9608433735  0.9036144578  0.9550898204  0.9404761905  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.7749244713  0.7650602410  0.9954682779  0.9939759036  1.0000000000  0.9880239521  0.7493975904  0.6111111111  8.2175226586  2.2769608498  0.4828839302  170           0.1311295748 
0.7317122664  0.9487951807  0.9277108434  0.8236714976  0.6968973747  0.9518072289  0.8915662651  0.9550898204  0.9404761905  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.7129909366  0.7469879518  0.9954682779  0.9939759036  0.9910044978  0.9760479042  0.8000000000  0.6062801932  8.7009063444  2.2354947329  0.4828839302  180           0.1319296837 
0.7477631567  0.9292168675  0.9216867470  0.7971014493  0.7875894988  0.9894578313  0.8975903614  0.9191616766  0.8928571429  0.9879699248  0.9760479042  0.9954819277  0.9939759036  0.8580060423  0.8433734940  0.9909365559  0.9879518072  1.0000000000  0.9880239521  0.7662650602  0.6400966184  9.1842900302  2.0421987891  0.4828839302  190           0.1301572561 
0.7303967244  0.9442771084  0.9216867470  0.8067632850  0.7422434368  0.9774096386  0.8975903614  0.9520958084  0.9404761905  0.9939849624  0.9760479042  1.0000000000  1.0000000000  0.7734138973  0.7831325301  1.0000000000  1.0000000000  0.9985007496  0.9820359281  0.7518072289  0.6207729469  9.6676737160  2.1022572041  0.4828839302  200           0.1320561409 
0.7320311477  0.9683734940  0.9337349398  0.7705314010  0.8042959427  0.9608433735  0.9036144578  0.9745508982  0.9702380952  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.8006042296  0.8192771084  0.9984894260  0.9939759036  0.9970014993  1.0000000000  0.7349397590  0.6183574879  10.151057401  2.1006088734  0.4828839302  210           0.1324965477 
0.7194941087  0.9939759036  0.9638554217  0.7826086957  0.7565632458  0.9472891566  0.8975903614  0.9940119760  0.9880952381  0.9969924812  0.9760479042  0.9954819277  0.9939759036  0.6903323263  0.7289156627  0.9984894260  0.9939759036  0.9970014993  1.0000000000  0.7349397590  0.6038647343  10.634441087  2.0908211112  0.4828839302  220           0.1430841446 
0.7022298769  0.9864457831  0.9457831325  0.7898550725  0.6730310263  0.9623493976  0.8975903614  0.9835329341  0.9821428571  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.7280966767  0.7469879518  0.9984894260  0.9939759036  0.9970014993  1.0000000000  0.7421686747  0.6038647343  11.117824773  2.0229193211  0.4828839302  230           0.1335335732 
0.7341436619  0.9503012048  0.9337349398  0.8067632850  0.6945107399  0.9939759036  0.9156626506  0.9416167665  0.9226190476  0.9939849624  0.9760479042  0.9984939759  0.9939759036  0.8444108761  0.8493975904  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7855421687  0.6497584541  11.601208459  2.0493922353  0.4828839302  240           0.1332164526 
0.6974392155  0.9382530120  0.9216867470  0.7874396135  0.6563245823  0.9533132530  0.8855421687  0.9535928144  0.9345238095  0.9894736842  0.9700598802  1.0000000000  1.0000000000  0.6676737160  0.7108433735  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7590361446  0.5869565217  12.084592145  2.0797070503  0.4828839302  250           0.1318746090 
0.7123470917  0.9563253012  0.9216867470  0.7705314010  0.7207637232  0.9789156627  0.9036144578  0.9535928144  0.9464285714  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.7824773414  0.7831325301  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7493975904  0.6086956522  12.567975830  2.0008815408  0.4828839302  260           0.1293366194 
0.7190182889  0.9487951807  0.9277108434  0.7705314010  0.7064439141  0.9954819277  0.9216867470  0.9281437126  0.8928571429  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.8323262840  0.8253012048  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7734939759  0.6256038647  13.051359516  1.9756609917  0.4828839302  270           0.1270873070 
0.7035122990  0.9292168675  0.9096385542  0.7777777778  0.6396181384  0.9954819277  0.9216867470  0.9161676647  0.8928571429  0.9879699248  0.9760479042  1.0000000000  1.0000000000  0.7975830816  0.7951807229  1.0000000000  1.0000000000  1.0000000000  0.9880239521  0.7855421687  0.6111111111  13.534743202  1.9424098492  0.4828839302  280           0.1339303017 
0.7022687478  0.9743975904  0.9337349398  0.7753623188  0.6587112172  0.9864457831  0.9096385542  0.9730538922  0.9523809524  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.7356495468  0.7650602410  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7493975904  0.6256038647  14.018126888  1.9315998793  0.4828839302  290           0.1281693459 
0.7016130552  0.9834337349  0.9337349398  0.7608695652  0.6778042959  0.9954819277  0.9216867470  0.9865269461  0.9821428571  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.8081570997  0.8253012048  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7397590361  0.6280193237  14.501510574  1.9856898546  0.4828839302  300           0.1363590240 
0.6631863277  0.9984939759  0.9819277108  0.7367149758  0.6085918854  0.9156626506  0.8674698795  0.9985029940  0.9940476190  0.9969924812  0.9640718563  0.9984939759  0.9939759036  0.6208459215  0.6686746988  1.0000000000  1.0000000000  0.9985007496  0.9820359281  0.7204819277  0.5869565217  14.984894259  1.9916265607  0.4828839302  310           0.1324199915 
0.7207940614  0.8689759036  0.8614457831  0.7512077295  0.7255369928  0.9969879518  0.9277108434  0.8697604790  0.8511904762  0.9774436090  0.9580838323  0.9924698795  0.9939759036  0.9486404834  0.9277108434  0.9879154079  0.9879518072  1.0000000000  1.0000000000  0.7373493976  0.6690821256  15.468277945  1.8228947043  0.4828839302  320           0.1394054174 
0.6981380748  0.9849397590  0.9518072289  0.7971014493  0.6205250597  0.9743975904  0.8975903614  0.9790419162  0.9523809524  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.6435045317  0.6746987952  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7807228916  0.5942028986  15.951661631  1.9779598117  0.4828839302  330           0.1327384472 
0.7005348258  0.9563253012  0.9337349398  0.7850241546  0.6276849642  0.9954819277  0.9216867470  0.9281437126  0.9047619048  0.9879699248  0.9760479042  1.0000000000  1.0000000000  0.7492447130  0.8072289157  1.0000000000  1.0000000000  1.0000000000  0.9880239521  0.7759036145  0.6135265700  16.435045317  1.8882011175  0.4828839302  340           0.1324768543 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [8, 9, 10, 11]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0005
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1,2->pu3
Start training
average_acc   env0_in_acc   env0_out_acc  env10_test_a  env11_test_a  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_in_acc   env4_out_acc  env5_in_acc   env5_out_acc  env6_in_acc   env6_out_acc  env7_in_acc   env7_out_acc  env8_test_ac  env9_test_ac  epoch         loss          mem_gb        step          step_time    
0.3869811438  0.5662650602  0.5783132530  0.4492753623  0.3460620525  0.5481927711  0.5421686747  0.5718562874  0.5833333333  0.4992481203  0.5389221557  0.5813253012  0.5662650602  0.4123867069  0.4277108434  0.6072507553  0.6144578313  0.5217391304  0.4910179641  0.4289156627  0.3236714976  0.0000000000  8.0079784393  0.2073326111  0             0.6647884846 
0.6295620412  0.8147590361  0.8253012048  0.6642512077  0.5608591885  0.8584337349  0.8192771084  0.8637724551  0.8630952381  0.6992481203  0.6766467066  0.6957831325  0.6867469880  0.7900302115  0.7771084337  0.7703927492  0.7349397590  0.8785607196  0.8862275449  0.6409638554  0.6521739130  0.4833836858  5.4595543623  0.3946604729  10            0.1030194044 
0.7548707333  0.9141566265  0.9096385542  0.8236714976  0.6181384248  0.8117469880  0.7891566265  0.9191616766  0.8928571429  0.8887218045  0.8682634731  0.9322289157  0.9578313253  0.7507552870  0.7891566265  0.9501510574  0.9096385542  0.8620689655  0.8682634731  0.8433734940  0.7342995169  0.9667673716  2.8145343304  0.3946604729  20            0.0964118481 
0.7889470059  0.8975903614  0.8674698795  0.8043478261  0.7470167064  0.8825301205  0.8554216867  0.9700598802  0.9285714286  0.9428571429  0.9161676647  0.9036144578  0.9397590361  0.8247734139  0.8674698795  0.9320241692  0.9457831325  0.9595202399  0.9580838323  0.7686746988  0.8357487923  1.4501510574  2.0830217123  0.3946604729  30            0.0986822367 
0.7807821094  0.9262048193  0.9337349398  0.8333333333  0.6348448687  0.8192771084  0.7710843373  0.9476047904  0.9226190476  0.9413533835  0.9101796407  0.9909638554  1.0000000000  0.7039274924  0.7469879518  0.9818731118  0.9879518072  0.9550224888  0.9281437126  0.8506024096  0.8043478261  1.9335347432  1.5714705229  0.3949875832  40            0.0968514681 
0.7781018995  0.8554216867  0.8554216867  0.7971014493  0.7374701671  0.9156626506  0.8674698795  0.9221556886  0.8928571429  0.9473684211  0.9341317365  0.9804216867  0.9819277108  0.8700906344  0.9036144578  0.9652567976  0.9457831325  0.9910044978  0.9760479042  0.7759036145  0.8019323671  2.4169184290  1.2977976680  0.3949875832  50            0.0974535227 
0.7715932527  0.8840361446  0.8855421687  0.8140096618  0.6873508353  0.9231927711  0.8614457831  0.9191616766  0.9047619048  0.9293233083  0.9461077844  0.9924698795  0.9939759036  0.7719033233  0.7891566265  0.9818731118  0.9759036145  0.9910044978  1.0000000000  0.8048192771  0.7801932367  2.9003021148  1.0745385885  0.3949875832  60            0.0964982510 
0.7383650336  0.9472891566  0.9216867470  0.8212560386  0.6992840095  0.8915662651  0.8674698795  0.9820359281  0.9761904762  0.9879699248  0.9520958084  0.9894578313  0.9939759036  0.6948640483  0.7349397590  0.9894259819  0.9939759036  0.9640179910  0.9520958084  0.7710843373  0.6618357488  3.3836858006  0.9339124441  0.3949875832  70            0.0973633051 
0.7702775024  0.9337349398  0.9036144578  0.8260869565  0.7255369928  0.9518072289  0.8795180723  0.9431137725  0.9166666667  0.9804511278  0.9700598802  0.9864457831  0.9939759036  0.7885196375  0.8192771084  0.9879154079  0.9879518072  0.9895052474  0.9700598802  0.7927710843  0.7367149758  3.8670694864  0.8198531210  0.3949875832  80            0.0978102446 
0.7426351840  0.9262048193  0.9096385542  0.8019323671  0.6801909308  0.9487951807  0.8674698795  0.9431137725  0.9166666667  0.9849624060  0.9760479042  0.9924698795  0.9939759036  0.7583081571  0.7831325301  0.9879154079  0.9879518072  0.9880059970  0.9880239521  0.7951807229  0.6932367150  4.3504531722  0.6157096386  0.5854034424  90            0.0986730337 
0.7492515043  0.8780120482  0.8975903614  0.7705314010  0.6801909308  0.9472891566  0.8373493976  0.8892215569  0.8809523810  0.9218045113  0.9281437126  0.9864457831  0.9939759036  0.7114803625  0.7530120482  0.9305135952  0.9397590361  0.9985007496  0.9940119760  0.8385542169  0.7077294686  4.8338368580  0.7868374348  0.5854034424  100           0.0992892265 
0.7456689197  0.9533132530  0.9096385542  0.8309178744  0.6754176611  0.9804216867  0.8975903614  0.9730538922  0.9523809524  0.9849624060  0.9640718563  0.9849397590  0.9879518072  0.8293051360  0.8253012048  0.9909365559  0.9759036145  0.9910044978  0.9880239521  0.7951807229  0.6811594203  5.3172205438  0.6907310784  0.5854034424  110           0.0980370283 
0.7299252699  0.9246987952  0.9036144578  0.7971014493  0.6921241050  0.9201807229  0.8855421687  0.9296407186  0.8988095238  0.9759398496  0.9760479042  0.9969879518  1.0000000000  0.7764350453  0.7831325301  0.9954682779  0.9939759036  0.9985007496  0.9940119760  0.7831325301  0.6473429952  5.8006042296  0.6484548479  0.5854034424  120           0.0960889339 
0.7578165417  0.9487951807  0.9277108434  0.8260869565  0.6420047733  0.9728915663  0.8795180723  0.9476047904  0.9226190476  0.9909774436  0.9760479042  0.9924698795  0.9939759036  0.7432024169  0.7710843373  0.9864048338  0.9819277108  0.9970014993  0.9760479042  0.8457831325  0.7173913043  6.2839879154  0.4711059332  0.5854034424  130           0.0993254185 
0.7222982067  0.9021084337  0.8975903614  0.8164251208  0.6109785203  0.9683734940  0.8855421687  0.9251497006  0.8928571429  0.9654135338  0.9700598802  0.9984939759  0.9939759036  0.7477341390  0.7771084337  0.9969788520  1.0000000000  0.9970014993  0.9880239521  0.8192771084  0.6425120773  6.7673716012  0.4133497447  0.5854034424  140           0.0968869686 
0.7498036801  0.9352409639  0.9096385542  0.8115942029  0.7040572792  0.9713855422  0.8734939759  0.9461077844  0.9166666667  0.9939849624  0.9760479042  0.9954819277  0.9939759036  0.7779456193  0.8012048193  1.0000000000  1.0000000000  0.9985007496  0.9940119760  0.8048192771  0.6787439614  7.2507552870  0.4161475509  0.5854034424  150           0.0963788748 
0.7076486535  0.9713855422  0.9578313253  0.7874396135  0.6730310263  0.8990963855  0.8493975904  0.9910179641  0.9880952381  0.9969924812  0.9640718563  0.9969879518  1.0000000000  0.6283987915  0.6626506024  1.0000000000  1.0000000000  0.9835082459  0.9700598802  0.7686746988  0.6014492754  7.7341389728  0.3465988979  0.5854034424  160           0.0965589762 
0.7125169177  0.9849397590  0.9759036145  0.7946859903  0.6563245823  0.9472891566  0.8855421687  0.9910179641  0.9880952381  0.9984962406  0.9820359281  0.9954819277  0.9939759036  0.6586102719  0.6987951807  0.9969788520  0.9879518072  0.9835082459  0.9700598802  0.7903614458  0.6086956522  8.2175226586  0.3846286058  0.5854034424  170           0.0965917587 
0.7107024827  0.9683734940  0.9457831325  0.7874396135  0.6587112172  0.9231927711  0.8855421687  0.9790419162  0.9642857143  0.9969924812  0.9760479042  0.9969879518  1.0000000000  0.6465256798  0.6987951807  0.9984894260  0.9939759036  0.9700149925  0.9640718563  0.7831325301  0.6135265700  8.7009063444  0.2921786726  0.5854034424  180           0.0975046635 
0.7095609931  0.9759036145  0.9397590361  0.7946859903  0.6348448687  0.9548192771  0.8795180723  0.9850299401  0.9642857143  0.9969924812  0.9760479042  1.0000000000  1.0000000000  0.6767371601  0.7228915663  1.0000000000  1.0000000000  0.9835082459  0.9820359281  0.7927710843  0.6159420290  9.1842900302  0.2705192208  0.5854034424  190           0.0980374575 
0.7196423861  0.9246987952  0.9156626506  0.7850241546  0.7016706444  0.9894578313  0.9096385542  0.9266467066  0.8750000000  0.9774436090  0.9700598802  0.9984939759  0.9939759036  0.7432024169  0.7831325301  0.9924471299  0.9939759036  1.0000000000  1.0000000000  0.7638554217  0.6280193237  9.6676737160  0.3001417719  0.5854034424  200           0.0970594883 
0.7184188589  0.9563253012  0.8975903614  0.7632850242  0.7088305489  0.9939759036  0.9156626506  0.9356287425  0.8988095238  0.9894736842  0.9700598802  0.9924698795  0.9939759036  0.8338368580  0.8674698795  0.9984894260  0.9939759036  1.0000000000  1.0000000000  0.7542168675  0.6473429952  10.151057401  0.3138878867  0.5854034424  210           0.0992582560 
0.7167281037  0.9728915663  0.9277108434  0.7657004831  0.6610978520  0.9774096386  0.8855421687  0.9610778443  0.9404761905  0.9909774436  0.9760479042  1.0000000000  1.0000000000  0.7190332326  0.7710843373  1.0000000000  1.0000000000  1.0000000000  1.0000000000  0.7927710843  0.6473429952  10.634441087  0.1788457781  0.5854034424  220           0.0985398531 
0.6896911745  0.9954819277  0.9698795181  0.7632850242  0.6181384248  0.9668674699  0.8915662651  0.9910179641  0.9880952381  0.9984962406  0.9820359281  1.0000000000  1.0000000000  0.6948640483  0.7349397590  0.9984894260  0.9939759036  0.9985007496  0.9940119760  0.7807228916  0.5966183575  11.117824773  0.2279233620  0.5854172707  230           0.0983921766 

trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [4, 5, 6, 7]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1,2->pu3
Start training
average_acc   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_in_acc   env4_out_acc  env4_test_ac  env5_in_acc   env5_out_acc  env5_test_ac  env6_in_acc   env6_out_acc  env6_test_ac  env7_in_acc   env7_out_acc  env7_test_ac  epoch         loss          mem_gb        step          step_time    
0.4349449827  0.3343373494  0.3493975904  0.3403614458  0.3734939759  0.3323353293  0.3333333333  0.3473684211  0.3532934132  0.3358433735  0.3313253012  0.4361445783  0.3429003021  0.3313253012  0.4275362319  0.3338368580  0.3313253012  0.4444444444  0.3328358209  0.3273809524  0.4316546763  0.0000000000  10.365321159  0.2909131050  0             0.4849593639 
0.3668026815  0.7665662651  0.7771084337  0.5165662651  0.4759036145  0.7619760479  0.7083333333  0.5984962406  0.5988023952  0.8945783133  0.8674698795  0.3373493976  0.8383685801  0.8253012048  0.3816425121  0.8187311178  0.8072289157  0.3357487923  0.7492537313  0.7857142857  0.4124700240  0.4833836858  8.8949287415  0.4781484604  10            0.1362748146 
0.4240881574  0.8192771084  0.8192771084  0.6596385542  0.6024096386  0.8532934132  0.8095238095  0.7729323308  0.7664670659  0.9156626506  0.9036144578  0.5373493976  0.8157099698  0.8192771084  0.3333333333  0.8504531722  0.8614457831  0.4347826087  0.9029850746  0.8988095238  0.3908872902  0.9667673716  7.1776003838  0.4781484604  20            0.1327249289 
0.4439142348  0.9096385542  0.8915662651  0.7198795181  0.6385542169  0.9176646707  0.8988095238  0.8766917293  0.8443113772  0.9141566265  0.9216867470  0.5686746988  0.8413897281  0.8493975904  0.3285024155  0.8202416918  0.8253012048  0.4420289855  0.9059701493  0.8988095238  0.4364508393  1.4501510574  5.5728592873  0.4781484604  30            0.1331522942 
0.4746591203  0.9412650602  0.9216867470  0.7334337349  0.6927710843  0.9595808383  0.9107142857  0.8872180451  0.8862275449  0.9593373494  0.9578313253  0.5975903614  0.8670694864  0.8795180723  0.3550724638  0.8625377644  0.8493975904  0.4903381643  0.8805970149  0.8809523810  0.4556354916  1.9335347432  4.8085256577  0.4781484604  40            0.1324635744 
0.5620455024  0.9111445783  0.8734939759  0.7996987952  0.7650602410  0.9655688623  0.9107142857  0.9503759398  0.9461077844  0.9713855422  0.9698795181  0.6771084337  0.8927492447  0.9096385542  0.4396135266  0.9138972810  0.9096385542  0.6062801932  0.9388059701  0.9345238095  0.5251798561  2.4169184290  4.3178518295  0.4781484604  50            0.1308653355 
0.5741516896  0.9051204819  0.8493975904  0.8177710843  0.7650602410  0.9625748503  0.9107142857  0.9563909774  0.9341317365  0.9894578313  0.9939759036  0.7012048193  0.9123867069  0.9277108434  0.4565217391  0.9456193353  0.9518072289  0.6376811594  0.9820895522  0.9880952381  0.5011990408  2.9003021148  3.8569582701  0.4781484604  60            0.1336482048 
0.5662870228  0.9292168675  0.9096385542  0.8147590361  0.7530120482  0.9670658683  0.9285714286  0.9789473684  0.9640718563  0.9909638554  0.9879518072  0.6819277108  0.9003021148  0.9036144578  0.4589371981  0.9305135952  0.9277108434  0.6086956522  0.9820895522  0.9880952381  0.5155875300  3.3836858006  3.6014107704  0.4782390594  70            0.1365423679 
0.6211082993  0.9021084337  0.8493975904  0.8659638554  0.8253012048  0.9640718563  0.9285714286  0.9864661654  0.9700598802  0.9894578313  0.9939759036  0.7108433735  0.9305135952  0.9277108434  0.5120772947  0.9577039275  0.9397590361  0.6835748792  0.9835820896  0.9940476190  0.5779376499  3.8670694864  3.4342602968  0.4782390594  80            0.1342673302 
0.5711642734  0.9186746988  0.8554216867  0.8057228916  0.7650602410  0.9775449102  0.9345238095  0.9548872180  0.9281437126  0.9969879518  1.0000000000  0.6843373494  0.9138972810  0.9216867470  0.4879227053  0.9818731118  0.9759036145  0.6231884058  0.9940298507  1.0000000000  0.4892086331  4.3504531722  3.1940466166  0.4782390594  90            0.1318883181 
0.5434242653  0.9698795181  0.9518072289  0.7801204819  0.7349397590  0.9835329341  0.9464285714  0.9744360902  0.9221556886  1.0000000000  1.0000000000  0.6433734940  0.9018126888  0.9096385542  0.4734299517  0.9577039275  0.9518072289  0.5748792271  0.9791044776  0.9642857143  0.4820143885  4.8338368580  3.2303690672  0.4782390594  100           0.1316791773 
0.6162759264  0.9563253012  0.9457831325  0.8614457831  0.8072289157  0.9685628743  0.9464285714  0.9909774436  0.9760479042  0.9894578313  0.9939759036  0.7132530120  0.9078549849  0.9096385542  0.5120772947  0.9290030211  0.9216867470  0.6618357488  0.9895522388  0.9821428571  0.5779376499  5.3172205438  3.0637862921  0.4782390594  110           0.1295827389 
0.6205087580  0.9412650602  0.9457831325  0.8674698795  0.8192771084  0.9730538922  0.9523809524  0.9939849624  0.9760479042  0.9969879518  1.0000000000  0.7180722892  0.9214501511  0.9156626506  0.5241545894  0.9561933535  0.9578313253  0.6666666667  0.9940298507  1.0000000000  0.5731414868  5.8006042296  3.0690907240  0.4782390594  120           0.1339442968 
0.5723257120  0.9759036145  0.9638554217  0.8207831325  0.7650602410  0.9895209581  0.9583333333  0.9759398496  0.9401197605  1.0000000000  1.0000000000  0.6674698795  0.9078549849  0.9096385542  0.4855072464  0.9592145015  0.9578313253  0.6159420290  0.9895522388  0.9821428571  0.5203836930  6.2839879154  2.8387702227  0.4782390594  130           0.1350031853 
Traceback (most recent call last):
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/scripts/train.py", line 330, in <module>
    acc = misc.accuracy(algorithm, loader, weights, device)
  File "/home/yfy/Desktop/my_project/DomainBed-IFD/domainbed/lib/misc.py", line 173, in accuracy
    for x, y in loader:
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1171, in _next_data
    self._shutdown_workers()
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1297, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py", line 124, in join
    res = self._popen.wait(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/popen_fork.py", line 47, in wait
    if not wait([self.sentinel], timeout):
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/home/yfy/anaconda3/envs/pytorch/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
trails: 0
Args:
	algorithm: FC
	checkpoint_freq: None
	data_dir: /home/yfy/Desktop/Dataset/
	dataset: Bearing
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	normlizetype: 0-1
	output_dir: train_output
	save_model_every_checkpoint: False
	seed: 0
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [8, 9, 10, 11]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 32
	beta: 1
	class_balanced: False
	data_augmentation: True
	heldout_p: 100
	lr: 0.0001
	lr_omega: 0.005
	meta_step: 1
	nonlinear_classifier: True
	resnet18: False
	resnet_dropout: 0.0
	weight_decay: 0.0008
Load Data.
pu1,2->pu3
Start training
